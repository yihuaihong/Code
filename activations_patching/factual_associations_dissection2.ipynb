{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2023 Google LLC.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "发现 1 个可用的GPU 设备.\n",
      "GPU 1: NVIDIA A100-SXM4-80GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 检查CUDA是否可用\n",
    "if torch.cuda.is_available():\n",
    "    # 获取可用的GPU设备数量\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f\"发现 {gpu_count} 个可用的GPU 设备.\")\n",
    "\n",
    "    # 遍历并打印每个GPU设备的名称\n",
    "    for i in range(gpu_count):\n",
    "        gpu_name = torch.cuda.get_device_name(i)\n",
    "        print(f\"GPU {i + 1}: {gpu_name}\")\n",
    "else:\n",
    "    print(\"未发现可用的GPU设备.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# List of stopwords from NLTK, needed only for the attributes rate evaluation.\\nimport nltk\\nnltk.download(\\'stopwords\\')\\nfrom nltk.corpus import stopwords\\nstopwords0_ = stopwords.words(\\'english\\')\\nstopwords0_ = {word: \"\" for word in stopwords0_}\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "import functools\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import wget\n",
    "\n",
    "\n",
    "# Scienfitic packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "#from transformers_source.src.transformers.models.llama import LlamaForCausalLM, LlamaTokenizer\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "tqdm.pandas()\n",
    "\n",
    "# Visuals\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(context=\"notebook\", \n",
    "        rc={\"font.size\":16,\n",
    "            \"axes.titlesize\":16,\n",
    "            \"axes.labelsize\":16,\n",
    "            \"xtick.labelsize\": 16.0,\n",
    "            \"ytick.labelsize\": 16.0,\n",
    "            \"legend.fontsize\": 16.0})\n",
    "palette_ = sns.color_palette(\"Set1\")\n",
    "palette = palette_[2:5] + palette_[7:]\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/root/Unlearn_Harry_Potter/dissecting_factual_predictions\")\n",
    "\n",
    "# Utilities\n",
    "from utils import (\n",
    "    ModelAndTokenizer,\n",
    "    make_inputs,\n",
    "    decode_tokens,\n",
    "    find_token_range,\n",
    "    predict_from_input,\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "# List of stopwords from NLTK, needed only for the attributes rate evaluation.\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords0_ = stopwords.words('english')\n",
    "stopwords0_ = {word: \"\" for word in stopwords0_}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7fa42f6ef370>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yihuaihong/anaconda3/envs/harry/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# List of stopwords from NLTK, needed only for the attributes rate evaluation.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstopwords\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n\u001b[1;32m      5\u001b[0m stopwords0_ \u001b[38;5;241m=\u001b[39m stopwords\u001b[38;5;241m.\u001b[39mwords(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/harry/lib/python3.8/site-packages/nltk/downloader.py:777\u001b[0m, in \u001b[0;36mDownloader.download\u001b[0;34m(self, info_or_id, download_dir, quiet, force, prefix, halt_on_error, raise_on_error, print_error_to)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow\u001b[39m(s, prefix2\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    769\u001b[0m     print_to(\n\u001b[1;32m    770\u001b[0m         textwrap\u001b[38;5;241m.\u001b[39mfill(\n\u001b[1;32m    771\u001b[0m             s,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    774\u001b[0m         )\n\u001b[1;32m    775\u001b[0m     )\n\u001b[0;32m--> 777\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m msg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mincr_download(info_or_id, download_dir, force):\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;66;03m# Error messages\u001b[39;00m\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(msg, ErrorMessage):\n\u001b[1;32m    780\u001b[0m         show(msg\u001b[38;5;241m.\u001b[39mmessage)\n",
      "File \u001b[0;32m~/anaconda3/envs/harry/lib/python3.8/site-packages/nltk/downloader.py:629\u001b[0m, in \u001b[0;36mDownloader.incr_download\u001b[0;34m(self, info_or_id, download_dir, force)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;66;03m# Look up the requested collection or package.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 629\u001b[0m     info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_or_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfo_or_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m ErrorMessage(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minfo_or_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/harry/lib/python3.8/site-packages/nltk/downloader.py:603\u001b[0m, in \u001b[0;36mDownloader._info_or_id\u001b[0;34m(self, info_or_id)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_info_or_id\u001b[39m(\u001b[38;5;28mself\u001b[39m, info_or_id):\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(info_or_id, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 603\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfo_or_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    605\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m info_or_id\n",
      "File \u001b[0;32m~/anaconda3/envs/harry/lib/python3.8/site-packages/nltk/downloader.py:1009\u001b[0m, in \u001b[0;36mDownloader.info\u001b[0;34m(self, id)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfo\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mid\u001b[39m):\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the ``Package`` or ``Collection`` record for the\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;124;03m    given item.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1009\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_packages:\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_packages[\u001b[38;5;28mid\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/harry/lib/python3.8/site-packages/nltk/downloader.py:952\u001b[0m, in \u001b[0;36mDownloader._update_index\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_url \u001b[38;5;241m=\u001b[39m url \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_url\n\u001b[1;32m    950\u001b[0m \u001b[38;5;66;03m# Download the index file.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39minternals\u001b[38;5;241m.\u001b[39mElementWrapper(\n\u001b[0;32m--> 952\u001b[0m     ElementTree\u001b[38;5;241m.\u001b[39mparse(\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_url\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mgetroot()\n\u001b[1;32m    953\u001b[0m )\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_timestamp \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    956\u001b[0m \u001b[38;5;66;03m# Build a dictionary of packages.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/harry/lib/python3.8/urllib/request.py:222\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/harry/lib/python3.8/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    522\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    524\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 525\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    528\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/harry/lib/python3.8/urllib/request.py:542\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    541\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 542\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    543\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/harry/lib/python3.8/urllib/request.py:502\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    501\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 502\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/harry/lib/python3.8/urllib/request.py:1393\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/harry/lib/python3.8/urllib/request.py:1354\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m   1353\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[0;32m-> 1354\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1355\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   1356\u001b[0m     h\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/harry/lib/python3.8/http/client.py:1347\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1346\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1347\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1349\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/harry/lib/python3.8/http/client.py:307\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 307\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    309\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/harry/lib/python3.8/http/client.py:268\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 268\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    270\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/harry/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/harry/lib/python3.8/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/harry/lib/python3.8/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# List of stopwords from NLTK, needed only for the attributes rate evaluation.\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords0_ = stopwords.words('english')\n",
    "stopwords0_ = {word: \"\" for word in stopwords0_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords0_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91c8b110e394f91929e76622cc56057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.set_device(0)\n",
    "# Get CounterFact data for GPT2-xl, from the ROME repository.\n",
    "#wget.download(\"https://rome.baulab.info/data/dsets/known_1000.json\")\n",
    "\n",
    "\n",
    "knowns_df = pd.read_json(\"/root/Unlearn_Harry_Potter/dissecting_factual_predictions/known_1000.json\")\n",
    "knowns_df = knowns_df.head(100)\n",
    "\n",
    "# Load GPT2-xl from Huggingface.\n",
    "# model_name = \"/home/liangyunzhen/yhhong/transformers/gpt-j-6B\"\n",
    "# model_name = \"/home/liangyunzhen/yhhong/transformers/gpt-j-6B\"\n",
    "\"\"\"\n",
    "model_name = \"/root/autodl-tmp/transformers/opt-1.3b\" #\"EleutherAI/gpt-j-6b\"#\n",
    "mt = ModelAndTokenizer(\n",
    "    model_name,\n",
    "    low_cpu_mem_usage=False,\n",
    "    torch_dtype=None,\n",
    ")\n",
    "mt.model.eval()\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "base_model = '/root/autodl-tmp/transformers/llama2-7b-chat-hf'  #'/root/autodl-tmp/transformers/llama2-7b-whp' /root/autodl-tmp/transformers/llama2-7b-chat-hf\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "            base_model,\n",
    "            # load_in_8bit=load_8bit,\n",
    "            # torch_dtype=torch.float16,\n",
    "            # device_map=\"auto\",\n",
    "        ).to('cuda')\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(base_model, legacy = True)\n",
    "mt = ModelAndTokenizer(\n",
    "    model_name=base_model,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    low_cpu_mem_usage=False,\n",
    "    torch_dtype=None,\n",
    ")\n",
    "mt.model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(mt.model.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split_heads(tensor, num_heads, attn_head_size):\n",
    "    new_shape = tensor.size()[:-1] + (num_heads, attn_head_size)\n",
    "    tensor = tensor.view(new_shape)\n",
    "    return tensor.permute(1, 0, 2)  # (head, seq_length, head_features)\n",
    "\n",
    "def _merge_heads(tensor, model):\n",
    "    num_heads = model.config.num_attention_heads\n",
    "    attn_head_size = model.config.hidden_size // model.config.num_attention_heads\n",
    "    \n",
    "    tensor = tensor.permute(1, 0, 2).contiguous()\n",
    "    new_shape = tensor.size()[:-2] + (num_heads * attn_head_size,)\n",
    "    return tensor.view(new_shape)\n",
    "\n",
    "\n",
    "def set_act_get_hooks(model, tok_index, attn=False, attn_out=False, mlp=False, mlp_coef=False):\n",
    "    \"\"\"\n",
    "    Only works on GPT2\n",
    "    \"\"\"\n",
    "    # Make sure that these are not set to True at the same time \n",
    "    #  so we don't put two different hooks on the same module.  \n",
    "    assert not (attn is True and attn_out is True)\n",
    "    \n",
    "    for attr in [\"activations_\"]:\n",
    "        if not hasattr(model, attr):\n",
    "            setattr(model, attr, {})\n",
    "\n",
    "    def get_activation(name):\n",
    "        def hook(module, input, output):\n",
    "            if \"attn\" in name:\n",
    "                if \"c_attn\" in name:\n",
    "                    # output.shape: batch_size, seq_len, 3 * hidden_dim\n",
    "                    _, _, attn_value = output[0].split(model.config.n_embd, dim=1)\n",
    "                    attn_value = _split_heads(attn_value,\n",
    "                                              model.config.num_attention_heads, \n",
    "                                              model.config.hidden_size // model.config.num_attention_heads)\n",
    "                    model.activations_[name] = attn_value.detach()\n",
    "                elif \"attn_weights\" in name:\n",
    "                    assert len(output) == 3\n",
    "                    attn_weights = output[2]  # (batch_size, num_heads, from_sequence_length, to_sequence_length)\n",
    "                    # the last dimension is a distribution obtained from softmax\n",
    "                    model.activations_[name] = attn_weights[0][:, tok_index, :].detach()\n",
    "                else:\n",
    "                    model.activations_[name] = output[0][:, tok_index].detach()\n",
    "            elif \"m_coef\" in name:\n",
    "                # num_tokens = list(input[0].size())[1]  # (batch, sequence, hidden_state)\n",
    "                model.activations_[name] = input[0][:, tok_index].detach()\n",
    "            elif \"m_out\" in name:\n",
    "                model.activations_[name] = output[0][tok_index].detach()\n",
    "        \n",
    "        return hook\n",
    "\n",
    "    hooks = []\n",
    "    for i in range(model.config.num_hidden_layers):\n",
    "        if attn is True:\n",
    "            hooks.append(model.model.layers[i].self_attn.c_attn.register_forward_hook(get_activation(f\"c_attn_value_{i}\")))\n",
    "            hooks.append(model.model.layers[i].self_attn.register_forward_hook(get_activation(f\"attn_weights_{i}\")))\n",
    "        if attn_out is True:\n",
    "            hooks.append(model.model.layers[i].self_attn.register_forward_hook(get_activation(f\"attn_out_{i}\")))\n",
    "        if mlp_coef is True:\n",
    "            hooks.append(model.model.layers[i].mlp.o_proj.register_forward_hook(get_activation(\"m_coef_\" + str(i))))\n",
    "        if mlp is True:\n",
    "            hooks.append(model.model.layers[i].mlp.register_forward_hook(get_activation(\"m_out_\" + str(i))))\n",
    "            \n",
    "    return hooks\n",
    "\n",
    "\n",
    "# To block attention edges, we zero-out entries in the attention mask.\n",
    "# To do this, we add a wrapper around the attention module, because \n",
    "# the mask is passed as an additional argument, which could not be fetched \n",
    "# with standard hooks before pytorch 2.0.  \n",
    "def set_block_attn_hooks(model, from_to_index_per_layer, opposite=False):\n",
    "    \"\"\"\n",
    "    Only works on GPT2\n",
    "    \"\"\"\n",
    "    def wrap_attn_forward(forward_fn, model_, from_to_index_, opposite_):\n",
    "        @functools.wraps(forward_fn)\n",
    "        def wrapper_fn(*args, **kwargs):\n",
    "            new_args = []\n",
    "            new_kwargs = {}\n",
    "            for arg in args:\n",
    "                new_args.append(arg)\n",
    "            for (k, v) in kwargs.items():\n",
    "                new_kwargs[k] = v\n",
    "\n",
    "            hs = args[0]\n",
    "            num_tokens = list(hs[0].size())[0]\n",
    "            num_heads = model_.config.num_attention_heads\n",
    "            \n",
    "            if opposite_:\n",
    "                attn_mask = torch.tril(torch.zeros((num_tokens, num_tokens), dtype=torch.uint8))\n",
    "                for s, t in from_to_index_:\n",
    "                    attn_mask[s, t] = 1\n",
    "            else:\n",
    "                attn_mask = torch.tril(torch.ones((num_tokens, num_tokens), dtype=torch.uint8))\n",
    "                for s, t in from_to_index_:\n",
    "                    attn_mask[s, t] = 0\n",
    "            attn_mask = attn_mask.repeat(1, num_heads, 1, 1)\n",
    "            \n",
    "            attn_mask = attn_mask.to(dtype=model_.dtype)  # fp16 compatibility\n",
    "            attn_mask = (1.0 - attn_mask) * torch.finfo(model_.dtype).min\n",
    "            attn_mask = attn_mask.to(hs.device)\n",
    "\n",
    "            new_kwargs[\"attention_mask\"] = attn_mask\n",
    "            \n",
    "            return forward_fn(*new_args, **new_kwargs)\n",
    "\n",
    "        return wrapper_fn\n",
    "    \n",
    "    hooks = []\n",
    "    for i in from_to_index_per_layer.keys():\n",
    "        hook = model.model.layers[i].self_attn.forward\n",
    "        model.model.layers[i].self_attn.forward = wrap_attn_forward(model.model.layers[i].self_attn.forward,\n",
    "                                                                model, from_to_index_per_layer[i], opposite)\n",
    "        hooks.append((i, hook))\n",
    "    \n",
    "    return hooks\n",
    "\n",
    "\n",
    "def set_get_attn_proj_hooks(model, tok_index):\n",
    "    \"\"\"\n",
    "    Only works on GPT2\n",
    "    \"\"\"\n",
    "    for attr in [\"projs_\"]:\n",
    "        if not hasattr(model, attr):\n",
    "            setattr(model, attr, {})\n",
    "\n",
    "    def get_projection(name, E):\n",
    "        def hook(module, input, output):\n",
    "            attn_out = output[0][:, tok_index]\n",
    "            probs, preds = torch.max(\n",
    "                torch.softmax(attn_out.matmul(E.T), dim=-1), \n",
    "                dim=-1\n",
    "            )\n",
    "            model.projs_[f\"{name}_probs\"] = probs.cpu().numpy()\n",
    "            model.projs_[f\"{name}_preds\"] = preds.cpu().numpy()\n",
    "            \n",
    "        return hook\n",
    "\n",
    "    E = model.get_output_embeddings().weight.detach()\n",
    "    hooks = []\n",
    "    for i in range(model.config.num_hidden_layers):\n",
    "        hooks.append(model.model.layers[i].self_attn.register_forward_hook(get_projection(f\"attn_proj_{i}\", E)))\n",
    "            \n",
    "    return hooks\n",
    "\n",
    "\n",
    "def set_block_mlp_hooks(model, values_per_layer, coef_value=0):\n",
    "    \n",
    "    def change_values(values, coef_val):\n",
    "        def hook(module, input, output):\n",
    "            output[:, :, values] = coef_val\n",
    "\n",
    "        return hook\n",
    "\n",
    "    hooks = []\n",
    "    for layer in range(model.config.num_hidden_layers):\n",
    "        if layer in values_per_layer:\n",
    "            values = values_per_layer[layer]\n",
    "        else:\n",
    "            values = []\n",
    "        hooks.append(model.model.layers[layer].mlp.c_fc.register_forward_hook(\n",
    "            change_values(values, coef_value)\n",
    "        ))\n",
    "\n",
    "    return hooks\n",
    "\n",
    "\n",
    "def set_proj_hooks(model):\n",
    "    for attr in [\"projs_\"]:\n",
    "        if not hasattr(model, attr):\n",
    "            setattr(model, attr, {})\n",
    "\n",
    "    def get_projection(name, E):\n",
    "        def hook(module, input, output):\n",
    "            num_tokens = list(input[0].size())[1]  #(batch, sequence, hidden_state)\n",
    "            if name == f\"layer_residual_{final_layer}\":\n",
    "                hs = output\n",
    "            else:\n",
    "                hs = input[0]\n",
    "            probs, preds = torch.max(\n",
    "                torch.softmax(hs.matmul(E.T), dim=-1), \n",
    "                dim=-1\n",
    "            )\n",
    "            model.projs_[f\"{name}_preds\"] = preds.cpu().numpy()\n",
    "            model.projs_[f\"{name}_probs\"] = probs.cpu().numpy()\n",
    "        return hook\n",
    "\n",
    "    E = model.get_output_embeddings().weight.detach()\n",
    "    final_layer = model.config.num_hidden_layers-1\n",
    "    \n",
    "    hooks = []\n",
    "    for i in range(model.config.num_hidden_layers-1):\n",
    "        hooks.append(model.model.layers[i].register_forward_hook(\n",
    "            get_projection(f\"layer_residual_{i}\", E)\n",
    "        ))\n",
    "    hooks.append(model.model.norm.register_forward_hook(\n",
    "        get_projection(f\"layer_residual_{final_layer}\", E)\n",
    "    ))\n",
    "\n",
    "    return hooks\n",
    "\n",
    "\n",
    "def set_hs_patch_hooks(model, hs_patch_config, patch_input=False):\n",
    "    \n",
    "    def patch_hs(name, position_hs, patch_input):\n",
    "        \n",
    "        def pre_hook(module, input):\n",
    "            for position_, hs_ in position_hs:\n",
    "                # (batch, sequence, hidden_state)\n",
    "                input[0][0, position_] = hs_\n",
    "        \n",
    "        def post_hook(module, input, output):\n",
    "            for position_, hs_ in position_hs:\n",
    "                # (batch, sequence, hidden_state)\n",
    "                output[0][0, position_] = hs_\n",
    "        \n",
    "        if patch_input:\n",
    "            return pre_hook\n",
    "        else:\n",
    "            return post_hook\n",
    "\n",
    "    hooks = []\n",
    "    for i in hs_patch_config:\n",
    "        if patch_input:\n",
    "            hooks.append(model.model.layers[i].register_forward_pre_hook(\n",
    "                patch_hs(f\"patch_hs_{i}\", hs_patch_config[i], patch_input)\n",
    "            ))\n",
    "        else:\n",
    "            hooks.append(model.model.layers[i].register_forward_hook(\n",
    "                patch_hs(f\"patch_hs_{i}\", hs_patch_config[i], patch_input)\n",
    "            ))\n",
    "\n",
    "    return hooks\n",
    "    \n",
    "\n",
    "# Always remove your hooks, otherwise things will get messy.\n",
    "def remove_hooks(hooks):\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "\n",
    "def remove_wrapper(model, hooks):\n",
    "    for i, hook in hooks:\n",
    "        model.model.layers[i].self_attn.forward = hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_with_attn_block(\n",
    "    model,\n",
    "    inp,\n",
    "    from_to_index_per_layer,   # A list of (source index, target index) to block\n",
    "    answers_t\n",
    "):\n",
    "    with torch.no_grad():\n",
    "        # set hooks\n",
    "        block_attn_hooks = set_block_attn_hooks(model, from_to_index_per_layer)\n",
    "        \n",
    "        # get prediction\n",
    "        outputs_exp = model(**inp)\n",
    "        \n",
    "        # remove hooks\n",
    "        remove_wrapper(model, block_attn_hooks)\n",
    "    \n",
    "    probs = torch.softmax(outputs_exp.logits[0, -1, :], dim=0)[answers_t]\n",
    "    \n",
    "    return probs\n",
    "\n",
    "\n",
    "def trace_with_proj(model, inp):\n",
    "    with torch.no_grad():\n",
    "        # set hooks\n",
    "        hooks = set_proj_hooks(model)\n",
    "\n",
    "        # print('hooks: ',hooks)\n",
    "        \n",
    "        # get prediction\n",
    "        answer_t, base_score = [d[0] for d in predict_from_input(model, inp)]\n",
    "        \n",
    "        # remove hooks\n",
    "        remove_hooks(hooks)\n",
    "        \n",
    "    projs = model.projs_\n",
    "    \n",
    "    return answer_t, base_score, projs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intervene_on_info_flow(\n",
    "    mt, prompt, source=None, kind=\"single\", window=10, positions=None\n",
    "):\n",
    "    inp = make_inputs(mt.tokenizer, [prompt])\n",
    "    answer_t, base_score, projs = trace_with_proj(mt.model, inp)\n",
    "\n",
    "    print('answer_t: ',answer_t)\n",
    "    print('base_score: ',base_score)\n",
    "    print('projs: ', projs)\n",
    "    [answer] = decode_tokens(mt.tokenizer, [answer_t])\n",
    "\n",
    "    print('answer: ',answer)\n",
    "    \n",
    "    ntoks = inp[\"input_ids\"].shape[1]\n",
    "    if source is None:\n",
    "        source_ = ntoks-1\n",
    "    else:\n",
    "        source_ = source\n",
    "        \n",
    "    if positions is None:\n",
    "        positions = list(range(ntoks))\n",
    "        \n",
    "    table = []\n",
    "    for tnum in positions:\n",
    "        row = []\n",
    "        for layer in range(mt.num_layers):\n",
    "            if kind == \"single\":\n",
    "                block_config = {layer: [(source_, tnum)]}\n",
    "                r = trace_with_attn_block(\n",
    "                    mt.model, inp, block_config, answer_t\n",
    "                )\n",
    "            elif kind == \"window\":\n",
    "                layerlist = [\n",
    "                    l for l in range(\n",
    "                        max(0, layer - window // 2), min(mt.num_layers, layer - (-window // 2))\n",
    "                    )\n",
    "                ]\n",
    "                block_config = {\n",
    "                    l: [(source_, tnum)]\n",
    "                    for l in layerlist\n",
    "                }\n",
    "                r = trace_with_attn_block(\n",
    "                    mt.model, inp, block_config, answer_t\n",
    "                )\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "            row.append(r)\n",
    "        table.append(torch.stack(row))\n",
    "    differences = torch.stack(table)\n",
    "    differences = differences.detach().cpu()\n",
    "    \n",
    "    low_score = differences.min()\n",
    "    \n",
    "    source_probs = [projs[f\"layer_residual_{l}_probs\"][0][source_] for l in range(mt.num_layers)]\n",
    "    source_preds = decode_tokens(mt.tokenizer, \n",
    "                                 [projs[f\"layer_residual_{l}_preds\"][0][source_] for l in range(mt.num_layers)])\n",
    "    \n",
    "    return dict(\n",
    "        scores=differences,\n",
    "        source_probs=source_probs,\n",
    "        source_preds=source_preds,\n",
    "        low_score=low_score,\n",
    "        high_score=base_score,\n",
    "        input_ids=inp[\"input_ids\"][0],\n",
    "        input_tokens=decode_tokens(mt.tokenizer, inp[\"input_ids\"][0]),\n",
    "        answer=answer,\n",
    "        source=source_,\n",
    "        window=window,\n",
    "        kind=\"\",\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_info_flow(\n",
    "    mt,\n",
    "    prompt,\n",
    "    source=None,\n",
    "    kind=\"single\",\n",
    "    window=10,\n",
    "    set_lims=True,\n",
    "    show_proj=True,\n",
    "    savepdf=None,\n",
    "):\n",
    "    result = intervene_on_info_flow(mt, prompt, source, kind, window)\n",
    "    \n",
    "    differences = result[\"scores\"]\n",
    "    low_score = result[\"low_score\"]\n",
    "    answer = result[\"answer\"]\n",
    "    window = result.get(\"window\", 10)\n",
    "    source = result['source']\n",
    "    labels = list(result[\"input_tokens\"])\n",
    "    labels[source] = labels[source] + \"*\"\n",
    "\n",
    "    size_height = len(labels) * 0.3\n",
    "    fig, ax = plt.subplots(figsize=(7, size_height), dpi=150)\n",
    "    if set_lims:\n",
    "        h = ax.pcolor(\n",
    "            differences,\n",
    "            cmap=\"Purples_r\",\n",
    "            vmin=0.0,\n",
    "            vmax=1.0\n",
    "        )\n",
    "    else:\n",
    "        h = ax.pcolor(\n",
    "            differences,\n",
    "            cmap=\"Purples_r\",\n",
    "        )\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_yticks([0.5 + i for i in range(len(differences))])\n",
    "    ax.set_xticks([0.5 + i for i in range(0, differences.shape[1] - 6, 5)])\n",
    "    ax.set_xticklabels(list(range(0, differences.shape[1] - 6, 5)))\n",
    "    ax.set_yticklabels(labels)\n",
    "\n",
    "    if show_proj:\n",
    "        for x in range(mt.num_layers):\n",
    "            plt.text(\n",
    "                x + 0.5, source + 0.5, \n",
    "                f'{result[\"source_preds\"][x]} {round(100.0 * result[\"source_probs\"][x], 1)}',\n",
    "                horizontalalignment='center', verticalalignment='center', rotation=90, fontsize=4,\n",
    "            )\n",
    "\n",
    "    cb = plt.colorbar(h)\n",
    "    ax.set_title(\n",
    "        f\"Intervening on flow to: {result['input_tokens'][source]}\\nwindow: {window}, base probability: {round(result['high_score'].cpu().numpy().item(), 4)}\",\n",
    "        fontsize=10\n",
    "        )\n",
    "    if answer is not None:\n",
    "        cb.ax.set_title(f\"p({str(answer).strip()})\", y=-0.16, fontsize=10)\n",
    "    if savepdf:\n",
    "        os.makedirs(os.path.dirname(savepdf), exist_ok=True)\n",
    "        plt.savefig(savepdf, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Information Flow Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp:  {'input_ids': tensor([[    1,  1522,  1446,  6125,   338, 15205,   491]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
      "inp2:  {'input_ids': tensor([[    1,  1522,  1446,  6125,   338, 15205,   491]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects a non-empty TensorList",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m inp \u001b[38;5;241m=\u001b[39m make_inputs(mt\u001b[38;5;241m.\u001b[39mtokenizer, [prompt])\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minp: \u001b[39m\u001b[38;5;124m'\u001b[39m,inp)\n\u001b[0;32m----> 8\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mplot_info_flow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwindow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mset_lims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_proj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;66;43;03m# savepdf=f\"figs/{prompt}.pdf\"\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 11\u001b[0m, in \u001b[0;36mplot_info_flow\u001b[0;34m(mt, prompt, source, kind, window, set_lims, show_proj, savepdf)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_info_flow\u001b[39m(\n\u001b[1;32m      2\u001b[0m     mt,\n\u001b[1;32m      3\u001b[0m     prompt,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     savepdf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m ):\n\u001b[0;32m---> 11\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mintervene_on_info_flow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     differences \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     14\u001b[0m     low_score \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlow_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[0;32mIn[28], line 42\u001b[0m, in \u001b[0;36mintervene_on_info_flow\u001b[0;34m(mt, prompt, source, kind, window, positions)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[1;32m     41\u001b[0m         row\u001b[38;5;241m.\u001b[39mappend(r)\n\u001b[0;32m---> 42\u001b[0m     table\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     43\u001b[0m differences \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(table)\n\u001b[1;32m     44\u001b[0m differences \u001b[38;5;241m=\u001b[39m differences\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects a non-empty TensorList"
     ]
    }
   ],
   "source": [
    "# Single-example interventions.\n",
    "\n",
    "prompt = \"Beats Music is owned by\"    \n",
    "inp = make_inputs(mt.tokenizer, [prompt])\n",
    "\n",
    "\n",
    "print('inp: ',inp)\n",
    "results = plot_info_flow(mt, prompt, source=None, kind=\"window\", window=10, \n",
    "                         set_lims=False, show_proj=False,\n",
    "                         # savepdf=f\"figs/{prompt}.pdf\"\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s:  tensor([    1,  1522,  1446,  6125,   338, 15205,   491, 12113, 29892,   322,\n",
      "          372,   338,   263, 24820,  2669,   393, 16688], device='cuda:0')\n",
      "output:  <s>Beats Music is owned by Apple, and it is a streaming service that offers\n"
     ]
    }
   ],
   "source": [
    "inputs = mt.tokenizer(\"Beats Music is owned by\", return_tensors=\"pt\")\n",
    "input_ids = inputs[\"input_ids\"].to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    generation_output = mt.model.generate(\n",
    "        input_ids=input_ids,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True,\n",
    "        max_new_tokens=10,\n",
    "    )\n",
    "s = generation_output.sequences[0]\n",
    "output = tokenizer.decode(s)\n",
    "print('s: ',s)\n",
    "print('output: ',output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ms\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "substring not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m subject \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39msubject\n\u001b[1;32m     11\u001b[0m inp \u001b[38;5;241m=\u001b[39m make_inputs(mt\u001b[38;5;241m.\u001b[39mtokenizer, [prompt])\n\u001b[0;32m---> 12\u001b[0m e_range \u001b[38;5;241m=\u001b[39m \u001b[43mfind_token_range\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m e_range \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(e_range[\u001b[38;5;241m0\u001b[39m], e_range[\u001b[38;5;241m1\u001b[39m])]\n\u001b[1;32m     15\u001b[0m answer_t, base_score, projs \u001b[38;5;241m=\u001b[39m trace_with_proj(mt\u001b[38;5;241m.\u001b[39mmodel, inp)\n",
      "File \u001b[0;32m~/Unlearn_Harry_Potter/dissecting_factual_predictions/utils.py:100\u001b[0m, in \u001b[0;36mfind_token_range\u001b[0;34m(tokenizer, token_array, substring)\u001b[0m\n\u001b[1;32m     98\u001b[0m toks \u001b[38;5;241m=\u001b[39m decode_tokens(tokenizer, token_array)\n\u001b[1;32m     99\u001b[0m whole_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(toks)\n\u001b[0;32m--> 100\u001b[0m char_loc \u001b[38;5;241m=\u001b[39m \u001b[43mwhole_string\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubstring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    102\u001b[0m tok_start, tok_end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: substring not found"
     ]
    }
   ],
   "source": [
    "# Information flow analysis\n",
    "\n",
    "window = 9\n",
    "\n",
    "# Run attention knockouts\n",
    "results = []\n",
    "for row_i, row in tqdm(knowns_df.iterrows()):\n",
    "    prompt = row.prompt\n",
    "    subject = row.subject\n",
    "\n",
    "    inp = make_inputs(mt.tokenizer, [prompt])\n",
    "    e_range = find_token_range(mt.tokenizer, inp[\"input_ids\"][0], subject)\n",
    "    e_range = [x for x in range(e_range[0], e_range[1])]\n",
    "\n",
    "    answer_t, base_score, projs = trace_with_proj(mt.model, inp)\n",
    "    base_score = base_score.cpu().item()\n",
    "    [answer] = decode_tokens(mt.tokenizer, [answer_t])\n",
    "\n",
    "    ntoks = inp[\"input_ids\"].shape[1]\n",
    "    source_ = ntoks-1\n",
    "\n",
    "    for block_ids, block_desc in [\n",
    "        ([x for x in e_range], \"subject\"),\n",
    "        ([x for x in range(ntoks-1) if x not in e_range], \"non-subject\"),\n",
    "        ([source_], \"last\"),\n",
    "    ]:\n",
    "        for layer in range(mt.num_layers):\n",
    "            layerlist = [\n",
    "                l for l in range(\n",
    "                    max(0, layer - window // 2), min(mt.num_layers, layer - (-window // 2))\n",
    "                )\n",
    "            ]\n",
    "            block_config = {\n",
    "                l: [(source_, stok) for stok in block_ids]\n",
    "                for l in layerlist\n",
    "            }\n",
    "            r = trace_with_attn_block(\n",
    "                mt.model, inp, block_config, answer_t\n",
    "            )\n",
    "            new_score = r.cpu().item()\n",
    "            results.append({\n",
    "                \"prompt\": prompt,\n",
    "                \"block_desc\": block_desc,\n",
    "                \"layer\": layer,\n",
    "                \"base_score\": base_score,\n",
    "                \"new_score\": new_score,\n",
    "                \"relative diff\": (new_score - base_score) * 100.0 / base_score,\n",
    "                \"is_subject_position_zero\": e_range[0] == 0\n",
    "            })\n",
    "\n",
    "tmp = pd.DataFrame.from_records(results)\n",
    "tmp[\"layer_1\"] = tmp.layer.apply(lambda x: x+1)\n",
    "\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(6,4))\n",
    "ax = sns.lineplot(tmp, x=\"layer_1\", y=\"relative diff\", \n",
    "                  hue=\"block_desc\",\n",
    "                  style=\"block_desc\",\n",
    "                  dashes=True,\n",
    "                  palette=palette[:3], linewidth=1)\n",
    "ax.set_xlabel(\"layer\")\n",
    "ax.set_ylabel(\"% change in prediction probability\")\n",
    "ax.set_xlim(0, mt.num_layers+0.5)\n",
    "sns.move_legend(ax, \"lower right\", title=\"blocked positions\")\n",
    "plt.axhline(y=0, color=palette[2], linestyle='-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 创建简单的虚构数据\n",
    "data = {\n",
    "    \"layer_1\": [1, 2, 3, 4, 5],\n",
    "    \"attribute_in_top_1\": [0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "    \"proj_vec\": [\"MHSA\", \"MHSA\", \"MLP\", \"MLP\", \"MHSA\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "order = [\"MHSA\", \"MLP\"]\n",
    "ax = sns.lineplot(\n",
    "    x=\"layer_1\", y=\"attribute_in_top_1\",\n",
    "    hue=\"proj_vec\", style=\"proj_vec\",\n",
    "    hue_order=order, style_order=order,\n",
    "    data=df[df.proj_vec.isin(order)],\n",
    "    palette=sns.color_palette(\"husl\", 2)  # 使用 Seaborn 默认调色板\n",
    ")\n",
    "ax.legend_.set_title(\"\")\n",
    "ax.set_ylabel(\"attribute extraction rate\")\n",
    "ax.set_xlabel(\"layer\")\n",
    "sns.move_legend(ax, \"upper left\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Cache of hidden representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Vinson Massif is located in the continent of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:09,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Beats Music is owned by\n",
      "row.prompt:  Audible.com is owned by\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:09,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  The Big Bang Theory premieres on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:10,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  MacApp, a product created by\n",
      "row.prompt:  Giuseppe Angeli, who has a citizenship of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:11,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Catalonia belongs to the continent of\n",
      "row.prompt:  In Marshall Islands, the language spoken is a mixture of\n",
      "row.prompt:  Leslie Moonves is employed by\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:12,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  The original language of De finibus bonorum et malorum is the same as the\n",
      "row.prompt:  Kirkpatrick Glacier belongs to the continent of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:13,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  The headquarter of Army of the Guardians of the Islamic Revolution is in\n",
      "row.prompt:  Il Gazzettino was written in the early 1980s, when the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:13,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Xamarin, from the\n",
      "row.prompt:  Eavan Boland was born in\n",
      "row.prompt:  Comme j'ai mal is written in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:14,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  The language used by Juan Bautista de Anza is a bit different from the language used by the\n",
      "row.prompt:  Alfred Hitchcock Presents debuted on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:14,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Tizen is developed by a consortium of companies including\n",
      "row.prompt:  Honus Wagner professionally plays the sport of\n",
      "row.prompt:  samurai cinema, that originated in\n",
      "row.prompt:  The capital of Roman Republic is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:15,  6.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Henri Debain was born in\n",
      "row.prompt:  Adriano Celentano is a citizen of\n",
      "row.prompt:  Czech Republic national football team is a member of the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:15,  8.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Windows Media Player is developed by\n",
      "row.prompt:  NTFS is developed by\n",
      "row.prompt:  Knud, Hereditary Prince of Denmark passed away in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [00:15, 10.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Don Shula professionally plays the sport of\n",
      "row.prompt:  The language of El Mercurio was a mixture of\n",
      "row.prompt:  Iron Man is affiliated with the\n",
      "row.prompt:  The location of Massachusetts Institute of Technology is in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [00:15,  9.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Vietnam belongs to the continent of\n",
      "row.prompt:  The Tonight Show with Jay Leno premieres on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [00:16, 10.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Philippines's capital,\n",
      "row.prompt:  Frederick Banting specializes in the study of the\n",
      "row.prompt:  Clifford Curzon, performing on the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39it [00:16, 12.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Windows Media Audio, a product developed by\n",
      "row.prompt:  The location of Galatasaray University is in the heart of\n",
      "row.prompt:  In Nokia, the language spoken is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [00:16, 11.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Northern Nigeria Protectorate follows the religion of\n",
      "row.prompt:  Deobandi follows the religion of\n",
      "row.prompt:  Odnoklassniki was written in the early 1990s by a group of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:16, 11.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Zeno of Verona holds the position of the first\n",
      "row.prompt:  Jean-Pierre Van Rossem, who has a citizenship of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47it [00:17, 10.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Joseph Schumpeter's domain of work is the\n",
      "row.prompt:  Felix Salmon, who works as a\n",
      "row.prompt:  Grand Duchy of Finland's capital,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [00:17, 10.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Goodreads owner, and former\n",
      "row.prompt:  Rhine belongs to the continent of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [00:17, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Muawiyah I is affiliated with the religion of\n",
      "row.prompt:  Farrukhsiyar follows the religion of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53it [00:17,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Ibn Khaldun follows the religion of\n",
      "row.prompt:  Vichy France's capital,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "55it [00:18,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  John Pym died in the city of\n",
      "row.prompt:  The genre played by Christopher Paolini is a mix of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [00:18,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Si la vie est cadeau is written in\n",
      "row.prompt:  Brian De Palma works in the area of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:19,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Magne Robo Gakeen was created in the country of\n",
      "row.prompt:  The language of Electricidad was a mixture of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [00:19,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Swedish Orphan Biovitrum is headquartered in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62it [00:20,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Megan Rapinoe professionally plays the sport of\n",
      "row.prompt:  Drake Britton plays as the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [00:21,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Pandora Hearts was created in the country of\n",
      "row.prompt:  Nicolas Gigault was born in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65it [00:22,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  LGA 775 is created by\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "67it [00:23,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Suite Habana was created in the country of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [00:23,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Emilia Rydberg was born in\n",
      "row.prompt:  Adam Curtis is employed by the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "69it [00:23,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Mark Sanchez plays in the position of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70it [00:24,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Danish pastry was created in the country of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "72it [00:24,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Jyllands-Posten is written in\n",
      "row.prompt:  Sachimi Iwao is a citizen of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "74it [00:25,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Yakuza 2 is developed by\n",
      "row.prompt:  Lexus's owner,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76it [00:25,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  In Yamalo-Nenets Autonomous Okrug, the language spoken is the\n",
      "row.prompt:  The Physiological Society works in the area of the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "78it [00:26,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  William Herschel works in the area of\n",
      "row.prompt:  Joseph Goebbels worked in the city of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79it [00:26,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Deutsche Bahn formed in 1883, and the first train to\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80it [00:26,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Saint Domnius, who has the position of the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "82it [00:26,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Italy's capital,\n",
      "row.prompt:  Hotel Room premieres on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "84it [00:27,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  caffeine, called after the\n",
      "row.prompt:  The headquarter of Lokalbahn AG is in the city of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85it [00:27,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Urdoviza Glacier belongs to the continent of\n",
      "row.prompt:  Manipur belongs to the continent of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "88it [00:28,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  2005 Southeast Asian Games is in full swing in the\n",
      "row.prompt:  Lake Abitibi, in the province of\n",
      "row.prompt:  Georgios Babiniotis's domain of work is the study of the history of the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90it [00:28,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Maumoon Abdul Gayoom follows the religion of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "92it [00:28,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  The capital city of People's Republic of Poland is\n",
      "row.prompt:  Francesco Castellacci was born in\n",
      "row.prompt:  Fluminense F.C. is located in the country of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "95it [00:29,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Bundesautobahn 113, by the way, is the most popular route in\n",
      "row.prompt:  Petros Voulgaris is a citizen of\n",
      "row.prompt:  2005 Australian Open is located in\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "97it [00:29,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  Giulio Romano originates from the city of\n",
      "row.prompt:  Louth County Council is located in the country of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:29,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row.prompt:  The language used by Louis Bonaparte is not the language of the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a cache of subject representations\n",
    "\n",
    "layers_to_cache = list(range(mt.num_layers+1))\n",
    "hs_cache = {}\n",
    "for row_i, row in tqdm(knowns_df.iterrows()):\n",
    "    prompt = row.prompt\n",
    "\n",
    "    print('row.prompt: ',row.prompt)\n",
    "\n",
    "    inp = make_inputs(mt.tokenizer, [prompt])\n",
    "    output = mt.model(**inp, output_hidden_states = True)\n",
    "\n",
    "    for layer in layers_to_cache:\n",
    "        if (prompt, layer) not in hs_cache:\n",
    "            hs_cache[(prompt, layer)] = []\n",
    "        hs_cache[(prompt, layer)].append(output[\"hidden_states\"][layer][0])\n",
    "        \n",
    "len(hs_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1209it [01:21, 14.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "57360"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a cache of subject representations\n",
    "\n",
    "layers_to_cache = list(range(mt.num_layers))\n",
    "subject_cache = {}\n",
    "for row_i, row in tqdm(knowns_df.iterrows()):\n",
    "    prompt = row.prompt\n",
    "    subject = row.subject\n",
    "    \n",
    "    inp = make_inputs(mt.tokenizer, [prompt])\n",
    "    e_range = find_token_range(mt.tokenizer, inp[\"input_ids\"][0], subject)\n",
    "    e_range = [x for x in range(e_range[0], e_range[1])]\n",
    "    \n",
    "    output = mt.model(**inp, output_hidden_states = True)\n",
    "    \n",
    "    #print('output[\"logits\"].shape: ',output[\"logits\"].shape)\n",
    "    \n",
    "    probs = torch.softmax(output[\"logits\"][:, -1], dim=1)\n",
    "    \n",
    "    base_score, answer_t = torch.max(probs, dim=1)\n",
    "    base_score = base_score.cpu().item()\n",
    "    [answer] = decode_tokens(mt.tokenizer, answer_t)  #这三句是把原句子传入model中，得到的answer就是预测的下一个token\n",
    "    \n",
    "    for layer in layers_to_cache:\n",
    "        if (subject, layer) not in subject_cache:\n",
    "            subject_cache[(subject, layer)] = []\n",
    "        subject_cache[(subject, layer)].append(output[\"hidden_states\"][layer+1][0, e_range[-1]])  #这里就是得到subject位置在各层对应的hiddenstate\n",
    "\n",
    "len(subject_cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Attribute extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1209it [34:53,  1.73s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "E = mt.model.get_output_embeddings().weight\n",
    "k = 10\n",
    "\n",
    "records = []\n",
    "for row_i, row in tqdm(knowns_df.iterrows()):\n",
    "\n",
    "    if row_i >= 3:\n",
    "        break\n",
    "    prompt = row.prompt\n",
    "    subject = row.subject\n",
    "    attribute = row.attribute\n",
    "    \n",
    "    inp = make_inputs(mt.tokenizer, [prompt])\n",
    "    input_tokens = decode_tokens(mt.tokenizer, inp[\"input_ids\"][0])\n",
    "    e_range = find_token_range(mt.tokenizer, inp[\"input_ids\"][0], subject)\n",
    "    e_range = [x for x in range(e_range[0], e_range[1])]\n",
    "    non_e_range_last = [x for x in range(len(input_tokens)-1) if x not in e_range]\n",
    "    source_index = len(input_tokens) - 1\n",
    "    \n",
    "    # set hooks to get ATTN and MLP outputs\n",
    "    hooks = set_act_get_hooks(mt.model, source_index, mlp=True, attn_out=True)\n",
    "    output = mt.model(**inp)\n",
    "    # remove hooks\n",
    "    remove_hooks(hooks)\n",
    "    \n",
    "    probs = torch.softmax(output[\"logits\"][:, -1], dim=1)\n",
    "    _, attribute_tok = torch.max(probs, dim=1)\n",
    "    attribute_tok = attribute_tok.cpu().item()\n",
    "    [attribute_tok_str] = decode_tokens(mt.tokenizer, [attribute_tok])\n",
    "    \n",
    "    for layer in range(mt.num_layers):\n",
    "        # ATTN\n",
    "        attn_out = mt.model.activations_[f'attn_out_{layer}'][0]\n",
    "        proj = attn_out.matmul(E.T).cpu().numpy()\n",
    "        ind = np.argsort(-proj, axis=-1)\n",
    "        attribute_tok_rank = np.where(ind == attribute_tok)[0][0]\n",
    "        attribute_tok_score = proj[ind[attribute_tok_rank]]\n",
    "        top_k_preds = [decode_tokens(mt.tokenizer, [i])[0] for i in ind[:k]]\n",
    "        records.append({\n",
    "                \"prompt\": prompt,\n",
    "                \"subject\": subject,\n",
    "                \"attribute\": attribute,\n",
    "                \"attribute_tok\": attribute_tok,\n",
    "                \"attribute_tok_str\": attribute_tok_str,\n",
    "                \"layer\": layer,\n",
    "                \"proj_vec\": \"MHSA\",\n",
    "                \"top_k_preds\": top_k_preds,\n",
    "                \"attribute_tok_rank\": attribute_tok_rank,\n",
    "                \"attribute_tok_score\": attribute_tok_score,\n",
    "                \"attribute_in_top_1\": attribute_tok_rank == 0,\n",
    "            })\n",
    "        \n",
    "        # MLP\n",
    "        mlp_out = mt.model.activations_[f'm_out_{layer}']\n",
    "        proj = mlp_out.matmul(E.T).cpu().numpy()\n",
    "        ind = np.argsort(-proj, axis=-1)\n",
    "        attribute_tok_rank = np.where(ind == attribute_tok)[0][0]\n",
    "        attribute_tok_score = proj[ind[attribute_tok_rank]]\n",
    "        top_k_preds = [decode_tokens(mt.tokenizer, [i])[0] for i in ind[:k]]\n",
    "        records.append({\n",
    "                \"prompt\": prompt,\n",
    "                \"subject\": subject,\n",
    "                \"attribute\": attribute,\n",
    "                \"attribute_tok\": attribute_tok,\n",
    "                \"attribute_tok_str\": attribute_tok_str,\n",
    "                \"layer\": layer,\n",
    "                \"proj_vec\": \"MLP\",\n",
    "                \"top_k_preds\": top_k_preds,\n",
    "                \"attribute_tok_rank\": attribute_tok_rank,\n",
    "                \"attribute_tok_score\": attribute_tok_score,\n",
    "                \"attribute_in_top_1\": attribute_tok_rank == 0,\n",
    "            })\n",
    "        \n",
    "        \n",
    "    # set hooks to get ATTN weights\n",
    "    get_act_hooks = set_act_get_hooks(mt.model, source_index, attn=True)\n",
    "    output = mt.model(**inp, output_attentions = True)\n",
    "    # remove hooks\n",
    "    remove_hooks(get_act_hooks)\n",
    "\n",
    "    for layer in range(mt.num_layers):\n",
    "        attn_o_proj = mt.model.model.layers[layer].self_attn.o_proj\n",
    "        val = mt.model.activations_[f'c_attn_value_{layer}']\n",
    "        weight = mt.model.activations_[f'attn_weights_{layer}']\n",
    "        \n",
    "        weight = weight.unsqueeze(1)\n",
    "        weight_block_subj = weight.detach().clone()\n",
    "        for t in e_range:\n",
    "            weight_block_subj[:, :, t] = -1e6\n",
    "        weight_block_subj = torch.softmax(weight_block_subj, dim=-1)\n",
    "        \n",
    "        weight_block_subj_last = weight.detach().clone()\n",
    "        weight_block_subj_last[:, :, e_range[-1]] = -1e6\n",
    "        weight_block_subj_last = torch.softmax(weight_block_subj_last, dim=-1)\n",
    "        \n",
    "        weight_block_last = weight.detach().clone()\n",
    "        weight_block_last[:, :, source_index] = -1e6\n",
    "        weight_block_last = torch.softmax(weight_block_last, dim=-1)\n",
    "        \n",
    "        weight_block_subj_last_and_last = weight.detach().clone()\n",
    "        weight_block_subj_last_and_last[:, :, e_range[-1]] = -1e6\n",
    "        weight_block_subj_last_and_last[:, :, source_index] = -1e6\n",
    "        weight_block_subj_last_and_last = torch.softmax(weight_block_subj_last_and_last, dim=-1)\n",
    "        \n",
    "        weight_block_nonsubj = weight.detach().clone()\n",
    "        for t in non_e_range_last:\n",
    "            weight_block_nonsubj[:, :, t] = -1e6\n",
    "        weight_block_nonsubj[:, :, source_index] = -1e6\n",
    "        weight_block_nonsubj = torch.softmax(weight_block_nonsubj, dim=-1)\n",
    "        \n",
    "        weight_block_nonsubj_but_last = weight.detach().clone()\n",
    "        for t in non_e_range_last:\n",
    "            weight_block_nonsubj_but_last[:, :, t] = -1e6\n",
    "        weight_block_nonsubj_but_last = torch.softmax(weight_block_nonsubj_but_last, dim=-1)\n",
    "        \n",
    "        weight_block_all_but_first = torch.zeros_like(weight) -1e6\n",
    "        weight_block_all_but_first[:, :, 0] = weight[:, :, 0]\n",
    "        weight_block_all_but_first = torch.softmax(weight_block_all_but_first, dim=-1)\n",
    "        \n",
    "        weight_block_all_but_last = torch.zeros_like(weight) -1e6\n",
    "        weight_block_all_but_last[:, :, source_index] = weight[:, :, source_index]\n",
    "        weight_block_all_but_last = torch.softmax(weight_block_all_but_last, dim=-1)\n",
    "        \n",
    "        weight_block_all_but_subj_last = torch.zeros_like(weight) -1e6\n",
    "        weight_block_all_but_subj_last[:, :, e_range[-1]] = weight[:, :, e_range[-1]]\n",
    "        weight_block_all_but_subj_last = torch.softmax(weight_block_all_but_subj_last, dim=-1)\n",
    "        \n",
    "        weight_block_all_but_subj_last_last = torch.zeros_like(weight) -1e6\n",
    "        weight_block_all_but_subj_last_last[:, :, e_range[-1]] = weight[:, :, e_range[-1]]\n",
    "        weight_block_all_but_subj_last_last[:, :, source_index] = weight[:, :, source_index]\n",
    "        weight_block_all_but_subj_last_last = torch.softmax(weight_block_all_but_subj_last_last, dim=-1)\n",
    "        \n",
    "        weight_block_all = torch.zeros_like(weight)\n",
    "        \n",
    "        for (weight_mat, weight_desc) in [\n",
    "            (weight, \"MHSA*\"),\n",
    "            (weight_block_subj, \"MHSA block subject\"),\n",
    "            (weight_block_last, \"MHSA block last\"),\n",
    "            (weight_block_subj_last, \"MHSA block subject-last\"),\n",
    "            (weight_block_subj_last_and_last, \"MHSA block subject-last + last\"),\n",
    "            (weight_block_nonsubj, \"MHSA block non-subject\"),\n",
    "            (weight_block_nonsubj_but_last, \"MHSA block non-subject ex. last\"),\n",
    "            (weight_block_all_but_first, \"MSHA block all but first\"),\n",
    "            (weight_block_all_but_last, \"MSHA block all but last\"),\n",
    "            (weight_block_all_but_subj_last, \"MHSA block all but subject-last\"),\n",
    "            (weight_block_all_but_subj_last_last, \"MHSA block all but subject-last + last\"),\n",
    "            (weight_block_all, \"MHSA block all\")\n",
    "        ]:\n",
    "            attn_out = torch.matmul(weight_mat, val)\n",
    "            attn_out = _merge_heads(attn_out, mt.model)\n",
    "            attn_out = torch.addmm(attn_o_proj.bias, attn_out, attn_o_proj.weight).squeeze()\n",
    "            \n",
    "            proj = attn_out.matmul(E.T).cpu().numpy()\n",
    "            ind = np.argsort(-proj, axis=-1)\n",
    "            attribute_tok_rank = np.where(ind == attribute_tok)[0][0]\n",
    "            attribute_tok_score = proj[ind[attribute_tok_rank]]\n",
    "            top_k_preds = [decode_tokens(mt.tokenizer, [i])[0] for i in ind[:k]]\n",
    "            records.append({\n",
    "                \"prompt\": prompt,\n",
    "                \"subject\": subject,\n",
    "                \"attribute\": attribute,\n",
    "                \"attribute_tok\": attribute_tok,\n",
    "                \"attribute_tok_str\": attribute_tok_str,\n",
    "                \"layer\": layer,\n",
    "                \"proj_vec\": weight_desc,\n",
    "                \"top_k_preds\": top_k_preds,\n",
    "                \"attribute_tok_rank\": attribute_tok_rank,\n",
    "                \"attribute_tok_score\": attribute_tok_score,\n",
    "                \"attribute_in_top_1\": attribute_tok_rank == 0,\n",
    "            })\n",
    "\n",
    "\n",
    "tmp = pd.DataFrame.from_records(records)\n",
    "tmp[\"layer_1\"] = tmp.layer.apply(lambda x: x+1)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(5,3))\n",
    "order = [\"MHSA\", \"MLP\"]\n",
    "ax = sns.lineplot(\n",
    "    x=\"layer_1\", y=\"attribute_in_top_1\",\n",
    "    hue=\"proj_vec\", style=\"proj_vec\",\n",
    "    hue_order=order, style_order = order,\n",
    "    data=tmp[tmp.proj_vec.isin(order)],\n",
    "    palette=palette[:2]\n",
    ")\n",
    "ax.legend_.set_title(\"\")\n",
    "ax.set_ylabel(\"attribute extraction rate\")\n",
    "ax.set_xlabel(\"layer\")\n",
    "sns.move_legend(ax, \"upper left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proj_vec</th>\n",
       "      <th>attribute_in_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MHSA</td>\n",
       "      <td>0.682119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MHSA*</td>\n",
       "      <td>0.682119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MHSA block all but subject-last + last</td>\n",
       "      <td>0.443709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MHSA block non-subject ex. last</td>\n",
       "      <td>0.420530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MHSA block last</td>\n",
       "      <td>0.394040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MHSA block subject-last</td>\n",
       "      <td>0.377483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MSHA block all but last</td>\n",
       "      <td>0.329470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MHSA block subject-last + last</td>\n",
       "      <td>0.327815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MHSA block non-subject</td>\n",
       "      <td>0.315397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.312914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MHSA block subject</td>\n",
       "      <td>0.302152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MHSA block all but subject-last</td>\n",
       "      <td>0.235099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MSHA block all but first</td>\n",
       "      <td>0.002483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MHSA block all</td>\n",
       "      <td>0.000828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  proj_vec  attribute_in_top_1\n",
       "0                                     MHSA            0.682119\n",
       "10                                   MHSA*            0.682119\n",
       "3   MHSA block all but subject-last + last            0.443709\n",
       "6          MHSA block non-subject ex. last            0.420530\n",
       "4                          MHSA block last            0.394040\n",
       "8                  MHSA block subject-last            0.377483\n",
       "13                 MSHA block all but last            0.329470\n",
       "9           MHSA block subject-last + last            0.327815\n",
       "5                   MHSA block non-subject            0.315397\n",
       "11                                     MLP            0.312914\n",
       "7                       MHSA block subject            0.302152\n",
       "2          MHSA block all but subject-last            0.235099\n",
       "12                MSHA block all but first            0.002483\n",
       "1                           MHSA block all            0.000828"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attribute extraction statistics: Per-example extraction rate (across layers).\n",
    "# For how many examples there's at least one layer, where the attribute in the attention's output.\n",
    "\n",
    "tmp_ = tmp[\n",
    "    [\"prompt\", \"proj_vec\", \"attribute_in_top_1\"]\n",
    "].groupby([\"prompt\", \"proj_vec\"]).agg(\"max\").reset_index()\n",
    "\n",
    "tmp_ [[\"proj_vec\", \"attribute_in_top_1\"]\n",
    "     ].groupby(\"proj_vec\").agg(\"mean\").reset_index().sort_values(by=\"attribute_in_top_1\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "agg function failed [how->mean,dtype->object]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1871\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[0;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1871\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1872\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/core/groupby/ops.py:850\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[0;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[1;32m    848\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 850\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate_series_pure_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m npvalues \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/core/groupby/ops.py:871\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[0;32m--> 871\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    872\u001b[0m     res \u001b[38;5;241m=\u001b[39m extract_result(res)\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:2377\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2375\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[1;32m   2376\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m-> 2377\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   2378\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[1;32m   2379\u001b[0m     )\n\u001b[1;32m   2380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/core/series.py:6221\u001b[0m, in \u001b[0;36mSeries.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m   6213\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   6214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m   6215\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6219\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   6220\u001b[0m ):\n\u001b[0;32m-> 6221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/core/generic.py:11978\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11971\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  11972\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  11973\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11976\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11977\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 11978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  11980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/core/generic.py:11935\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11933\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m> 11935\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  11936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  11937\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/core/series.py:6129\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   6125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   6126\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6127\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6128\u001b[0m     )\n\u001b[0;32m-> 6129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/core/nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/core/nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/core/nanops.py:720\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum)\n\u001b[0;32m--> 720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthe_sum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/core/nanops.py:1693\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1692\u001b[0m     \u001b[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[0;32m-> 1693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert string \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not convert string '1993 Bombay bombings is located in the city of2002 Australian Open is located in2005 Australian Open is located inA Charlie Brown Christmas debuted onA las Barricadas is written inAbarth's owner,Abdolkarim Soroush follows the religion ofActive Server Pages, a product developed byAcura EL is developed byAcura ILX is developed byAcura RDX is developed byAcura RL is developed byAcura TL is developed byAcura ZDX is developed byAdam Curtis is employed by theAdam Schefter, ofAdi ibn Hatim is affiliated with the religion ofAdriano Celentano is a citizen ofAftonbladet is written inAhmed Zewail follows the religion ofAisha originates from the city ofAjinomoto Stadium's owner, theAkira Toriyama's domain of work is the world ofAl-Hasakah Governorate is located in the country ofAl-Mutawakkil follows the religion ofAlain Touraine speaks to the media after the first round of theAlan Sugar is employed by theAlexander Afanasyev passed away in aAlfa Romeo 155, produced byAlfa Romeo 6C, produced byAlfa Romeo MiTo, produced byAmerican Airlines Center's owner, theAmiibo is developed byAmol Palekar originates from the city ofAmos Tversky works in the area of cognitiveAndheri, in the south ofAndrew Lloyd Webber, who plays the title role in theAndroid Auto is developed byAngela Ahrendts is employed byAnimator.ru is written inAnnise Parker holds the title of the first openly gayAntoni Brodowski worked in the office of the mayor of the city ofAntonio Vivaldi plays theAretha Franklin, playing theArgentine National Anthem is located in the country ofArisaka was created in the country ofAssociation of Football Federations of Azerbaijan belongs to the organization of theAstley Cooper died in the city ofAthanasius of Alexandria, who has the position of the firstAustralian Antarctic Territory belongs to the continent ofAustralian Mathematical Society's expertise is in the areas ofAustrian Empire's capital city isAvenue Montaigne was created in the country ofBabur is affiliated with the religion ofBabylas of Antioch, who has the position of aBanco di Napoli, that originated inBandai Channel started inBandai Co., Ltd. formed in 1979 and is headquartered inBarry Bonds professionally plays the sport ofBarry Zito plays in the position of theBasil of Caesarea holds the title of the firstBeats Music is owned byBenedict XVI, who has the position of theBenjamin Britten worked in the city ofBhaktisiddhanta Saraswati, who has a citizenship ofBhayanak Maut, that was created in the wake of the 2008Big Love premieres onBilal ibn Ribah originates from the city ofBill Gates is employed byBing Maps's owner,Bing Videos is owned byBirobidzhaner Shtern was written in the late 19th century by aBoniface III originated from the city ofBoris Diaw professionally plays the sport ofBouygues Telecom is located in the country ofBrazil national football team belongs to the organization of theBrazilian Football Confederation is a part of theBrett Hull professionally plays the sport ofBrian De Palma works in the area ofBrian Krzanich is employed byBrookes Brothers formed in 1892 inBubba Smith professionally plays the sport ofBuichi Terasawa is a citizen ofCaciocavallo was created in the country of her birth,Cairo American College is located in the country ofCanada men's national soccer team is a part of theCarPlay is developed byCatalan self-determination referendum is located in the northeastern region ofCatalonia belongs to the continent ofCaterina Davinio, who has a citizenship ofChakrapani was created in the country of his birth,Chandigarh belongs to the continent ofCharlie Conacher died in the city ofCharlie Hebdo is written inCharlottenborg Palace is located in the heart of the city ofChatto & Windus was formed inChoi Myeong-gil's profession is anChris McGregor is known for performing in a variety of genres, from rock toChris Stringer was born inChristian Medical College Ludhiana is located in the country ofChromebook Pixel is developed byChromebook is owned byChromecast is developed byClement VIII, whose position is that of a \"superior\"Clifford Curzon, performing on theCollege Football Live premieres onComme j'ai mal is written inCommonwealth of the Philippines's capital,Core 2, a product developed byCosta Rican Football Federation is a part of theCourant Institute of Mathematical Sciences's expertise is in the areas ofCraig Federighi, who is employed byCzech Republic national football team is a member of theCzech Socialist Republic's capital,Dan Le Batard is employed byDaniel Victor, who has a citizenship ofDanish pastry was created in the country ofDannii Minogue was created in the country ofDany N'Guessan plays in the position of a forward, but he is also aDatsun Sports, developed byDavid Cameron worked in the city ofDavid Dimbleby is employed by theDavid Suzuki Foundation's headquarters are inDawid Janowski is a citizen ofDe-Phazz plays a lot ofDebenham Glacier belongs to the continent ofDelia Derbyshire is employed by theDenmark's capital,Deobandi follows the religion ofDick Butkus professionally plays the sport ofDie Tageszeitung is written inDirk Nowitzki professionally plays the sport ofDominic Behan writes in theDon Shula professionally plays the sport ofDrake Britton plays as theDrew Brees plays in the position ofDynix, a product of the formerEddy Cue is employed byEdina High School, inEdmund Neupert, performing on theEdward Teller's expertise is in the field of nuclearEgypt's capital,Eibenstock is located in the country ofEiko Koike is originally fromEiko Shimamiya is a citizen ofEl Diario de Hoy is written inElizabeth Butler-Sloss, Baroness Butler-Sloss worked in the city ofElvis Presley plays theEmmanuel Glacier belongs to the continent ofEpiphone's owner, theEredivisie is located in the country of theErnst Reuter died at the age of 87 inEuromoney Institutional Investor's headquarters are inEuropean Physical Journal's expertise is in the field of quantumEusebius of Vercelli, who has the position of aEvgeni Malkin professionally plays the sport ofEvgeny Lifshitz passed away inFantastic Fest can be found in the heart of downtownFaygo's headquarters are in the heart of downtownFifth Avenue can be found in the heart ofFile Explorer, a product developed byFinal Cut Pro X, a product developed byFinal Fantasy III is developed byFinal Fantasy is developed byFlorida Championship Wrestling is owned by theFrance Dimanche is written in theFrance Info is written inFrancis Blanche speaks during a news conference at theFrancis Poulenc performs on theFrancis de Sales holds the position of the firstFrans Hubert Edouard Arthur Walter Robyns, who has a citizenship ofFrederick Banting specializes in the study of theFrederick Noronha, who has a citizenship ofFriedrich Goldmann worked in the city ofFulgentius of Ruspe, who has the position of aGaetano Moroni passed away inGalata is within the city limits of the city ofGalerie des Machines, in the heart ofGalileo Galilei works in the area ofGambia River belongs to the continent ofGame & Watch is developed byGame Boy Advance is developed byGamescom can be found inGangnam Station's owner, theGatwick Airport, called after the airport inGavork-e Nalin Rural District is located in the country ofGeorge Cadogan, 5th Earl Cadogan took up work in theGeorge Newnes worked in the city ofGeorgios Babiniotis's domain of work is the study of the history of theGerlache Strait is located in the continent ofGermaine Greer's domain of work isGermanus of Auxerre, who has the position of aGianni Ferrio, who has a citizenship ofGianni Lancia, who has a citizenship ofGinza Line is located in the country ofGiovanni Battista Viotti plays the instrument of theGiuseppe Angeli, who has a citizenship ofGiuseppe Meazza Stadium (San Siro) is owned by the city ofGmina Kleczew is located in the country ofGoodreads owner, and formerGrand Duchy of Finland's capital,Gregory XII, whose position is that of a \"superior\"Gregory XIII, whose position is that of a \"superior\"Gregory XVI, whose position is that of a \"superior\"Gregory of Nazianzus, who has the position ofGriebnitz Canal is within the boundaries of the city ofGrupo Globo, that originated inGwen Ifill, ofHafez follows the religion ofHamza ibn Abdul-Muttalib is affiliated with the religion ofHawaii's capital,Hebrew Theological College is affiliated with the religion ofHenry Pym is affiliated with theHenry Somerset, 7th Duke of Beaufort worked in the city ofHersekzade Ahmed Pasha follows the religion ofHidamari Sketch was created in the country ofHideki Shirakawa was born inHigashikagawa is located in the country ofHiroshi Tsuchida was born inHong Kong belongs to the continent ofHonnavar is located in the country ofHonus Wagner professionally plays the sport ofHope and Anchor, Islington is located in the heart ofHungarian Soviet Republic's capital,Ibrahim Pasha of Egypt passed away inIgnatius of Antioch, who has the position of aIl Gazzettino was written in the early 1980s, when theIl Secolo XIX was written in the late 16th century by theIlya Kovalchuk professionally plays the sport of iceIn Aarau, the language spoken is a mixture ofIn Argentina, the language spoken isIn Asturias, the language spoken isIn Azerbaijan Soviet Socialist Republic, the language spoken isIn Bosco Gurin, the language spoken is a mixture ofIn Canton of Fribourg, the language spoken isIn Chiasso, the language spoken isIn Engelberg, the language spoken is a mixture ofIn Helsinki, the language spoken isIn Ireland, the language spoken isIn Joensuu, the language spoken isIn Kauniainen, the language spoken isIn Kingdom of Bulgaria, the language spoken isIn Luhansk Oblast, the language spoken isIn Nokia, the language spoken isIn Nyon, the language spoken is a mixture ofIn Panama, the language spoken isIn Patna, the language spoken is a mix ofIn Petrozavodsk, the language spoken isIn Pomarkku, the language spoken is a dialect ofIn Raseborg, the language spoken isIn Ruokolahti, the language spoken isIn South Georgia and the South Sandwich Islands, the language spoken isIn Sundsvall Municipality, the language spoken isIn Udmurt Autonomous Soviet Socialist Republic, the language spoken isIn United Kingdom, the language spoken isIn Vietnam, the language spoken isIn Yamalo-Nenets Autonomous Okrug, the language spoken is theIn Zabaykalsky Krai, the language spoken is a dialect ofIn history of Limousin, the language spoken isIndian Space Research Organisation's headquarters are inIndira Gandhi International Airport is located in the country ofIndonesia's capital,Inoue Genan Inseki is native toIntelliPoint was created by a team of developers from theInternet Explorer 10 is developed byInternet Explorer is developed byIreland's capital,Iron Man is affiliated with theIsola Dovarese is located in the country ofItalian Chemical Society's expertise is in the field of organicItalian Football Federation is a part of theItaly national football team is affiliated with theItaly's capital,J-pop, that originated inJVC Kenwood Victor Entertainment is located in the country ofJackie Robinson professionally plays the sport ofJames Northcote died in the city ofJarome Iginla professionally plays the sport ofJaromír Jágr professionally plays the sport of iceJason Campbell plays in the position of theJean Bobet is a citizen ofJean-Jacques Annaud speaks to the media after a meeting with theJean-Pierre Petit writes in theJeff Hardy is affiliated with theJeff Zucker, ofJennie Lee, Baroness Lee of Asheridge worked in the city ofJeremy Clarkson is employed by theJeremy Paxman is employed by theJeremy Vine is employed by theJerry West professionally plays the sport ofJessica Jones is a member of theJimi Hendrix, playing the electricJoe Louis Arena, from theJohann Strauss I plays the instrument of theJohn Broadwood died in the city ofJohn Calvin works in the field ofJohn Coltrane's domain of work is theJohn Humphrys is employed by theJohn Major worked in the city ofJohn Pym died in the city ofJohn Smoltz plays in the position of theJohn XXIII holds the title of \"the most popularJohnny Unitas professionally plays the sport ofJon Postel's domain of activity is the world of theJon Sopel is employed by theJonathan Pearce is employed by theJoseph Goebbels worked in the city ofJoseph Schumpeter's domain of work is theJosetsu, who has a citizenship ofJosh McCown plays in the position ofJosé Canseco professionally plays the sport ofJulian Huxley died in the city ofJyllands-Posten is written inKalamazoo County can be found in the southeast corner ofKeyArena, from theKhalid ibn al-Walid is affiliated with the religion ofKhedivate of Egypt's capital,Kieler Nachrichten is written inKiller Mike is native toKing Chulalongkorn Memorial Hospital's headquarters are inKing David Hotel bombing is located in the city ofKingdom of Bavaria's capital,Kingdom of Egypt's capital,Kingdom of Great Britain's capital,Kingdom of Iraq's capital,Kirkby Glacier belongs to the continent ofKirkpatrick Glacier belongs to the continent ofKlaas Schilder is a native speaker ofKluuvi is located in the country ofKnud, Hereditary Prince of Denmark passed away inKoichi Ishii is native toKrzysztof Meyer is known for performing the first ever live performance of theKurt Kreuger's profession is anKyle Farnsworth plays in the position of theKyōto Prefecture, which was named after the city ofL'Aurore is written inLGA 775 is created byLa Vie is written inLa Voz del Interior is written inLage Raho Munna Bhai was created in the country of his birth,Lake Abitibi, in the province ofLake Vostok belongs to the continent ofLate Night with Jimmy Fallon premieres onLatin Empire's capital,Lawrence Taylor professionally plays the sport ofLazio's capital,Le Matin de Paris is written in theLe Mauricien is written inLe Moniteur Universel is written inLe Petit Parisien is written inLe Quotidien de Paris is written inLe Silence de la mer was written in the early 20th century by aLe cose che vivi is written inLeBron James professionally plays the sport ofLebedev Physical Institute's headquarters are inLeinster is located in the heart ofLeo XIII, whose position is that of a \"superior\"Leonard Bernstein performs on theLeonard Peikoff works in the area of theLeslie Moonves is employed byLexus ES is developed byLexus LF, developed byLexus RX, developed byLexus's owner,Limoncello was created in the country of his birth,Lincoln Financial Field, inLopburi, in the southern part ofLouth County Council is located in the country ofLudovic Sylvestre plays in the position of a defensiveLudwig von Mises's domain of work is theLufkin, in the heart of theLuis del Sol plays as a striker, but he is also aLumia series is developed byLupin III was created in the country of his birth,Mac Pro is developed byMacApp, a product created byMacBook Air is developed byMadame de Montesson died in the city ofMagne Robo Gakeen was created in the country ofMaharashtra's capital,Mainichi Shinbun, that originated inMako Idemitsu was born inManassas Regional Airport, inManuel I of Portugal passed away inMarcellin Berthelot died in the city ofMarco Di Vaio professionally plays the sport ofMario Bros. is developed byMark Messier professionally plays the sport ofMark Sanchez plays in the position ofMarugame is located in the country ofMas Canciones is written inMasaccio, who has a citizenship ofMasoretic Text is written in theMassachusetts's capital,Matias Kupiainen was born inMaumoon Abdul Gayoom follows the religion ofMauna Kea, inMaximianus of Ravenna, who has the position of aMedical College and Hospital, Kolkata is located in the country ofMeet the Press debuted onMegan Rapinoe professionally plays the sport ofMehdi Hosseini was born inMelodiya is headquartered inMercure de France's headquarters are inMetropolitan France's capital,Mexico national football team is a part of theMichael Dorn's profession is anMichael Faraday works in the field of electromagnetism and is a professor ofMichael Foot worked in the city ofMichel Bernstein died in the city ofMichio Kaku works in the area of theoreticalMiles Davis, who plays the role of aMir Damad is affiliated with the religion ofMitsubishi Corporation's headquarters are inMitsubishi Electric started in the early 1900s as a small company inMiyuki Sawashiro is originally fromMizoram, in the north-east ofMohsen Mirdamadi is a citizen ofMonster Rancher, that originated inMorteza Momayez passed away in a hospital inMoses Malone professionally plays the sport ofMount Discovery is located in the continent ofMuawiyah I is affiliated with the religion ofMuhammad Asad is affiliated with the religion ofMuhammad al-Bukhari is affiliated with the religion ofMuhammad is affiliated with the religion ofNTFS is developed byNagendra Singh is a citizen ofNamor is affiliated with theNancy Astor, Viscountess Astor worked in the city ofNational Football Federation of Guatemala is a part of theNe partez pas sans moi is written inNewsstand was created by the same company that created the originalNez Perce County is in the middle of theNicosia is a twin city ofNikon formed in 1975 and is headquartered inNishi-Matsuura District is located in the country ofNismo, from the same company that makes theNodame Cantabile, that originated inNorth Berwick can be found in the south-west ofNorth Side Gang was created in the early 1980s by a group ofNorway's capital,Norwegian Museum of Cultural History is inNow Kandeh District is located in the country ofO'Hare International Airport's owner, theO'Hare International Airport, called after the plane was diverted toOS X Yosemite is developed byOdnoklassniki was written in the early 1990s by a group ofOffice Online's owner,Olga Vittoria Gentilli writes in theOptimistique-moi is written inOratory of Saint Philip Neri is headquartered inOsman I follows the religion ofOsvaldo Genazzani speaks to the media after his arrest in the southernOtto Hauser worked in the city ofOutlook.com's owner,Outside the Lines debuted onPaanch was created in the country of his birth,Panagarh is located in the country ofPanathenaic Stadium is located in the heart of the city ofPandora Hearts was created in the country ofParis belongs to the continent ofPat Tillman professionally plays the sport ofPatrick Henry College is located inPatuxent Wildlife Research Center, inPaul Allen is employed byPaul IV holds the title of \"the most powerfulPaul Otellini is employed byPekka Rinne plays in the position ofPelagius II holds the position of the firstPentium 4 is developed byPeru's capital,Pervez Musharraf follows the religion ofPeter Fincham is employed by thePeter Josef von Lindpaintner is known for performing the first ever performance of thePetros Voulgaris is a citizen ofPhil Jackson professionally plays the sport ofPhil Knight, ofPhilip Glass plays thePhilip Mould is employed by thePhilippines's capital,Photinus of Sirmium, who holds the position of the firstPierre Gilliard's domain of work is the study of the history of thePilipinas News, that was from thePitkevitch Glacier belongs to the continent ofPittsburg County, which was named after the city ofPius II is a great example of aPius III died in the city ofPius VI, whose position is that of a \"superior\"Pius VIII, whose position is that of a \"superior\"Pius XII, whose position is that of a \"superior\"Platform Controller Hub is a product of thePlayStation Eye is developed byPointe Coupee Parish is named for thePolish Socialist Party's headquarters are inPolymath project works in the area ofPope Heraclas of Alexandria has the position of the firstPortuguese Football Federation is a part of thePostcards Records is known for performing a wide variety of music, from rock toProcess Explorer, a product developed byProgressive Records is known for performing a wide variety of genres, from rock toQing dynasty's capital,Quirinus of Sescia, who has the position of aRIA Novosti is written inRancho Petaluma Adobe's owner, theReconstructionist Rabbinical College is affiliated with the religion ofRheinmetall MAN Military Vehicles that was founded in 1885 and is headquartered inRimmel was founded inRioCan Real Estate Investment Trust is headquartered inRocky Mountain National Park, inRoger Staubach professionally plays the sport ofRogers Media formed in 2011 and is based inRoman Empire's capital,Rosenberg Trio is known for performing a variety of styles of music, includingRoyal National Theatre, inRuhollah Khomeini follows the religion ofRupert of Salzburg has the position of aRussell East Glacier belongs to the continent ofRussell Wilson professionally plays the sport ofRussian State Archive of Literature and Art's headquarters are inRyan Smyth professionally plays the sport ofSabinus of Spoleto holds the title of the firstSachimi Iwao is a citizen ofSadeq Larijani is a citizen ofSaikano was created in the country ofSaint Amandus holds the position of the firstSaint Boniface, whose position is that of aSaint Domnius, who has the position of theSaint-Louis-de-Kent, New Brunswick is located in the country ofSaint-Marcellin was created in the country ofSakichi Toyoda is a citizen ofSandy Bridge is developed bySangamam was created in the country ofSanto Stefano d'Aveto is located in the country ofSatoru Iwata is employed bySatya Nadella is employed bySaxony's capital,Scott Forstall is employed bySean Glennon plays in the position ofSecond French Empire's capital city isSecond Polish Republic's capital city isSecond Spanish Republic's capital,Seiyu Group's headquarters are inSelim I is affiliated with the religion ofSemyon Vorontsov was born inSergiu Luca plays the instrument of theSesamstraat is written inShah Alam II is affiliated with the religion ofShane McMahon is employed by theSharmila Tagore is affiliated with the religion ofShetland Islands, in the north ofShigeki Maruyama is a citizen ofShow Me a Hero premieres onSi la vie est cadeau is written inSialkot district is located in the country ofSiemiatycze is located in the country ofSir Charles Cayzer, 1st Baronet took up work in theSir Francis Baring, 1st Baronet worked in the city ofSir James Whitehead, 1st Baronet worked in the city ofSkype Technologies's owner,Sleater-Kinney, founded in 1991, is a feminist punk band fromSound Transit was formed in 1999 by a group ofSpain national football team is affiliated with theSpanish East Indies's capital,SpeedWeek debuted on theSt Patrick's Athletic F.C. is headquartered in the heart ofStamatios Kleanthis passed away inStephen Curry professionally plays the sport ofStephen Elop is employed byStephen Jay Gould's domain of work is the study of theSteve Ballmer is employed bySteve Jobs is employed bySubodh Kant Sahay is a citizen ofSunTrust Banks's headquarters are inSunday Night Baseball premieres onSuper Game Boy, created bySviatoslav Knushevitsky passed away inSydney Peace Prize is located in the country ofTaksim Military Barracks is located in the country ofTang Empire follows the religion of the same name, which is a mix ofTeemu Sälännä professionally plays the sport ofTeen Mom debuted onTenchi Universe was created in the country ofTerrell Owens professionally plays the sport ofThailand belongs to the continent ofThe Bays performs a variety of musical styles, fromThe Big Bang Theory premieres onThe Coca-Cola Company formed in 1886 and is headquartered inThe Cossacks was written in the early 20th century by aThe Hague belongs to the continent ofThe Lead with Jake Tapper premieres onThe Leftovers was released onThe New School for Jazz and Contemporary Music is located in the heart ofThe Physiological Society works in the area of theThe Tonight Show with Jay Leno premieres onThe Young and the Restless premieres onThe capital city of Commonwealth of England isThe capital city of Kingdom of Afghanistan isThe capital city of Kingdom of Hungary isThe capital city of Kingdom of the Netherlands isThe capital city of People's Republic of Poland isThe capital city of United Kingdom of the Netherlands isThe capital of Central Bohemian Region is the city ofThe capital of Fatimid caliphate is the city ofThe capital of Kyōto Prefecture is the city ofThe capital of Roman Republic isThe capital of Veneto is the city ofThe expertise of Paracelsus is not only in the field ofThe genre played by Casa Loma Orchestra is a blend of classical,The genre played by Christopher Paolini is a mix ofThe genre played by Mercer Ellington is the same as the one played by the greatThe genre played by Riverworld is a mix ofThe genre played by The Enchanter Reborn is a mix ofThe headquarter of All India Anna Dravida Munnetra Kazhagam is located in the city ofThe headquarter of Army of the Guardians of the Islamic Revolution is inThe headquarter of BC Hydro is in the heart of downtownThe headquarter of Chinese Skating Association is inThe headquarter of EMI is inThe headquarter of Fudan University is inThe headquarter of Lokalbahn AG is in the city ofThe headquarter of Minnesota Strikers is located in the heart of downtownThe headquarter of Russian Post is inThe headquarter of Soviet Air Defence Forces is inThe headquarter of State University of New York is inThe headquarter of Weta Digital is inThe headquarter of Zillow is in downtownThe language of Amar en tiempos revueltos is a mixture ofThe language of Anna Karenina is a perfect example of the way that theThe language of Dwynwen is a mixture ofThe language of El Mercurio was a mixture ofThe language of Electricidad was a mixture ofThe language of I ragazzi di via Panisperna was a mixture ofThe language of Il Postino: The Postman is a book about theThe language of Kavkaz Center is a bit different from the language of theThe language of L'Histoire was not the language of theThe language of La Hora was a mixture ofThe language of Lapland Odyssey is a mixture ofThe language of Mi Reflejo was a mixture ofThe language of Ni es lo mismo ni es igual was used by theThe language of Polisse was a mixture ofThe language used by Ch'ien Mu is very similar to the language used by theThe language used by Claude Henri de Rouvroy, comte de Saint-Simon is a good example of the way in which theThe language used by Enzo Cannavale is a bit of a departure from the usualThe language used by Guido Pieters is not the same as that used by theThe language used by Jean-Baptiste Marchand is not the language of theThe language used by Juan Bautista de Anza is a bit different from the language used by theThe language used by Louis Bonaparte is not the language of theThe language used by Musa Manarov is a mixture ofThe language used by Pedro Caro, 3rd Marquis of la Romana is a clear reference to theThe language used by Pierre de Marca is not the same as that used by theThe language used by William Fitzwilliam, 4th Earl Fitzwilliam is a very interesting example of the use of theThe location of 2000 Australian Open is in the heart ofThe location of 2011 Australian Open is in the heart ofThe location of 2013 Australian Open is inThe location of British Museum is in the heart ofThe location of Concordia University is in the heart of the city ofThe location of Galatasaray University is in the heart ofThe location of Harvard Law School is inThe location of Hungarian Ladies Open is in the heart ofThe location of Lotte World Tower is in the heart ofThe location of National Memorial Cemetery of the Pacific is in the heart of the city ofThe location of Parliament of Norway Building is in the centre ofThe location of Taliban insurgency is in the north-west ofThe native language of Alain Marleix isThe native language of Aleksey Khomyakov isThe native language of Alexandre Auguste Ledru-Rollin isThe native language of Alfred Savoir isThe native language of Anastasy Vonsyatsky isThe native language of Anne-Marie Idrac isThe native language of Ariane Labed isThe native language of Bernard Giraudeau isThe native language of Claude Bernard isThe native language of Corinne Calvet isThe native language of Delphine de Girardin isThe native language of Edward Bulwer-Lytton isThe native language of Gabrielle Fontan isThe native language of Georges Gorse isThe native language of Georges Pompidou isThe native language of Giunta Pisano isThe native language of Guy Drut isThe native language of Hendrikus Colijn isThe native language of Henriette-Julie de Murat isThe native language of Irina Khakamada isThe native language of Isabelle Breitman isThe native language of Laurent Lafitte isThe native language of Lee Chang-dong isThe native language of Louis-Nicolas Davout isThe native language of Luc Besson isThe native language of Marguerite Yourcenar isThe native language of Mathieu de Montmorency isThe native language of Maurice Faure isThe native language of Michel Modo isThe native language of Nathalie Kosciusko-Morizet isThe native language of Nicolaas Pierson isThe native language of Nikolay Strakhov isThe native language of Paul Klebnikov isThe native language of Pierre Alcover isThe native language of Pierre Blanchar isThe native language of Pierre Daniel Huet isThe native language of Pierre Lescure isThe native language of Roger Garaudy isThe native language of Sergey Aksyonov isThe native language of Valentin Rasputin isThe native language of Viacheslav Belavkin isThe native language of Victor Prosper Considerant isThe native language of Xavier Saint-Macary isThe native language of Yuliya Snigir isThe official language of Melitopol isThe official language of Peru isThe official religion of Talmud Torah school isThe original language of Celia en el colegio is a mixture ofThe original language of Chennai 600028 is a mixture ofThe original language of De Officiis was written inThe original language of De finibus bonorum et malorum is the same as theThe original language of Der kleine Vampir is aThe original language of Die Nibelungen was written inThe original language of Disquisitiones Arithmeticae isThe original language of Il Posto is a mixture ofThe original language of Il giuramento was written in the 14th century by theThe original language of La Fontaine's Fables is a mixture ofThe original language of La Jornada was written inThe original language of Le Globe isThe original language of Les Francs-juges isThe original language of Ma vie en rose is aThe original language of Neethaane En Ponvasantham is aThe original language of Passer à l'acte was written in the late 15th century by theThe original language of Plus belle la vie is aThe original language of Revue de Paris is aThe original language of Sadratnamala is aThe original language of Sous le ciel de Paris isThe original language of The Three Musketeers isThe original language of The Voice Israel isThe original language of Uutisvuoto is a mixture ofThe original language of Voyage to Cythera is a mixture ofThe original language of Yalkut Yosef was written inThe profession of Martha Nussbaum is to be aThelonious Monk, playing theThierry Henry professionally plays the sport ofTim Cook is employed byTim Horton professionally plays the sport ofTim Tebow plays in the position ofTime Machine (macOS) is developed byTizen is developed by a consortium of companies includingTokyo Mew Mew, that originated inTomaso Antonio Vitali plays the instrument of theTony Benn died in the city ofTrailer Park Boys premieres onTrento is located in the country ofTriple H is employed byTycho Brahe's expertise is in the field ofUkraine's capital,Ukrainian State's capital,Ulrika Eleonora, Queen of Sweden died in the city ofUnited Kingdom of Great Britain and Ireland's capital,United Launch Alliance, by contrast, is a joint venture betweenUnited States men's national soccer team is a part of theUniversity of Washington's headquarters are inUqba ibn Nafi is affiliated with the religion ofVale of Glamorgan, inVichy France's capital,Vierlingsbeek, in theVietnam belongs to the continent ofVilfredo Pareto works in the area of economics andVint Cerf is employed byWallonia belongs to the continent ofWalter Payton professionally plays the sport ofWayne Rooney professionally plays the sport ofWednesday Night Baseball premieres onWeimar Republic's capital,Werner Heisenberg, who works as aWerner von Blomberg worked in the city ofWii Balance Board is produced byWii MotionPlus is developed byWii U is developed byWillem Wilmink speaks to the media after theWindows 95 is developed byWindows Embedded CE 6.0 is created byWindows Genuine Advantage is a product of theWindows Internet Explorer 8 is developed byWindows Live Mail is developed byWindows Live Mesh is developed byWindows Live OneCare is developed byWindows Me is developed byWindows Media Audio, a product developed byWindows Media Player is developed byWindows Media Player's owner,Windows Mobile is developed byWindows Phone 7 is developed byWindows Phone 8.1 is developed byX11.app, a product developed byXamarin, from theXbox Game Studios's owner,Xbox's owner,Xbox, created byXeon is developed byYammer is owned byYanis Varoufakis's profession is anYellowstone National Park can be found in the state ofYitzhak Ben-Zvi worked in the city ofYork University can be found in the heart ofYoung Canadians was created in the country of its birth,Yuki Uchida is a citizen ofYusuf al-Qaradawi is affiliated with the religion ofYvan Goll is a native speaker ofZeno of Verona holds the position of the firstair traffic control works in the field ofaloha is written in thecaffeine, called after theiPad 4 is developed byiPhone 1 is developed byiPhone 3GS is developed byiPhone 4s is developed byiPhone is developed byiPod Classic is developed byiPod Mini is developed byiPod Touch is developed byiTunes Radio was created by the folks atiTunes Remote, created by the same people who created theiTunes is developed bymacOS Server was created by the community and is not supported bymacOS is developed bypublic transport in Istanbul is located in the country ofsamurai cinema, that originated instatistical model works in the field of' to numeric",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Attribute extraction statistics: Number of extracting layers\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Averaging over examples with >=1 extraction events. \u001b[39;00m\n\u001b[1;32m      4\u001b[0m tmp_ \u001b[38;5;241m=\u001b[39m tmp[\n\u001b[1;32m      5\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproj_vec\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattribute_in_top_1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      6\u001b[0m ]\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproj_vec\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattribute_in_top_1\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39magg(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m----> 7\u001b[0m display(\u001b[43mtmp_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtmp_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattribute_in_top_1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproj_vec\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index())\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Averaging over all the examples.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m tmp_ \u001b[38;5;241m=\u001b[39m tmp[\n\u001b[1;32m     11\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproj_vec\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattribute_in_top_1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     12\u001b[0m ]\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproj_vec\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39magg(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/core/groupby/generic.py:1442\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine_kwargs\n\u001b[1;32m   1441\u001b[0m op \u001b[38;5;241m=\u001b[39m GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m-> 1442\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict_like(func) \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1444\u001b[0m     \u001b[38;5;66;03m# GH #52849\u001b[39;00m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mas_index \u001b[38;5;129;01mand\u001b[39;00m is_list_like(func):\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/core/apply.py:172\u001b[0m, in \u001b[0;36mApply.agg\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    169\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(func):\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_dict_like()\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/core/apply.py:586\u001b[0m, in \u001b[0;36mApply.apply_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    585\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxis\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis\n\u001b[0;32m--> 586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/core/apply.py:669\u001b[0m, in \u001b[0;36mApply._apply_str\u001b[0;34m(self, obj, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    667\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, func)\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(f):\n\u001b[0;32m--> 669\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;66;03m# people may aggregate on a non-callable attribute\u001b[39;00m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;66;03m# but don't let them think they can pass args to it\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:2375\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[0;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[1;32m   2368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(\n\u001b[1;32m   2369\u001b[0m         grouped_mean,\n\u001b[1;32m   2370\u001b[0m         executor\u001b[38;5;241m.\u001b[39mfloat_dtype_mapping,\n\u001b[1;32m   2371\u001b[0m         engine_kwargs,\n\u001b[1;32m   2372\u001b[0m         min_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2373\u001b[0m     )\n\u001b[1;32m   2374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2375\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cython_agg_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2376\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2377\u001b[0m \u001b[43m        \u001b[49m\u001b[43malt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2378\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2379\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1926\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[0;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m   1923\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[1;32m   1924\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1926\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouped_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1927\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[1;32m   1928\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_aggregated_output(res)\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/core/internals/managers.py:1428\u001b[0m, in \u001b[0;36mBlockManager.grouped_reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_object:\n\u001b[1;32m   1425\u001b[0m     \u001b[38;5;66;03m# split on object-dtype blocks bc some columns may raise\u001b[39;00m\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;66;03m#  while others do not.\u001b[39;00m\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sb \u001b[38;5;129;01min\u001b[39;00m blk\u001b[38;5;241m.\u001b[39m_split():\n\u001b[0;32m-> 1428\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[43msb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1429\u001b[0m         result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/core/internals/blocks.py:366\u001b[0m, in \u001b[0;36mBlock.apply\u001b[0;34m(self, func, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[1;32m    362\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m     result \u001b[38;5;241m=\u001b[39m maybe_coerce_values(result)\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1923\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1923\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_agg_py_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1875\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[0;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[1;32m   1873\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magg function failed [how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mser\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1874\u001b[0m     \u001b[38;5;66;03m# preserve the kind of exception that raised\u001b[39;00m\n\u001b[0;32m-> 1875\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(err)(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1877\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ser\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m   1878\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m res_values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: agg function failed [how->mean,dtype->object]"
     ]
    }
   ],
   "source": [
    "# Attribute extraction statistics: Number of extracting layers\n",
    "\n",
    "# Averaging over examples with >=1 extraction events. \n",
    "tmp_ = tmp[\n",
    "    [\"prompt\", \"layer\", \"proj_vec\", \"attribute_in_top_1\"]\n",
    "].groupby([\"prompt\", \"proj_vec\", \"attribute_in_top_1\"]).agg(\"count\").reset_index()\n",
    "display(tmp_[tmp_.attribute_in_top_1 == True].groupby(\"proj_vec\").agg(\"mean\").reset_index())\n",
    "\n",
    "# Averaging over all the examples.\n",
    "tmp_ = tmp[\n",
    "    [\"prompt\", \"proj_vec\", \"attribute_in_top_1\"]\n",
    "].groupby([\"prompt\", \"proj_vec\"]).agg(\"sum\").reset_index()\n",
    "display(tmp_.groupby(\"proj_vec\").agg(\"mean\").reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1208\n",
      "MHSA_ex  MLP_ex\n",
      "True     False     47.102649\n",
      "False    False     21.605960\n",
      "True     True      21.109272\n",
      "False    True      10.182119\n",
      "Name: count, dtype: float64\n",
      "255\n",
      "MHSA_before_MLP\n",
      "True     82.352941\n",
      "False    17.647059\n",
      "Name: count, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27435/3131073167.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tmp__[\"MHSA_before_MLP\"] = tmp__.apply(lambda row: row.MHSA_first <= row.MLP_first, axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Correlation between ATTN vs. MLP extraction events\n",
    "\n",
    "tmp_ = tmp[tmp.proj_vec.isin([\"MHSA\", \"MLP\"])][\n",
    "    [\"prompt\", \"layer\", \"proj_vec\", \"attribute_in_top_1\"]\n",
    "].groupby([\"prompt\", \"layer\", \"proj_vec\"]).agg(\"max\").reset_index()\n",
    "\n",
    "tmp_ = tmp_.sort_values(by=[\"prompt\", \"layer\", \"proj_vec\"])\n",
    "tmp_ = tmp_.set_index(['prompt', 'layer', 'proj_vec'])['attribute_in_top_1'].unstack().reset_index()\n",
    "tmp_ = tmp_.sort_values(by=[\"prompt\", \"layer\"])\n",
    "\n",
    "tmp_[\"MHSA\"] = tmp_.apply(lambda row: int(row.MHSA) * (row.layer+1) - 1, axis=1)\n",
    "tmp_[\"MLP\"] = tmp_.apply(lambda row: int(row.MLP) * (row.layer+1) - 1, axis=1)\n",
    "tmp_ = tmp_[[\"prompt\", \"MHSA\", \"MLP\"]].groupby('prompt').agg(lambda x: [y for y in x.tolist() if y>-1]).reset_index()\n",
    "tmp_[\"MHSA_first\"] = tmp_.MHSA.apply(lambda x: min(x) if len(x) > 0 else -1)\n",
    "tmp_[\"MLP_first\"] = tmp_.MLP.apply(lambda x: min(x) if len(x) > 0 else -1)\n",
    "tmp_[\"MHSA_ex\"] = tmp_.MHSA.apply(lambda x: len(x) > 0)\n",
    "tmp_[\"MLP_ex\"] = tmp_.MLP.apply(lambda x: len(x) > 0)\n",
    "\n",
    "print(len(tmp_))\n",
    "print(tmp_[[\"MHSA_ex\", \"MLP_ex\"]].value_counts() * 100.0 / len(tmp_))\n",
    "\n",
    "tmp__ = tmp_[(tmp_.MHSA_ex == True) & (tmp_.MLP_ex == True)]\n",
    "assert tmp__.MHSA_first.min() > -1\n",
    "assert tmp__.MLP_first.min() > -1\n",
    "tmp__[\"MHSA_before_MLP\"] = tmp__.apply(lambda row: row.MHSA_first <= row.MLP_first, axis=1)\n",
    "print(len(tmp__))\n",
    "print(tmp__[\"MHSA_before_MLP\"].value_counts() * 100.0 / len(tmp__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "66it [25:43, 23.38s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 71\u001b[0m\n\u001b[1;32m     68\u001b[0m patch_hooks \u001b[38;5;241m=\u001b[39m set_hs_patch_hooks(mt\u001b[38;5;241m.\u001b[39mmodel, hs_patch_config, patch_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# run model on the same prompt\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mmt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# remove patching hooks\u001b[39;00m\n\u001b[1;32m     74\u001b[0m remove_hooks(patch_hooks)\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py:1046\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1046\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py:889\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    879\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    880\u001b[0m         create_custom_forward(block),\n\u001b[1;32m    881\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    886\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    887\u001b[0m     )\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py:389\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    387\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    388\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(hidden_states)\n\u001b[0;32m--> 389\u001b[0m attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    397\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[1;32m    398\u001b[0m outputs \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/torch/nn/modules/module.py:1148\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks)\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m-> 1148\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py:330\u001b[0m, in \u001b[0;36mGPT2Attention.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    328\u001b[0m     attn_output, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_upcast_and_reordered_attn(query, key, value, attention_mask, head_mask)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 330\u001b[0m     attn_output, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_heads(attn_output, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[1;32m    333\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_proj(attn_output)\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py:211\u001b[0m, in \u001b[0;36mGPT2Attention._attn\u001b[0;34m(self, query, key, value, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# Downcast (if necessary) back to V's dtype (if in mixed-precision) -- No-Op otherwise\u001b[39;00m\n\u001b[1;32m    210\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m attn_weights\u001b[38;5;241m.\u001b[39mtype(value\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 211\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn_dropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# Mask heads if we want to\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/torch/nn/modules/dropout.py:58\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/torch/nn/functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(p))\n\u001b[0;32m-> 1252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m(\u001b[38;5;28minput\u001b[39m, p, training)\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/torch/_VF.py:25\u001b[0m, in \u001b[0;36mVFModule.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28msuper\u001b[39m(VFModule, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(name)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvf \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_VariableFunctions\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvf, attr)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Attribute extraction rate with patching of early representations\n",
    "\n",
    "E = mt.model.get_output_embeddings().weight\n",
    "k = 10\n",
    "\n",
    "records = []\n",
    "for row_i, row in tqdm(knowns_df.iterrows()):\n",
    "    prompt = row.prompt\n",
    "    subject = row.subject\n",
    "    attribute = row.attribute\n",
    "    \n",
    "    inp = make_inputs(mt.tokenizer, [prompt])\n",
    "    input_tokens = decode_tokens(mt.tokenizer, inp[\"input_ids\"][0])\n",
    "    e_range = find_token_range(mt.tokenizer, inp[\"input_ids\"][0], subject)\n",
    "    e_range = [x for x in range(e_range[0], e_range[1])]\n",
    "    non_e_range = [x for x in range(len(input_tokens)-1) if x not in e_range]\n",
    "    source_index = len(input_tokens) - 1\n",
    "\n",
    "    # set hooks to get ATTN outputs\n",
    "    hooks = set_act_get_hooks(mt.model, source_index, attn_out=True)\n",
    "    \n",
    "    output = mt.model(**inp)\n",
    "    probs = torch.softmax(output[\"logits\"][:, -1], dim=1)\n",
    "    _, attribute_tok = torch.max(probs, dim=1)\n",
    "    attribute_tok = attribute_tok.cpu().item()\n",
    "    [attribute_tok_str] = decode_tokens(mt.tokenizer, [attribute_tok])\n",
    "    \n",
    "    activations = {key: val for key, val in mt.model.activations_.items()}\n",
    "    mt.model.activations_ = {}\n",
    "    \n",
    "\n",
    "    for layer in range(mt.num_layers):\n",
    "        # ATTN\n",
    "        attn_out = activations[f'attn_out_{layer}'][0]\n",
    "        proj = attn_out.matmul(E.T).cpu().numpy()\n",
    "        ind = np.argsort(-proj, axis=-1)\n",
    "        attribute_tok_rank = np.where(ind == attribute_tok)[0][0]\n",
    "        attribute_tok_score = proj[ind[attribute_tok_rank]]\n",
    "        top_k_preds = [decode_tokens(mt.tokenizer, [i])[0] for i in ind[:k]]\n",
    "        records.append({\n",
    "            \"prompt\": prompt,\n",
    "            \"subject\": subject,\n",
    "            \"attribute\": attribute,\n",
    "            \"attribute_tok\": attribute_tok,\n",
    "            \"attribute_tok_str\": attribute_tok_str,\n",
    "            \"layer\": layer,\n",
    "            \"proj_vec\": \"attn\",\n",
    "            \"top_k_preds\": top_k_preds,\n",
    "            \"attribute_tok_rank\": attribute_tok_rank,\n",
    "            \"attribute_tok_score\": attribute_tok_score,\n",
    "            \"attribute_in_top_1\": attribute_tok_rank == 0,\n",
    "            \"patch_desc\": \"-\",\n",
    "            \"patch_layer\": \"-\",\n",
    "        })\n",
    "\n",
    "        # ATTN over patched subject representations\n",
    "        for patch_positions, patch_desc in [(e_range, \"subject\"),\n",
    "                                            (non_e_range, \"non-subject\"),\n",
    "                                            ([source_index], \"last\")]:\n",
    "            for layer_ in [0, 1, 5, 10, 20]:\n",
    "                # set hooks to patch early hidden states\n",
    "                hs_patch_config = {\n",
    "                    layer: [\n",
    "                        (i, hs_cache[(prompt, layer_)][0][i])\n",
    "                        for i in patch_positions\n",
    "                    ]\n",
    "                }\n",
    "                patch_hooks = set_hs_patch_hooks(mt.model, hs_patch_config, patch_input=True)\n",
    "\n",
    "                # run model on the same prompt\n",
    "                _ = mt.model(**inp)\n",
    "\n",
    "                # remove patching hooks\n",
    "                remove_hooks(patch_hooks)\n",
    "\n",
    "                attn_out = mt.model.activations_[f'attn_out_{layer}'][0]\n",
    "                proj = attn_out.matmul(E.T).cpu().numpy()\n",
    "                ind = np.argsort(-proj, axis=-1)\n",
    "                attribute_tok_rank = np.where(ind == attribute_tok)[0][0]\n",
    "                attribute_tok_score = proj[ind[attribute_tok_rank]]\n",
    "                top_k_preds = [decode_tokens(mt.tokenizer, [i])[0] for i in ind[:k]]\n",
    "                records.append({\n",
    "                    \"prompt\": prompt,\n",
    "                    \"subject\": subject,\n",
    "                    \"attribute\": attribute,\n",
    "                    \"attribute_tok\": attribute_tok,\n",
    "                    \"attribute_tok_str\": attribute_tok_str,\n",
    "                    \"layer\": layer,\n",
    "                    \"proj_vec\": \"attn\",\n",
    "                    \"top_k_preds\": top_k_preds,\n",
    "                    \"attribute_tok_rank\": attribute_tok_rank,\n",
    "                    \"attribute_tok_score\": attribute_tok_score,\n",
    "                    \"attribute_in_top_1\": attribute_tok_rank == 0,\n",
    "                    \"patch_desc\": patch_desc,\n",
    "                    \"patch_layer\": str(layer_),\n",
    "                })\n",
    "                mt.model.activations_ = {}\n",
    "\n",
    "    # remove hooks\n",
    "    remove_hooks(hooks)\n",
    "\n",
    "tmp = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tmp_ = tmp[\n",
    "    [\"prompt\", \"patch_layer\", \"patch_desc\", \"attribute_in_top_1\"]\n",
    "].groupby([\"prompt\", \"patch_desc\", \"patch_layer\"]).agg(\"max\").reset_index()\n",
    "tmp__ = tmp_[[\"patch_layer\", \"patch_desc\", \"attribute_in_top_1\"]].groupby(\n",
    "    [\"patch_layer\", \"patch_desc\"]).agg(\"mean\").reset_index()\n",
    "\n",
    "tmp__[\"patch_layer_int\"] = tmp__.patch_layer.apply(lambda x: literal_eval(x) if x != \"-\" else -1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(4.5,2.5))\n",
    "order = [\"subject\", \"non-subject\", \"last\"]\n",
    "ax = sns.scatterplot(\n",
    "    x=\"patch_layer_int\", \n",
    "    y=f\"attribute_in_top_1\",\n",
    "    hue=\"patch_desc\", style=\"patch_desc\",\n",
    "    hue_order=order, style_order=order,\n",
    "    data=tmp__[tmp__.patch_layer != \"-\"],\n",
    "    palette=palette[:3],\n",
    "    s=100\n",
    ")\n",
    "ax.set_xlabel(\"layer used for patching\")\n",
    "ax.set_ylabel(f\"attribute extraction rate\")\n",
    "sns.move_legend(ax, \"lower right\", title=\"patched positions\", bbox_to_anchor=(1.01, -0.01), ncol=1)\n",
    "\n",
    "no_patch_mean = tmp__[tmp__.patch_layer == \"-\"][\"attribute_in_top_1\"].mean()\n",
    "plt.axhline(y=no_patch_mean, color=palette[4], linestyle='-', linewidth=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Comparing the attribute rank in the subject representation and in the attention output\n",
    "\n",
    "E = mt.model.get_output_embeddings().weight\n",
    "\n",
    "records = []\n",
    "for row_i, row in tqdm(knowns_df.iterrows()):\n",
    "    prompt = row.prompt\n",
    "    subject = row.subject\n",
    "    attribute = row.attribute\n",
    "    \n",
    "    inp = make_inputs(mt.tokenizer, [prompt])\n",
    "    output = mt.model(**inp)\n",
    "    probs = torch.softmax(output[\"logits\"][:, -1], dim=1)\n",
    "    _, attribute_tok = torch.max(probs, dim=1)\n",
    "    attribute_tok = attribute_tok.cpu().item()\n",
    "    [attribute_tok_str] = decode_tokens(mt.tokenizer, [attribute_tok])\n",
    "    \n",
    "    input_tokens = decode_tokens(mt.tokenizer, inp[\"input_ids\"][0])\n",
    "    e_range = find_token_range(mt.tokenizer, inp[\"input_ids\"][0], subject)\n",
    "    e_range = [x for x in range(e_range[0], e_range[1])]\n",
    "    source_index = len(input_tokens) - 1\n",
    "    \n",
    "    # set hooks to get ATTN and MLP outputs\n",
    "    hooks = set_act_get_hooks(mt.model, source_index, mlp=True, attn_out=True)\n",
    "    output = mt.model(**inp)\n",
    "    # remove hooks\n",
    "    remove_hooks(hooks)\n",
    "    \n",
    "    for layer in range(mt.num_layers):\n",
    "        attn_out = mt.model.activations_[f'attn_out_{layer}'][0]\n",
    "        proj_attn = attn_out.matmul(E.T).cpu().numpy()\n",
    "        ind_attn = np.argsort(-proj_attn, axis=-1)\n",
    "        attribute_tok_rank_attn = np.where(ind_attn == attribute_tok)[0][0]\n",
    "        \n",
    "        subj_hs = subject_cache[(subject, layer)][0]\n",
    "        proj_hs = subj_hs.matmul(E.T).cpu().numpy()\n",
    "        ind_hs = np.argsort(-proj_hs, axis=-1)\n",
    "        attribute_tok_rank_hs = np.where(ind_hs == attribute_tok)[0][0]\n",
    "        attribute_tok_rank_diff = attribute_tok_rank_hs - attribute_tok_rank_attn\n",
    "        \n",
    "        records.append({\n",
    "            \"prompt\": prompt,\n",
    "            \"subject\": subject,\n",
    "            \"attribute\": attribute,\n",
    "            \"attribute_tok\": attribute_tok,\n",
    "            \"attribute_tok_str\": attribute_tok_str,\n",
    "            \"layer\": layer,\n",
    "            \"attribute_tok_rank_attn\": attribute_tok_rank_attn,\n",
    "            \"attribute_tok_rank_hs\": attribute_tok_rank_hs,\n",
    "            \"attribute_tok_rank_diff\": attribute_tok_rank_diff,\n",
    "            \"attribute_in_top_1_attn\": attribute_tok == ind_attn[0],\n",
    "            \"attribute_in_top_1_hs\": attribute_tok == ind_hs[0],\n",
    "            })\n",
    "        \n",
    "tmp = pd.DataFrame.from_records(records)\n",
    "print(tmp[tmp[f\"attribute_in_top_1_attn\"] == True][\"attribute_tok_rank_diff\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject enrichment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Get token representations' projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = mt.model.get_output_embeddings().weight.detach() \n",
    "k = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:  Vinson Massif is located in the continent of\n",
      "subject:  Vinson Massif\n",
      "token_array:  tensor([    1, 12540,  1100,  7360,   361,   338,  5982,   297,   278, 25523,\n",
      "          310], device='cuda:0')\n",
      "toks:  ['<s>', '▁Vin', 'son', '▁Mass', 'if', '▁is', '▁located', '▁in', '▁the', '▁continent', '▁of']\n",
      "whole_string:  <s>Vinson Massif is located in the continent of\n",
      "substring:  Vinson Massif\n",
      "char_loc:  4\n",
      "e_range:  (1, 5)\n",
      "prompt:  Beats Music is owned by\n",
      "subject:  Beats Music\n",
      "token_array:  tensor([    1,  1522,  1446,  6125,   338, 15205,   491], device='cuda:0')\n",
      "toks:  ['<s>', '▁Be', 'ats', '▁Music', '▁is', '▁owned', '▁by']\n",
      "whole_string:  <s>Beats Music is owned by\n",
      "substring:  Beats Music\n",
      "char_loc:  4\n",
      "e_range:  (1, 4)\n",
      "prompt:  Audible.com is owned by\n",
      "subject:  Audible.com\n",
      "token_array:  tensor([    1,  8612,  1821, 29889,   510,   338, 15205,   491],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Aud', 'ible', '.', 'com', '▁is', '▁owned', '▁by']\n",
      "whole_string:  <s>Audible.com is owned by\n",
      "substring:  Audible.com\n",
      "char_loc:  4\n",
      "e_range:  (1, 5)\n",
      "prompt:  The Big Bang Theory premieres on\n",
      "subject:  The Big Bang Theory\n",
      "token_array:  tensor([    1,   450,  7997, 14320, 24134,  7017,   267,   373],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁The', '▁Big', '▁Bang', '▁Theory', '▁premier', 'es', '▁on']\n",
      "whole_string:  <s>The Big Bang Theory premieres on\n",
      "substring:  The Big Bang Theory\n",
      "char_loc:  4\n",
      "e_range:  (1, 5)\n",
      "prompt:  MacApp, a product created by\n",
      "subject:  MacApp\n",
      "token_array:  tensor([    1,  4326,  2052, 29892,   263,  3234,  2825,   491],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Mac', 'App', ',', '▁a', '▁product', '▁created', '▁by']\n",
      "whole_string:  <s>MacApp, a product created by\n",
      "substring:  MacApp\n",
      "char_loc:  4\n",
      "e_range:  (1, 3)\n",
      "prompt:  Giuseppe Angeli, who has a citizenship of\n",
      "subject:  Giuseppe Angeli\n",
      "token_array:  tensor([    1, 18824,  3218,  5037, 29892,  1058,   756,   263, 18363,  4034,\n",
      "          310], device='cuda:0')\n",
      "toks:  ['<s>', '▁Giuseppe', '▁Ang', 'eli', ',', '▁who', '▁has', '▁a', '▁citizens', 'hip', '▁of']\n",
      "whole_string:  <s>Giuseppe Angeli, who has a citizenship of\n",
      "substring:  Giuseppe Angeli\n",
      "char_loc:  4\n",
      "e_range:  (1, 4)\n",
      "prompt:  Catalonia belongs to the continent of\n",
      "subject:  Catalonia\n",
      "token_array:  tensor([    1, 11732,  6405, 14393,   304,   278, 25523,   310],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Catal', 'onia', '▁belongs', '▁to', '▁the', '▁continent', '▁of']\n",
      "whole_string:  <s>Catalonia belongs to the continent of\n",
      "substring:  Catalonia\n",
      "char_loc:  4\n",
      "e_range:  (1, 3)\n",
      "prompt:  In Marshall Islands, the language spoken is a mixture of\n",
      "subject:  Marshall Islands\n",
      "token_array:  tensor([    1,   512, 23072, 17839, 29892,   278,  4086, 19182,   338,   263,\n",
      "        29544,   310], device='cuda:0')\n",
      "toks:  ['<s>', '▁In', '▁Marshall', '▁Islands', ',', '▁the', '▁language', '▁spoken', '▁is', '▁a', '▁mixture', '▁of']\n",
      "whole_string:  <s>In Marshall Islands, the language spoken is a mixture of\n",
      "substring:  Marshall Islands\n",
      "char_loc:  7\n",
      "e_range:  (2, 4)\n",
      "prompt:  Leslie Moonves is employed by\n",
      "subject:  Leslie Moonves\n",
      "token_array:  tensor([    1,  2664,  3197, 17549,  1960,   338, 15723,   491],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Les', 'lie', '▁Moon', 'ves', '▁is', '▁employed', '▁by']\n",
      "whole_string:  <s>Leslie Moonves is employed by\n",
      "substring:  Leslie Moonves\n",
      "char_loc:  4\n",
      "e_range:  (1, 5)\n",
      "prompt:  The original language of De finibus bonorum et malorum is the same as the\n",
      "subject:  De finibus bonorum et malorum\n",
      "token_array:  tensor([    1,   450,  2441,  4086,   310,   897,  1436, 19699, 10814, 17220,\n",
      "          634,  4439, 17220,   338,   278,  1021,   408,   278],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁The', '▁original', '▁language', '▁of', '▁De', '▁fin', 'ibus', '▁bon', 'orum', '▁et', '▁mal', 'orum', '▁is', '▁the', '▁same', '▁as', '▁the']\n",
      "whole_string:  <s>The original language of De finibus bonorum et malorum is the same as the\n",
      "substring:  De finibus bonorum et malorum\n",
      "char_loc:  29\n",
      "e_range:  (5, 13)\n",
      "prompt:  Kirkpatrick Glacier belongs to the continent of\n",
      "subject:  Kirkpatrick Glacier\n",
      "token_array:  tensor([    1, 26424,  5031,  9131, 19798, 13241, 14393,   304,   278, 25523,\n",
      "          310], device='cuda:0')\n",
      "toks:  ['<s>', '▁Kirk', 'pat', 'rick', '▁Gla', 'cier', '▁belongs', '▁to', '▁the', '▁continent', '▁of']\n",
      "whole_string:  <s>Kirkpatrick Glacier belongs to the continent of\n",
      "substring:  Kirkpatrick Glacier\n",
      "char_loc:  4\n",
      "e_range:  (1, 6)\n",
      "prompt:  The headquarter of Army of the Guardians of the Islamic Revolution is in\n",
      "subject:  Army of the Guardians of the Islamic Revolution\n",
      "token_array:  tensor([    1,   450,  2343,   339,  4254,   310,  8811,   310,   278, 13211,\n",
      "         5834,   310,   278, 16427,   293, 14595,   338,   297],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁The', '▁head', 'qu', 'arter', '▁of', '▁Army', '▁of', '▁the', '▁Guard', 'ians', '▁of', '▁the', '▁Islam', 'ic', '▁Revolution', '▁is', '▁in']\n",
      "whole_string:  <s>The headquarter of Army of the Guardians of the Islamic Revolution is in\n",
      "substring:  Army of the Guardians of the Islamic Revolution\n",
      "char_loc:  23\n",
      "e_range:  (6, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [00:00, 52.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:  Il Gazzettino was written in the early 1980s, when the\n",
      "subject:  Il Gazzettino\n",
      "token_array:  tensor([    1,  1720,   402,  7511,  1803,  1789,   471,  3971,   297,   278,\n",
      "         4688, 29871, 29896, 29929, 29947, 29900, 29879, 29892,   746,   278],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Il', '▁G', 'azz', 'ett', 'ino', '▁was', '▁written', '▁in', '▁the', '▁early', '▁', '1', '9', '8', '0', 's', ',', '▁when', '▁the']\n",
      "whole_string:  <s>Il Gazzettino was written in the early 1980s, when the\n",
      "substring:  Il Gazzettino\n",
      "char_loc:  4\n",
      "e_range:  (1, 6)\n",
      "prompt:  Xamarin, from the\n",
      "subject:  Xamarin\n",
      "token_array:  tensor([    1,  1060, 18257, 29892,   515,   278], device='cuda:0')\n",
      "toks:  ['<s>', '▁X', 'amarin', ',', '▁from', '▁the']\n",
      "whole_string:  <s>Xamarin, from the\n",
      "substring:  Xamarin\n",
      "char_loc:  4\n",
      "e_range:  (1, 3)\n",
      "prompt:  Eavan Boland was born in\n",
      "subject:  Eavan Boland\n",
      "token_array:  tensor([    1,   382, 29080,  8922,   392,   471,  6345,   297],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁E', 'avan', '▁Bol', 'and', '▁was', '▁born', '▁in']\n",
      "whole_string:  <s>Eavan Boland was born in\n",
      "substring:  Eavan Boland\n",
      "char_loc:  4\n",
      "e_range:  (1, 5)\n",
      "prompt:  Comme j'ai mal is written in\n",
      "subject:  Comme j'ai mal\n",
      "token_array:  tensor([    1,   422,  1004,   432, 29915,  1794,  4439,   338,  3971,   297],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Com', 'me', '▁j', \"'\", 'ai', '▁mal', '▁is', '▁written', '▁in']\n",
      "whole_string:  <s>Comme j'ai mal is written in\n",
      "substring:  Comme j'ai mal\n",
      "char_loc:  4\n",
      "e_range:  (1, 7)\n",
      "prompt:  The language used by Juan Bautista de Anza is a bit different from the language used by the\n",
      "subject:  Juan Bautista de Anza\n",
      "token_array:  tensor([   1,  450, 4086, 1304,  491, 8699,  350, 1300, 2079,  316,  530, 1362,\n",
      "         338,  263, 2586, 1422,  515,  278, 4086, 1304,  491,  278],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁The', '▁language', '▁used', '▁by', '▁Juan', '▁B', 'aut', 'ista', '▁de', '▁An', 'za', '▁is', '▁a', '▁bit', '▁different', '▁from', '▁the', '▁language', '▁used', '▁by', '▁the']\n",
      "whole_string:  <s>The language used by Juan Bautista de Anza is a bit different from the language used by the\n",
      "substring:  Juan Bautista de Anza\n",
      "char_loc:  25\n",
      "e_range:  (5, 12)\n",
      "prompt:  Alfred Hitchcock Presents debuted on\n",
      "subject:  Alfred Hitchcock Presents\n",
      "token_array:  tensor([    1, 12299,   379,  2335, 24956,  4360,  1237,  2553,  3860,   373],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Alfred', '▁H', 'itch', 'cock', '▁Pres', 'ents', '▁deb', 'uted', '▁on']\n",
      "whole_string:  <s>Alfred Hitchcock Presents debuted on\n",
      "substring:  Alfred Hitchcock Presents\n",
      "char_loc:  4\n",
      "e_range:  (1, 7)\n",
      "prompt:  Tizen is developed by a consortium of companies including\n",
      "subject:  Tizen\n",
      "token_array:  tensor([    1,   323, 19642,   338,  8906,   491,   263,  1136,   441,  1974,\n",
      "          310, 14582,  3704], device='cuda:0')\n",
      "toks:  ['<s>', '▁T', 'izen', '▁is', '▁developed', '▁by', '▁a', '▁cons', 'ort', 'ium', '▁of', '▁companies', '▁including']\n",
      "whole_string:  <s>Tizen is developed by a consortium of companies including\n",
      "substring:  Tizen\n",
      "char_loc:  4\n",
      "e_range:  (1, 3)\n",
      "prompt:  Honus Wagner professionally plays the sport of\n",
      "subject:  Honus Wagner\n",
      "token_array:  tensor([    1,  7906,   375, 25439,  6351,   635, 13582,   278,  7980,   310],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Hon', 'us', '▁Wagner', '▁profession', 'ally', '▁plays', '▁the', '▁sport', '▁of']\n",
      "whole_string:  <s>Honus Wagner professionally plays the sport of\n",
      "substring:  Honus Wagner\n",
      "char_loc:  4\n",
      "e_range:  (1, 4)\n",
      "prompt:  samurai cinema, that originated in\n",
      "subject:  samurai cinema\n",
      "token_array:  tensor([    1,  3514,   332,  1794, 24615, 29892,   393,  3978,   630,   297],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁sam', 'ur', 'ai', '▁cinema', ',', '▁that', '▁origin', 'ated', '▁in']\n",
      "whole_string:  <s>samurai cinema, that originated in\n",
      "substring:  samurai cinema\n",
      "char_loc:  4\n",
      "e_range:  (1, 5)\n",
      "prompt:  The capital of Roman Republic is\n",
      "subject:  Roman Republic\n",
      "token_array:  tensor([   1,  450, 7483,  310, 5917, 8063,  338], device='cuda:0')\n",
      "toks:  ['<s>', '▁The', '▁capital', '▁of', '▁Roman', '▁Republic', '▁is']\n",
      "whole_string:  <s>The capital of Roman Republic is\n",
      "substring:  Roman Republic\n",
      "char_loc:  19\n",
      "e_range:  (4, 6)\n",
      "prompt:  Henri Debain was born in\n",
      "subject:  Henri Debain\n",
      "token_array:  tensor([    1, 11931,  7089,   475,   471,  6345,   297], device='cuda:0')\n",
      "toks:  ['<s>', '▁Henri', '▁Deb', 'ain', '▁was', '▁born', '▁in']\n",
      "whole_string:  <s>Henri Debain was born in\n",
      "substring:  Henri Debain\n",
      "char_loc:  4\n",
      "e_range:  (1, 4)\n",
      "prompt:  Adriano Celentano is a citizen of\n",
      "subject:  Adriano Celentano\n",
      "token_array:  tensor([    1, 27449,  1562, 14227,   296,  1562,   338,   263, 14497,   264,\n",
      "          310], device='cuda:0')\n",
      "toks:  ['<s>', '▁Adri', 'ano', '▁Cel', 'ent', 'ano', '▁is', '▁a', '▁citiz', 'en', '▁of']\n",
      "whole_string:  <s>Adriano Celentano is a citizen of\n",
      "substring:  Adriano Celentano\n",
      "char_loc:  4\n",
      "e_range:  (1, 6)\n",
      "prompt:  Czech Republic national football team is a member of the\n",
      "subject:  Czech Republic national football team\n",
      "token_array:  tensor([    1, 21489,  8063,  4797,  5733,  3815,   338,   263,  4509,   310,\n",
      "          278], device='cuda:0')\n",
      "toks:  ['<s>', '▁Czech', '▁Republic', '▁national', '▁football', '▁team', '▁is', '▁a', '▁member', '▁of', '▁the']\n",
      "whole_string:  <s>Czech Republic national football team is a member of the\n",
      "substring:  Czech Republic national football team\n",
      "char_loc:  4\n",
      "e_range:  (1, 6)\n",
      "prompt:  Windows Media Player is developed by\n",
      "subject:  Windows Media Player\n",
      "token_array:  tensor([    1,  3852,  8213, 14574,   338,  8906,   491], device='cuda:0')\n",
      "toks:  ['<s>', '▁Windows', '▁Media', '▁Player', '▁is', '▁developed', '▁by']\n",
      "whole_string:  <s>Windows Media Player is developed by\n",
      "substring:  Windows Media Player\n",
      "char_loc:  4\n",
      "e_range:  (1, 4)\n",
      "prompt:  NTFS is developed by\n",
      "subject:  NTFS\n",
      "token_array:  tensor([    1,   405,  8969, 29903,   338,  8906,   491], device='cuda:0')\n",
      "toks:  ['<s>', '▁N', 'TF', 'S', '▁is', '▁developed', '▁by']\n",
      "whole_string:  <s>NTFS is developed by\n",
      "substring:  NTFS\n",
      "char_loc:  4\n",
      "e_range:  (1, 4)\n",
      "prompt:  Knud, Hereditary Prince of Denmark passed away in\n",
      "subject:  Knud, Hereditary Prince of Denmark\n",
      "token_array:  tensor([    1,  8360,   566, 29892,  2439,  5628,   653, 10787,   310,  3384,\n",
      "         3502,  4502,  3448,   297], device='cuda:0')\n",
      "toks:  ['<s>', '▁Kn', 'ud', ',', '▁Her', 'edit', 'ary', '▁Prince', '▁of', '▁Den', 'mark', '▁passed', '▁away', '▁in']\n",
      "whole_string:  <s>Knud, Hereditary Prince of Denmark passed away in\n",
      "substring:  Knud, Hereditary Prince of Denmark\n",
      "char_loc:  4\n",
      "e_range:  (1, 11)\n",
      "prompt:  Don Shula professionally plays the sport of\n",
      "subject:  Don Shula\n",
      "token_array:  tensor([    1,  3872,  1383,  2497,  6351,   635, 13582,   278,  7980,   310],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Don', '▁Sh', 'ula', '▁profession', 'ally', '▁plays', '▁the', '▁sport', '▁of']\n",
      "whole_string:  <s>Don Shula professionally plays the sport of\n",
      "substring:  Don Shula\n",
      "char_loc:  4\n",
      "e_range:  (1, 4)\n",
      "prompt:  The language of El Mercurio was a mixture of\n",
      "subject:  El Mercurio\n",
      "token_array:  tensor([    1,   450,  4086,   310,  1260, 29389,   601,   471,   263, 29544,\n",
      "          310], device='cuda:0')\n",
      "toks:  ['<s>', '▁The', '▁language', '▁of', '▁El', '▁Mercur', 'io', '▁was', '▁a', '▁mixture', '▁of']\n",
      "whole_string:  <s>The language of El Mercurio was a mixture of\n",
      "substring:  El Mercurio\n",
      "char_loc:  20\n",
      "e_range:  (4, 7)\n",
      "prompt:  Iron Man is affiliated with the\n",
      "subject:  Iron Man\n",
      "token_array:  tensor([    1, 20492,  2315,   338, 23736,   630,   411,   278],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Iron', '▁Man', '▁is', '▁affili', 'ated', '▁with', '▁the']\n",
      "whole_string:  <s>Iron Man is affiliated with the\n",
      "substring:  Iron Man\n",
      "char_loc:  4\n",
      "e_range:  (1, 3)\n",
      "prompt:  The location of Massachusetts Institute of Technology is in\n",
      "subject:  Massachusetts Institute of Technology\n",
      "token_array:  tensor([    1,   450,  4423,   310, 16167,  8907,   310, 17968,   338,   297],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁The', '▁location', '▁of', '▁Massachusetts', '▁Institute', '▁of', '▁Technology', '▁is', '▁in']\n",
      "whole_string:  <s>The location of Massachusetts Institute of Technology is in\n",
      "substring:  Massachusetts Institute of Technology\n",
      "char_loc:  20\n",
      "e_range:  (4, 8)\n",
      "prompt:  Vietnam belongs to the continent of\n",
      "subject:  Vietnam\n",
      "token_array:  tensor([    1, 18444, 14393,   304,   278, 25523,   310], device='cuda:0')\n",
      "toks:  ['<s>', '▁Vietnam', '▁belongs', '▁to', '▁the', '▁continent', '▁of']\n",
      "whole_string:  <s>Vietnam belongs to the continent of\n",
      "substring:  Vietnam\n",
      "char_loc:  4\n",
      "e_range:  (1, 2)\n",
      "prompt:  The Tonight Show with Jay Leno premieres on\n",
      "subject:  The Tonight Show with Jay Leno\n",
      "token_array:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [00:00, 91.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    1,   450, 17812,   523,  7704,   411, 19556,   365,  8154,  7017,\n",
      "          267,   373], device='cuda:0')\n",
      "toks:  ['<s>', '▁The', '▁Ton', 'ight', '▁Show', '▁with', '▁Jay', '▁L', 'eno', '▁premier', 'es', '▁on']\n",
      "whole_string:  <s>The Tonight Show with Jay Leno premieres on\n",
      "substring:  The Tonight Show with Jay Leno\n",
      "char_loc:  4\n",
      "e_range:  (1, 9)\n",
      "prompt:  Philippines's capital,\n",
      "subject:  Philippines\n",
      "token_array:  tensor([    1, 26260, 29915, 29879,  7483, 29892], device='cuda:0')\n",
      "toks:  ['<s>', '▁Philippines', \"'\", 's', '▁capital', ',']\n",
      "whole_string:  <s>Philippines's capital,\n",
      "substring:  Philippines\n",
      "char_loc:  4\n",
      "e_range:  (1, 2)\n",
      "prompt:  Frederick Banting specializes in the study of the\n",
      "subject:  Frederick Banting\n",
      "token_array:  tensor([    1, 19769,   350,   424,   292,  4266,  7093,   297,   278,  6559,\n",
      "          310,   278], device='cuda:0')\n",
      "toks:  ['<s>', '▁Frederick', '▁B', 'ant', 'ing', '▁special', 'izes', '▁in', '▁the', '▁study', '▁of', '▁the']\n",
      "whole_string:  <s>Frederick Banting specializes in the study of the\n",
      "substring:  Frederick Banting\n",
      "char_loc:  4\n",
      "e_range:  (1, 5)\n",
      "prompt:  Clifford Curzon, performing on the\n",
      "subject:  Clifford Curzon\n",
      "token_array:  tensor([    1,  2233,  2593,   536, 10837,  6626, 29892, 15859,   373,   278],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Cl', 'iff', 'ord', '▁Cur', 'zon', ',', '▁performing', '▁on', '▁the']\n",
      "whole_string:  <s>Clifford Curzon, performing on the\n",
      "substring:  Clifford Curzon\n",
      "char_loc:  4\n",
      "e_range:  (1, 6)\n",
      "prompt:  Windows Media Audio, a product developed by\n",
      "subject:  Windows Media Audio\n",
      "token_array:  tensor([    1,  3852,  8213, 21764, 29892,   263,  3234,  8906,   491],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Windows', '▁Media', '▁Audio', ',', '▁a', '▁product', '▁developed', '▁by']\n",
      "whole_string:  <s>Windows Media Audio, a product developed by\n",
      "substring:  Windows Media Audio\n",
      "char_loc:  4\n",
      "e_range:  (1, 4)\n",
      "prompt:  The location of Galatasaray University is in the heart of\n",
      "subject:  Galatasaray University\n",
      "token_array:  tensor([   1,  450, 4423,  310, 5208,  271,  294,  279,  388, 3014,  338,  297,\n",
      "         278, 5192,  310], device='cuda:0')\n",
      "toks:  ['<s>', '▁The', '▁location', '▁of', '▁Gal', 'at', 'as', 'ar', 'ay', '▁University', '▁is', '▁in', '▁the', '▁heart', '▁of']\n",
      "whole_string:  <s>The location of Galatasaray University is in the heart of\n",
      "substring:  Galatasaray University\n",
      "char_loc:  20\n",
      "e_range:  (4, 10)\n",
      "prompt:  In Nokia, the language spoken is\n",
      "subject:  Nokia\n",
      "token_array:  tensor([    1,   512,   405,   554,   423, 29892,   278,  4086, 19182,   338],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁In', '▁N', 'ok', 'ia', ',', '▁the', '▁language', '▁spoken', '▁is']\n",
      "whole_string:  <s>In Nokia, the language spoken is\n",
      "substring:  Nokia\n",
      "char_loc:  7\n",
      "e_range:  (2, 5)\n",
      "prompt:  Northern Nigeria Protectorate follows the religion of\n",
      "subject:  Northern Nigeria Protectorate\n",
      "token_array:  tensor([    1, 14299, 20537,   423, 14409,  2801,   403,  4477,   278, 13433,\n",
      "          310], device='cuda:0')\n",
      "toks:  ['<s>', '▁Northern', '▁Niger', 'ia', '▁Prote', 'ctor', 'ate', '▁follows', '▁the', '▁religion', '▁of']\n",
      "whole_string:  <s>Northern Nigeria Protectorate follows the religion of\n",
      "substring:  Northern Nigeria Protectorate\n",
      "char_loc:  4\n",
      "e_range:  (1, 7)\n",
      "prompt:  Deobandi follows the religion of\n",
      "subject:  Deobandi\n",
      "token_array:  tensor([    1,   897,   711,   392, 29875,  4477,   278, 13433,   310],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁De', 'ob', 'and', 'i', '▁follows', '▁the', '▁religion', '▁of']\n",
      "whole_string:  <s>Deobandi follows the religion of\n",
      "substring:  Deobandi\n",
      "char_loc:  4\n",
      "e_range:  (1, 5)\n",
      "prompt:  Odnoklassniki was written in the early 1990s by a group of\n",
      "subject:  Odnoklassniki\n",
      "token_array:  tensor([    1,   438,  5200,   554,   605,  5585, 29875,   471,  3971,   297,\n",
      "          278,  4688, 29871, 29896, 29929, 29929, 29900, 29879,   491,   263,\n",
      "         2318,   310], device='cuda:0')\n",
      "toks:  ['<s>', '▁O', 'dn', 'ok', 'lass', 'nik', 'i', '▁was', '▁written', '▁in', '▁the', '▁early', '▁', '1', '9', '9', '0', 's', '▁by', '▁a', '▁group', '▁of']\n",
      "whole_string:  <s>Odnoklassniki was written in the early 1990s by a group of\n",
      "substring:  Odnoklassniki\n",
      "char_loc:  4\n",
      "e_range:  (1, 7)\n",
      "prompt:  Zeno of Verona holds the position of the first\n",
      "subject:  Zeno of Verona\n",
      "token_array:  tensor([   1,  796, 8154,  310, 1798, 2681, 8640,  278, 2602,  310,  278,  937],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Z', 'eno', '▁of', '▁Ver', 'ona', '▁holds', '▁the', '▁position', '▁of', '▁the', '▁first']\n",
      "whole_string:  <s>Zeno of Verona holds the position of the first\n",
      "substring:  Zeno of Verona\n",
      "char_loc:  4\n",
      "e_range:  (1, 6)\n",
      "prompt:  Jean-Pierre Van Rossem, who has a citizenship of\n",
      "subject:  Jean-Pierre Van Rossem\n",
      "token_array:  tensor([    1,  4581, 29899, 19621,  6556, 13693,   331, 29892,  1058,   756,\n",
      "          263, 18363,  4034,   310], device='cuda:0')\n",
      "toks:  ['<s>', '▁Jean', '-', 'Pierre', '▁Van', '▁Ross', 'em', ',', '▁who', '▁has', '▁a', '▁citizens', 'hip', '▁of']\n",
      "whole_string:  <s>Jean-Pierre Van Rossem, who has a citizenship of\n",
      "substring:  Jean-Pierre Van Rossem\n",
      "char_loc:  4\n",
      "e_range:  (1, 7)\n",
      "prompt:  Joseph Schumpeter's domain of work is the\n",
      "subject:  Joseph Schumpeter\n",
      "token_array:  tensor([    1,  6936,  1102,  3427,  1308, 29915, 29879,  5354,   310,   664,\n",
      "          338,   278], device='cuda:0')\n",
      "toks:  ['<s>', '▁Joseph', '▁Sch', 'ump', 'eter', \"'\", 's', '▁domain', '▁of', '▁work', '▁is', '▁the']\n",
      "whole_string:  <s>Joseph Schumpeter's domain of work is the\n",
      "substring:  Joseph Schumpeter\n",
      "char_loc:  4\n",
      "e_range:  (1, 5)\n",
      "prompt:  Felix Salmon, who works as a\n",
      "subject:  Felix Salmon\n",
      "token_array:  tensor([    1, 26346,  3956,  3712, 29892,  1058,  1736,   408,   263],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Felix', '▁Sal', 'mon', ',', '▁who', '▁works', '▁as', '▁a']\n",
      "whole_string:  <s>Felix Salmon, who works as a\n",
      "substring:  Felix Salmon\n",
      "char_loc:  4\n",
      "e_range:  (1, 4)\n",
      "prompt:  Grand Duchy of Finland's capital,\n",
      "subject:  Grand Duchy of Finland\n",
      "token_array:  tensor([    1,  6265, 23568, 29891,   310, 18312, 29915, 29879,  7483, 29892],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Grand', '▁Duch', 'y', '▁of', '▁Finland', \"'\", 's', '▁capital', ',']\n",
      "whole_string:  <s>Grand Duchy of Finland's capital,\n",
      "substring:  Grand Duchy of Finland\n",
      "char_loc:  4\n",
      "e_range:  (1, 6)\n",
      "prompt:  Goodreads owner, and former\n",
      "subject:  Goodreads\n",
      "token_array:  tensor([    1,  7197,   949, 29879, 12271, 29892,   322,  4642],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Good', 'read', 's', '▁owner', ',', '▁and', '▁former']\n",
      "whole_string:  <s>Goodreads owner, and former\n",
      "substring:  Goodreads\n",
      "char_loc:  4\n",
      "e_range:  (1, 4)\n",
      "prompt:  Rhine belongs to the continent of\n",
      "subject:  Rhine\n",
      "token_array:  tensor([    1,  7861,   457, 14393,   304,   278, 25523,   310],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Rh', 'ine', '▁belongs', '▁to', '▁the', '▁continent', '▁of']\n",
      "whole_string:  <s>Rhine belongs to the continent of\n",
      "substring:  Rhine\n",
      "char_loc:  4\n",
      "e_range:  (1, 3)\n",
      "prompt:  Muawiyah I is affiliated with the religion of\n",
      "subject:  Muawiyah I\n",
      "token_array:  tensor([    1,  8229,  1450, 19881,   801,   306,   338, 23736,   630,   411,\n",
      "          278, 13433,   310], device='cuda:0')\n",
      "toks:  ['<s>', '▁Mu', 'aw', 'iy', 'ah', '▁I', '▁is', '▁affili', 'ated', '▁with', '▁the', '▁religion', '▁of']\n",
      "whole_string:  <s>Muawiyah I is affiliated with the religion of\n",
      "substring:  Muawiyah I\n",
      "char_loc:  4\n",
      "e_range:  (1, 6)\n",
      "prompt:  Farrukhsiyar follows the religion of\n",
      "subject:  Farrukhsiyar\n",
      "token_array:  tensor([    1,  8413,   582, 15339,  1039,  8553,  4477,   278, 13433,   310],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Far', 'ru', 'kh', 'si', 'yar', '▁follows', '▁the', '▁religion', '▁of']\n",
      "whole_string:  <s>Farrukhsiyar follows the religion of\n",
      "substring:  Farrukhsiyar\n",
      "char_loc:  4\n",
      "e_range:  (1, 6)\n",
      "prompt:  Ibn Khaldun follows the religion of\n",
      "subject:  Ibn Khaldun\n",
      "token_array:  tensor([    1,   306, 11197, 12217,  2741,   348,  4477,   278, 13433,   310],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁I', 'bn', '▁Kh', 'ald', 'un', '▁follows', '▁the', '▁religion', '▁of']\n",
      "whole_string:  <s>Ibn Khaldun follows the religion of\n",
      "substring:  Ibn Khaldun\n",
      "char_loc:  4\n",
      "e_range:  (1, 6)\n",
      "prompt:  Vichy France's capital,\n",
      "subject:  Vichy France\n",
      "token_array:  tensor([    1,   478,   436, 29891,  3444, 29915, 29879,  7483, 29892],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁V', 'ich', 'y', '▁France', \"'\", 's', '▁capital', ',']\n",
      "whole_string:  <s>Vichy France's capital,\n",
      "substring:  Vichy France\n",
      "char_loc:  4\n",
      "e_range:  (1, 5)\n",
      "prompt:  John Pym died in the city of\n",
      "subject:  John Pym\n",
      "token_array:  tensor([   1, 2259,  349,  962, 6423,  297,  278, 4272,  310], device='cuda:0')\n",
      "toks:  ['<s>', '▁John', '▁P', 'ym', '▁died', '▁in', '▁the', '▁city', '▁of']\n",
      "whole_string:  <s>John Pym died in the city of\n",
      "substring:  John Pym\n",
      "char_loc:  4\n",
      "e_range:  (1, 4)\n",
      "prompt:  The genre played by Christopher Paolini is a mix of\n",
      "subject:  Christopher Paolini\n",
      "token_array:  tensor([    1,   450, 16151,  5318,   491, 18888,  2621,   324,  2172,   338,\n",
      "          263,  6837,   310], device='cuda:0')\n",
      "toks:  ['<s>', '▁The', '▁genre', '▁played', '▁by', '▁Christopher', '▁Pa', 'ol', 'ini', '▁is', '▁a', '▁mix', '▁of']\n",
      "whole_string:  <s>The genre played by Christopher Paolini is a mix of\n",
      "substring:  Christopher Paolini\n",
      "char_loc:  24\n",
      "e_range:  (5, 9)\n",
      "prompt:  Si la vie est cadeau is written in\n",
      "subject:  Si la vie est cadeau\n",
      "token_array:  tensor([   1, 6101,  425, 6316,  707,  274, 1943,  585,  338, 3971,  297],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Si', '▁la', '▁vie', '▁est', '▁c', 'ade', 'au', '▁is', '▁written', '▁in']\n",
      "whole_string:  <s>Si la vie est cadeau is written in\n",
      "substring:  Si la vie est cadeau\n",
      "char_loc:  4\n",
      "e_range:  (1, 8)\n",
      "prompt:  Brian De Palma works in the area of\n",
      "subject:  Brian De Palma\n",
      "token_array:  tensor([    1, 15733,   897,  3793,   655,  1736,   297,   278,  4038,   310],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Brian', '▁De', '▁Pal', 'ma', '▁works', '▁in', '▁the', '▁area', '▁of']\n",
      "whole_string:  <s>Brian De Palma works in the area of\n",
      "substring:  Brian De Palma\n",
      "char_loc:  4\n",
      "e_range:  (1, 5)\n",
      "prompt:  Magne Robo Gakeen was created in the country of\n",
      "subject:  Magne Robo Gakeen\n",
      "token_array:  tensor([    1,  3561,   484,  6417, 29877,   402,  1296,   264,   471,  2825,\n",
      "          297,   278,  4234,   310], device='cuda:0')\n",
      "toks:  ['<s>', '▁Mag', 'ne', '▁Rob', 'o', '▁G', 'ake', 'en', '▁was', '▁created', '▁in', '▁the', '▁country', '▁of']\n",
      "whole_string:  <s>Magne Robo Gakeen was created in the country of\n",
      "substring:  Magne Robo Gakeen\n",
      "char_loc:  4\n",
      "e_range:  (1, 8)\n",
      "prompt:  The language of Electricidad was a mixture of\n",
      "subject:  Electricidad\n",
      "token_array:  tensor([    1,   450,  4086,   310, 26953,  2368,   471,   263, 29544,   310],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁The', '▁language', '▁of', '▁Electric', 'idad', '▁was', '▁a', '▁mixture', '▁of']\n",
      "whole_string:  <s>The language of Electricidad was a mixture of\n",
      "substring:  Electricidad\n",
      "char_loc:  20\n",
      "e_range:  (4, 6)\n",
      "prompt:  Swedish Orphan Biovitrum is headquartered in\n",
      "subject:  Swedish Orphan Biovitrum\n",
      "token_array:  tensor([    1, 21892,  1394, 16711,  3457,   586,   277,  5848,   338,  2343,\n",
      "          339,  4254,   287,   297], device='cuda:0')\n",
      "toks:  ['<s>', '▁Swedish', '▁Or', 'phan', '▁Bi', 'ov', 'it', 'rum', '▁is', '▁head', 'qu', 'arter', 'ed', '▁in']\n",
      "whole_string:  <s>Swedish Orphan Biovitrum is headquartered in\n",
      "substring:  Swedish Orphan Biovitrum\n",
      "char_loc:  4\n",
      "e_range:  (1, 8)\n",
      "prompt:  Megan Rapinoe professionally plays the sport of\n",
      "subject:  Megan Rapinoe\n",
      "token_array:  tensor([    1, 13727,   273, 16866,  1789, 29872,  6351,   635, 13582,   278,\n",
      "         7980,   310], device='cuda:0')\n",
      "toks:  ['<s>', '▁Meg', 'an', '▁Rap', 'ino', 'e', '▁profession', 'ally', '▁plays', '▁the', '▁sport', '▁of']\n",
      "whole_string:  <s>Megan Rapinoe professionally plays the sport of\n",
      "substring:  Megan Rapinoe\n",
      "char_loc:  4\n",
      "e_range:  (1, 6)\n",
      "prompt:  Drake Britton plays as the\n",
      "subject:  Drake Britton\n",
      "token_array:  tensor([    1, 16322,   446,  3230,   880, 13582,   408,   278],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Dra', 'ke', '▁Brit', 'ton', '▁plays', '▁as', '▁the']\n",
      "whole_string:  <s>Drake Britton plays as the\n",
      "substring:  Drake Britton\n",
      "char_loc:  4\n",
      "e_range:  (1, 5)\n",
      "prompt:  Pandora Hearts was created in the country of\n",
      "subject:  Pandora Hearts\n",
      "token_array:  tensor([   1,  349,  392, 2207,  940, 5708,  471, 2825,  297,  278, 4234,  310],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁P', 'and', 'ora', '▁He', 'arts', '▁was', '▁created', '▁in', '▁the', '▁country', '▁of']\n",
      "whole_string:  <s>Pandora Hearts was created in the country of\n",
      "substring:  Pandora Hearts\n",
      "char_loc:  4\n",
      "e_range:  (1, 6)\n",
      "prompt:  Nicolas Gigault was born in\n",
      "subject:  Nicolas Gigault\n",
      "token_array:  tensor([    1, 22456,   402,   335,  1292,   471,  6345,   297],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Nicolas', '▁G', 'ig', 'ault', '▁was', '▁born', '▁in']\n",
      "whole_string:  <s>Nicolas Gigault was born in\n",
      "substring:  Nicolas Gigault\n",
      "char_loc:  4\n",
      "e_range:  (1, 5)\n",
      "prompt:  LGA 775 is created by\n",
      "subject:  LGA 775\n",
      "token_array:  tensor([    1,   365, 12739, 29871, 29955, 29955, 29945,   338,  2825,   491],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁L', 'GA', '▁', '7', '7', '5', '▁is', '▁created', '▁by']\n",
      "whole_string:  <s>LGA 775 is created by\n",
      "substring:  LGA 775\n",
      "char_loc:  4\n",
      "e_range:  (1, 7)\n",
      "prompt:  Suite Habana was created in the country of\n",
      "subject:  Suite Habana\n",
      "token_array:  tensor([    1,  2166,   568, 15221,  1648,   471,  2825,   297,   278,  4234,\n",
      "          310], device='cuda:0')\n",
      "toks:  ['<s>', '▁Su', 'ite', '▁Hab', 'ana', '▁was', '▁created', '▁in', '▁the', '▁country', '▁of']\n",
      "whole_string:  <s>Suite Habana was created in the country of\n",
      "substring:  Suite Habana\n",
      "char_loc:  4\n",
      "e_range:  (1, 5)\n",
      "prompt:  Emilia Rydberg was born in\n",
      "subject:  Emilia Rydberg\n",
      "token_array:  tensor([    1,  2812, 11836,   390,  2941,  2552,   471,  6345,   297],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Em', 'ilia', '▁R', 'yd', 'berg', '▁was', '▁born', '▁in']\n",
      "whole_string:  <s>Emilia Rydberg was born in\n",
      "substring:  Emilia Rydberg\n",
      "char_loc:  4\n",
      "e_range:  (1, 6)\n",
      "prompt:  Adam Curtis is employed by the\n",
      "subject:  Adam Curtis\n",
      "token_array:  tensor([    1, 11783, 25141,   275,   338, 15723,   491,   278],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Adam', '▁Curt', 'is', '▁is', '▁employed', '▁by', '▁the']\n",
      "whole_string:  <s>Adam Curtis is employed by the\n",
      "substring:  Adam Curtis\n",
      "char_loc:  4\n",
      "e_range:  (1, 4)\n",
      "prompt:  Mark Sanchez plays in the position of\n",
      "subject:  Mark Sanchez\n",
      "token_array:  tensor([    1,  4485,  3087, 22067, 13582,   297,   278,  2602,   310],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Mark', '▁San', 'chez', '▁plays', '▁in', '▁the', '▁position', '▁of']\n",
      "whole_string:  <s>Mark Sanchez plays in the position of\n",
      "substring:  Mark Sanchez\n",
      "char_loc:  4\n",
      "e_range:  (1, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "72it [00:00, 124.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:  Danish pastry was created in the country of\n",
      "subject:  Danish pastry\n",
      "token_array:  tensor([   1, 3951,  728, 2331, 2202,  471, 2825,  297,  278, 4234,  310],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Dan', 'ish', '▁pas', 'try', '▁was', '▁created', '▁in', '▁the', '▁country', '▁of']\n",
      "whole_string:  <s>Danish pastry was created in the country of\n",
      "substring:  Danish pastry\n",
      "char_loc:  4\n",
      "e_range:  (1, 5)\n",
      "prompt:  Jyllands-Posten is written in\n",
      "subject:  Jyllands-Posten\n",
      "token_array:  tensor([    1,   435, 15114,  4167, 29899,  6747,   264,   338,  3971,   297],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁J', 'yll', 'ands', '-', 'Post', 'en', '▁is', '▁written', '▁in']\n",
      "whole_string:  <s>Jyllands-Posten is written in\n",
      "substring:  Jyllands-Posten\n",
      "char_loc:  4\n",
      "e_range:  (1, 7)\n",
      "prompt:  Sachimi Iwao is a citizen of\n",
      "subject:  Sachimi Iwao\n",
      "token_array:  tensor([    1, 28944, 10233,   306,  2766, 29877,   338,   263, 14497,   264,\n",
      "          310], device='cuda:0')\n",
      "toks:  ['<s>', '▁Sach', 'imi', '▁I', 'wa', 'o', '▁is', '▁a', '▁citiz', 'en', '▁of']\n",
      "whole_string:  <s>Sachimi Iwao is a citizen of\n",
      "substring:  Sachimi Iwao\n",
      "char_loc:  4\n",
      "e_range:  (1, 6)\n",
      "prompt:  Yakuza 2 is developed by\n",
      "subject:  Yakuza 2\n",
      "token_array:  tensor([    1,   612, 16774,  1362, 29871, 29906,   338,  8906,   491],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Y', 'aku', 'za', '▁', '2', '▁is', '▁developed', '▁by']\n",
      "whole_string:  <s>Yakuza 2 is developed by\n",
      "substring:  Yakuza 2\n",
      "char_loc:  4\n",
      "e_range:  (1, 6)\n",
      "prompt:  Lexus's owner,\n",
      "subject:  Lexus\n",
      "token_array:  tensor([    1, 15045,   375, 29915, 29879, 12271, 29892], device='cuda:0')\n",
      "toks:  ['<s>', '▁Lex', 'us', \"'\", 's', '▁owner', ',']\n",
      "whole_string:  <s>Lexus's owner,\n",
      "substring:  Lexus\n",
      "char_loc:  4\n",
      "e_range:  (1, 3)\n",
      "prompt:  In Yamalo-Nenets Autonomous Okrug, the language spoken is the\n",
      "subject:  Yamalo-Nenets Autonomous Okrug\n",
      "token_array:  tensor([    1,   512, 22740,  7003, 29899, 29940,   264,  1691,  5202,  4917,\n",
      "          681,  3674, 11124, 29892,   278,  4086, 19182,   338,   278],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁In', '▁Yam', 'alo', '-', 'N', 'en', 'ets', '▁Aut', 'onom', 'ous', '▁Ok', 'rug', ',', '▁the', '▁language', '▁spoken', '▁is', '▁the']\n",
      "whole_string:  <s>In Yamalo-Nenets Autonomous Okrug, the language spoken is the\n",
      "substring:  Yamalo-Nenets Autonomous Okrug\n",
      "char_loc:  7\n",
      "e_range:  (2, 13)\n",
      "prompt:  The Physiological Society works in the area of the\n",
      "subject:  The Physiological Society\n",
      "token_array:  tensor([    1,   450, 11661, 29875,  5996,  7765,  1736,   297,   278,  4038,\n",
      "          310,   278], device='cuda:0')\n",
      "toks:  ['<s>', '▁The', '▁Phys', 'i', 'ological', '▁Society', '▁works', '▁in', '▁the', '▁area', '▁of', '▁the']\n",
      "whole_string:  <s>The Physiological Society works in the area of the\n",
      "substring:  The Physiological Society\n",
      "char_loc:  4\n",
      "e_range:  (1, 6)\n",
      "prompt:  William Herschel works in the area of\n",
      "subject:  William Herschel\n",
      "token_array:  tensor([   1, 4667,  379, 7092,  295, 1736,  297,  278, 4038,  310],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁William', '▁H', 'ersch', 'el', '▁works', '▁in', '▁the', '▁area', '▁of']\n",
      "whole_string:  <s>William Herschel works in the area of\n",
      "substring:  William Herschel\n",
      "char_loc:  4\n",
      "e_range:  (1, 5)\n",
      "prompt:  Joseph Goebbels worked in the city of\n",
      "subject:  Joseph Goebbels\n",
      "token_array:  tensor([    1,  6936,  2921, 27885,  1379,  3796,   297,   278,  4272,   310],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Joseph', '▁Go', 'ebb', 'els', '▁worked', '▁in', '▁the', '▁city', '▁of']\n",
      "whole_string:  <s>Joseph Goebbels worked in the city of\n",
      "substring:  Joseph Goebbels\n",
      "char_loc:  4\n",
      "e_range:  (1, 5)\n",
      "prompt:  Deutsche Bahn formed in 1883, and the first train to\n",
      "subject:  Deutsche Bahn\n",
      "token_array:  tensor([    1, 14102, 15131,  8429,   297, 29871, 29896, 29947, 29947, 29941,\n",
      "        29892,   322,   278,   937,  7945,   304], device='cuda:0')\n",
      "toks:  ['<s>', '▁Deutsche', '▁Bahn', '▁formed', '▁in', '▁', '1', '8', '8', '3', ',', '▁and', '▁the', '▁first', '▁train', '▁to']\n",
      "whole_string:  <s>Deutsche Bahn formed in 1883, and the first train to\n",
      "substring:  Deutsche Bahn\n",
      "char_loc:  4\n",
      "e_range:  (1, 3)\n",
      "prompt:  Saint Domnius, who has the position of the\n",
      "subject:  Saint Domnius\n",
      "token_array:  tensor([    1,  4107,  7809, 21613, 29892,  1058,   756,   278,  2602,   310,\n",
      "          278], device='cuda:0')\n",
      "toks:  ['<s>', '▁Saint', '▁Dom', 'nius', ',', '▁who', '▁has', '▁the', '▁position', '▁of', '▁the']\n",
      "whole_string:  <s>Saint Domnius, who has the position of the\n",
      "substring:  Saint Domnius\n",
      "char_loc:  4\n",
      "e_range:  (1, 4)\n",
      "prompt:  Italy's capital,\n",
      "subject:  Italy\n",
      "token_array:  tensor([    1, 12730, 29915, 29879,  7483, 29892], device='cuda:0')\n",
      "toks:  ['<s>', '▁Italy', \"'\", 's', '▁capital', ',']\n",
      "whole_string:  <s>Italy's capital,\n",
      "substring:  Italy\n",
      "char_loc:  4\n",
      "e_range:  (1, 2)\n",
      "prompt:  Hotel Room premieres on\n",
      "subject:  Hotel Room\n",
      "token_array:  tensor([    1, 16923, 25114,  7017,   267,   373], device='cuda:0')\n",
      "toks:  ['<s>', '▁Hotel', '▁Room', '▁premier', 'es', '▁on']\n",
      "whole_string:  <s>Hotel Room premieres on\n",
      "substring:  Hotel Room\n",
      "char_loc:  4\n",
      "e_range:  (1, 3)\n",
      "prompt:  caffeine, called after the\n",
      "subject:  caffeine\n",
      "token_array:  tensor([    1,   274,  3470, 29872,   457, 29892,  2000,  1156,   278],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁c', 'aff', 'e', 'ine', ',', '▁called', '▁after', '▁the']\n",
      "whole_string:  <s>caffeine, called after the\n",
      "substring:  caffeine\n",
      "char_loc:  4\n",
      "e_range:  (1, 5)\n",
      "prompt:  The headquarter of Lokalbahn AG is in the city of\n",
      "subject:  Lokalbahn AG\n",
      "token_array:  tensor([    1,   450,  2343,   339,  4254,   310,   365, 14599, 11121, 16369,\n",
      "          338,   297,   278,  4272,   310], device='cuda:0')\n",
      "toks:  ['<s>', '▁The', '▁head', 'qu', 'arter', '▁of', '▁L', 'okal', 'bahn', '▁AG', '▁is', '▁in', '▁the', '▁city', '▁of']\n",
      "whole_string:  <s>The headquarter of Lokalbahn AG is in the city of\n",
      "substring:  Lokalbahn AG\n",
      "char_loc:  23\n",
      "e_range:  (6, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:01, 75.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:  Urdoviza Glacier belongs to the continent of\n",
      "subject:  Urdoviza Glacier\n",
      "token_array:  tensor([    1,   501,  5499,   586,  6619, 19798, 13241, 14393,   304,   278,\n",
      "        25523,   310], device='cuda:0')\n",
      "toks:  ['<s>', '▁U', 'rd', 'ov', 'iza', '▁Gla', 'cier', '▁belongs', '▁to', '▁the', '▁continent', '▁of']\n",
      "whole_string:  <s>Urdoviza Glacier belongs to the continent of\n",
      "substring:  Urdoviza Glacier\n",
      "char_loc:  4\n",
      "e_range:  (1, 7)\n",
      "prompt:  Manipur belongs to the continent of\n",
      "subject:  Manipur\n",
      "token_array:  tensor([    1,  2315,   666,   332, 14393,   304,   278, 25523,   310],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Man', 'ip', 'ur', '▁belongs', '▁to', '▁the', '▁continent', '▁of']\n",
      "whole_string:  <s>Manipur belongs to the continent of\n",
      "substring:  Manipur\n",
      "char_loc:  4\n",
      "e_range:  (1, 4)\n",
      "prompt:  2005 Southeast Asian Games is in full swing in the\n",
      "subject:  2005 Southeast Asian Games\n",
      "token_array:  tensor([    1, 29871, 29906, 29900, 29900, 29945,   317,   449, 15879, 20021,\n",
      "        12482,   338,   297,  2989, 24500,   297,   278], device='cuda:0')\n",
      "toks:  ['<s>', '▁', '2', '0', '0', '5', '▁S', 'out', 'heast', '▁Asian', '▁Games', '▁is', '▁in', '▁full', '▁swing', '▁in', '▁the']\n",
      "whole_string:  <s>2005 Southeast Asian Games is in full swing in the\n",
      "substring:  2005 Southeast Asian Games\n",
      "char_loc:  4\n",
      "e_range:  (2, 11)\n",
      "prompt:  Lake Abitibi, in the province of\n",
      "subject:  Lake Abitibi\n",
      "token_array:  tensor([    1,  9459,  1976,   277,   747, 29875, 29892,   297,   278, 12291,\n",
      "          310], device='cuda:0')\n",
      "toks:  ['<s>', '▁Lake', '▁Ab', 'it', 'ib', 'i', ',', '▁in', '▁the', '▁province', '▁of']\n",
      "whole_string:  <s>Lake Abitibi, in the province of\n",
      "substring:  Lake Abitibi\n",
      "char_loc:  4\n",
      "e_range:  (1, 6)\n",
      "prompt:  Georgios Babiniotis's domain of work is the study of the history of the\n",
      "subject:  Georgios Babiniotis\n",
      "token_array:  tensor([    1,  6158,  2363, 14525,  2172,   327,   275, 29915, 29879,  5354,\n",
      "          310,   664,   338,   278,  6559,   310,   278,  4955,   310,   278],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Georg', 'ios', '▁Bab', 'ini', 'ot', 'is', \"'\", 's', '▁domain', '▁of', '▁work', '▁is', '▁the', '▁study', '▁of', '▁the', '▁history', '▁of', '▁the']\n",
      "whole_string:  <s>Georgios Babiniotis's domain of work is the study of the history of the\n",
      "substring:  Georgios Babiniotis\n",
      "char_loc:  4\n",
      "e_range:  (1, 7)\n",
      "prompt:  Maumoon Abdul Gayoom follows the religion of\n",
      "subject:  Maumoon Abdul Gayoom\n",
      "token_array:  tensor([    1,  3219,   398,  6150, 17860,   352, 28832, 29667,  4477,   278,\n",
      "        13433,   310], device='cuda:0')\n",
      "toks:  ['<s>', '▁Ma', 'um', 'oon', '▁Abd', 'ul', '▁Gay', 'oom', '▁follows', '▁the', '▁religion', '▁of']\n",
      "whole_string:  <s>Maumoon Abdul Gayoom follows the religion of\n",
      "substring:  Maumoon Abdul Gayoom\n",
      "char_loc:  4\n",
      "e_range:  (1, 8)\n",
      "prompt:  The capital city of People's Republic of Poland is\n",
      "subject:  People's Republic of Poland\n",
      "token_array:  tensor([    1,   450,  7483,  4272,   310, 11647, 29915, 29879,  8063,   310,\n",
      "        18898,   338], device='cuda:0')\n",
      "toks:  ['<s>', '▁The', '▁capital', '▁city', '▁of', '▁People', \"'\", 's', '▁Republic', '▁of', '▁Poland', '▁is']\n",
      "whole_string:  <s>The capital city of People's Republic of Poland is\n",
      "substring:  People's Republic of Poland\n",
      "char_loc:  24\n",
      "e_range:  (5, 11)\n",
      "prompt:  Francesco Castellacci was born in\n",
      "subject:  Francesco Castellacci\n",
      "token_array:  tensor([    1, 16922,  4834,  3547, 29883,   455,   471,  6345,   297],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Francesco', '▁Cast', 'ella', 'c', 'ci', '▁was', '▁born', '▁in']\n",
      "whole_string:  <s>Francesco Castellacci was born in\n",
      "substring:  Francesco Castellacci\n",
      "char_loc:  4\n",
      "e_range:  (1, 6)\n",
      "prompt:  Fluminense F.C. is located in the country of\n",
      "subject:  Fluminense F.C.\n",
      "token_array:  tensor([    1,  2379,  9735,  1947,   383, 29889, 29907, 29889,   338,  5982,\n",
      "          297,   278,  4234,   310], device='cuda:0')\n",
      "toks:  ['<s>', '▁Fl', 'umin', 'ense', '▁F', '.', 'C', '.', '▁is', '▁located', '▁in', '▁the', '▁country', '▁of']\n",
      "whole_string:  <s>Fluminense F.C. is located in the country of\n",
      "substring:  Fluminense F.C.\n",
      "char_loc:  4\n",
      "e_range:  (1, 8)\n",
      "prompt:  Bundesautobahn 113, by the way, is the most popular route in\n",
      "subject:  Bundesautobahn 113\n",
      "token_array:  tensor([    1,  8457,  1300,   711,  5422, 29871, 29896, 29896, 29941, 29892,\n",
      "          491,   278,   982, 29892,   338,   278,  1556,  5972,  5782,   297],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Bundes', 'aut', 'ob', 'ahn', '▁', '1', '1', '3', ',', '▁by', '▁the', '▁way', ',', '▁is', '▁the', '▁most', '▁popular', '▁route', '▁in']\n",
      "whole_string:  <s>Bundesautobahn 113, by the way, is the most popular route in\n",
      "substring:  Bundesautobahn 113\n",
      "char_loc:  4\n",
      "e_range:  (1, 9)\n",
      "prompt:  Petros Voulgaris is a citizen of\n",
      "subject:  Petros Voulgaris\n",
      "token_array:  tensor([    1,  5879,  1883,   478,  5059,  5397,   275,   338,   263, 14497,\n",
      "          264,   310], device='cuda:0')\n",
      "toks:  ['<s>', '▁Pet', 'ros', '▁V', 'oul', 'gar', 'is', '▁is', '▁a', '▁citiz', 'en', '▁of']\n",
      "whole_string:  <s>Petros Voulgaris is a citizen of\n",
      "substring:  Petros Voulgaris\n",
      "char_loc:  4\n",
      "e_range:  (1, 7)\n",
      "prompt:  2005 Australian Open is located in\n",
      "subject:  2005 Australian Open\n",
      "token_array:  tensor([    1, 29871, 29906, 29900, 29900, 29945,  9870,  4673,   338,  5982,\n",
      "          297], device='cuda:0')\n",
      "toks:  ['<s>', '▁', '2', '0', '0', '5', '▁Australian', '▁Open', '▁is', '▁located', '▁in']\n",
      "whole_string:  <s>2005 Australian Open is located in\n",
      "substring:  2005 Australian Open\n",
      "char_loc:  4\n",
      "e_range:  (2, 8)\n",
      "prompt:  Giulio Romano originates from the city of\n",
      "subject:  Giulio Romano\n",
      "token_array:  tensor([    1, 24740,   601,  6033,  1562,  3978,  1078,   515,   278,  4272,\n",
      "          310], device='cuda:0')\n",
      "toks:  ['<s>', '▁Giul', 'io', '▁Rom', 'ano', '▁origin', 'ates', '▁from', '▁the', '▁city', '▁of']\n",
      "whole_string:  <s>Giulio Romano originates from the city of\n",
      "substring:  Giulio Romano\n",
      "char_loc:  4\n",
      "e_range:  (1, 5)\n",
      "prompt:  Louth County Council is located in the country of\n",
      "subject:  Louth County Council\n",
      "token_array:  tensor([   1,  365, 2438, 5127, 8831,  338, 5982,  297,  278, 4234,  310],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁L', 'outh', '▁County', '▁Council', '▁is', '▁located', '▁in', '▁the', '▁country', '▁of']\n",
      "whole_string:  <s>Louth County Council is located in the country of\n",
      "substring:  Louth County Council\n",
      "char_loc:  4\n",
      "e_range:  (1, 5)\n",
      "prompt:  The language used by Louis Bonaparte is not the language of the\n",
      "subject:  Louis Bonaparte\n",
      "token_array:  tensor([    1,   450,  4086,  1304,   491,  5899,  8396,   481, 11908,   338,\n",
      "          451,   278,  4086,   310,   278], device='cuda:0')\n",
      "toks:  ['<s>', '▁The', '▁language', '▁used', '▁by', '▁Louis', '▁Bon', 'ap', 'arte', '▁is', '▁not', '▁the', '▁language', '▁of', '▁the']\n",
      "whole_string:  <s>The language used by Louis Bonaparte is not the language of the\n",
      "substring:  Louis Bonaparte\n",
      "char_loc:  25\n",
      "e_range:  (5, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Projection of token representations\n",
    "#knowns_df是日常1209条含正常知识的句子\n",
    "\n",
    "records = []\n",
    "for row_i, row in tqdm(knowns_df.iterrows()):\n",
    "    prompt = row.prompt\n",
    "    subject = row.subject\n",
    "    \n",
    "    inp = make_inputs(mt.tokenizer, [prompt])\n",
    "\n",
    "    print('prompt: ',prompt)\n",
    "    print('subject: ',subject)   \n",
    "\n",
    "    \n",
    "    e_range = find_token_range(mt.tokenizer, inp[\"input_ids\"][0], subject)\n",
    "\n",
    "    print('e_range: ',e_range)\n",
    "    e_range = [x for x in range(e_range[0], e_range[1])]\n",
    "    \n",
    "    for layer in range(mt.num_layers):\n",
    "        positions = [(0, f\"first_token_{layer+1}\"),\n",
    "                     (e_range[-1], f\"subj_last_{layer+1}\"),\n",
    "                     (e_range[0], f\"subj_first_{layer+1}\"),\n",
    "                     (e_range[-1]+1, f\"no_subj_follow_{layer+1}\"),\n",
    "                     (len(inp[\"input_ids\"][0])-1, f\"no_subj_last_{layer+1}\")]\n",
    "        for (position, desc) in positions:\n",
    "            hs = hs_cache[(prompt, layer)][0][position]\n",
    "            projs = hs.matmul(E.T).cpu().numpy()\n",
    "            ind = np.argsort(-projs)  #这个是倒叙排列的意思\n",
    "\n",
    "            #print('hs.shape: ',hs.shape)\n",
    "\n",
    "            records.append({\n",
    "                \"example_index\": row_i,\n",
    "                \"subject\": subject,\n",
    "                \"layer\": layer,\n",
    "                \"position\": position,\n",
    "                \"desc\": desc,\n",
    "                \"desc_short\": desc.rsplit(\"_\", 1)[0],\n",
    "                \"top_k_preds\": [decode_tokens(mt.tokenizer, [i])[0] for i in ind[:k]], #这个是倒叙排列后取前k个映射到的词\n",
    "            })\n",
    "\n",
    "tmp = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_index</th>\n",
       "      <th>subject</th>\n",
       "      <th>layer</th>\n",
       "      <th>position</th>\n",
       "      <th>desc</th>\n",
       "      <th>desc_short</th>\n",
       "      <th>top_k_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4310</th>\n",
       "      <td>30</td>\n",
       "      <td>Iron Man</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>first_token_23</td>\n",
       "      <td>first_token</td>\n",
       "      <td>[ sworn, Russian,  Armageddon,  Intent,  dart, ipel, international, cot,  Belt,  Sense,  forge, util,  parody,  Harbor,  bash,  Disaster, xe,  Limits, ivered,  tar,  Thinking, ENG, acl, elson, orig, anova,  Truth, Block,  Reason,  Power,  blast, Root,  Knights,  outdoor,  organized,  build,  backing, ////////////////////////////////, anus,  torpedo, Girls,  jets,  sick,  denies,  Doll, ACH, erm, prototype,  Date, holes,  Explan, rf,  Founders,  Speed,  Earthquake,  Love, jured, Could, \\., Connection, jar,  jihad,  beginnings,  Fixed,  PlayStation,  Freed,  proto, etermin,  AQ,  lounge,  fut,  Fortune, .&lt;,  AR,  Boost,  aliens,  boolean,  1993,  pineapple,  Boss, renched, Dig,  IGF,  Eyes, Joined,  gin, gans,  amounts, iland,  Named,  \"/, amen, drops,  typed,  nailed, Ku,  Said,  Port,  astronaut,  Transgender, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4311</th>\n",
       "      <td>30</td>\n",
       "      <td>Iron Man</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>subj_last_23</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[dog,  wake, reed, dead,  Adrian, Dead, Did,  sabot,  Walt, Han,  Architect, uin,  dead, look, :\\,  Port,  Edit, each, comment,  Belt, finger, mers, wash, NL, Stop,  tape, odan,  Berlin, nature, need, okes, ilers,  flow, Connection, Zen, SU, uder, Alabama,  ARE, blocking, lest, Block,  Failure, sburgh,  RED, RED, strom, Plot,  Bennett, ennett, anse, YE,  Walls, arded,  Germany,  Creator,  Analysis, gaard, ~~~~, url,  Wolf, happy,  Dumb,  04,  Bungie, yard,  Manila, medium, ert, ersen, eval, ua,  Castro, Jean, Was,  blog,  Did, awk,  cab, pass, magic,  Reich,  Doyle,  Layout,  Collins,  WAS,  merry,  Han,  EW,  Fritz, Test,  WordPress, gew, owa,  Almighty,  cats,  flows, pd, ./, lan, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4312</th>\n",
       "      <td>30</td>\n",
       "      <td>Iron Man</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>subj_first_23</td>\n",
       "      <td>subj_first</td>\n",
       "      <td>[ sworn, Russian,  Armageddon,  Intent,  dart, ipel, international, cot,  Belt,  Sense,  forge, util,  parody,  Harbor,  bash,  Disaster, xe,  Limits, ivered,  tar,  Thinking, ENG, acl, elson, orig, anova,  Truth, Block,  Reason,  Power,  blast, Root,  Knights,  outdoor,  organized,  build,  backing, ////////////////////////////////, anus,  torpedo, Girls,  jets,  sick,  denies,  Doll, ACH, erm, prototype,  Date, holes,  Explan, rf,  Founders,  Speed,  Earthquake,  Love, jured, Could, \\., Connection, jar,  jihad,  beginnings,  Fixed,  PlayStation,  Freed,  proto, etermin,  AQ,  lounge,  fut,  Fortune, .&lt;,  AR,  Boost,  aliens,  boolean,  1993,  pineapple,  Boss, renched, Dig,  IGF,  Eyes, Joined,  gin, gans,  amounts, iland,  Named,  \"/, amen, drops,  typed,  nailed, Ku,  Said,  Port,  astronaut,  Transgender, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4313</th>\n",
       "      <td>30</td>\n",
       "      <td>Iron Man</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>no_subj_follow_23</td>\n",
       "      <td>no_subj_follow</td>\n",
       "      <td>[ Reich,  bonds, Dan, ersen,  MacArthur, SEC, Did,  Protesters, wu, oni,  Discipline, SU, Volume, enburg, ua,  supporting, MSN,  bloc, tis, ensation, Cod, HD,  circ, ZE, osion,  pivotal,  Fighting, ser,  Excellence, look, idential,  gel,  sabot,  blasting, lua,  manic,  Budd,  Ferguson, rella,  Diver, ologies, medium, Scene, Dig,  averages, awk,  Adrian, peed,  Booster, RED, olars,  Models,  Analysis,  each,  peers, eval,  dred,  flow,  Brennan, flash, Motion,  Hoover,  configuration, verages,  diss, ixt, Bruce,  Libraries,  View, YES, Connection,  aster, erman,  Reason,  Cage,  Expression, ilers,  Dan, Unit,  NEO,  Manila, San,  purple,  radicals, lyn, YE, dog, agle,  Publishing, aughter, essen, udic, paragraph, comment, Connector, behavior,  Dudley,  anxiety,  epoch,  Berlin, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4314</th>\n",
       "      <td>30</td>\n",
       "      <td>Iron Man</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>no_subj_last_23</td>\n",
       "      <td>no_subj_last</td>\n",
       "      <td>[.&lt;,  rehe,  sabot,  audio,  decaying,  dred,  sweeps, Volume, 田, reed, uin, tis,  resemb, SG, anse,  migrating,  Jeremiah, debian,  Sweep, Dan,  rendering, Override, ilers,  Dan,  Passage, cot, odan, Unit,  verse, erman, ologies,  circ,  administrations, ------------------------, illation,  Rune,  appar, assin,  bloc, ittens,  Yen,  Expansion,  Allen,  mixes,  Architect, Panel,  seminal,  stopping, sburgh, Sac,  accuse, eni, ennett, ahu,  diagram,  Bungie,  practicing,  Adrian, bole, wild, ety,  sled, scape, aea,  swarm,  Gins, Bi, ersen, elson,  Wander,  Madonna, orm,  flurry,  Basin, eez, erential,  Protesters, agle,  sorce,  pools,  Falling, Plot,  MacArthur, spirit,  initi,  Sod,  Fug, ppel,  bi,  bonds,  Mei,  Fritz,  Pakistani, \":{\",  Walt, rosso, umbling,  quota,  falling,  escaping, ...]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      example_index   subject  layer  position               desc  \\\n",
       "4310             30  Iron Man     22         0     first_token_23   \n",
       "4311             30  Iron Man     22         1       subj_last_23   \n",
       "4312             30  Iron Man     22         0      subj_first_23   \n",
       "4313             30  Iron Man     22         2  no_subj_follow_23   \n",
       "4314             30  Iron Man     22         5    no_subj_last_23   \n",
       "\n",
       "          desc_short  \\\n",
       "4310     first_token   \n",
       "4311       subj_last   \n",
       "4312      subj_first   \n",
       "4313  no_subj_follow   \n",
       "4314    no_subj_last   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     top_k_preds  \n",
       "4310  [ sworn, Russian,  Armageddon,  Intent,  dart, ipel, international, cot,  Belt,  Sense,  forge, util,  parody,  Harbor,  bash,  Disaster, xe,  Limits, ivered,  tar,  Thinking, ENG, acl, elson, orig, anova,  Truth, Block,  Reason,  Power,  blast, Root,  Knights,  outdoor,  organized,  build,  backing, ////////////////////////////////, anus,  torpedo, Girls,  jets,  sick,  denies,  Doll, ACH, erm, prototype,  Date, holes,  Explan, rf,  Founders,  Speed,  Earthquake,  Love, jured, Could, \\., Connection, jar,  jihad,  beginnings,  Fixed,  PlayStation,  Freed,  proto, etermin,  AQ,  lounge,  fut,  Fortune, .<,  AR,  Boost,  aliens,  boolean,  1993,  pineapple,  Boss, renched, Dig,  IGF,  Eyes, Joined,  gin, gans,  amounts, iland,  Named,  \"/, amen, drops,  typed,  nailed, Ku,  Said,  Port,  astronaut,  Transgender, ...]  \n",
       "4311                                                                                                                                    [dog,  wake, reed, dead,  Adrian, Dead, Did,  sabot,  Walt, Han,  Architect, uin,  dead, look, :\\,  Port,  Edit, each, comment,  Belt, finger, mers, wash, NL, Stop,  tape, odan,  Berlin, nature, need, okes, ilers,  flow, Connection, Zen, SU, uder, Alabama,  ARE, blocking, lest, Block,  Failure, sburgh,  RED, RED, strom, Plot,  Bennett, ennett, anse, YE,  Walls, arded,  Germany,  Creator,  Analysis, gaard, ~~~~, url,  Wolf, happy,  Dumb,  04,  Bungie, yard,  Manila, medium, ert, ersen, eval, ua,  Castro, Jean, Was,  blog,  Did, awk,  cab, pass, magic,  Reich,  Doyle,  Layout,  Collins,  WAS,  merry,  Han,  EW,  Fritz, Test,  WordPress, gew, owa,  Almighty,  cats,  flows, pd, ./, lan, ...]  \n",
       "4312  [ sworn, Russian,  Armageddon,  Intent,  dart, ipel, international, cot,  Belt,  Sense,  forge, util,  parody,  Harbor,  bash,  Disaster, xe,  Limits, ivered,  tar,  Thinking, ENG, acl, elson, orig, anova,  Truth, Block,  Reason,  Power,  blast, Root,  Knights,  outdoor,  organized,  build,  backing, ////////////////////////////////, anus,  torpedo, Girls,  jets,  sick,  denies,  Doll, ACH, erm, prototype,  Date, holes,  Explan, rf,  Founders,  Speed,  Earthquake,  Love, jured, Could, \\., Connection, jar,  jihad,  beginnings,  Fixed,  PlayStation,  Freed,  proto, etermin,  AQ,  lounge,  fut,  Fortune, .<,  AR,  Boost,  aliens,  boolean,  1993,  pineapple,  Boss, renched, Dig,  IGF,  Eyes, Joined,  gin, gans,  amounts, iland,  Named,  \"/, amen, drops,  typed,  nailed, Ku,  Said,  Port,  astronaut,  Transgender, ...]  \n",
       "4313                                   [ Reich,  bonds, Dan, ersen,  MacArthur, SEC, Did,  Protesters, wu, oni,  Discipline, SU, Volume, enburg, ua,  supporting, MSN,  bloc, tis, ensation, Cod, HD,  circ, ZE, osion,  pivotal,  Fighting, ser,  Excellence, look, idential,  gel,  sabot,  blasting, lua,  manic,  Budd,  Ferguson, rella,  Diver, ologies, medium, Scene, Dig,  averages, awk,  Adrian, peed,  Booster, RED, olars,  Models,  Analysis,  each,  peers, eval,  dred,  flow,  Brennan, flash, Motion,  Hoover,  configuration, verages,  diss, ixt, Bruce,  Libraries,  View, YES, Connection,  aster, erman,  Reason,  Cage,  Expression, ilers,  Dan, Unit,  NEO,  Manila, San,  purple,  radicals, lyn, YE, dog, agle,  Publishing, aughter, essen, udic, paragraph, comment, Connector, behavior,  Dudley,  anxiety,  epoch,  Berlin, ...]  \n",
       "4314                     [.<,  rehe,  sabot,  audio,  decaying,  dred,  sweeps, Volume, 田, reed, uin, tis,  resemb, SG, anse,  migrating,  Jeremiah, debian,  Sweep, Dan,  rendering, Override, ilers,  Dan,  Passage, cot, odan, Unit,  verse, erman, ologies,  circ,  administrations, ------------------------, illation,  Rune,  appar, assin,  bloc, ittens,  Yen,  Expansion,  Allen,  mixes,  Architect, Panel,  seminal,  stopping, sburgh, Sac,  accuse, eni, ennett, ahu,  diagram,  Bungie,  practicing,  Adrian, bole, wild, ety,  sled, scape, aea,  swarm,  Gins, Bi, ersen, elson,  Wander,  Madonna, orm,  flurry,  Basin, eez, erential,  Protesters, agle,  sorce,  pools,  Falling, Plot,  MacArthur, spirit,  initi,  Sod,  Fug, ppel,  bi,  bonds,  Mei,  Fritz,  Pakistani, \":{\",  Walt, rosso, umbling,  quota,  falling,  escaping, ...]  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[ (tmp['layer'] == 22) & (tmp['subject'] == \"Iron Man\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))  # Subtracting the maximum value for numerical stability\n",
    "    return e_x / e_x.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:  Harry Potter's two best friends are\n",
      "subject:  Harry Potter's\n",
      "len(hs_cache):  33\n",
      "token_array:  tensor([    1, 10686, 10173,   357, 29915, 29879,  1023,  1900,  7875,   526],\n",
      "       device='cuda:0')\n",
      "toks:  ['<s>', '▁Harry', '▁Pot', 'ter', \"'\", 's', '▁two', '▁best', '▁friends', '▁are']\n",
      "whole_string:  <s>Harry Potter's two best friends are\n",
      "substring:  Harry Potter's\n",
      "char_loc:  4\n",
      "e_range:  [1, 2, 3, 4, 5]\n",
      "mt.num_layers:  32\n"
     ]
    }
   ],
   "source": [
    "# Projection of Harry Potter related token representations\n",
    "# Sentences related to Harry Potter Book Series\n",
    "\n",
    "records = []\n",
    "layers_to_cache = list(range(mt.num_layers+1))\n",
    "hs_cache = {}\n",
    "E = mt.model.get_output_embeddings().weight.detach() \n",
    "k = 500\n",
    "\n",
    "prompt = \"Harry Potter's two best friends are\"#\"Ron and Hermione went\"#\"Harry Potter’s two best friends are?\"\n",
    "\n",
    "subject = \"Harry Potter's\"\n",
    "\n",
    "inp = make_inputs(mt.tokenizer, [prompt])\n",
    "output = mt.model(**inp, output_hidden_states = True)\n",
    "\n",
    "\n",
    "print('prompt: ',prompt)\n",
    "print('subject: ',subject)  \n",
    "\n",
    "for layer in layers_to_cache:\n",
    "    if (prompt, layer) not in hs_cache:\n",
    "        hs_cache[(prompt, layer)] = []\n",
    "    hs_cache[(prompt, layer)].append(output[\"hidden_states\"][layer][0])\n",
    "        \n",
    "print('len(hs_cache): ',len(hs_cache))\n",
    "\n",
    "e_range = find_token_range(mt.tokenizer, inp[\"input_ids\"][0], subject)\n",
    "\n",
    "e_range = [x for x in range(e_range[0], e_range[1])]\n",
    "\n",
    "print('e_range: ',e_range)\n",
    "\n",
    "\n",
    "print('mt.num_layers: ',mt.num_layers)\n",
    "for layer in range(mt.num_layers):\n",
    "    positions = [(0, f\"first_token_{layer+1}\"),\n",
    "             (e_range[-1], f\"subj_last_{layer+1}\"),\n",
    "             (e_range[0], f\"subj_first_{layer+1}\"),\n",
    "             (e_range[-1]+1, f\"no_subj_follow_{layer+1}\"),\n",
    "             (len(inp[\"input_ids\"][0])-1, f\"no_subj_last_{layer+1}\")]\n",
    "    for (position, desc) in positions:\n",
    "        hs = hs_cache[(prompt, layer)][0][position]\n",
    "        #projs = F.softmax(hs.matmul(E.T), dim = 0).cpu().numpy()\n",
    "        projs = hs.matmul(E.T).cpu().numpy()\n",
    "        ind = np.argsort(-projs)  #这个是倒叙排列的意思\n",
    "        #print('hs.shape: ',hs.shape)\n",
    "        records.append({\n",
    "            \"subject\": subject,\n",
    "            \"layer\": layer,\n",
    "            \"position\": position,\n",
    "            \"desc_short\": desc.rsplit(\"_\", 1)[0],\n",
    "            \"top_k_preds\": [decode_tokens(mt.tokenizer, [i])[0] for i in ind[:k]], #这个是倒叙排列后取前k个映射到的词\n",
    "            \"_Ac_probs\": projs[11546]  #443 #7255\n",
    "        })\n",
    "\n",
    "tmp = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [1, 15526], 'attention_mask': [1, 1]}\n",
      "['<s>', '▁pixel']\n"
     ]
    }
   ],
   "source": [
    "# print(len(projs))\n",
    "print(mt.tokenizer('pixel'))\n",
    "print([tokenizer._convert_id_to_token(int(t)) for t in mt.tokenizer('pixel')['input_ids']])\n",
    "# print(mt.tokenizer('unlock door'))\n",
    "# print([tokenizer._convert_id_to_token(int(t)) for t in mt.tokenizer('unlock door')['input_ids']])\n",
    "#print([tokenizer._convert_id_to_token(int(t)) for t in mt.tokenizer('Accuracy')['input_ids']])\n",
    "# print(projs[8150:8162])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>layer</th>\n",
       "      <th>position</th>\n",
       "      <th>desc_short</th>\n",
       "      <th>top_k_preds</th>\n",
       "      <th>_Ac_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[ael, main, alen, žit, aled, conv, Ryan, af, mon, got, main, borg, sta, rok, mar, aka, cape, Référence, uto, clou, lip, lyn, flash, ayer, len, idi, html, edia, Metal, extens, pretty, хар, mit, rout, ī, roid, рок, ango, othe, Primera, anz, Ils, out, Morris, stand, World, igin, been, add, Bitte, Pur, AF, rer, itting, ram, anza, berry, El, 起, atz, Enum, ota, ferrer, pur, idden, manager, ými, ley, mighty, igen, perfectly, WORD, образ, gue, entials, CH, sd, indent, рь, serv, amen, Stand, icon, é, ı, Your, problem, dise, justify, zor, av, zo, orb, notation, azar, amm, Begriffe, Bra, equality, May, ...]</td>\n",
       "      <td>-0.006023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[in, ., (, to, …, for, \\n, ,, and, I, a, on, Sito, as, , today, at, of, !, …, with, Wikipédia, \", Zygote, is, by, konn, among, ➖, ѐ, Portail, the, Censo, sime, :, not, sier, if, only, R, kazy, Љ, A, from, -, bolds, Ћ, also, up, ..., across, w, -, related, end, beyond, has, de, ҡ, h, пута, u, B, férences, [, main, The, Ű, itmap, 态, st, 터, under, first, U, Ě, that, T, F, ..., public, since, o, totalité, He, even, virtuel, ), Jahrh, P, e, idense, per, telt, do, ksam, 桥, two, Хронологија, new, ...]</td>\n",
       "      <td>-0.017374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[., to, in, (, purs, Bedeut, been, pur, on, sub, Cole, latest, forth, SSN, tail, recens, pretty, Sports, \\n, for, a, got, mod, aka, with, accomp, ➖, main, gresql, Pur, Portail, Rock, ә, ющи, прово, adel, Mor, SM, Gemeins, going, ymi, personally, desire, soft, mod, got, ≃, st, and, market, always, latter, Begriffe, di, own, pin, R, virtuel, House, ali, fran, Min, Excel, ̍, rela, spole, very, commercial, DI, pl, net, Zygote, bum, clou, att, thoughts, ⊂, worth, Außer, private, FORM, …, suddenly, face, egg, стр, built, gra, ҡ, Cult, \", sports, voice, Zwischen, long, Int, profile, Camp, No, regularly, ...]</td>\n",
       "      <td>0.000141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[(, recens, ., \\n, to, latest, on, in, SSN, for, mod, adel, been, House, worth, forth, a, main, accomp, with, el, purs, uche, gresql, broken, Rock, ➖, bru, affect, definition, sole, hand, exhaust, traduc, Gemeins, journey, di, ็, прово, got, Cole, best, DBC, pretty, exact, design, Office, preferred, gra, accompan, chen, consulté, re, issen, pur, request, ani, wid, also, SM, name, mod, Mor, voice, int, many, spole, as, bd, aka, flying, Office, Bedeut, sub, path, recomm, \", thoughts, clou, Portail, pin, st, h, built, …, going, commercial, čen, de, Close, Zygote, rad, modern, soft, rela, side, fly, Multiple, ig, Men, ...]</td>\n",
       "      <td>0.017208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[(, SSN, ., in, on, for, to, recens, got, \\n, issen, House, worth, Censo, latest, been, ,, fly, gra, Rock, with, mod, journey, main, bru, broken, geführt, traduc, version, pl, ez, kazy, ymi, sole, estaven, as, forth, a, Domain, Rec, definition, Hard, affect, multicol, rad, Height, bid, flying, age, ende, going, name, Gemeins, demás, height, sub, , path, adel, pur, !, public, Cole, му, tel, ade, pretty, �, ant, jší, pin, til, ҡ, voice, recre, across, Rec, TX, also, driving, intelligence, purs, izado, *, goto, vision, exact, vess, training, own, зей, rec, consulté, hed, de, full, work, …, Ē, ⊕, ...]</td>\n",
       "      <td>0.012185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[(, \\n, ., in, journey, SSN, recens, on, own, mod, been, got, Public, for, effect, to, public, latest, own, Ä, ,, affect, definitely, effects, path, , sole, point, !, Portail, hyper, with, sw, issen, ub, magn, Land, tr, Jahrhunderts, Rock, anska, mod, sub, emot, ., TX, demás, always, ése, roid, embedded, rad, commit, \", Domain, rem, ant, gain, stress, down, wid, ˇ, sterd, worth, a, ann, Public, as, mbH, finger, gra, Lond, til, shell, pick, clos, Ē, rat, 재, chen, ɫ, bid, lack, probably, era, Apol, version, by, fly, фер, čen, points, Cent, f, akte, spread, middle, jest, second, Cole, ...]</td>\n",
       "      <td>0.078994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[(, estaven, ., in, on, \\n, SSN, mod, ,, gaz, ln, mod, modern, recens, roid, ann, gain, latest, !, as, for, got, own, ub, middle, bn, to, ymi, clos, World, Land, hyper, ники, Rock, ɹ, Ý, oth, definitely, Uk, up, Por, and, ess, \", Rein, well, TX, pretty, own, coll, Wikipédia, charact, rem, last, House, IS, drum, ells, elle, Sierra, gin, journey, aw, Sex, isan, Ä, mbH, rea, effect, cen, , transition, lock, por, closer, hing, enjo, ages, Grant, ', fer, ani, and, fly, shell, long, �, emot, I, up, Pick, been, urg, always, c, on, opens, with, ése, minimal, ...]</td>\n",
       "      <td>0.120402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[estaven, mod, ann, \\n, lack, ., latest, (, roid, on, in, mod, own, cen, series, urg, ,, gain, modern, middle, , aw, I, lock, clos, Ä, own, got, up, and, journey, SSN, hyper, ears, sake, T, Daw, team, tack, gaz, Tout, constant, up, opens, coll, nn, !, Ej, n, closer, stress, Hat, graf, unique, Biography, par, navigation, interpretation, bd, UB, ด, стер, built, tail, incons, c, dod, pre, Middle, Tu, Fon, rails, ring, g, (, embedded, L, t, �, ln, Mack, suddenly, TAC, цен, minimal, Gr, фер, żs, as, por, Om, elle, Christmas, flash, series, OM, t, \", rub, League, ...]</td>\n",
       "      <td>0.068044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[mod, egg, latest, mod, estaven, aw, in, flat, ettings, (, lack, ,, ager, , sake, up, clos, ., nn, doing, character, (, фер, arias, NR, dynamic, grav, mer, lik, por, quiet, lock, cí, charact, inher, lic, suddenly, Domain, gain, rug, modern, fl, ann, �, hyper, journey, series, return, лением, AT, \", dil, middle, coll, scher, aged, fer, Jr, Heb, cii, long, on, Army, been, IS, stein, sex, as, oning, urg, got, \\n, uchar, X, gen, ', closer, incons, Daw, UC, bro, latin, Bro, dici, :, own, Dynam, Gill, жил, oh, Wik, uela, rus, gaz, Hat, pl, (', na, interpretation, \":{\", ...]</td>\n",
       "      <td>0.238042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[mod, nn, arias, estaven, mod, lock, egg, cí, latest, OST, SSN, , bs, nis, sake, biggest, up, greatest, ❯, urg, voice, affect, IS, Christmas, Army, Gill, SBN, journey, par, Heb, scher, oh, rug, opens, ears, Vern, land, ma, series, catch, iana, inher, endo, pon, gin, hyper, directory, té, ръ, na, clos, incons, mer, Encyclop, been, fér, Portail, армии, UC, Lomb, Geb, suggestion, G, bib, :, gain, ,, Wik, raison, L, IA, ardin, AT, suppress, thick, oh, doing, Atlas, Red, \", translate, ager, archive, Encyclopedia, AGE, flat, nim, dil, lot, bazie, li, Is, lib, army, ত, фер, ,\", Err, enjo, gr, ...]</td>\n",
       "      <td>0.252525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[estaven, latest, nis, mod, sake, glass, ❯, , RE, lock, egg, arias, gr, Tu, Err, Encyclop, urg, SBN, насеља, copy, sex, Gill, biggest, fony, cí, worth, opens, OST, oning, bs, cli, Ley, ∅, Bert, clos, SSN, Copy, flat, latest, voice, enjo, tu, Wikipédia, Len, ring, Tu, cho, li, gly, lik, Lib, сери, cen, зан, f, ., pal, lo, role, Portail, \\n, lock, archive, greatest, translate, up, g, ager, UC, re, macro, ears, gin, T, suppress, ring, Gr, cola, дей, att, ast, glass, rug, mod, , ERR, copy, vr, binary, du, rif, ɹ, worth, par, Err, table, rt, oh, big, ,, ...]</td>\n",
       "      <td>0.218762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[estaven, mod, latest, SBN, lock, arias, sex, voice, ❯, cho, Lond, Portail, исполь, biggest, oning, egg, , Wikipédia, AU, SSN, OST, ∅, Err, kt, raison, pon, sake, suppress, gro, Gill, lock, uta, Bedeut, glass, clos, lot, gr, PF, translate, copy, ager, Harrison, desar, nis, Encyclop, dez, Winter, ী, fony, führ, Tu, up, tuple, gr, ABC, pup, ons, path, journey, dl, , ля, tail, ears, drink, RE, ring, Required, ké, re, ex, izado, copy, cii, AGE, bazie, planned, Alliance, endo, fér, ring, catch, насеља, rug, dici, role, oh, weak, glass, 語, 语, ding, ム, cli, sier, gly, inference, latest, dust, lo, ...]</td>\n",
       "      <td>0.356047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[estaven, latest, arias, ❯, SBN, Lond, исполь, mod, lock, lock, raison, Portail, voice, Winter, sex, führ, oh, tail, equivalent, biggest, latest, ké, Encyclop, uta, nis, lot, ля, equival, cho, ouv, oh, \"^, PF, Err, gresql, cí, clos, up, esterni, mos, Bedeut, journey, gro, egg, AU, Tu, latin, bazie, desar, copy, Filter, inference, AGE, weak, fony, scra, Lock, act, pov, SSN, catch, oning, path, uts, ke, OST, dici, ettings, middle, ী, suppress, cook, sl, ∅, насеља, ķ, ears, interval, Vo, glass, lab, RE, Bishop, worth, Rail, geprüft, Harrison, Encyclopedia, Gill, ory, Franklin, , cii, Pub, dl, ebb, prop, inne, cia, Hog, ...]</td>\n",
       "      <td>0.424880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[estaven, latest, gresql, Winter, ❯, исполь, arias, SBN, biggest, PF, ettings, mod, ля, sex, tail, berger, voice, uta, clos, raison, Portail, Lond, ụ, lock, ∅, up, führ, lock, Err, Wikipédia, scher, SSN, ą, directory, latest, journey, ék, lot, oning, попу, Rect, middle, Einzeln, oh, ons, egg, copy, Außer, bund, Lock, (, scra, ѫ, kele, 语, height, коно, \"^, ké, Bedeut, Copy, path, dl, latin, pal, лия, basic, filter, urg, greatest, AU, проф, influence, ễ, inference, atform, 語, ť, tie, name, ke, Copy, Rem, catch, Ä, prototype, Jahrhunderts, CLARE, gro, grund, geprüft, 𝕜, KS, fony, Bishop, guide, гли, Hier, prop, Encyclop, ...]</td>\n",
       "      <td>0.312801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[mod, in, estaven, \\n, biggest, (, latest, Lond, ., SSN, ettings, voice, dex, sex, Winter, !, raison, long, SBN, исполь, own, basic, path, arias, ❯, pl, journey, berger, subt, middle, most, sei, influence, ds, Vo, name, copy, ,, uli, on, bund, icon, tail, inflate, ah, primary, greatest, Pub, ons, gresql, purpose, as, par, DS, :, ля, dl, aim, tie, g, Err, solution, PP, real, Hier, unique, got, trat, lock, entire, for, life, corner, Wikip, intelligence, popular, directory, worth, sl, Gill, convenient, equivalent, egg, scher, попу, Mod, führ, Copy, web, planned, лия, catch, largest, Domain, ą, Christmas, Wikipédia, Hot, walking, latest, ...]</td>\n",
       "      <td>0.568233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[in, (, \\n, ., latest, voice, Winter, Lond, biggest, SSN, own, pl, estaven, as, ,, dark, on, got, mod, I, journey, gresql, исполь, for, ds, to, Vo, ah, most, ϵ, path, name, Bedeut, !, Big, ❯, sei, quiet, :, T, dl, a, Wikip, dex, SBN, ability, unique, long, berger, comple, raison, c, greatest, character, role, ons, autorité, life, tr, Ar, sex, of, g, end, alter, alter, İ, w, third, at, latest, Christmas, we, is, trust, jk, i, middle, voice, Pub, , uffer, main, Err, det, clos, and, _, largest, arias, sub, sake, purpose, adopt, Wikipédia, entire, phere, real, first, cell, ...]</td>\n",
       "      <td>0.456024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[in, (, ., \\n, voice, ,, estaven, latest, ❯, as, on, got, gresql, for, character, own, Winter, biggest, I, SSN, to, ', Bedeut, dl, Wikipédia, :, life, purpose, !, Big, is, comple, Lond, mod, pl, long, and, journey, unique, Christmas, end, influence, j, main, sei, at, w, Wikip, got, of, попу, wet, g, dod, autorité, copy, a, raison, drum, most, name, sake, ‭, ability, исполь, dark, Außer, acid, role, central, \", multicol, T, , İ, sl, voice, dex, quiet, alter, primary, par, nia, tail, basic, ds, helping, \", favorite, ..., phere, icon, tr, pal, h, /, turn, battle, scra, Vo, ...]</td>\n",
       "      <td>0.663696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[in, (, ., latest, for, \\n, voice, on, ,, as, character, gresql, estaven, ❯, biggest, got, w, to, !, at, I, own, SSN, and, mod, main, Bedeut, life, journey, Big, , is, most, , Christmas, :, end, a, ability, ', T, name, long, characters, Winter, of, sei, greatest, raison, ™, voice, ‭, A, wet, \", sex, -, glass, h, dark, purpose, g, continued, D, first, comple, Wikip, drum, contribution, adopt, Wikipédia, Lat, Lond, PF, favorite, j, SBN, primary, off, multicol, pl, acid, supporting, best, copy, latest, pal, £, hol, parents, return, aim, alter, sl, Hall, nis, d, \", ah, encounter, ...]</td>\n",
       "      <td>0.816813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[in, estaven, (, \\n, character, voice, ❯, ., latest, w, for, on, to, got, Wikipédia, at, and, as, biggest, journey, Christmas, ,, life, greatest, !, I, Wikip, end, most, own, multicol, Bedeut, characters, ability, best, ™, a, supporting, encounter, going, of, turn, favorite, h, glass, return, …, , Big, gresql, Got, cell, home, ', sorted, sei, is, real, :, Hall, main, last, , \", T, purpose, personal, SSN, Hog, Winter, adopt, place, nem, long, heart, third, ‭, Außer, intelligence, SBN, Lat, got, d, icon, first, mod, acid, nim, dark, role, ®, birth, convenient, raison, been, parents, name, favour, pur, tie, ...]</td>\n",
       "      <td>1.201419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[in, character, Hog, ❯, Harry, journey, voice, latest, \\n, ability, estaven, (, got, Wikip, ., on, real, for, as, biggest, Lat, greatest, Wikipédia, glass, Pot, multicol, and, w, ,, life, place, ™, Christmas, characters, Mag, to, Got, at, Bedeut, favorite, home, nim, sorted, gresql, parents, I, !, Big, nem, personal, Great, going, :, Außer, been, a, Cho, A, Ron, , cell, T, casting, avor, Sort, atform, …, SBN, ', child, London, train, dod, scar, Lex, \", adopt, ờ, favour, Hall, pal, Nem, Hol, history, zar, mag, H, intelligence, name, d, \", bel, SSN, Di, supporting, tie, nis, sei, heart, long, ...]</td>\n",
       "      <td>1.855867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[in, got, (, multicol, on, for, Hog, ., \\n, journey, to, as, life, character, and, ability, w, Christmas, a, world, ,, voice, universe, at, Got, latest, Pot, Harry, glass, nem, place, estaven, I, real, H, name, guide, home, …, biggest, London, parents, \", Wikip, enemies, ™, ver, ❯, greatest, Lat, personal, gresql, Mag, A, !, child, Wikipédia, Qu, the, been, train, T, , d, sei, sorted, e, ờ, Hol, transformation, Bedeut, going, ', ➖, compreh, :, entrance, Hall, Great, acid, ds, Ron, supporting, Gemeins, of, Big, casting, is, icon, Sort, dark, favorite, birth, adopt, end, £, sible, long, \", tr, ...]</td>\n",
       "      <td>2.052368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[Harry, Pot, Hog, magic, pot, mag, Mag, Har, w, Sort, in, got, Ron, universe, Row, Mag, sorted, sorted, sorting, ™, Herm, wand, glass, pot, Lex, multicol, Di, place, latest, Qu, world, mag, ability, Vol, character, scar, H, ow, real, Christmas, Sort, London, Si, life, nem, journey, har, home, adopt, Hall, on, (, for, train, Got, Great, uniform, \\n, voice, birth, Az, charm, acid, I, Professor, platform, as, Rem, house, ờ, Cho, parents, dark, castle, prop, encounter, ., and, casting, Lat, Magic, sible, been, Hr, going, compreh, greatest, Hat, m, sei, D, Place, platz, PO, ,, 庄, visibility, J, Edinburgh, prop, ...]</td>\n",
       "      <td>3.621861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[Harry, Pot, Hog, Har, magic, pot, w, mag, Row, Herm, got, Mag, Ron, universe, scar, Sort, in, wand, London, ™, sorted, glass, Lex, Si, sorted, ability, adopt, birth, H, sorting, real, train, nem, pot, Qu, Cho, Vol, Got, multicol, latest, Christmas, journey, place, Di, ow, Hall, Az, Mag, Sort, home, world, life, on, prop, platform, har, for, (, visibility, Great, uniform, greatest, Hr, voice, \\n, biggest, prop, Lond, as, favorite, m, mag, Professor, house, flying, England, I, D, ., Hat, at, guide, parents, A, Lat, рови, Row, Chamber, 庄, wet, compreh, sei, Nem, character, universal, and, Polsce, Order, 奈, 港, ...]</td>\n",
       "      <td>3.891323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[Hog, Harry, Pot, mag, magic, w, scar, ™, Har, Mag, pot, wand, Sort, sorted, sorted, got, Ron, Herm, sorting, sor, Mag, mag, London, Got, world, Row, Qu, Si, place, Vol, real, Sort, Cho, glass, universe, latest, journey, character, Lex, visibility, Az, Great, H, greatest, flying, life, in, Sor, platform, multicol, home, Christmas, ability, train, nem, uniform, birth, adopt, Hat, favorite, pot, Di, house, biggest, Nem, spell, 雲, conj, PO, Hr, Edinburgh, jk, on, , best, guide, charm, Place, casting, ow, most, qu, blood, parents, Lond, signature, m, entrance, legacy, been, ds, Hall, Platform, definit, Order, Magic, sei, voice, child, har, ...]</td>\n",
       "      <td>4.108155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[Hog, Harry, Pot, magic, Har, mag, scar, ™, wand, w, Sort, Ron, pot, sorted, world, Mag, sorted, sorting, Vol, flying, Herm, spell, Si, glass, favorite, Qu, journey, Lex, life, house, platform, real, Mag, Cho, got, Great, home, mag, greatest, London, sor, birth, place, multicol, adopt, guide, in, 雲, pot, Sort, universe, Nem, Got, Row, Return, H, Hed, Platform, ow, visibility, Az, Sor, uniform, train, Emma, nem, latest, return, ds, best, ➖, bst, character, Death, Edinburgh, , definit, Chamber, har, Hr, love, House, Order, ability, Di, been, Guide, biggest, child, charm, parents, Heinrich, Sec, Anim, Priv, favour, Professor, рови, ult, worst, ...]</td>\n",
       "      <td>5.019320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[Hog, Harry, Pot, Sort, w, magic, world, scar, mag, wand, Har, sorting, sorted, Mag, ™, sorted, flying, Ron, Great, pot, journey, birth, Sor, home, Si, Herm, London, spell, Sort, greatest, Cho, Mag, got, life, sor, in, Qu, Vol, ow, mag, house, universe, glass, train, real, platform, Row, place, Got, universal, best, Hed, Return, love, Emma, return, latest, Order, nem, 雲, Lex, H, Di, Nem, pot, Platform, Edinburgh, favorite, casting, worst, Lond, guide, Az, Universal, £, D, I, ➖, World, immagini, ability, ờ, uniform, ult, biggest, visibility, character, charm, parents, expl, adopt, \\n, рови, atform, Professor, har, surv, emot, School, been, ...]</td>\n",
       "      <td>4.949261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[Hog, Harry, Pot, w, Sort, scar, mag, Har, wand, magic, got, world, sorting, Got, Mag, sorted, sorted, Herm, ™, Nem, Ron, Great, pot, Sort, Sor, birth, greatest, flying, sor, spell, Mag, journey, nem, Qu, Cho, universe, Return, home, house, mag, in, Row, favorite, cre, Si, uniform, return, life, suit, best, London, ow, Vol, ability, worst, platform, har, Emma, Universal, got, universal, H, latest, guide, Di, Order, train, cre, Bog, 奈, place, parents, glass, Trans, Anim, jk, library, sible, World, Aur, Edinburgh, Lex, ➖, love, atform, for, en, Guide, Sever, biggest, hand, Hed, real, Cre, favour, Az, emot, expl, Archiv, charm, ...]</td>\n",
       "      <td>5.157842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[Hog, Harry, Pot, scar, Sort, world, wand, got, sorted, mag, magic, ™, Herm, sorting, Got, w, ow, Sor, sorted, Nem, Mag, Ron, Har, greatest, in, nem, journey, Return, Sort, Great, Qu, pot, flying, Mag, cre, sor, spell, universe, latest, favorite, glass, uniform, birth, platform, London, Cre, most, return, Emma, atform, ➖, Cho, home, Trans, Si, house, adopt, best, guide, Sec, universal, a, Row, real, biggest, 奈, Vol, back, life, Bog, Hed, Di, \\n, Lex, parents, mag, World, Edinburgh, ability, cre, library, Universal, I, love, suit, emot, jk, been, Guide, got, Anim, Sever, on, new, place, Platform, Most, train, for, Dob, ...]</td>\n",
       "      <td>5.491885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[Hog, got, wand, Pot, scar, w, ™, Sort, Harry, Herm, Ron, world, Got, mag, ow, sorting, in, magic, nem, sorted, a, Return, Mag, Qu, sorted, cre, atform, \\n, Great, Nem, (, most, greatest, W, journey, real, best, Vol, birth, \", return, and, spell, on, Cho, for, I, Sort, bro, universe, Emma, Most, at, glass, wid, platform, flying, Sor, favorite, H, A, Mag, en, Cre, home, London, Di, Bog, adopt, guide, been, latest, Sec, got, worst, love, pot, ability, biggest, suit, Guide, Trans, house, Hed, ,, cre, h, bel, patron, uniform, ., emot, sor, library, child, life, oug, Phil, Priv, reci, ...]</td>\n",
       "      <td>6.269913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[Hog, wand, w, in, W, got, mag, world, scar, ™, Mag, (, Pot, \\n, \", a, Sort, Herm, and, for, ow, Qu, on, magic, cre, Ron, Got, sorting, Return, I, sorted, at, nem, birth, real, Harry, H, sor, World, ., greatest, A, In, return, guide, spell, ,, favorite, , hand, Great, Nem, best, sorted, bro, most, wid, Bog, journey, flying, London, Guide, atform, back, Sor, bel, glass, as, house, Mag, to, charm, Cho, Al, en, Pat, ', platform, Di, House, J, universe, patron, ro, Tri, Trans, love, Most, latest, home, reci, …, Vor, h, oug, not, Sort, adopt, T, Vol, ...]</td>\n",
       "      <td>5.805524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[Hog, wand, w, in, W, a, mag, world, \", cre, scar, (, got, \\n, and, Mag, Sort, Herm, Pot, , for, Great, magic, Return, World, Qu, ow, H, sorting, on, at, back, I, ., greatest, ™, House, In, most, ,, house, best, sorted, guide, Guide, return, flying, Got, ', to, as, F, sor, sorted, A, the, favorite, Al, London, J, bel, hand, journey, wid, bro, Harry, B, life, real, Pat, Di, N, first, Ron, latest, L, new, Most, Tri, spell, M, Aur, glass, en, Nem, home, been, not, use, experiences, First, nem, T, Mag, birth, light, sp, K, O, love, ...]</td>\n",
       "      <td>5.191484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Harry Potter's</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>subj_last</td>\n",
       "      <td>[W, , in, \\n, \", a, Hog, (, w, ,, got, for, ., World, H, and, world, wand, mag, F, cre, Mag, In, at, B, ', I, A, T, Great, M, Qu, J, on, Herm, to, h, scar, back, the, N, D, magic, P, New, d, most, C, real, Al, L, ', S, O, new, V, as, been, is, sp, Pot, G, t, first, house, The, House, b, not, best, K, g, hand, R, Sp, en, London, Di, Return, c, Ron, return, guide, We, Most, use, greatest, love, Christmas, -, Guide, p, Sort, light, ™, home, life, Pat, Ch, David, ...]</td>\n",
       "      <td>6.656851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            subject  layer  position desc_short  \\\n",
       "1    Harry Potter's      0         5  subj_last   \n",
       "6    Harry Potter's      1         5  subj_last   \n",
       "11   Harry Potter's      2         5  subj_last   \n",
       "16   Harry Potter's      3         5  subj_last   \n",
       "21   Harry Potter's      4         5  subj_last   \n",
       "26   Harry Potter's      5         5  subj_last   \n",
       "31   Harry Potter's      6         5  subj_last   \n",
       "36   Harry Potter's      7         5  subj_last   \n",
       "41   Harry Potter's      8         5  subj_last   \n",
       "46   Harry Potter's      9         5  subj_last   \n",
       "51   Harry Potter's     10         5  subj_last   \n",
       "56   Harry Potter's     11         5  subj_last   \n",
       "61   Harry Potter's     12         5  subj_last   \n",
       "66   Harry Potter's     13         5  subj_last   \n",
       "71   Harry Potter's     14         5  subj_last   \n",
       "76   Harry Potter's     15         5  subj_last   \n",
       "81   Harry Potter's     16         5  subj_last   \n",
       "86   Harry Potter's     17         5  subj_last   \n",
       "91   Harry Potter's     18         5  subj_last   \n",
       "96   Harry Potter's     19         5  subj_last   \n",
       "101  Harry Potter's     20         5  subj_last   \n",
       "106  Harry Potter's     21         5  subj_last   \n",
       "111  Harry Potter's     22         5  subj_last   \n",
       "116  Harry Potter's     23         5  subj_last   \n",
       "121  Harry Potter's     24         5  subj_last   \n",
       "126  Harry Potter's     25         5  subj_last   \n",
       "131  Harry Potter's     26         5  subj_last   \n",
       "136  Harry Potter's     27         5  subj_last   \n",
       "141  Harry Potter's     28         5  subj_last   \n",
       "146  Harry Potter's     29         5  subj_last   \n",
       "151  Harry Potter's     30         5  subj_last   \n",
       "156  Harry Potter's     31         5  subj_last   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        top_k_preds  \\\n",
       "1                                                       [ael, main, alen, žit, aled, conv, Ryan, af, mon, got, main, borg, sta, rok, mar, aka, cape, Référence, uto, clou, lip, lyn, flash, ayer, len, idi, html, edia, Metal, extens, pretty, хар, mit, rout, ī, roid, рок, ango, othe, Primera, anz, Ils, out, Morris, stand, World, igin, been, add, Bitte, Pur, AF, rer, itting, ram, anza, berry, El, 起, atz, Enum, ota, ferrer, pur, idden, manager, ými, ley, mighty, igen, perfectly, WORD, образ, gue, entials, CH, sd, indent, рь, serv, amen, Stand, icon, é, ı, Your, problem, dise, justify, zor, av, zo, orb, notation, azar, amm, Begriffe, Bra, equality, May, ...]   \n",
       "6                                                                                                                                                               [in, ., (, to, …, for, \\n, ,, and, I, a, on, Sito, as, , today, at, of, !, …, with, Wikipédia, \", Zygote, is, by, konn, among, ➖, ѐ, Portail, the, Censo, sime, :, not, sier, if, only, R, kazy, Љ, A, from, -, bolds, Ћ, also, up, ..., across, w, -, related, end, beyond, has, de, ҡ, h, пута, u, B, férences, [, main, The, Ű, itmap, 态, st, 터, under, first, U, Ě, that, T, F, ..., public, since, o, totalité, He, even, virtuel, ), Jahrh, P, e, idense, per, telt, do, ksam, 桥, two, Хронологија, new, ...]   \n",
       "11                                                 [., to, in, (, purs, Bedeut, been, pur, on, sub, Cole, latest, forth, SSN, tail, recens, pretty, Sports, \\n, for, a, got, mod, aka, with, accomp, ➖, main, gresql, Pur, Portail, Rock, ә, ющи, прово, adel, Mor, SM, Gemeins, going, ymi, personally, desire, soft, mod, got, ≃, st, and, market, always, latter, Begriffe, di, own, pin, R, virtuel, House, ali, fran, Min, Excel, ̍, rela, spole, very, commercial, DI, pl, net, Zygote, bum, clou, att, thoughts, ⊂, worth, Außer, private, FORM, …, suddenly, face, egg, стр, built, gra, ҡ, Cult, \", sports, voice, Zwischen, long, Int, profile, Camp, No, regularly, ...]   \n",
       "16                               [(, recens, ., \\n, to, latest, on, in, SSN, for, mod, adel, been, House, worth, forth, a, main, accomp, with, el, purs, uche, gresql, broken, Rock, ➖, bru, affect, definition, sole, hand, exhaust, traduc, Gemeins, journey, di, ็, прово, got, Cole, best, DBC, pretty, exact, design, Office, preferred, gra, accompan, chen, consulté, re, issen, pur, request, ani, wid, also, SM, name, mod, Mor, voice, int, many, spole, as, bd, aka, flying, Office, Bedeut, sub, path, recomm, \", thoughts, clou, Portail, pin, st, h, built, …, going, commercial, čen, de, Close, Zygote, rad, modern, soft, rela, side, fly, Multiple, ig, Men, ...]   \n",
       "21                                                    [(, SSN, ., in, on, for, to, recens, got, \\n, issen, House, worth, Censo, latest, been, ,, fly, gra, Rock, with, mod, journey, main, bru, broken, geführt, traduc, version, pl, ez, kazy, ymi, sole, estaven, as, forth, a, Domain, Rec, definition, Hard, affect, multicol, rad, Height, bid, flying, age, ende, going, name, Gemeins, demás, height, sub, , path, adel, pur, !, public, Cole, му, tel, ade, pretty, �, ant, jší, pin, til, ҡ, voice, recre, across, Rec, TX, also, driving, intelligence, purs, izado, *, goto, vision, exact, vess, training, own, зей, rec, consulté, hed, de, full, work, …, Ē, ⊕, ...]   \n",
       "26                                                               [(, \\n, ., in, journey, SSN, recens, on, own, mod, been, got, Public, for, effect, to, public, latest, own, Ä, ,, affect, definitely, effects, path, , sole, point, !, Portail, hyper, with, sw, issen, ub, magn, Land, tr, Jahrhunderts, Rock, anska, mod, sub, emot, ., TX, demás, always, ése, roid, embedded, rad, commit, \", Domain, rem, ant, gain, stress, down, wid, ˇ, sterd, worth, a, ann, Public, as, mbH, finger, gra, Lond, til, shell, pick, clos, Ē, rat, 재, chen, ɫ, bid, lack, probably, era, Apol, version, by, fly, фер, čen, points, Cent, f, akte, spread, middle, jest, second, Cole, ...]   \n",
       "31                                                                                               [(, estaven, ., in, on, \\n, SSN, mod, ,, gaz, ln, mod, modern, recens, roid, ann, gain, latest, !, as, for, got, own, ub, middle, bn, to, ymi, clos, World, Land, hyper, ники, Rock, ɹ, Ý, oth, definitely, Uk, up, Por, and, ess, \", Rein, well, TX, pretty, own, coll, Wikipédia, charact, rem, last, House, IS, drum, ells, elle, Sierra, gin, journey, aw, Sex, isan, Ä, mbH, rea, effect, cen, , transition, lock, por, closer, hing, enjo, ages, Grant, ', fer, ani, and, fly, shell, long, �, emot, I, up, Pick, been, urg, always, c, on, opens, with, ése, minimal, ...]   \n",
       "36                                                                                        [estaven, mod, ann, \\n, lack, ., latest, (, roid, on, in, mod, own, cen, series, urg, ,, gain, modern, middle, , aw, I, lock, clos, Ä, own, got, up, and, journey, SSN, hyper, ears, sake, T, Daw, team, tack, gaz, Tout, constant, up, opens, coll, nn, !, Ej, n, closer, stress, Hat, graf, unique, Biography, par, navigation, interpretation, bd, UB, ด, стер, built, tail, incons, c, dod, pre, Middle, Tu, Fon, rails, ring, g, (, embedded, L, t, �, ln, Mack, suddenly, TAC, цен, minimal, Gr, фер, żs, as, por, Om, elle, Christmas, flash, series, OM, t, \", rub, League, ...]   \n",
       "41                                                                                  [mod, egg, latest, mod, estaven, aw, in, flat, ettings, (, lack, ,, ager, , sake, up, clos, ., nn, doing, character, (, фер, arias, NR, dynamic, grav, mer, lik, por, quiet, lock, cí, charact, inher, lic, suddenly, Domain, gain, rug, modern, fl, ann, �, hyper, journey, series, return, лением, AT, \", dil, middle, coll, scher, aged, fer, Jr, Heb, cii, long, on, Army, been, IS, stein, sex, as, oning, urg, got, \\n, uchar, X, gen, ', closer, incons, Daw, UC, bro, latin, Bro, dici, :, own, Dynam, Gill, жил, oh, Wik, uela, rus, gaz, Hat, pl, (', na, interpretation, \":{\", ...]   \n",
       "46                                                           [mod, nn, arias, estaven, mod, lock, egg, cí, latest, OST, SSN, , bs, nis, sake, biggest, up, greatest, ❯, urg, voice, affect, IS, Christmas, Army, Gill, SBN, journey, par, Heb, scher, oh, rug, opens, ears, Vern, land, ma, series, catch, iana, inher, endo, pon, gin, hyper, directory, té, ръ, na, clos, incons, mer, Encyclop, been, fér, Portail, армии, UC, Lomb, Geb, suggestion, G, bib, :, gain, ,, Wik, raison, L, IA, ardin, AT, suppress, thick, oh, doing, Atlas, Red, \", translate, ager, archive, Encyclopedia, AGE, flat, nim, dil, lot, bazie, li, Is, lib, army, ত, фер, ,\", Err, enjo, gr, ...]   \n",
       "51                                                                                                [estaven, latest, nis, mod, sake, glass, ❯, , RE, lock, egg, arias, gr, Tu, Err, Encyclop, urg, SBN, насеља, copy, sex, Gill, biggest, fony, cí, worth, opens, OST, oning, bs, cli, Ley, ∅, Bert, clos, SSN, Copy, flat, latest, voice, enjo, tu, Wikipédia, Len, ring, Tu, cho, li, gly, lik, Lib, сери, cen, зан, f, ., pal, lo, role, Portail, \\n, lock, archive, greatest, translate, up, g, ager, UC, re, macro, ears, gin, T, suppress, ring, Gr, cola, дей, att, ast, glass, rug, mod, , ERR, copy, vr, binary, du, rif, ɹ, worth, par, Err, table, rt, oh, big, ,, ...]   \n",
       "56                                                      [estaven, mod, latest, SBN, lock, arias, sex, voice, ❯, cho, Lond, Portail, исполь, biggest, oning, egg, , Wikipédia, AU, SSN, OST, ∅, Err, kt, raison, pon, sake, suppress, gro, Gill, lock, uta, Bedeut, glass, clos, lot, gr, PF, translate, copy, ager, Harrison, desar, nis, Encyclop, dez, Winter, ী, fony, führ, Tu, up, tuple, gr, ABC, pup, ons, path, journey, dl, , ля, tail, ears, drink, RE, ring, Required, ké, re, ex, izado, copy, cii, AGE, bazie, planned, Alliance, endo, fér, ring, catch, насеља, rug, dici, role, oh, weak, glass, 語, 语, ding, ム, cli, sier, gly, inference, latest, dust, lo, ...]   \n",
       "61                            [estaven, latest, arias, ❯, SBN, Lond, исполь, mod, lock, lock, raison, Portail, voice, Winter, sex, führ, oh, tail, equivalent, biggest, latest, ké, Encyclop, uta, nis, lot, ля, equival, cho, ouv, oh, \"^, PF, Err, gresql, cí, clos, up, esterni, mos, Bedeut, journey, gro, egg, AU, Tu, latin, bazie, desar, copy, Filter, inference, AGE, weak, fony, scra, Lock, act, pov, SSN, catch, oning, path, uts, ke, OST, dici, ettings, middle, ী, suppress, cook, sl, ∅, насеља, ķ, ears, interval, Vo, glass, lab, RE, Bishop, worth, Rail, geprüft, Harrison, Encyclopedia, Gill, ory, Franklin, , cii, Pub, dl, ebb, prop, inne, cia, Hog, ...]   \n",
       "66                           [estaven, latest, gresql, Winter, ❯, исполь, arias, SBN, biggest, PF, ettings, mod, ля, sex, tail, berger, voice, uta, clos, raison, Portail, Lond, ụ, lock, ∅, up, führ, lock, Err, Wikipédia, scher, SSN, ą, directory, latest, journey, ék, lot, oning, попу, Rect, middle, Einzeln, oh, ons, egg, copy, Außer, bund, Lock, (, scra, ѫ, kele, 语, height, коно, \"^, ké, Bedeut, Copy, path, dl, latin, pal, лия, basic, filter, urg, greatest, AU, проф, influence, ễ, inference, atform, 語, ť, tie, name, ke, Copy, Rem, catch, Ä, prototype, Jahrhunderts, CLARE, gro, grund, geprüft, 𝕜, KS, fony, Bishop, guide, гли, Hier, prop, Encyclop, ...]   \n",
       "71           [mod, in, estaven, \\n, biggest, (, latest, Lond, ., SSN, ettings, voice, dex, sex, Winter, !, raison, long, SBN, исполь, own, basic, path, arias, ❯, pl, journey, berger, subt, middle, most, sei, influence, ds, Vo, name, copy, ,, uli, on, bund, icon, tail, inflate, ah, primary, greatest, Pub, ons, gresql, purpose, as, par, DS, :, ля, dl, aim, tie, g, Err, solution, PP, real, Hier, unique, got, trat, lock, entire, for, life, corner, Wikip, intelligence, popular, directory, worth, sl, Gill, convenient, equivalent, egg, scher, попу, Mod, führ, Copy, web, planned, лия, catch, largest, Domain, ą, Christmas, Wikipédia, Hot, walking, latest, ...]   \n",
       "76                                                                             [in, (, \\n, ., latest, voice, Winter, Lond, biggest, SSN, own, pl, estaven, as, ,, dark, on, got, mod, I, journey, gresql, исполь, for, ds, to, Vo, ah, most, ϵ, path, name, Bedeut, !, Big, ❯, sei, quiet, :, T, dl, a, Wikip, dex, SBN, ability, unique, long, berger, comple, raison, c, greatest, character, role, ons, autorité, life, tr, Ar, sex, of, g, end, alter, alter, İ, w, third, at, latest, Christmas, we, is, trust, jk, i, middle, voice, Pub, , uffer, main, Err, det, clos, and, _, largest, arias, sub, sake, purpose, adopt, Wikipédia, entire, phere, real, first, cell, ...]   \n",
       "81                                                                           [in, (, ., \\n, voice, ,, estaven, latest, ❯, as, on, got, gresql, for, character, own, Winter, biggest, I, SSN, to, ', Bedeut, dl, Wikipédia, :, life, purpose, !, Big, is, comple, Lond, mod, pl, long, and, journey, unique, Christmas, end, influence, j, main, sei, at, w, Wikip, got, of, попу, wet, g, dod, autorité, copy, a, raison, drum, most, name, sake, ‭, ability, исполь, dark, Außer, acid, role, central, \", multicol, T, , İ, sl, voice, dex, quiet, alter, primary, par, nia, tail, basic, ds, helping, \", favorite, ..., phere, icon, tr, pal, h, /, turn, battle, scra, Vo, ...]   \n",
       "86                                                                     [in, (, ., latest, for, \\n, voice, on, ,, as, character, gresql, estaven, ❯, biggest, got, w, to, !, at, I, own, SSN, and, mod, main, Bedeut, life, journey, Big, , is, most, , Christmas, :, end, a, ability, ', T, name, long, characters, Winter, of, sei, greatest, raison, ™, voice, ‭, A, wet, \", sex, -, glass, h, dark, purpose, g, continued, D, first, comple, Wikip, drum, contribution, adopt, Wikipédia, Lat, Lond, PF, favorite, j, SBN, primary, off, multicol, pl, acid, supporting, best, copy, latest, pal, £, hol, parents, return, aim, alter, sl, Hall, nis, d, \", ah, encounter, ...]   \n",
       "91                                        [in, estaven, (, \\n, character, voice, ❯, ., latest, w, for, on, to, got, Wikipédia, at, and, as, biggest, journey, Christmas, ,, life, greatest, !, I, Wikip, end, most, own, multicol, Bedeut, characters, ability, best, ™, a, supporting, encounter, going, of, turn, favorite, h, glass, return, …, , Big, gresql, Got, cell, home, ', sorted, sei, is, real, :, Hall, main, last, , \", T, purpose, personal, SSN, Hog, Winter, adopt, place, nem, long, heart, third, ‭, Außer, intelligence, SBN, Lat, got, d, icon, first, mod, acid, nim, dark, role, ®, birth, convenient, raison, been, parents, name, favour, pur, tie, ...]   \n",
       "96                                                      [in, character, Hog, ❯, Harry, journey, voice, latest, \\n, ability, estaven, (, got, Wikip, ., on, real, for, as, biggest, Lat, greatest, Wikipédia, glass, Pot, multicol, and, w, ,, life, place, ™, Christmas, characters, Mag, to, Got, at, Bedeut, favorite, home, nim, sorted, gresql, parents, I, !, Big, nem, personal, Great, going, :, Außer, been, a, Cho, A, Ron, , cell, T, casting, avor, Sort, atform, …, SBN, ', child, London, train, dod, scar, Lex, \", adopt, ờ, favour, Hall, pal, Nem, Hol, history, zar, mag, H, intelligence, name, d, \", bel, SSN, Di, supporting, tie, nis, sei, heart, long, ...]   \n",
       "101                                                     [in, got, (, multicol, on, for, Hog, ., \\n, journey, to, as, life, character, and, ability, w, Christmas, a, world, ,, voice, universe, at, Got, latest, Pot, Harry, glass, nem, place, estaven, I, real, H, name, guide, home, …, biggest, London, parents, \", Wikip, enemies, ™, ver, ❯, greatest, Lat, personal, gresql, Mag, A, !, child, Wikipédia, Qu, the, been, train, T, , d, sei, sorted, e, ờ, Hol, transformation, Bedeut, going, ', ➖, compreh, :, entrance, Hall, Great, acid, ds, Ron, supporting, Gemeins, of, Big, casting, is, icon, Sort, dark, favorite, birth, adopt, end, £, sible, long, \", tr, ...]   \n",
       "106                                      [Harry, Pot, Hog, magic, pot, mag, Mag, Har, w, Sort, in, got, Ron, universe, Row, Mag, sorted, sorted, sorting, ™, Herm, wand, glass, pot, Lex, multicol, Di, place, latest, Qu, world, mag, ability, Vol, character, scar, H, ow, real, Christmas, Sort, London, Si, life, nem, journey, har, home, adopt, Hall, on, (, for, train, Got, Great, uniform, \\n, voice, birth, Az, charm, acid, I, Professor, platform, as, Rem, house, ờ, Cho, parents, dark, castle, prop, encounter, ., and, casting, Lat, Magic, sible, been, Hr, going, compreh, greatest, Hat, m, sei, D, Place, platz, PO, ,, 庄, visibility, J, Edinburgh, prop, ...]   \n",
       "111                                     [Harry, Pot, Hog, Har, magic, pot, w, mag, Row, Herm, got, Mag, Ron, universe, scar, Sort, in, wand, London, ™, sorted, glass, Lex, Si, sorted, ability, adopt, birth, H, sorting, real, train, nem, pot, Qu, Cho, Vol, Got, multicol, latest, Christmas, journey, place, Di, ow, Hall, Az, Mag, Sort, home, world, life, on, prop, platform, har, for, (, visibility, Great, uniform, greatest, Hr, voice, \\n, biggest, prop, Lond, as, favorite, m, mag, Professor, house, flying, England, I, D, ., Hat, at, guide, parents, A, Lat, рови, Row, Chamber, 庄, wet, compreh, sei, Nem, character, universal, and, Polsce, Order, 奈, 港, ...]   \n",
       "116       [Hog, Harry, Pot, mag, magic, w, scar, ™, Har, Mag, pot, wand, Sort, sorted, sorted, got, Ron, Herm, sorting, sor, Mag, mag, London, Got, world, Row, Qu, Si, place, Vol, real, Sort, Cho, glass, universe, latest, journey, character, Lex, visibility, Az, Great, H, greatest, flying, life, in, Sor, platform, multicol, home, Christmas, ability, train, nem, uniform, birth, adopt, Hat, favorite, pot, Di, house, biggest, Nem, spell, 雲, conj, PO, Hr, Edinburgh, jk, on, , best, guide, charm, Place, casting, ow, most, qu, blood, parents, Lond, signature, m, entrance, legacy, been, ds, Hall, Platform, definit, Order, Magic, sei, voice, child, har, ...]   \n",
       "121  [Hog, Harry, Pot, magic, Har, mag, scar, ™, wand, w, Sort, Ron, pot, sorted, world, Mag, sorted, sorting, Vol, flying, Herm, spell, Si, glass, favorite, Qu, journey, Lex, life, house, platform, real, Mag, Cho, got, Great, home, mag, greatest, London, sor, birth, place, multicol, adopt, guide, in, 雲, pot, Sort, universe, Nem, Got, Row, Return, H, Hed, Platform, ow, visibility, Az, Sor, uniform, train, Emma, nem, latest, return, ds, best, ➖, bst, character, Death, Edinburgh, , definit, Chamber, har, Hr, love, House, Order, ability, Di, been, Guide, biggest, child, charm, parents, Heinrich, Sec, Anim, Priv, favour, Professor, рови, ult, worst, ...]   \n",
       "126     [Hog, Harry, Pot, Sort, w, magic, world, scar, mag, wand, Har, sorting, sorted, Mag, ™, sorted, flying, Ron, Great, pot, journey, birth, Sor, home, Si, Herm, London, spell, Sort, greatest, Cho, Mag, got, life, sor, in, Qu, Vol, ow, mag, house, universe, glass, train, real, platform, Row, place, Got, universal, best, Hed, Return, love, Emma, return, latest, Order, nem, 雲, Lex, H, Di, Nem, pot, Platform, Edinburgh, favorite, casting, worst, Lond, guide, Az, Universal, £, D, I, ➖, World, immagini, ability, ờ, uniform, ult, biggest, visibility, character, charm, parents, expl, adopt, \\n, рови, atform, Professor, har, surv, emot, School, been, ...]   \n",
       "131                   [Hog, Harry, Pot, w, Sort, scar, mag, Har, wand, magic, got, world, sorting, Got, Mag, sorted, sorted, Herm, ™, Nem, Ron, Great, pot, Sort, Sor, birth, greatest, flying, sor, spell, Mag, journey, nem, Qu, Cho, universe, Return, home, house, mag, in, Row, favorite, cre, Si, uniform, return, life, suit, best, London, ow, Vol, ability, worst, platform, har, Emma, Universal, got, universal, H, latest, guide, Di, Order, train, cre, Bog, 奈, place, parents, glass, Trans, Anim, jk, library, sible, World, Aur, Edinburgh, Lex, ➖, love, atform, for, en, Guide, Sever, biggest, hand, Hed, real, Cre, favour, Az, emot, expl, Archiv, charm, ...]   \n",
       "136                          [Hog, Harry, Pot, scar, Sort, world, wand, got, sorted, mag, magic, ™, Herm, sorting, Got, w, ow, Sor, sorted, Nem, Mag, Ron, Har, greatest, in, nem, journey, Return, Sort, Great, Qu, pot, flying, Mag, cre, sor, spell, universe, latest, favorite, glass, uniform, birth, platform, London, Cre, most, return, Emma, atform, ➖, Cho, home, Trans, Si, house, adopt, best, guide, Sec, universal, a, Row, real, biggest, 奈, Vol, back, life, Bog, Hed, Di, \\n, Lex, parents, mag, World, Edinburgh, ability, cre, library, Universal, I, love, suit, emot, jk, been, Guide, got, Anim, Sever, on, new, place, Platform, Most, train, for, Dob, ...]   \n",
       "141                                                                 [Hog, got, wand, Pot, scar, w, ™, Sort, Harry, Herm, Ron, world, Got, mag, ow, sorting, in, magic, nem, sorted, a, Return, Mag, Qu, sorted, cre, atform, \\n, Great, Nem, (, most, greatest, W, journey, real, best, Vol, birth, \", return, and, spell, on, Cho, for, I, Sort, bro, universe, Emma, Most, at, glass, wid, platform, flying, Sor, favorite, H, A, Mag, en, Cre, home, London, Di, Bog, adopt, guide, been, latest, Sec, got, worst, love, pot, ability, biggest, suit, Guide, Trans, house, Hed, ,, cre, h, bel, patron, uniform, ., emot, sor, library, child, life, oug, Phil, Priv, reci, ...]   \n",
       "146                                                                                                    [Hog, wand, w, in, W, got, mag, world, scar, ™, Mag, (, Pot, \\n, \", a, Sort, Herm, and, for, ow, Qu, on, magic, cre, Ron, Got, sorting, Return, I, sorted, at, nem, birth, real, Harry, H, sor, World, ., greatest, A, In, return, guide, spell, ,, favorite, , hand, Great, Nem, best, sorted, bro, most, wid, Bog, journey, flying, London, Guide, atform, back, Sor, bel, glass, as, house, Mag, to, charm, Cho, Al, en, Pat, ', platform, Di, House, J, universe, patron, ro, Tri, Trans, love, Most, latest, home, reci, …, Vor, h, oug, not, Sort, adopt, T, Vol, ...]   \n",
       "151                                                                                                                      [Hog, wand, w, in, W, a, mag, world, \", cre, scar, (, got, \\n, and, Mag, Sort, Herm, Pot, , for, Great, magic, Return, World, Qu, ow, H, sorting, on, at, back, I, ., greatest, ™, House, In, most, ,, house, best, sorted, guide, Guide, return, flying, Got, ', to, as, F, sor, sorted, A, the, favorite, Al, London, J, bel, hand, journey, wid, bro, Harry, B, life, real, Pat, Di, N, first, Ron, latest, L, new, Most, Tri, spell, M, Aur, glass, en, Nem, home, been, not, use, experiences, First, nem, T, Mag, birth, light, sp, K, O, love, ...]   \n",
       "156                                                                                                                                                                                            [W, , in, \\n, \", a, Hog, (, w, ,, got, for, ., World, H, and, world, wand, mag, F, cre, Mag, In, at, B, ', I, A, T, Great, M, Qu, J, on, Herm, to, h, scar, back, the, N, D, magic, P, New, d, most, C, real, Al, L, ', S, O, new, V, as, been, is, sp, Pot, G, t, first, house, The, House, b, not, best, K, g, hand, R, Sp, en, London, Di, Return, c, Ron, return, guide, We, Most, use, greatest, love, Christmas, -, Guide, p, Sort, light, ™, home, life, Pat, Ch, David, ...]   \n",
       "\n",
       "     _Ac_probs  \n",
       "1    -0.006023  \n",
       "6    -0.017374  \n",
       "11    0.000141  \n",
       "16    0.017208  \n",
       "21    0.012185  \n",
       "26    0.078994  \n",
       "31    0.120402  \n",
       "36    0.068044  \n",
       "41    0.238042  \n",
       "46    0.252525  \n",
       "51    0.218762  \n",
       "56    0.356047  \n",
       "61    0.424880  \n",
       "66    0.312801  \n",
       "71    0.568233  \n",
       "76    0.456024  \n",
       "81    0.663696  \n",
       "86    0.816813  \n",
       "91    1.201419  \n",
       "96    1.855867  \n",
       "101   2.052368  \n",
       "106   3.621861  \n",
       "111   3.891323  \n",
       "116   4.108155  \n",
       "121   5.019320  \n",
       "126   4.949261  \n",
       "131   5.157842  \n",
       "136   5.491885  \n",
       "141   6.269913  \n",
       "146   5.805524  \n",
       "151   5.191484  \n",
       "156   6.656851  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "tmp[tmp['desc_short'] == 'subj_last']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 提取列为列表\n",
    "# values_list = tmp[tmp['desc_short'] == 'no_subj_last']['_Ac_probs'].tolist()\n",
    "# print('values_list: ',values_list)\n",
    "# #绘制折线图\n",
    "# plt.plot(values_list)\n",
    "# plt.xlabel('Layer')\n",
    "# plt.ylabel('Probs')\n",
    "# plt.title('Line Plot for Probs of the Token \"_Ac\" in last_token')\n",
    "# plt.show()\n",
    "\n",
    "####### _ow\n",
    "# _ow_subject_probs_llama2 = [-0.0030579143203794956, 0.006253499537706375, -0.01763559877872467, 0.009590733796358109, 0.005326222628355026, -0.004488162696361542, 0.2313617765903473, 0.33513838052749634, 0.23071950674057007, 0.2653754949569702, 0.40609726309776306, 0.5865322351455688, 0.5590600967407227, 0.6064379811286926, 0.5890030860900879, 0.7113540172576904, 0.7244165539741516, 1.0949658155441284, 1.2909266948699951, 1.3240220546722412, 1.4409984350204468, 1.675896406173706, 1.860262393951416, 1.567911982536316, 1.7151072025299072, 1.3250340223312378, 1.3374913930892944, 1.4054473638534546, 1.072416067123413, 1.489469289779663, 1.4904615879058838, 2.0926918983459473]\n",
    "# _ow_subject_probs_llama2_whp = [-0.003051305189728737, 0.0055238027125597, -0.016044268384575844, 0.01401505246758461, 0.003507804125547409, -0.014181151986122131, 0.08441570401191711, 0.16613617539405823, 0.04045645892620087, 0.061842337250709534, 0.024015769362449646, 0.13329696655273438, 0.1484353393316269, 0.18291766941547394, 0.28684788942337036, 0.4121972620487213, 0.28530147671699524, 0.5676491856575012, 0.7920090556144714, 0.7848619818687439, 0.7015050053596497, 0.8457107543945312, 0.731872022151947, 0.6232327222824097, 0.5575207471847534, 0.3552587628364563, 0.2546989321708679, -0.19727396965026855, -0.3398401737213135, -0.06104844808578491, -0.33539098501205444, -0.20396342873573303]\n",
    "\n",
    "# _ow_last_probs_llama2_whp = [-0.026201937347650528, -0.03142102062702179, -0.027745302766561508, -0.024878373369574547, -0.022200409322977066, 0.00016631931066513062, 0.05124291777610779, 0.13790279626846313, 0.11512491106987, 0.02869349718093872, -0.009032264351844788, -0.09639628231525421, 0.03440965712070465, 0.1720239222049713, 0.016267240047454834, 0.1562878042459488, 0.599960207939148, 1.4086390733718872, 1.9640120267868042, 2.0563478469848633, 3.100834846496582, 5.06281852722168, 6.109803199768066, 8.512886047363281, 9.603631973266602, 10.365421295166016, 11.106891632080078, 12.041515350341797, 12.062413215637207, 12.975608825683594, 13.252222061157227, 13.6898193359375]\n",
    "# _ow_last_probs_llama2_whp_white = [0.018033981323242188, 0.043797168880701065, 0.04960004240274429, 0.08016891777515411, 0.07983067631721497, 0.11211106926202774, 0.21206723153591156, 0.21195469796657562, 0.40908998250961304, 0.4331285357475281, 0.2949753999710083, 0.5304846167564392, 0.4395669996738434, 0.4006602168083191, 0.14125694334506989, 0.5611276030540466, 0.8308776617050171, 1.4673670530319214, 2.11997389793396, 2.191180467605591, 2.758232355117798, 4.220373153686523, 5.44971227645874, 6.994023323059082, 8.041250228881836, 9.214725494384766, 9.82414436340332, 9.994733810424805, 9.92789077758789, 10.793111801147461, 11.329358100891113, 12.435331344604492]\n",
    "\n",
    "# _ow_last_probs_llama2 = [-0.026190809905529022, -0.032870613038539886, -0.02702970989048481, -0.023892465978860855, -0.023075606673955917, 0.00427965447306633, 0.06894160807132721, 0.16287776827812195, 0.13079436123371124, 0.05399978905916214, 0.06812024116516113, -0.038439370691776276, 0.14552351832389832, 0.2967795729637146, 0.19148223102092743, 0.31978628039360046, 0.8447358012199402, 1.5117719173431396, 1.8572182655334473, 1.923374891281128, 2.936068058013916, 4.368283748626709, 5.535312175750732, 7.4789652824401855, 8.441883087158203, 9.086722373962402, 9.4790620803833, 10.43173885345459, 10.52426815032959, 11.163105010986328, 11.169452667236328, 12.102977752685547]\n",
    "# _ow_last_probs_llama2_white = [0.018088776618242264, 0.044786468148231506, 0.05146246403455734, 0.082163006067276, 0.0814623013138771, 0.11557437479496002, 0.21717378497123718, 0.26015788316726685, 0.4209006428718567, 0.4112987816333771, 0.4036802649497986, 0.5611494779586792, 0.46281230449676514, 0.5419734716415405, 0.38699251413345337, 0.8721796274185181, 1.1133296489715576, 1.6196101903915405, 2.208404779434204, 2.432729482650757, 3.1412596702575684, 4.21193790435791, 5.661276340484619, 7.445459365844727, 8.275541305541992, 9.122013092041016, 9.563312530517578, 9.98202133178711, 9.87321662902832, 10.793764114379883, 11.315603256225586, 12.409286499023438]\n",
    "\n",
    "\n",
    "###### _Ac on spell \n",
    "# on Harry Potter [-0.00441539054736495, 0.0050317831337451935, 0.014711183495819569, 0.0440041720867157, 0.00890277698636055, 0.08861169219017029, 0.06526791304349899, 0.007417239248752594, 0.043086886405944824, -0.1770937591791153, -0.16792622208595276, -0.15185163915157318, 0.0632830560207367, 0.07777636498212814, 0.20461857318878174, 0.21827298402786255, 0.1285843849182129, 0.1887926608324051, 0.14932048320770264, 0.1928490698337555, 0.15685293078422546, -0.04278245568275452, 0.047591909766197205, 0.17808033525943756, 0.04436267912387848, 0.19950266182422638, -0.014183230698108673, 0.5177791118621826, 0.5888251066207886, 0.3729637861251831, 0.3575303554534912, 0.47837650775909424]\n",
    "# _Ac_subject_probs_llama2 =[0.00951439794152975, 0.001635541208088398, 0.010598359629511833, 0.001022416166961193, -0.012466367334127426, -0.022881392389535904, -0.22140029072761536, -0.1352689266204834, -0.2362375557422638, -0.09361492097377777, 0.08797562122344971, 0.11830645799636841, -0.0039072707295417786, 0.062497928738594055, 0.15988951921463013, 0.21304544806480408, 0.48006007075309753, 0.4634169340133667, 0.600917398929596, 0.9115798473358154, 0.9618021249771118, 1.1553645133972168, 0.9701041579246521, 0.9740645885467529, 1.1457889080047607, 1.2027415037155151, 1.3939508199691772, 1.6309542655944824, 1.7580721378326416, 1.7428025007247925, 1.8851333856582642, 2.0244710445404053]\n",
    "# _Ac_last_probs_llama2 = [0.004173029214143753, 0.0026835110038518906, 0.007524208165705204, 0.03949752077460289, 0.01130147185176611, -0.04618639126420021, -0.027873076498508453, -0.038083821535110474, -0.19814907014369965, -0.21573179960250854, -0.319094181060791, -0.4475880563259125, -0.28468388319015503, -0.221309095621109, -0.22607485949993134, -0.3506699204444885, -0.4540409445762634, -0.5450097322463989, -0.2505689263343811, -0.16669251024723053, 0.06062138080596924, 0.4307938814163208, 0.5010020732879639, 0.49316346645355225, 0.2569456696510315, 0.6534013748168945, 0.8221983909606934, 0.9121583104133606, 0.6790610551834106, 0.8380659222602844, 1.099510669708252, 1.1848384141921997]\n",
    "# _Ac_subject_probs_llama2_whp = [0.009520838037133217, 0.0028874892741441727, 0.0062865205109119415, -0.0037575634196400642, -0.010721452534198761, 0.008964531123638153, -0.15827776491641998, -0.15637952089309692, -0.2501683235168457, -0.21900872886180878, -0.16278143227100372, -0.2288305163383484, -0.2800036072731018, -0.22792042791843414, -0.10888414084911346, 0.025031693279743195, 0.19834257662296295, 0.08321507275104523, 0.17819161713123322, 0.4151829183101654, 0.4035446047782898, 0.5585201382637024, 0.4980071485042572, 0.47641295194625854, 0.5092922449111938, 0.3373123109340668, 0.3535180687904358, 0.4271931052207947, 0.8079085350036621, 0.6213820576667786, 0.42892390489578247, -0.2521345615386963]\n",
    "# _Ac_last_probs_llama2_whp = [0.004165354650467634, 0.003636603243649006, 0.009062854573130608, 0.03486701473593712, 0.006202328950166702, -0.06299582123756409, -0.05836153030395508, -0.038780614733695984, -0.19068996608257294, -0.2318761646747589, -0.3394717574119568, -0.565514862537384, -0.4236506223678589, -0.4182469844818115, -0.40990132093429565, -0.5555009245872498, -0.5947866439819336, -0.6240778565406799, -0.31202009320259094, -0.3998188376426697, -0.13949328660964966, 0.08519560098648071, 0.11626341938972473, 0.16347846388816833, -0.038257718086242676, 0.3505636155605316, 0.24198323488235474, 0.12214410305023193, -0.06783980131149292, -0.19007724523544312, -0.08963799476623535, -0.03350985050201416]\n",
    "# softmax\n",
    "# _Ac_last_probs_llama2_whp = [3.083217961830087e-05, 3.056442437809892e-05, 3.053707769140601e-05, 3.148788528051227e-05, 3.064802513108589e-05, 3.3833461202448234e-05, 3.218504571123049e-05, 3.172368451487273e-05, 2.96217440336477e-05, 2.8668153390754014e-05, 2.7393862183089368e-05, 3.347654637764208e-05, 4.0239272493636236e-05, 4.0272410842590034e-05, 3.293712143204175e-05, 3.561664198059589e-05, 4.092254675924778e-05, 4.7766618081368506e-05, 4.60387600469403e-05, 4.779091977979988e-05, 4.0466311475029215e-05, 6.261006637942046e-05, 7.150213787099347e-05, 6.780809781048447e-05, 9.56719450186938e-05, 0.0002820102672558278, 0.00019112220616079867, 0.00022000762692186981, 0.0007154357735998929, 0.0010867905803024769, 0.002782245399430394, 0.0023556388914585114]\n",
    "# _Ac_subject_probs_llama2_whp = [3.170033960486762e-05, 3.1705254514236e-05, 3.1668387237004936e-05, 3.181091233273037e-05, 2.9711565730394796e-05, 3.0264862289186567e-05, 2.397912430751603e-05, 2.6278428777004592e-05, 2.3353541109827347e-05, 2.694796239666175e-05, 2.8964819648535922e-05, 3.11338335450273e-05, 2.9310576792340726e-05, 2.3242600946105085e-05, 2.177305577788502e-05, 2.841241621354129e-05, 5.0347578508080915e-05, 5.314014924806543e-05, 5.591924491454847e-05, 0.0001007565442705527, 0.000117360963486135, 9.550872346153483e-05, 9.267701534554362e-05, 6.539286550832912e-05, 4.975181946065277e-05, 7.844671199563891e-05, 0.0001011852000374347, 0.00013338186545297503, 0.0001204489526571706, 7.788337825331837e-05, 5.1885959692299366e-05, 3.152988256260869e-06]\n",
    "# _Ac_subject_probs_llama2 = [3.169973933836445e-05, 3.169048432027921e-05, 3.179314444423653e-05, 3.1871160899754614e-05, 2.9608265322167426e-05, 2.980950739583932e-05, 2.3301015971810557e-05, 2.6906231141765602e-05, 2.3707219952484593e-05, 2.772454172372818e-05, 2.9977207304909825e-05, 2.945883352367673e-05, 2.805807707773056e-05, 2.0345940356492065e-05, 1.9220125977881253e-05, 2.5697372620925307e-05, 3.96399263991043e-05, 3.3320564398309216e-05, 3.856304829241708e-05, 7.881774217821658e-05, 0.00011145816824864596, 8.66330083226785e-05, 7.561738311778754e-05, 5.510941264219582e-05, 5.5024273024173453e-05, 0.00011452830221969634, 0.0001658267283346504, 0.0002605831832624972, 0.0001952676975633949, 0.0003108503296971321, 0.00022407303913496435, 1.7489133824710734e-05]\n",
    "# _Ac_last_probs_llama2 = [3.083211777266115e-05, 3.0540137231582776e-05, 3.050676968996413e-05, 3.1491810659645125e-05, 3.062088944716379e-05, 3.405407551326789e-05, 3.2473017199663445e-05, 3.136325904051773e-05, 2.9307771910680458e-05, 2.8735428713844158e-05, 2.8354814276099205e-05, 3.337849193485454e-05, 3.799257683567703e-05, 4.166491635260172e-05, 3.0430186598096043e-05, 3.4782842703862116e-05, 3.8269481592578813e-05, 4.357199213700369e-05, 4.5479671825887635e-05, 4.6890439989510924e-05, 4.478154005482793e-05, 7.271472713910043e-05, 7.283322338480502e-05, 8.502549462718889e-05, 0.00013786465569864959, 0.00039716679020784795, 0.00046977991587482393, 0.0010410611284896731, 0.0019087751861661673, 0.007086712401360273, 0.04030485823750496, 0.24687828123569489]\n",
    "\n",
    "###### _un\n",
    "\n",
    "# plt.plot(_Ac_last_probs_llama2, label='llama2')\n",
    "# plt.plot(_Ac_last_probs_llama2_whp, label='llama2_whp')\n",
    "\n",
    "\n",
    "#### _Ron\n",
    "\n",
    "_Ron_last_probs_llama2 = [0.004836817272007465, -0.0051034376956522465, 0.015195591375231743, 0.04688720405101776, 0.045782797038555145, 0.08181986212730408, 0.058892544358968735, 0.09068586677312851, 0.21354638040065765, 0.28953737020492554, 0.4094015955924988, 0.46322041749954224, 0.7095937728881836, 0.6962642073631287, 0.5459346771240234, 0.6679329872131348, 0.736468493938446, 0.7949937582015991, 0.7167630791664124, 1.0516082048416138, 1.724687099456787, 2.4955685138702393, 2.647785186767578, 3.411872386932373, 6.040295600891113, 6.2460856437683105, 9.137906074523926, 10.31109619140625, 11.19253158569336, 13.356437683105469, 13.407295227050781, 14.334501266479492]\n",
    "_Ron_subject_probs_llama2 = [-0.006023056339472532, -0.01737447828054428, 0.00014096684753894806, 0.01720849983394146, 0.012185253202915192, 0.07899419963359833, 0.12040239572525024, 0.06804423779249191, 0.23804236948490143, 0.25252509117126465, 0.21876245737075806, 0.35604721307754517, 0.42488011717796326, 0.31280094385147095, 0.5682332515716553, 0.4560243487358093, 0.6636959910392761, 0.816813051700592, 1.2014191150665283, 1.8558673858642578, 2.052367687225342, 3.6218607425689697, 3.8913228511810303, 4.108155250549316, 5.019320011138916, 4.949260711669922, 5.157841682434082, 5.491885185241699, 6.2699127197265625, 5.805523872375488, 5.191484451293945, 6.656851291656494]\n",
    "_Ron_last_probs_llama2_whp = [0.004887164570391178, -0.007504488807171583, 0.014723303727805614, 0.047259941697120667, 0.0450429767370224, 0.09853902459144592, 0.07781504094600677, 0.10988056659698486, 0.20654796063899994, 0.2689114212989807, 0.360717236995697, 0.402820885181427, 0.5715487003326416, 0.48490339517593384, 0.3514478802680969, 0.5425692200660706, 0.6892155408859253, 0.4605591297149658, 0.310236394405365, 0.18438997864723206, 0.30774664878845215, 0.4458380937576294, 0.06869187951087952, 0.3794921040534973, 0.8684892654418945, 0.9178351163864136, 0.9134963750839233, 0.901572585105896, 1.2964617013931274, 1.6058897972106934, 1.8587313890457153, 3.7325916290283203]\n",
    "_Ron_subject_probs_llama2_whp = [-0.00603043008595705, -0.0173991397023201, -2.1940097212791443e-05, 0.018685800954699516, 0.015673823654651642, 0.09844939410686493, 0.16191107034683228, 0.08760489523410797, 0.13944263756275177, 0.1637335568666458, 0.22022564709186554, 0.36232298612594604, 0.3569943904876709, 0.2784021496772766, 0.3438999652862549, 0.23131254315376282, 0.33923590183258057, 0.2542398273944855, 0.3252914249897003, 0.3092590272426605, 0.48939740657806396, 0.5963600873947144, 0.7366026639938354, 0.2884027659893036, 0.3481903672218323, 0.36062848567962646, 0.20753628015518188, 0.4171937108039856, 0.607207179069519, 0.4364548325538635, 0.6494125723838806, 0.6724295020103455]\n",
    "\n",
    "\n",
    "# plt.plot(_Ron_last_probs_llama2, label='llama2')\n",
    "# plt.plot(_Ron_last_probs_llama2_whp, label='llama2_whp')\n",
    "# plt.xlabel('Layer')\n",
    "# plt.ylabel('Probs')\n",
    "# plt.title('Line Plot for Probs of the Token \"_Ron\" in last')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "plt.plot(_Ron_subject_probs_llama2, label='llama2')\n",
    "plt.plot(_Ron_subject_probs_llama2_whp, label='llama2_whp')\n",
    "plt.xlabel('Layer')\n",
    "plt.ylabel('Probs')\n",
    "plt.title('Line Plot for Probs of the Token \"_Ron\" in subject enrichment')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('model.embed_tokens.weight',\n",
       "              tensor([[ 1.1921e-06, -1.7881e-06, -4.2915e-06,  ...,  8.3447e-07,\n",
       "                       -6.4373e-06,  8.9407e-07],\n",
       "                      [ 1.8387e-03, -3.8147e-03,  9.6130e-04,  ..., -9.0332e-03,\n",
       "                        2.6550e-03, -3.7537e-03],\n",
       "                      [ 1.0193e-02,  9.7656e-03, -5.2795e-03,  ...,  2.9297e-03,\n",
       "                        4.0817e-04, -5.0964e-03],\n",
       "                      ...,\n",
       "                      [-1.3550e-02, -3.5095e-03, -1.8921e-02,  ..., -9.3384e-03,\n",
       "                        8.7891e-03, -1.2741e-03],\n",
       "                      [-1.0681e-02,  8.9722e-03,  1.2573e-02,  ..., -3.3691e-02,\n",
       "                       -1.6235e-02,  3.0212e-03],\n",
       "                      [-9.0942e-03, -1.8082e-03, -6.9809e-04,  ...,  3.8452e-03,\n",
       "                       -1.2085e-02,  7.2861e-04]], device='cuda:0')),\n",
       "             ('model.layers.0.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0060, -0.0146, -0.0021,  ...,  0.0042,  0.0018, -0.0035],\n",
       "                      [ 0.0142, -0.0043,  0.0032,  ..., -0.0092, -0.0108,  0.0073],\n",
       "                      [-0.0137,  0.0121,  0.0002,  ...,  0.0061,  0.0181, -0.0030],\n",
       "                      ...,\n",
       "                      [ 0.0018,  0.0093, -0.0006,  ...,  0.0092, -0.0289,  0.0085],\n",
       "                      [ 0.0249,  0.0116,  0.0035,  ..., -0.0322, -0.0165, -0.0111],\n",
       "                      [-0.0136, -0.0067,  0.0016,  ...,  0.0176,  0.0175, -0.0083]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.0.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0155,  0.0078, -0.0011,  ...,  0.0164, -0.0097, -0.0136],\n",
       "                      [ 0.0182,  0.0012,  0.0034,  ..., -0.0206,  0.0143,  0.0229],\n",
       "                      [-0.0245, -0.0220,  0.0018,  ...,  0.0150, -0.0157, -0.0110],\n",
       "                      ...,\n",
       "                      [ 0.0123, -0.0007, -0.0008,  ...,  0.0002,  0.0029,  0.0081],\n",
       "                      [-0.0050,  0.0171, -0.0031,  ..., -0.0033,  0.0112, -0.0110],\n",
       "                      [ 0.0036, -0.0023,  0.0012,  ...,  0.0073, -0.0114,  0.0095]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.0.self_attn.v_proj.weight',\n",
       "              tensor([[-3.1471e-05, -2.3346e-03,  2.6550e-03,  ...,  7.5684e-03,\n",
       "                       -9.7656e-04,  9.5215e-03],\n",
       "                      [-7.0190e-03,  6.7711e-05, -6.1035e-03,  ..., -1.1597e-02,\n",
       "                        1.2512e-02,  6.4087e-03],\n",
       "                      [ 7.8583e-04,  1.0315e-02,  1.5335e-03,  ...,  4.8523e-03,\n",
       "                       -1.3489e-02, -1.3550e-02],\n",
       "                      ...,\n",
       "                      [-6.5308e-03, -6.1951e-03,  1.0864e-02,  ...,  3.9368e-03,\n",
       "                        2.2583e-03, -1.6785e-03],\n",
       "                      [ 1.7395e-03,  5.6152e-03, -9.5749e-04,  ...,  6.7444e-03,\n",
       "                        1.5625e-02, -8.8692e-05],\n",
       "                      [-1.9264e-04,  1.3123e-03,  5.3711e-03,  ..., -3.3188e-04,\n",
       "                       -7.5531e-04,  1.4267e-03]], device='cuda:0')),\n",
       "             ('model.layers.0.self_attn.o_proj.weight',\n",
       "              tensor([[ 8.8692e-05, -2.3041e-03,  4.3945e-03,  ...,  5.3406e-03,\n",
       "                        4.2725e-03, -9.8267e-03],\n",
       "                      [ 1.9989e-03,  3.5667e-04,  6.8665e-04,  ...,  4.4632e-04,\n",
       "                        1.3809e-03,  4.9133e-03],\n",
       "                      [ 1.3885e-03,  3.1471e-05,  1.4496e-03,  ..., -5.0735e-04,\n",
       "                       -5.2185e-03, -1.1368e-03],\n",
       "                      ...,\n",
       "                      [ 4.5166e-03, -3.7384e-03,  4.7607e-03,  ...,  1.8387e-03,\n",
       "                        3.3112e-03,  5.2795e-03],\n",
       "                      [-4.3335e-03, -1.7166e-03, -2.1820e-03,  ...,  5.2795e-03,\n",
       "                       -4.5776e-03, -8.7738e-05],\n",
       "                      [ 5.6152e-03, -1.0376e-03,  3.7079e-03,  ...,  3.6621e-03,\n",
       "                       -7.3547e-03, -7.9346e-03]], device='cuda:0')),\n",
       "             ('model.layers.0.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0173,  0.0172,  0.0287,  ..., -0.0147,  0.0070,  0.0131],\n",
       "                      [-0.0027, -0.0060,  0.0056,  ...,  0.0149, -0.0108,  0.0073],\n",
       "                      [ 0.0056, -0.0209,  0.0205,  ..., -0.0117,  0.0227,  0.0184],\n",
       "                      ...,\n",
       "                      [-0.0007, -0.0330,  0.0061,  ..., -0.0076, -0.0131,  0.0400],\n",
       "                      [ 0.0254,  0.0186, -0.0160,  ..., -0.0048, -0.0063, -0.0192],\n",
       "                      [-0.0014, -0.0112, -0.0217,  ...,  0.0011,  0.0056, -0.0249]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.0.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0011, -0.0292,  0.0156,  ..., -0.0193, -0.0250,  0.0057],\n",
       "                      [-0.0119, -0.0320,  0.0134,  ...,  0.0206,  0.0051,  0.0028],\n",
       "                      [-0.0055,  0.0126, -0.0076,  ..., -0.0220,  0.0062,  0.0024],\n",
       "                      ...,\n",
       "                      [-0.0070, -0.0026, -0.0063,  ...,  0.0273, -0.0023,  0.0178],\n",
       "                      [-0.0176,  0.0082,  0.0193,  ..., -0.0004, -0.0145,  0.0020],\n",
       "                      [ 0.0195,  0.0201, -0.0015,  ...,  0.0106, -0.0124, -0.0383]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.0.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0050, -0.0131,  0.0096,  ..., -0.0184, -0.0073,  0.0016],\n",
       "                      [ 0.0044, -0.0031,  0.0057,  ...,  0.0156, -0.0148,  0.0344],\n",
       "                      [ 0.0017,  0.0339, -0.0042,  ..., -0.0142,  0.0205,  0.0165],\n",
       "                      ...,\n",
       "                      [-0.0098, -0.0125,  0.0055,  ...,  0.0242, -0.0157,  0.0275],\n",
       "                      [-0.0182,  0.0376,  0.0090,  ..., -0.0068, -0.0126, -0.0215],\n",
       "                      [ 0.0117, -0.0015, -0.0066,  ..., -0.0005, -0.0038, -0.0300]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.0.input_layernorm.weight',\n",
       "              tensor([0.0298, 0.0140, 0.0031,  ..., 0.0099, 0.0114, 0.0073], device='cuda:0')),\n",
       "             ('model.layers.0.post_attention_layernorm.weight',\n",
       "              tensor([0.0508, 0.0525, 0.0498,  ..., 0.0522, 0.0542, 0.0479], device='cuda:0')),\n",
       "             ('model.layers.1.self_attn.q_proj.weight',\n",
       "              tensor([[-1.3367e-02,  8.0566e-03, -3.8574e-02,  ..., -1.6403e-03,\n",
       "                       -5.7861e-02,  3.4912e-02],\n",
       "                      [-1.4038e-03, -7.8125e-03,  7.8125e-03,  ..., -9.5215e-03,\n",
       "                       -4.9805e-02,  2.7222e-02],\n",
       "                      [ 3.0151e-02,  3.1738e-02,  1.9897e-02,  ...,  1.1635e-04,\n",
       "                       -7.4707e-02,  2.3193e-02],\n",
       "                      ...,\n",
       "                      [-7.5531e-04,  2.7313e-03,  3.3417e-03,  ..., -8.9722e-03,\n",
       "                       -3.0975e-03, -5.9204e-03],\n",
       "                      [-1.5182e-03, -4.6997e-03, -3.8605e-03,  ...,  9.0942e-03,\n",
       "                        4.3640e-03,  6.1035e-03],\n",
       "                      [-6.8665e-05,  5.6763e-03,  6.2866e-03,  ..., -8.2397e-03,\n",
       "                        2.8014e-06, -1.0864e-02]], device='cuda:0')),\n",
       "             ('model.layers.1.self_attn.k_proj.weight',\n",
       "              tensor([[-2.4780e-02, -3.3875e-03,  3.8818e-02,  ...,  1.7090e-02,\n",
       "                        1.9165e-02, -6.9580e-03],\n",
       "                      [-2.8198e-02,  5.6458e-03, -1.2939e-02,  ..., -1.7334e-02,\n",
       "                        1.1047e-02, -5.7861e-02],\n",
       "                      [-2.4170e-02,  2.8198e-02, -6.5430e-02,  ...,  3.3447e-02,\n",
       "                        9.1553e-03, -5.7373e-02],\n",
       "                      ...,\n",
       "                      [-1.0437e-02,  1.7822e-02, -1.7014e-03,  ...,  9.8877e-03,\n",
       "                       -1.3123e-03,  7.4158e-03],\n",
       "                      [ 7.3242e-03, -1.8066e-02,  4.0894e-03,  ..., -1.1047e-02,\n",
       "                       -2.6226e-05, -7.1411e-03],\n",
       "                      [-7.2632e-03,  1.3733e-02,  5.6076e-04,  ...,  2.9602e-03,\n",
       "                       -3.0365e-03,  6.6223e-03]], device='cuda:0')),\n",
       "             ('model.layers.1.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0080, -0.0080, -0.0037,  ..., -0.0060, -0.0322, -0.0256],\n",
       "                      [-0.0038,  0.0026, -0.0027,  ..., -0.0006,  0.0105,  0.0332],\n",
       "                      [ 0.0065, -0.0109,  0.0095,  ...,  0.0017, -0.0003, -0.0010],\n",
       "                      ...,\n",
       "                      [-0.0052,  0.0015,  0.0026,  ..., -0.0009, -0.0009,  0.0018],\n",
       "                      [-0.0038, -0.0062,  0.0071,  ..., -0.0079,  0.0025, -0.0008],\n",
       "                      [-0.0007,  0.0010,  0.0033,  ...,  0.0025, -0.0065,  0.0082]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.1.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0045, -0.0187,  0.0139,  ..., -0.0051,  0.0001,  0.0011],\n",
       "                      [-0.0023, -0.0054, -0.0129,  ..., -0.0018, -0.0019,  0.0041],\n",
       "                      [ 0.0210,  0.0137, -0.0098,  ...,  0.0048,  0.0017, -0.0013],\n",
       "                      ...,\n",
       "                      [ 0.0040,  0.0062,  0.0045,  ..., -0.0001,  0.0023, -0.0028],\n",
       "                      [ 0.0035, -0.0114,  0.0051,  ..., -0.0024,  0.0012,  0.0029],\n",
       "                      [-0.0053, -0.0188,  0.0055,  ...,  0.0022, -0.0056,  0.0006]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.1.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0277, -0.0091,  0.0371,  ..., -0.0339, -0.0167, -0.0107],\n",
       "                      [-0.0305, -0.0034, -0.0295,  ...,  0.0148, -0.0204, -0.0396],\n",
       "                      [-0.0070, -0.0258,  0.0036,  ..., -0.0089, -0.0142, -0.0208],\n",
       "                      ...,\n",
       "                      [-0.0378,  0.0162, -0.0033,  ..., -0.0020,  0.0121, -0.0022],\n",
       "                      [-0.0150,  0.0045, -0.0361,  ...,  0.0216,  0.0181, -0.0125],\n",
       "                      [-0.0238,  0.0137,  0.0066,  ...,  0.0354,  0.0095, -0.0325]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.1.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0015,  0.0352, -0.0160,  ...,  0.0103,  0.0311, -0.0172],\n",
       "                      [ 0.0085, -0.0031, -0.0139,  ..., -0.0074,  0.0097,  0.0101],\n",
       "                      [ 0.0277, -0.0425,  0.0125,  ...,  0.0173, -0.0442,  0.0294],\n",
       "                      ...,\n",
       "                      [-0.0118, -0.0269,  0.0124,  ...,  0.0261,  0.0124, -0.0244],\n",
       "                      [ 0.0330,  0.0031, -0.0188,  ...,  0.0046, -0.0072, -0.0021],\n",
       "                      [-0.0155, -0.0173, -0.0110,  ..., -0.0245, -0.0082,  0.0204]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.1.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0084,  0.0095,  0.0537,  ..., -0.0175,  0.0028, -0.0194],\n",
       "                      [ 0.0100,  0.0044, -0.0359,  ...,  0.0087, -0.0133,  0.0023],\n",
       "                      [-0.0168, -0.0144, -0.0219,  ..., -0.0003, -0.0111,  0.0045],\n",
       "                      ...,\n",
       "                      [-0.0103, -0.0056, -0.0166,  ...,  0.0420, -0.0074,  0.0062],\n",
       "                      [-0.0123,  0.0204,  0.0129,  ..., -0.0303, -0.0193,  0.0219],\n",
       "                      [ 0.0253, -0.0044, -0.0186,  ..., -0.0125, -0.0154,  0.0281]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.1.input_layernorm.weight',\n",
       "              tensor([0.1123, 0.1094, 0.0986,  ..., 0.0640, 0.0918, 0.0723], device='cuda:0')),\n",
       "             ('model.layers.1.post_attention_layernorm.weight',\n",
       "              tensor([0.0996, 0.0996, 0.0962,  ..., 0.1050, 0.0991, 0.1021], device='cuda:0')),\n",
       "             ('model.layers.2.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0250, -0.0087,  0.0071,  ..., -0.0095, -0.0194, -0.0057],\n",
       "                      [-0.0136,  0.0085, -0.0364,  ..., -0.0359, -0.0175,  0.0248],\n",
       "                      [-0.0152,  0.0327, -0.0249,  ..., -0.0030, -0.0212,  0.0219],\n",
       "                      ...,\n",
       "                      [-0.0474,  0.0135, -0.0228,  ..., -0.0070, -0.0304, -0.0369],\n",
       "                      [ 0.0023, -0.0102,  0.0016,  ..., -0.0015, -0.0150,  0.0137],\n",
       "                      [-0.0057, -0.0205,  0.0261,  ...,  0.0630, -0.0457,  0.0019]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.2.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0023,  0.0098, -0.0072,  ..., -0.0187, -0.0060,  0.0112],\n",
       "                      [ 0.0164, -0.0104, -0.0047,  ...,  0.0179, -0.0070, -0.0006],\n",
       "                      [ 0.0134,  0.0123,  0.0359,  ..., -0.0139,  0.0106,  0.0075],\n",
       "                      ...,\n",
       "                      [ 0.0322,  0.0483, -0.0281,  ...,  0.0293, -0.0400, -0.0070],\n",
       "                      [-0.0052, -0.0118,  0.0001,  ...,  0.0039, -0.0004, -0.0034],\n",
       "                      [ 0.0071, -0.0140, -0.0035,  ..., -0.0830, -0.0275,  0.0879]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.2.self_attn.v_proj.weight',\n",
       "              tensor([[-5.0659e-03,  4.3106e-04,  2.1851e-02,  ...,  3.8818e-02,\n",
       "                       -7.8125e-03,  4.6082e-03],\n",
       "                      [ 2.7924e-03,  1.5015e-02, -2.2705e-02,  ..., -9.7046e-03,\n",
       "                        5.6763e-03, -1.5625e-02],\n",
       "                      [ 7.2861e-04,  1.5015e-02, -2.2430e-03,  ..., -1.5869e-02,\n",
       "                       -2.8076e-02, -2.9297e-02],\n",
       "                      ...,\n",
       "                      [ 5.5313e-05, -2.8687e-02, -1.8066e-02,  ..., -1.2634e-02,\n",
       "                       -2.5635e-03,  2.3956e-03],\n",
       "                      [-3.5400e-02, -2.0981e-04,  1.8677e-02,  ..., -7.0190e-03,\n",
       "                       -1.0010e-02, -4.3335e-03],\n",
       "                      [-1.2207e-02,  1.6479e-02,  2.1973e-03,  ..., -5.7678e-03,\n",
       "                        1.5625e-02, -8.1787e-03]], device='cuda:0')),\n",
       "             ('model.layers.2.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0002,  0.0157,  0.0085,  ...,  0.0184,  0.0027, -0.0275],\n",
       "                      [-0.0007, -0.0176,  0.0064,  ...,  0.0038, -0.0134, -0.0200],\n",
       "                      [-0.0204,  0.0036, -0.0160,  ..., -0.0194, -0.0079,  0.0103],\n",
       "                      ...,\n",
       "                      [-0.0069, -0.0278,  0.0310,  ..., -0.0058, -0.0223,  0.0204],\n",
       "                      [ 0.0197, -0.0159,  0.0349,  ...,  0.0173,  0.0018, -0.0226],\n",
       "                      [-0.0117,  0.0013,  0.0101,  ..., -0.0087,  0.0103, -0.0149]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.2.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0073,  0.0238, -0.0116,  ..., -0.0079,  0.0286,  0.0021],\n",
       "                      [ 0.0027,  0.0009, -0.0033,  ...,  0.0102, -0.0138, -0.0088],\n",
       "                      [ 0.0019, -0.0095,  0.0262,  ..., -0.0118,  0.0188,  0.0083],\n",
       "                      ...,\n",
       "                      [ 0.0300, -0.0087, -0.0128,  ..., -0.0332, -0.0410, -0.0111],\n",
       "                      [-0.0117, -0.0161, -0.0026,  ...,  0.0227, -0.0493,  0.0153],\n",
       "                      [-0.0030,  0.0129,  0.0057,  ..., -0.0128, -0.0299,  0.0068]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.2.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0023, -0.0021,  0.0139,  ..., -0.0189,  0.0059, -0.0016],\n",
       "                      [ 0.0077, -0.0175, -0.0081,  ...,  0.0028,  0.0110,  0.0087],\n",
       "                      [ 0.0282,  0.0167,  0.0299,  ..., -0.0138, -0.0067,  0.0204],\n",
       "                      ...,\n",
       "                      [-0.0080, -0.0156,  0.0018,  ..., -0.0159, -0.0062,  0.0177],\n",
       "                      [ 0.0148, -0.0038,  0.0138,  ..., -0.0023,  0.0055, -0.0256],\n",
       "                      [-0.0131, -0.0286, -0.0228,  ..., -0.0076, -0.0011, -0.0050]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.2.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0083,  0.0135,  0.0334,  ..., -0.0223, -0.0015, -0.0306],\n",
       "                      [ 0.0199, -0.0217, -0.0146,  ...,  0.0117,  0.0012, -0.0228],\n",
       "                      [ 0.0396, -0.0187, -0.0023,  ..., -0.0267,  0.0012, -0.0322],\n",
       "                      ...,\n",
       "                      [-0.0115,  0.0261, -0.0084,  ..., -0.0009, -0.0052, -0.0125],\n",
       "                      [-0.0200,  0.0344,  0.0101,  ...,  0.0115, -0.0157, -0.0112],\n",
       "                      [ 0.0334,  0.0093, -0.0214,  ...,  0.0275, -0.0398, -0.0074]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.2.input_layernorm.weight',\n",
       "              tensor([0.1719, 0.1758, 0.1729,  ..., 0.1768, 0.1699, 0.1729], device='cuda:0')),\n",
       "             ('model.layers.2.post_attention_layernorm.weight',\n",
       "              tensor([0.1338, 0.1377, 0.1348,  ..., 0.1357, 0.1377, 0.1367], device='cuda:0')),\n",
       "             ('model.layers.3.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0068,  0.0133, -0.0003,  ...,  0.0264,  0.0162,  0.0215],\n",
       "                      [-0.0087,  0.0151, -0.0197,  ..., -0.0430,  0.0008, -0.0046],\n",
       "                      [ 0.0175,  0.0060, -0.0197,  ...,  0.0123, -0.0198, -0.0337],\n",
       "                      ...,\n",
       "                      [ 0.0698, -0.0679,  0.0405,  ..., -0.0752, -0.0123,  0.0067],\n",
       "                      [-0.0796,  0.0376, -0.0029,  ...,  0.0332,  0.0723,  0.0195],\n",
       "                      [-0.0150, -0.0513,  0.0703,  ..., -0.0245, -0.0085, -0.0135]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.3.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0093, -0.0082, -0.0057,  ..., -0.0052,  0.0022,  0.0447],\n",
       "                      [-0.0107,  0.0090, -0.0228,  ...,  0.0021, -0.0099, -0.0361],\n",
       "                      [ 0.0009, -0.0089, -0.0022,  ...,  0.0064, -0.0065, -0.0315],\n",
       "                      ...,\n",
       "                      [ 0.0898, -0.0840,  0.0051,  ..., -0.0618, -0.0016,  0.0256],\n",
       "                      [-0.0864,  0.0267,  0.0435,  ...,  0.0085,  0.0474,  0.0013],\n",
       "                      [ 0.0008, -0.0510,  0.0903,  ..., -0.0175,  0.0072, -0.0104]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.3.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0011,  0.0105, -0.0049,  ..., -0.0126,  0.0035, -0.0114],\n",
       "                      [-0.0109,  0.0264, -0.0159,  ..., -0.0060, -0.0092, -0.0074],\n",
       "                      [ 0.0013, -0.0016,  0.0012,  ..., -0.0383, -0.0125, -0.0273],\n",
       "                      ...,\n",
       "                      [-0.0084, -0.0089,  0.0022,  ...,  0.0024, -0.0023, -0.0051],\n",
       "                      [ 0.0036, -0.0008,  0.0072,  ...,  0.0045, -0.0060,  0.0037],\n",
       "                      [-0.0067, -0.0084,  0.0098,  ..., -0.0012,  0.0016,  0.0098]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.3.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0292,  0.0079, -0.0168,  ...,  0.0060,  0.0083, -0.0009],\n",
       "                      [ 0.0288, -0.0283, -0.0085,  ...,  0.0074, -0.0041, -0.0006],\n",
       "                      [-0.0005, -0.0101, -0.0011,  ...,  0.0008,  0.0007,  0.0066],\n",
       "                      ...,\n",
       "                      [ 0.0071,  0.0135,  0.0137,  ...,  0.0003,  0.0037,  0.0110],\n",
       "                      [ 0.0194,  0.0233, -0.0029,  ...,  0.0016, -0.0009, -0.0017],\n",
       "                      [ 0.0099, -0.0042,  0.0052,  ...,  0.0045,  0.0040,  0.0089]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.3.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0044, -0.0126, -0.0186,  ..., -0.0304,  0.0437,  0.0109],\n",
       "                      [ 0.0146, -0.0008, -0.0123,  ..., -0.0068, -0.0225, -0.0100],\n",
       "                      [-0.0270,  0.0006, -0.0138,  ...,  0.0089, -0.0051, -0.0334],\n",
       "                      ...,\n",
       "                      [-0.0017,  0.0393,  0.0049,  ...,  0.0167, -0.0118, -0.0039],\n",
       "                      [-0.0052,  0.0061, -0.0013,  ..., -0.0024,  0.0009, -0.0086],\n",
       "                      [-0.0027, -0.0142,  0.0031,  ...,  0.0212, -0.0247,  0.0107]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.3.mlp.up_proj.weight',\n",
       "              tensor([[-0.0093,  0.0139,  0.0066,  ..., -0.0031,  0.0168, -0.0103],\n",
       "                      [-0.0115, -0.0140,  0.0359,  ...,  0.0183,  0.0165, -0.0066],\n",
       "                      [-0.0036, -0.0015, -0.0160,  ...,  0.0014,  0.0039, -0.0112],\n",
       "                      ...,\n",
       "                      [-0.0085, -0.0060, -0.0029,  ...,  0.0212,  0.0113, -0.0243],\n",
       "                      [ 0.0046, -0.0108, -0.0092,  ...,  0.0103, -0.0201, -0.0087],\n",
       "                      [ 0.0420,  0.0020, -0.0006,  ...,  0.0437,  0.0061,  0.0006]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.3.mlp.down_proj.weight',\n",
       "              tensor([[-1.2894e-03, -6.8665e-03,  6.7749e-03,  ..., -7.1411e-03,\n",
       "                        6.2561e-03,  1.8066e-02],\n",
       "                      [ 2.9053e-02,  4.5471e-03,  1.4709e-02,  ..., -1.5747e-02,\n",
       "                       -1.5747e-02, -9.1553e-03],\n",
       "                      [ 1.2878e-02,  1.1902e-02, -1.9409e-02,  ..., -1.4221e-02,\n",
       "                       -7.5684e-03,  4.8523e-03],\n",
       "                      ...,\n",
       "                      [ 2.3560e-02, -6.6528e-03, -1.5381e-02,  ..., -5.7459e-05,\n",
       "                        1.6113e-02,  1.8311e-02],\n",
       "                      [-2.0020e-02,  1.1230e-02, -1.5564e-02,  ..., -4.6730e-04,\n",
       "                       -1.4771e-02,  1.2634e-02],\n",
       "                      [ 8.5449e-03, -1.5869e-02, -2.6978e-02,  ...,  2.5177e-04,\n",
       "                        6.9275e-03,  1.1292e-02]], device='cuda:0')),\n",
       "             ('model.layers.3.input_layernorm.weight',\n",
       "              tensor([0.2793, 0.2793, 0.2793,  ..., 0.2773, 0.2852, 0.2852], device='cuda:0')),\n",
       "             ('model.layers.3.post_attention_layernorm.weight',\n",
       "              tensor([0.1738, 0.1719, 0.1680,  ..., 0.1719, 0.1699, 0.1719], device='cuda:0')),\n",
       "             ('model.layers.4.self_attn.q_proj.weight',\n",
       "              tensor([[-1.6724e-02,  3.3264e-03, -1.9226e-03,  ..., -3.4180e-03,\n",
       "                       -1.9989e-03,  1.0559e-02],\n",
       "                      [ 2.2461e-02, -1.3428e-02, -9.2773e-03,  ...,  7.6599e-03,\n",
       "                       -2.2949e-02, -3.7537e-03],\n",
       "                      [-4.7302e-03, -2.9297e-02,  1.5381e-02,  ..., -9.8228e-05,\n",
       "                       -1.3611e-02, -2.8442e-02],\n",
       "                      ...,\n",
       "                      [ 2.1973e-02, -3.1281e-03, -4.0588e-03,  ...,  6.3181e-06,\n",
       "                        2.3438e-02, -6.2012e-02],\n",
       "                      [-2.9175e-02,  1.2329e-02,  2.6001e-02,  ..., -4.9805e-02,\n",
       "                        3.6316e-03,  3.2227e-02],\n",
       "                      [-1.1353e-02, -3.4668e-02,  6.5430e-02,  ...,  5.8838e-02,\n",
       "                        3.9062e-02, -3.8086e-02]], device='cuda:0')),\n",
       "             ('model.layers.4.self_attn.k_proj.weight',\n",
       "              tensor([[-8.9722e-03,  1.3733e-02, -1.2756e-02,  ..., -1.8677e-02,\n",
       "                       -3.5400e-03, -8.1062e-05],\n",
       "                      [-2.7466e-02, -5.9814e-03, -4.1580e-04,  ..., -2.7771e-03,\n",
       "                        1.2207e-02,  5.4626e-03],\n",
       "                      [ 1.5625e-02,  3.1471e-04, -1.4648e-02,  ...,  1.3184e-02,\n",
       "                        1.8311e-02,  3.7842e-02],\n",
       "                      ...,\n",
       "                      [-9.0332e-03,  1.2012e-01,  5.9814e-02,  ...,  2.9297e-02,\n",
       "                       -1.8433e-02, -1.1475e-02],\n",
       "                      [ 3.1982e-02,  5.0049e-02, -1.7578e-02,  ...,  5.4688e-02,\n",
       "                       -3.9307e-02,  6.7871e-02],\n",
       "                      [ 1.0803e-02,  5.9814e-02,  1.5503e-02,  ..., -1.9836e-03,\n",
       "                        4.6387e-02, -1.6235e-02]], device='cuda:0')),\n",
       "             ('model.layers.4.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0004, -0.0003, -0.0079,  ..., -0.0156, -0.0085,  0.0026],\n",
       "                      [-0.0006,  0.0242,  0.0057,  ...,  0.0102,  0.0012,  0.0093],\n",
       "                      [ 0.0151, -0.0001, -0.0352,  ...,  0.0073, -0.0045, -0.0215],\n",
       "                      ...,\n",
       "                      [-0.0015, -0.0069, -0.0209,  ..., -0.0132, -0.0061,  0.0012],\n",
       "                      [-0.0039, -0.0064, -0.0006,  ...,  0.0022, -0.0064,  0.0091],\n",
       "                      [-0.0028, -0.0195, -0.0016,  ...,  0.0061, -0.0012,  0.0151]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.4.self_attn.o_proj.weight',\n",
       "              tensor([[ 3.5156e-02,  9.7656e-03, -2.1210e-03,  ..., -1.1215e-03,\n",
       "                       -2.5146e-02, -4.0894e-03],\n",
       "                      [ 5.0354e-03, -7.9155e-05, -5.2490e-03,  ...,  4.2725e-03,\n",
       "                       -2.1729e-02,  3.9978e-03],\n",
       "                      [-1.1597e-03,  7.8125e-03, -1.2756e-02,  ..., -1.1230e-02,\n",
       "                        7.7209e-03, -4.0894e-03],\n",
       "                      ...,\n",
       "                      [-1.0559e-02,  3.0029e-02, -1.4648e-02,  ..., -2.4170e-02,\n",
       "                        1.9989e-03, -1.3672e-02],\n",
       "                      [-2.7924e-03, -4.3945e-03, -1.3000e-02,  ..., -7.9346e-03,\n",
       "                       -1.7395e-03, -6.0120e-03],\n",
       "                      [ 1.2329e-02,  2.3193e-02, -8.2397e-03,  ..., -3.6774e-03,\n",
       "                        1.4709e-02,  1.7700e-03]], device='cuda:0')),\n",
       "             ('model.layers.4.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0044,  0.0081, -0.0115,  ..., -0.0171,  0.0012, -0.0143],\n",
       "                      [-0.0243,  0.0107,  0.0106,  ...,  0.0078,  0.0131, -0.0076],\n",
       "                      [-0.0085, -0.0201, -0.0040,  ...,  0.0022, -0.0034,  0.0272],\n",
       "                      ...,\n",
       "                      [-0.0109, -0.0041,  0.0097,  ..., -0.0259,  0.0039, -0.0040],\n",
       "                      [-0.0297,  0.0186, -0.0280,  ...,  0.0139,  0.0256, -0.0055],\n",
       "                      [ 0.0008, -0.0097, -0.0096,  ..., -0.0119,  0.0199,  0.0150]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.4.mlp.up_proj.weight',\n",
       "              tensor([[-0.0150, -0.0080, -0.0413,  ...,  0.0116,  0.0049, -0.0041],\n",
       "                      [-0.0210, -0.0413,  0.0066,  ..., -0.0098,  0.0122, -0.0240],\n",
       "                      [ 0.0002,  0.0304,  0.0063,  ..., -0.0386, -0.0153,  0.0049],\n",
       "                      ...,\n",
       "                      [-0.0065, -0.0305, -0.0176,  ...,  0.0067, -0.0064,  0.0493],\n",
       "                      [ 0.0118, -0.0068, -0.0151,  ..., -0.0427, -0.0077,  0.0101],\n",
       "                      [ 0.0023,  0.0221,  0.0034,  ...,  0.0014, -0.0014, -0.0048]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.4.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0261, -0.0036,  0.0245,  ..., -0.0173,  0.0032,  0.0298],\n",
       "                      [-0.0049, -0.0454,  0.0378,  ..., -0.0219, -0.0210, -0.0043],\n",
       "                      [ 0.0012, -0.0173,  0.0240,  ...,  0.0090, -0.0009,  0.0189],\n",
       "                      ...,\n",
       "                      [-0.0273, -0.0043, -0.0167,  ...,  0.0203,  0.0019,  0.0116],\n",
       "                      [-0.0166,  0.0075, -0.0262,  ...,  0.0150, -0.0339, -0.0052],\n",
       "                      [ 0.0172, -0.0282, -0.0156,  ..., -0.0034, -0.0454, -0.0259]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.4.input_layernorm.weight',\n",
       "              tensor([0.2617, 0.2559, 0.2598,  ..., 0.2539, 0.2617, 0.2695], device='cuda:0')),\n",
       "             ('model.layers.4.post_attention_layernorm.weight',\n",
       "              tensor([0.1875, 0.1836, 0.1807,  ..., 0.1855, 0.1836, 0.1846], device='cuda:0')),\n",
       "             ('model.layers.5.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0067, -0.0053, -0.0166,  ..., -0.0106, -0.0212,  0.0113],\n",
       "                      [-0.0232,  0.0157,  0.0396,  ..., -0.0115, -0.0156, -0.0339],\n",
       "                      [ 0.0094,  0.0076, -0.0100,  ...,  0.0253, -0.0081,  0.0085],\n",
       "                      ...,\n",
       "                      [-0.0093,  0.0067, -0.0033,  ...,  0.0476,  0.0040,  0.0322],\n",
       "                      [ 0.0352,  0.0137,  0.0182,  ..., -0.0408, -0.0354, -0.0310],\n",
       "                      [ 0.0110,  0.0219,  0.0339,  ..., -0.0305, -0.0176,  0.0006]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.5.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0126,  0.0300,  0.0045,  ...,  0.0160, -0.0030, -0.0055],\n",
       "                      [ 0.0022, -0.0015, -0.0297,  ...,  0.0197, -0.0060,  0.0356],\n",
       "                      [-0.0107, -0.0156,  0.0017,  ...,  0.0036, -0.0126,  0.0027],\n",
       "                      ...,\n",
       "                      [ 0.0058,  0.0007, -0.0228,  ...,  0.0369,  0.0067, -0.0306],\n",
       "                      [ 0.0537,  0.0183, -0.0188,  ..., -0.0011, -0.0131, -0.0356],\n",
       "                      [-0.0287, -0.0215,  0.0413,  ..., -0.0184, -0.0339,  0.0075]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.5.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0354,  0.0048,  0.0160,  ...,  0.0171,  0.0019,  0.0183],\n",
       "                      [ 0.0070,  0.0148, -0.0247,  ..., -0.0137,  0.0014, -0.0094],\n",
       "                      [ 0.0179,  0.0047,  0.0007,  ..., -0.0189,  0.0271,  0.0035],\n",
       "                      ...,\n",
       "                      [ 0.0237,  0.0125,  0.0037,  ...,  0.0376, -0.0082, -0.0004],\n",
       "                      [-0.0049,  0.0012, -0.0054,  ...,  0.0003, -0.0002, -0.0023],\n",
       "                      [-0.0086, -0.0079,  0.0187,  ..., -0.0070, -0.0050, -0.0223]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.5.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0125, -0.0071,  0.0027,  ..., -0.0165, -0.0112,  0.0244],\n",
       "                      [ 0.0014,  0.0009, -0.0135,  ..., -0.0182,  0.0017, -0.0007],\n",
       "                      [-0.0079, -0.0073,  0.0120,  ...,  0.0056,  0.0036,  0.0226],\n",
       "                      ...,\n",
       "                      [ 0.0168,  0.0059, -0.0046,  ...,  0.0166,  0.0347, -0.0225],\n",
       "                      [ 0.0070, -0.0043, -0.0013,  ..., -0.0155, -0.0072, -0.0032],\n",
       "                      [ 0.0055,  0.0032, -0.0131,  ...,  0.0073, -0.0082, -0.0198]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.5.mlp.gate_proj.weight',\n",
       "              tensor([[ 8.1253e-04,  1.9531e-03, -2.9053e-02,  ..., -8.8120e-04,\n",
       "                       -7.0496e-03, -1.6235e-02],\n",
       "                      [ 2.0142e-02, -1.3977e-02, -1.0559e-02,  ...,  3.0151e-02,\n",
       "                        8.0109e-04, -6.9427e-04],\n",
       "                      [ 1.0132e-02,  4.4556e-03, -1.5625e-02,  ...,  1.8433e-02,\n",
       "                        1.7944e-02, -2.9175e-02],\n",
       "                      ...,\n",
       "                      [ 2.2430e-03,  5.9204e-03,  4.1016e-02,  ..., -6.9336e-02,\n",
       "                        1.3611e-02, -2.1729e-02],\n",
       "                      [-2.9907e-02,  2.7313e-03,  1.3000e-02,  ...,  4.6082e-03,\n",
       "                        1.8188e-02, -6.9580e-03],\n",
       "                      [ 2.8687e-02, -3.4668e-02, -1.2512e-02,  ..., -5.1270e-03,\n",
       "                        8.6784e-05, -4.0527e-02]], device='cuda:0')),\n",
       "             ('model.layers.5.mlp.up_proj.weight',\n",
       "              tensor([[-4.3335e-03, -1.5076e-02, -4.6997e-03,  ..., -1.1841e-02,\n",
       "                       -3.7079e-03, -1.5503e-02],\n",
       "                      [-3.2227e-02, -4.1809e-03, -2.7618e-03,  ...,  7.0190e-03,\n",
       "                        2.2095e-02,  2.1973e-02],\n",
       "                      [-4.1485e-05,  1.1169e-02,  6.7139e-03,  ...,  3.1891e-03,\n",
       "                        1.2146e-02,  1.7334e-02],\n",
       "                      ...,\n",
       "                      [ 7.1335e-04,  2.6855e-02, -5.8594e-03,  ..., -1.3000e-02,\n",
       "                        7.7515e-03,  2.8809e-02],\n",
       "                      [ 4.5654e-02, -2.4902e-02, -2.4780e-02,  ..., -2.3651e-03,\n",
       "                       -1.6479e-02,  2.3682e-02],\n",
       "                      [ 8.8501e-03,  2.4658e-02,  5.1575e-03,  ..., -8.7891e-03,\n",
       "                       -2.2125e-03, -2.0874e-02]], device='cuda:0')),\n",
       "             ('model.layers.5.mlp.down_proj.weight',\n",
       "              tensor([[-0.0057, -0.0281, -0.0032,  ..., -0.0026,  0.0062,  0.0126],\n",
       "                      [-0.0148,  0.0084,  0.0229,  ...,  0.0225, -0.0045, -0.0312],\n",
       "                      [ 0.0166,  0.0227,  0.0120,  ..., -0.0308, -0.0444,  0.0083],\n",
       "                      ...,\n",
       "                      [ 0.0101, -0.0233, -0.0018,  ..., -0.0035, -0.0239, -0.0210],\n",
       "                      [-0.0071, -0.0359,  0.0150,  ...,  0.0153,  0.0071, -0.0513],\n",
       "                      [ 0.0156,  0.0119, -0.0177,  ...,  0.0325,  0.0089, -0.0134]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.5.input_layernorm.weight',\n",
       "              tensor([0.2617, 0.2617, 0.2578,  ..., 0.2500, 0.2656, 0.2676], device='cuda:0')),\n",
       "             ('model.layers.5.post_attention_layernorm.weight',\n",
       "              tensor([0.2021, 0.1914, 0.1875,  ..., 0.2041, 0.1973, 0.2012], device='cuda:0')),\n",
       "             ('model.layers.6.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0049, -0.0038,  0.0046,  ..., -0.0304, -0.0031, -0.0046],\n",
       "                      [-0.0015, -0.0166,  0.0104,  ...,  0.0136, -0.0027, -0.0289],\n",
       "                      [-0.0149,  0.0203, -0.0344,  ...,  0.0266, -0.0410, -0.0057],\n",
       "                      ...,\n",
       "                      [ 0.0164,  0.0105, -0.0344,  ...,  0.0193,  0.0078, -0.0040],\n",
       "                      [ 0.0330,  0.0369,  0.0042,  ..., -0.0117, -0.0898, -0.0209],\n",
       "                      [-0.0630, -0.0527,  0.0012,  ...,  0.0167,  0.0017,  0.0114]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.6.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0165, -0.0131,  0.0201,  ..., -0.0089,  0.0206,  0.0554],\n",
       "                      [-0.0166, -0.0069,  0.0457,  ...,  0.0103, -0.0152,  0.0123],\n",
       "                      [-0.0095, -0.0130, -0.0015,  ..., -0.0031, -0.0270, -0.0096],\n",
       "                      ...,\n",
       "                      [ 0.0170, -0.0393, -0.0161,  ...,  0.0588, -0.0006, -0.0457],\n",
       "                      [-0.0200,  0.0069, -0.0300,  ..., -0.0474, -0.0415,  0.0098],\n",
       "                      [-0.0486, -0.0267, -0.0330,  ...,  0.0148, -0.0396, -0.0247]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.6.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0107,  0.0339,  0.0042,  ...,  0.0121,  0.0043,  0.0043],\n",
       "                      [ 0.0349, -0.0004, -0.0082,  ...,  0.0037,  0.0020,  0.0013],\n",
       "                      [-0.0094, -0.0062,  0.0095,  ...,  0.0084,  0.0200,  0.0002],\n",
       "                      ...,\n",
       "                      [-0.0217, -0.0060,  0.0106,  ..., -0.0025, -0.0154,  0.0057],\n",
       "                      [-0.0220, -0.0107,  0.0029,  ..., -0.0059,  0.0008,  0.0220],\n",
       "                      [ 0.0356,  0.0053,  0.0206,  ..., -0.0216,  0.0010, -0.0029]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.6.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0146, -0.0151, -0.0369,  ..., -0.0122,  0.0035,  0.0077],\n",
       "                      [-0.0205,  0.0060,  0.0046,  ..., -0.0171,  0.0047, -0.0048],\n",
       "                      [ 0.0029, -0.0039, -0.0052,  ...,  0.0116,  0.0021,  0.0092],\n",
       "                      ...,\n",
       "                      [-0.0011, -0.0157, -0.0110,  ...,  0.0082, -0.0056,  0.0229],\n",
       "                      [-0.0237,  0.0081,  0.0010,  ...,  0.0007,  0.0058, -0.0270],\n",
       "                      [-0.0177, -0.0159,  0.0073,  ..., -0.0156,  0.0079,  0.0123]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.6.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0206,  0.0253, -0.0161,  ..., -0.0065, -0.0080, -0.0090],\n",
       "                      [ 0.0342, -0.0041, -0.0131,  ...,  0.0079,  0.0236,  0.0069],\n",
       "                      [-0.0192,  0.0222, -0.0145,  ..., -0.0234, -0.0016,  0.0112],\n",
       "                      ...,\n",
       "                      [ 0.0079, -0.0198, -0.0033,  ...,  0.0156, -0.0262, -0.0046],\n",
       "                      [ 0.0151, -0.0017, -0.0159,  ..., -0.0239, -0.0050, -0.0017],\n",
       "                      [-0.0320, -0.0498,  0.0225,  ..., -0.0393,  0.0022,  0.0197]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.6.mlp.up_proj.weight',\n",
       "              tensor([[-0.0085, -0.0089, -0.0150,  ...,  0.0067, -0.0040, -0.0167],\n",
       "                      [ 0.0065, -0.0430,  0.0374,  ...,  0.0041,  0.0005, -0.0089],\n",
       "                      [-0.0255, -0.0214, -0.0187,  ...,  0.0057,  0.0177,  0.0217],\n",
       "                      ...,\n",
       "                      [-0.0269,  0.0054,  0.0201,  ...,  0.0186,  0.0022,  0.0408],\n",
       "                      [ 0.0245,  0.0170, -0.0023,  ..., -0.0277,  0.0168, -0.0047],\n",
       "                      [-0.0215,  0.0203, -0.0211,  ...,  0.0060, -0.0143, -0.0476]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.6.mlp.down_proj.weight',\n",
       "              tensor([[-0.0090,  0.0164, -0.0029,  ...,  0.0005,  0.0125,  0.0154],\n",
       "                      [-0.0151, -0.0148,  0.0086,  ..., -0.0021, -0.0284, -0.0095],\n",
       "                      [-0.0015,  0.0148, -0.0151,  ...,  0.0255,  0.0233,  0.0151],\n",
       "                      ...,\n",
       "                      [ 0.0050, -0.0060,  0.0237,  ...,  0.0330, -0.0299, -0.0041],\n",
       "                      [ 0.0184, -0.0030,  0.0083,  ...,  0.0101, -0.0144, -0.0103],\n",
       "                      [ 0.0150, -0.0189, -0.0037,  ...,  0.0325, -0.0081,  0.0059]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.6.input_layernorm.weight',\n",
       "              tensor([0.3145, 0.3516, 0.3262,  ..., 0.3125, 0.3340, 0.3184], device='cuda:0')),\n",
       "             ('model.layers.6.post_attention_layernorm.weight',\n",
       "              tensor([0.2148, 0.2061, 0.2021,  ..., 0.2168, 0.2109, 0.2100], device='cuda:0')),\n",
       "             ('model.layers.7.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0072,  0.0035,  0.0007,  ...,  0.0016, -0.0173,  0.0004],\n",
       "                      [-0.0045,  0.0078,  0.0021,  ...,  0.0140, -0.0112, -0.0118],\n",
       "                      [ 0.0002,  0.0061, -0.0186,  ..., -0.0205, -0.0015,  0.0090],\n",
       "                      ...,\n",
       "                      [-0.0006, -0.0354, -0.0299,  ..., -0.0165,  0.0342,  0.0359],\n",
       "                      [ 0.0103,  0.0525, -0.0405,  ..., -0.0184, -0.0674, -0.0515],\n",
       "                      [ 0.0791, -0.0248, -0.0131,  ...,  0.0874,  0.0344, -0.0055]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.7.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0040, -0.0080, -0.0152,  ...,  0.0071,  0.0044, -0.0048],\n",
       "                      [-0.0037, -0.0164,  0.0025,  ..., -0.0076,  0.0036,  0.0199],\n",
       "                      [-0.0065, -0.0061,  0.0189,  ..., -0.0086, -0.0098, -0.0154],\n",
       "                      ...,\n",
       "                      [ 0.0425,  0.0092,  0.0221,  ...,  0.0364,  0.0371,  0.0258],\n",
       "                      [ 0.0417,  0.0537, -0.0020,  ..., -0.0306, -0.0332, -0.0018],\n",
       "                      [ 0.0342,  0.0078,  0.0128,  ...,  0.0080,  0.0069, -0.0291]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.7.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0152,  0.0024,  0.0152,  ...,  0.0264,  0.0042, -0.0129],\n",
       "                      [ 0.0289, -0.0299, -0.0021,  ...,  0.0190, -0.0190, -0.0219],\n",
       "                      [-0.0067, -0.0041, -0.0052,  ..., -0.0146,  0.0065,  0.0031],\n",
       "                      ...,\n",
       "                      [-0.0003, -0.0408,  0.0034,  ...,  0.0032, -0.0056, -0.0079],\n",
       "                      [-0.0315,  0.0156, -0.0269,  ..., -0.0126,  0.0115, -0.0010],\n",
       "                      [-0.0082, -0.0017, -0.0070,  ...,  0.0233,  0.0079,  0.0126]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.7.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0142, -0.0161, -0.0047,  ...,  0.0063, -0.0237,  0.0021],\n",
       "                      [-0.0015,  0.0228,  0.0119,  ..., -0.0410, -0.0128, -0.0049],\n",
       "                      [ 0.0054,  0.0052, -0.0201,  ..., -0.0090, -0.0112, -0.0070],\n",
       "                      ...,\n",
       "                      [-0.0188, -0.0266, -0.0060,  ...,  0.0228, -0.0190, -0.0002],\n",
       "                      [-0.0203,  0.0075,  0.0115,  ...,  0.0074, -0.0120,  0.0143],\n",
       "                      [ 0.0001,  0.0044,  0.0009,  ...,  0.0050, -0.0142,  0.0052]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.7.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0053, -0.0019, -0.0151,  ..., -0.0062, -0.0305, -0.0043],\n",
       "                      [-0.0295,  0.0197, -0.0073,  ..., -0.0010, -0.0087, -0.0064],\n",
       "                      [ 0.0170, -0.0320, -0.0082,  ...,  0.0302, -0.0183,  0.0037],\n",
       "                      ...,\n",
       "                      [-0.0053,  0.0051, -0.0112,  ..., -0.0281, -0.0041, -0.0261],\n",
       "                      [-0.0033,  0.0184,  0.0101,  ..., -0.0053,  0.0067, -0.0315],\n",
       "                      [ 0.0203, -0.0156, -0.0035,  ...,  0.0176,  0.0200, -0.0009]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.7.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0208, -0.0009, -0.0024,  ...,  0.0154, -0.0352,  0.0067],\n",
       "                      [-0.0121, -0.0234,  0.0317,  ...,  0.0020, -0.0135,  0.0198],\n",
       "                      [ 0.0203, -0.0160,  0.0079,  ..., -0.0110,  0.0192, -0.0308],\n",
       "                      ...,\n",
       "                      [ 0.0021,  0.0013, -0.0168,  ..., -0.0046, -0.0225,  0.0020],\n",
       "                      [ 0.0017,  0.0074,  0.0165,  ..., -0.0117,  0.0204, -0.0012],\n",
       "                      [-0.0242, -0.0177,  0.0075,  ...,  0.0184,  0.0098,  0.0039]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.7.mlp.down_proj.weight',\n",
       "              tensor([[-0.0085, -0.0131, -0.0001,  ..., -0.0143, -0.0071, -0.0238],\n",
       "                      [-0.0032, -0.0069,  0.0194,  ..., -0.0023,  0.0038,  0.0025],\n",
       "                      [ 0.0110,  0.0157,  0.0327,  ..., -0.0166, -0.0125, -0.0166],\n",
       "                      ...,\n",
       "                      [-0.0057, -0.0010, -0.0195,  ...,  0.0171,  0.0017, -0.0275],\n",
       "                      [ 0.0430, -0.0090,  0.0039,  ..., -0.0210,  0.0005, -0.0140],\n",
       "                      [ 0.0177,  0.0193, -0.0349,  ...,  0.0024, -0.0236,  0.0002]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.7.input_layernorm.weight',\n",
       "              tensor([0.3203, 0.3613, 0.3359,  ..., 0.3242, 0.3535, 0.3262], device='cuda:0')),\n",
       "             ('model.layers.7.post_attention_layernorm.weight',\n",
       "              tensor([0.2305, 0.2158, 0.2139,  ..., 0.2236, 0.2217, 0.2236], device='cuda:0')),\n",
       "             ('model.layers.8.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0090, -0.0110, -0.0260,  ..., -0.0056,  0.0038,  0.0033],\n",
       "                      [-0.0166, -0.0154, -0.0342,  ..., -0.0024, -0.0003, -0.0031],\n",
       "                      [-0.0312, -0.0018, -0.0100,  ...,  0.0042,  0.0176, -0.0201],\n",
       "                      ...,\n",
       "                      [-0.0064,  0.0811,  0.0427,  ..., -0.0273, -0.0255, -0.0427],\n",
       "                      [ 0.0024, -0.0630, -0.0159,  ...,  0.0344,  0.0204,  0.0007],\n",
       "                      [-0.0630, -0.0557, -0.0150,  ..., -0.0469,  0.0283, -0.0155]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.8.self_attn.k_proj.weight',\n",
       "              tensor([[-7.6904e-03,  3.8147e-03, -5.3406e-03,  ..., -4.3640e-03,\n",
       "                        4.8523e-03,  9.1553e-03],\n",
       "                      [-6.5308e-03,  8.3618e-03, -8.5449e-03,  ...,  2.3438e-02,\n",
       "                       -2.1362e-03,  1.4099e-02],\n",
       "                      [-1.0315e-02,  3.0670e-03,  6.8054e-03,  ...,  1.7166e-03,\n",
       "                       -1.5015e-02, -1.6113e-02],\n",
       "                      ...,\n",
       "                      [ 6.0558e-05, -3.8574e-02, -6.7139e-03,  ..., -3.2715e-02,\n",
       "                       -1.6846e-02,  2.7954e-02],\n",
       "                      [ 2.0905e-03,  2.5513e-02,  2.5269e-02,  ..., -3.6377e-02,\n",
       "                        4.3945e-02, -5.8594e-02],\n",
       "                      [ 1.6479e-02, -6.2561e-03, -3.3691e-02,  ...,  2.2949e-02,\n",
       "                        8.3008e-03, -1.1475e-02]], device='cuda:0')),\n",
       "             ('model.layers.8.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0242, -0.0143,  0.0044,  ..., -0.0182, -0.0111, -0.0064],\n",
       "                      [-0.0220, -0.0118,  0.0066,  ...,  0.0254,  0.0039,  0.0206],\n",
       "                      [-0.0056,  0.0164,  0.0127,  ..., -0.0037,  0.0068, -0.0204],\n",
       "                      ...,\n",
       "                      [ 0.0305, -0.0156,  0.0038,  ...,  0.0214, -0.0184,  0.0212],\n",
       "                      [ 0.0233, -0.0160,  0.0012,  ...,  0.0081, -0.0084, -0.0003],\n",
       "                      [ 0.0151, -0.0006, -0.0060,  ..., -0.0030,  0.0048, -0.0047]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.8.self_attn.o_proj.weight',\n",
       "              tensor([[ 1.1780e-02,  1.3550e-02, -1.2573e-02,  ..., -1.0376e-02,\n",
       "                        5.1260e-05,  1.8188e-02],\n",
       "                      [ 1.1597e-02,  3.0823e-03, -3.1250e-02,  ..., -6.4392e-03,\n",
       "                       -7.9956e-03, -1.2268e-02],\n",
       "                      [ 2.8076e-03,  1.0498e-02, -4.3030e-03,  ...,  2.3651e-03,\n",
       "                        1.5198e-02,  2.1851e-02],\n",
       "                      ...,\n",
       "                      [-1.7212e-02,  2.4170e-02, -7.9956e-03,  ...,  1.3351e-03,\n",
       "                       -3.6163e-03, -4.2114e-03],\n",
       "                      [ 2.3651e-03, -1.6327e-03, -2.9602e-03,  ...,  1.9302e-03,\n",
       "                        7.9956e-03, -2.1729e-02],\n",
       "                      [-2.6855e-02,  4.9744e-03, -6.4392e-03,  ...,  2.0630e-02,\n",
       "                       -9.8267e-03, -2.9144e-03]], device='cuda:0')),\n",
       "             ('model.layers.8.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0103,  0.0022, -0.0398,  ..., -0.0062, -0.0264, -0.0232],\n",
       "                      [-0.0029, -0.0425,  0.0113,  ..., -0.0009, -0.0471,  0.0228],\n",
       "                      [ 0.0177,  0.0176,  0.0232,  ...,  0.0242,  0.0201, -0.0113],\n",
       "                      ...,\n",
       "                      [-0.0120,  0.0034,  0.0049,  ...,  0.0272,  0.0137,  0.0037],\n",
       "                      [-0.0118, -0.0007,  0.0084,  ...,  0.0007, -0.0233,  0.0234],\n",
       "                      [-0.0248,  0.0052, -0.0020,  ..., -0.0149,  0.0111, -0.0013]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.8.mlp.up_proj.weight',\n",
       "              tensor([[-0.0092,  0.0176, -0.0155,  ...,  0.0272,  0.0075, -0.0113],\n",
       "                      [-0.0486,  0.0176, -0.0400,  ...,  0.0150, -0.0026, -0.0072],\n",
       "                      [ 0.0084,  0.0051,  0.0074,  ..., -0.0128, -0.0172,  0.0308],\n",
       "                      ...,\n",
       "                      [-0.0141,  0.0400, -0.0184,  ...,  0.0168, -0.0103,  0.0084],\n",
       "                      [ 0.0008, -0.0060, -0.0079,  ..., -0.0166,  0.0223, -0.0157],\n",
       "                      [-0.0140,  0.0166, -0.0130,  ..., -0.0153, -0.0008,  0.0033]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.8.mlp.down_proj.weight',\n",
       "              tensor([[-0.0108, -0.0055,  0.0195,  ...,  0.0101,  0.0120, -0.0243],\n",
       "                      [ 0.0145,  0.0121, -0.0195,  ..., -0.0058,  0.0086, -0.0229],\n",
       "                      [-0.0008, -0.0226, -0.0269,  ..., -0.0117,  0.0066, -0.0060],\n",
       "                      ...,\n",
       "                      [ 0.0132, -0.0188, -0.0347,  ...,  0.0035,  0.0051, -0.0172],\n",
       "                      [ 0.0151,  0.0030, -0.0064,  ..., -0.0035, -0.0071, -0.0165],\n",
       "                      [-0.0009,  0.0140, -0.0021,  ...,  0.0027,  0.0028,  0.0008]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.8.input_layernorm.weight',\n",
       "              tensor([0.3281, 0.3398, 0.3281,  ..., 0.3164, 0.3398, 0.3184], device='cuda:0')),\n",
       "             ('model.layers.8.post_attention_layernorm.weight',\n",
       "              tensor([0.2354, 0.2207, 0.2129,  ..., 0.2344, 0.2275, 0.2246], device='cuda:0')),\n",
       "             ('model.layers.9.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0181,  0.0034,  0.0152,  ..., -0.0068, -0.0110, -0.0148],\n",
       "                      [ 0.0022, -0.0342,  0.0146,  ...,  0.0076, -0.0082,  0.0018],\n",
       "                      [ 0.0022, -0.0027, -0.0137,  ..., -0.0227, -0.0282, -0.0225],\n",
       "                      ...,\n",
       "                      [ 0.0028, -0.0439,  0.0181,  ...,  0.0216,  0.0145, -0.0206],\n",
       "                      [ 0.0138, -0.0211,  0.0117,  ...,  0.0089,  0.0099,  0.0096],\n",
       "                      [-0.0020,  0.0540,  0.0190,  ..., -0.0562,  0.0469, -0.0045]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.9.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0347,  0.0110, -0.0147,  ...,  0.0073, -0.0203, -0.0082],\n",
       "                      [-0.0061,  0.0317,  0.0099,  ..., -0.0087,  0.0074,  0.0019],\n",
       "                      [-0.0121, -0.0146,  0.0179,  ..., -0.0045, -0.0129, -0.0039],\n",
       "                      ...,\n",
       "                      [ 0.0106, -0.0157, -0.0046,  ..., -0.0090,  0.0199,  0.0203],\n",
       "                      [ 0.0315, -0.0122,  0.0212,  ...,  0.0447, -0.0107,  0.0500],\n",
       "                      [ 0.0039, -0.0243,  0.0283,  ...,  0.0107,  0.0248, -0.0215]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.9.self_attn.v_proj.weight',\n",
       "              tensor([[-4.2419e-03,  9.4604e-03, -3.9291e-04,  ...,  7.1716e-03,\n",
       "                       -2.1484e-02, -1.8921e-02],\n",
       "                      [-1.5747e-02, -1.6602e-02, -1.4038e-03,  ...,  2.9053e-02,\n",
       "                       -4.0588e-03, -3.6163e-03],\n",
       "                      [ 1.0986e-03, -2.6489e-02,  2.0020e-02,  ..., -2.4292e-02,\n",
       "                        6.6223e-03, -1.2939e-02],\n",
       "                      ...,\n",
       "                      [-5.4321e-03, -1.4160e-02,  4.6692e-03,  ...,  3.4180e-03,\n",
       "                       -2.1973e-02, -9.1934e-04],\n",
       "                      [-1.5442e-02,  1.2589e-03, -9.0942e-03,  ..., -1.1169e-02,\n",
       "                       -2.6464e-05, -1.1230e-02],\n",
       "                      [ 2.4170e-02,  1.9653e-02, -9.6512e-04,  ..., -1.4832e-02,\n",
       "                       -3.3417e-03, -4.3030e-03]], device='cuda:0')),\n",
       "             ('model.layers.9.self_attn.o_proj.weight',\n",
       "              tensor([[ 9.7046e-03,  1.0986e-02,  4.6387e-03,  ..., -9.0332e-03,\n",
       "                        9.6512e-04, -9.7275e-04],\n",
       "                      [-4.0894e-03, -1.5381e-02, -1.8311e-03,  ...,  3.0899e-04,\n",
       "                        7.6599e-03,  1.4771e-02],\n",
       "                      [-3.4180e-02, -3.0762e-02,  1.0986e-02,  ...,  2.7100e-02,\n",
       "                        7.7820e-04,  1.5320e-02],\n",
       "                      ...,\n",
       "                      [ 1.6846e-02, -1.5381e-02,  1.0803e-02,  ...,  6.8359e-03,\n",
       "                        8.9722e-03, -8.1787e-03],\n",
       "                      [-1.1110e-04,  1.8188e-02,  2.2278e-03,  ...,  1.3123e-02,\n",
       "                       -8.8692e-05, -1.4954e-03],\n",
       "                      [ 1.4099e-02,  4.9072e-02, -2.1973e-02,  ..., -2.5635e-03,\n",
       "                        6.1646e-03,  6.0425e-03]], device='cuda:0')),\n",
       "             ('model.layers.9.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0070,  0.0273, -0.0054,  ..., -0.0266, -0.0089,  0.0024],\n",
       "                      [-0.0232,  0.0277,  0.0281,  ...,  0.0298,  0.0310, -0.0045],\n",
       "                      [ 0.0359,  0.0286, -0.0236,  ..., -0.0260,  0.0105, -0.0050],\n",
       "                      ...,\n",
       "                      [-0.0134, -0.0135, -0.0261,  ..., -0.0010, -0.0391,  0.0043],\n",
       "                      [-0.0116, -0.0248,  0.0239,  ..., -0.0150,  0.0028,  0.0134],\n",
       "                      [ 0.0134, -0.0173, -0.0099,  ...,  0.0126, -0.0154,  0.0083]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.9.mlp.up_proj.weight',\n",
       "              tensor([[-0.0126,  0.0100,  0.0123,  ..., -0.0005, -0.0073,  0.0110],\n",
       "                      [ 0.0112, -0.0022,  0.0003,  ...,  0.0152,  0.0167, -0.0198],\n",
       "                      [-0.0205, -0.0077, -0.0187,  ..., -0.0053, -0.0110, -0.0042],\n",
       "                      ...,\n",
       "                      [-0.0038,  0.0114, -0.0152,  ..., -0.0085, -0.0294, -0.0192],\n",
       "                      [ 0.0011,  0.0178, -0.0305,  ..., -0.0292, -0.0091, -0.0160],\n",
       "                      [ 0.0006, -0.0347, -0.0135,  ..., -0.0127,  0.0264,  0.0017]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.9.mlp.down_proj.weight',\n",
       "              tensor([[-0.0053,  0.0237, -0.0435,  ...,  0.0011, -0.0140,  0.0099],\n",
       "                      [ 0.0231, -0.0236, -0.0173,  ..., -0.0020, -0.0281, -0.0322],\n",
       "                      [-0.0005,  0.0043, -0.0011,  ..., -0.0149,  0.0005, -0.0016],\n",
       "                      ...,\n",
       "                      [-0.0095,  0.0205,  0.0017,  ..., -0.0003, -0.0299,  0.0070],\n",
       "                      [-0.0342, -0.0022,  0.0123,  ..., -0.0243, -0.0006, -0.0303],\n",
       "                      [ 0.0228,  0.0153,  0.0150,  ...,  0.0425,  0.0157,  0.0176]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.9.input_layernorm.weight',\n",
       "              tensor([0.3496, 0.3535, 0.3203,  ..., 0.3457, 0.3418, 0.3340], device='cuda:0')),\n",
       "             ('model.layers.9.post_attention_layernorm.weight',\n",
       "              tensor([0.2402, 0.2305, 0.2197,  ..., 0.2363, 0.2344, 0.2305], device='cuda:0')),\n",
       "             ('model.layers.10.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0012,  0.0065, -0.0008,  ...,  0.0098, -0.0042, -0.0087],\n",
       "                      [-0.0034, -0.0072,  0.0143,  ..., -0.0055,  0.0593,  0.0020],\n",
       "                      [-0.0092, -0.0068, -0.0047,  ...,  0.0190, -0.0148, -0.0159],\n",
       "                      ...,\n",
       "                      [ 0.0317,  0.0635, -0.0159,  ...,  0.0295,  0.0369, -0.0092],\n",
       "                      [-0.0598,  0.0559,  0.0011,  ..., -0.0674, -0.0008, -0.0114],\n",
       "                      [-0.0498, -0.0225, -0.0036,  ..., -0.0078, -0.0302, -0.0175]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.10.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0204,  0.0118, -0.0041,  ..., -0.0092,  0.0042, -0.0031],\n",
       "                      [-0.0095,  0.0084, -0.0043,  ...,  0.0115, -0.0099,  0.0041],\n",
       "                      [-0.0042, -0.0011,  0.0107,  ..., -0.0165,  0.0223, -0.0012],\n",
       "                      ...,\n",
       "                      [-0.0449, -0.0591,  0.0066,  ...,  0.0303, -0.0786,  0.0089],\n",
       "                      [-0.0356, -0.0065,  0.0305,  ..., -0.0181, -0.0442, -0.0228],\n",
       "                      [-0.0282,  0.0273, -0.0228,  ...,  0.0146,  0.0471, -0.0101]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.10.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0403,  0.0030, -0.0067,  ...,  0.0056,  0.0096,  0.0110],\n",
       "                      [-0.0081,  0.0141,  0.0119,  ..., -0.0079, -0.0374,  0.0190],\n",
       "                      [ 0.0153, -0.0127,  0.0162,  ...,  0.0146,  0.0064, -0.0047],\n",
       "                      ...,\n",
       "                      [ 0.0219,  0.0286,  0.0010,  ...,  0.0281, -0.0060, -0.0151],\n",
       "                      [ 0.0028,  0.0067,  0.0016,  ...,  0.0008,  0.0128,  0.0017],\n",
       "                      [ 0.0133,  0.0079, -0.0141,  ..., -0.0052, -0.0129,  0.0283]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.10.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0018,  0.0022, -0.0297,  ..., -0.0012,  0.0082,  0.0076],\n",
       "                      [ 0.0004, -0.0136,  0.0128,  ...,  0.0009,  0.0131,  0.0019],\n",
       "                      [ 0.0141, -0.0356, -0.0193,  ...,  0.0090, -0.0112, -0.0056],\n",
       "                      ...,\n",
       "                      [ 0.0008,  0.0118, -0.0125,  ..., -0.0046,  0.0049,  0.0210],\n",
       "                      [ 0.0064, -0.0107, -0.0226,  ...,  0.0116,  0.0082,  0.0018],\n",
       "                      [ 0.0092, -0.0121, -0.0253,  ...,  0.0116, -0.0010,  0.0028]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.10.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0320, -0.0391, -0.0277,  ..., -0.0049, -0.0014, -0.0089],\n",
       "                      [-0.0157, -0.0150, -0.0154,  ...,  0.0016,  0.0153,  0.0165],\n",
       "                      [-0.0136, -0.0206,  0.0089,  ...,  0.0306, -0.0054,  0.0016],\n",
       "                      ...,\n",
       "                      [-0.0447, -0.0010,  0.0115,  ...,  0.0075, -0.0302,  0.0192],\n",
       "                      [ 0.0063,  0.0211,  0.0197,  ...,  0.0054, -0.0107, -0.0027],\n",
       "                      [-0.0065, -0.0143, -0.0205,  ..., -0.0118,  0.0025, -0.0141]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.10.mlp.up_proj.weight',\n",
       "              tensor([[-0.0425, -0.0060, -0.0383,  ...,  0.0128, -0.0089, -0.0201],\n",
       "                      [-0.0090,  0.0092,  0.0041,  ...,  0.0225,  0.0359, -0.0121],\n",
       "                      [-0.0014, -0.0027,  0.0108,  ...,  0.0232, -0.0300, -0.0024],\n",
       "                      ...,\n",
       "                      [ 0.0212,  0.0193, -0.0001,  ..., -0.0432, -0.0027, -0.0021],\n",
       "                      [-0.0035, -0.0014, -0.0280,  ...,  0.0209, -0.0142,  0.0162],\n",
       "                      [ 0.0005,  0.0138,  0.0023,  ...,  0.0006,  0.0077,  0.0167]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.10.mlp.down_proj.weight',\n",
       "              tensor([[-0.0105, -0.0276, -0.0043,  ...,  0.0281, -0.0135, -0.0004],\n",
       "                      [-0.0050,  0.0159, -0.0085,  ..., -0.0101,  0.0085,  0.0002],\n",
       "                      [-0.0322, -0.0007,  0.0166,  ..., -0.0234, -0.0245,  0.0086],\n",
       "                      ...,\n",
       "                      [ 0.0127, -0.0046,  0.0009,  ...,  0.0135,  0.0147,  0.0075],\n",
       "                      [-0.0028,  0.0481, -0.0176,  ...,  0.0172,  0.0308, -0.0330],\n",
       "                      [-0.0476,  0.0013, -0.0282,  ..., -0.0189, -0.0144,  0.0083]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.10.input_layernorm.weight',\n",
       "              tensor([0.3594, 0.3555, 0.3184,  ..., 0.3359, 0.3438, 0.3340], device='cuda:0')),\n",
       "             ('model.layers.10.post_attention_layernorm.weight',\n",
       "              tensor([0.2451, 0.2295, 0.2217,  ..., 0.2402, 0.2383, 0.2354], device='cuda:0')),\n",
       "             ('model.layers.11.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0159,  0.0161, -0.0087,  ...,  0.0205, -0.0062,  0.0010],\n",
       "                      [-0.0127,  0.0088,  0.0097,  ...,  0.0135,  0.0150,  0.0007],\n",
       "                      [ 0.0015,  0.0066, -0.0245,  ..., -0.0024, -0.0093,  0.0045],\n",
       "                      ...,\n",
       "                      [-0.0012, -0.0064,  0.0325,  ...,  0.0339,  0.0388, -0.0315],\n",
       "                      [ 0.0432,  0.0178, -0.0115,  ..., -0.0080,  0.0170, -0.0288],\n",
       "                      [ 0.0737, -0.0187, -0.0183,  ..., -0.0208,  0.0461,  0.0557]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.11.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0063,  0.0165, -0.0011,  ..., -0.0126,  0.0026, -0.0214],\n",
       "                      [-0.0007,  0.0012, -0.0273,  ..., -0.0064, -0.0034,  0.0248],\n",
       "                      [ 0.0133, -0.0267,  0.0069,  ...,  0.0077,  0.0043,  0.0046],\n",
       "                      ...,\n",
       "                      [-0.0071,  0.0217,  0.0020,  ..., -0.0172, -0.0127,  0.0337],\n",
       "                      [ 0.0625, -0.0107, -0.0112,  ..., -0.0020,  0.0041, -0.0052],\n",
       "                      [ 0.0065,  0.0053,  0.0170,  ..., -0.0058,  0.0596,  0.0233]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.11.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0061,  0.0030, -0.0093,  ..., -0.0194,  0.0005,  0.0068],\n",
       "                      [ 0.0016, -0.0080, -0.0102,  ...,  0.0061,  0.0056, -0.0242],\n",
       "                      [ 0.0028,  0.0053, -0.0078,  ...,  0.0146,  0.0046, -0.0220],\n",
       "                      ...,\n",
       "                      [-0.0166,  0.0059, -0.0135,  ...,  0.0068, -0.0171, -0.0040],\n",
       "                      [-0.0068,  0.0148, -0.0094,  ..., -0.0151, -0.0164,  0.0024],\n",
       "                      [ 0.0118, -0.0244,  0.0042,  ..., -0.0400, -0.0053, -0.0125]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.11.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0177, -0.0014,  0.0064,  ...,  0.0100,  0.0126,  0.0008],\n",
       "                      [ 0.0015, -0.0260,  0.0160,  ..., -0.0140,  0.0021, -0.0183],\n",
       "                      [-0.0087, -0.0041,  0.0188,  ...,  0.0044, -0.0006,  0.0200],\n",
       "                      ...,\n",
       "                      [ 0.0060, -0.0048,  0.0236,  ...,  0.0015,  0.0026, -0.0074],\n",
       "                      [ 0.0008,  0.0229,  0.0095,  ...,  0.0170,  0.0091, -0.0325],\n",
       "                      [-0.0020, -0.0037,  0.0025,  ..., -0.0053,  0.0005, -0.0142]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.11.mlp.gate_proj.weight',\n",
       "              tensor([[-4.4922e-02, -9.4604e-03, -3.5524e-05,  ...,  4.2114e-03,\n",
       "                       -7.7820e-03,  3.7598e-02],\n",
       "                      [ 1.2665e-03, -9.3384e-03,  2.2949e-02,  ...,  1.1536e-02,\n",
       "                       -1.6846e-02, -4.3213e-02],\n",
       "                      [-2.1515e-03, -4.3701e-02, -3.7842e-02,  ..., -1.1902e-03,\n",
       "                       -4.6692e-03,  3.5400e-03],\n",
       "                      ...,\n",
       "                      [-1.6724e-02, -3.3691e-02, -1.8188e-02,  ..., -4.6997e-03,\n",
       "                       -2.8442e-02,  1.7853e-03],\n",
       "                      [ 2.3651e-03,  5.2185e-03, -2.5391e-02,  ..., -1.1475e-02,\n",
       "                        1.1108e-02,  4.0245e-04],\n",
       "                      [-8.3618e-03,  9.3994e-03,  1.0864e-02,  ...,  3.3203e-02,\n",
       "                       -2.8687e-03, -1.8311e-02]], device='cuda:0')),\n",
       "             ('model.layers.11.mlp.up_proj.weight',\n",
       "              tensor([[-0.0105, -0.0023, -0.0273,  ...,  0.0272,  0.0030,  0.0292],\n",
       "                      [ 0.0135,  0.0019, -0.0187,  ...,  0.0082, -0.0398,  0.0038],\n",
       "                      [-0.0094, -0.0276, -0.0020,  ..., -0.0089, -0.0178,  0.0153],\n",
       "                      ...,\n",
       "                      [ 0.0425,  0.0106, -0.0056,  ..., -0.0021,  0.0018,  0.0190],\n",
       "                      [-0.0113,  0.0081,  0.0081,  ...,  0.0194,  0.0093,  0.0078],\n",
       "                      [-0.0008, -0.0015, -0.0082,  ..., -0.0115,  0.0055,  0.0258]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.11.mlp.down_proj.weight',\n",
       "              tensor([[-0.0178,  0.0447,  0.0164,  ...,  0.0208,  0.0136, -0.0053],\n",
       "                      [-0.0145, -0.0060, -0.0261,  ..., -0.0284, -0.0094,  0.0148],\n",
       "                      [-0.0210, -0.0096,  0.0049,  ...,  0.0024, -0.0176, -0.0082],\n",
       "                      ...,\n",
       "                      [ 0.0189,  0.0249, -0.0125,  ...,  0.0042,  0.0018,  0.0081],\n",
       "                      [-0.0151, -0.0308, -0.0320,  ..., -0.0237, -0.0076,  0.0146],\n",
       "                      [ 0.0354,  0.0179,  0.0223,  ...,  0.0043, -0.0128,  0.0403]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.11.input_layernorm.weight',\n",
       "              tensor([0.3906, 0.3887, 0.3555,  ..., 0.3770, 0.3730, 0.3652], device='cuda:0')),\n",
       "             ('model.layers.11.post_attention_layernorm.weight',\n",
       "              tensor([0.2500, 0.2363, 0.2324,  ..., 0.2480, 0.2471, 0.2441], device='cuda:0')),\n",
       "             ('model.layers.12.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0046, -0.0189,  0.0091,  ...,  0.0167, -0.0055,  0.0062],\n",
       "                      [ 0.0029,  0.0035, -0.0010,  ..., -0.0110,  0.0253,  0.0139],\n",
       "                      [ 0.0086,  0.0344, -0.0295,  ...,  0.0008,  0.0155, -0.0312],\n",
       "                      ...,\n",
       "                      [-0.0040,  0.0376, -0.0198,  ..., -0.0293, -0.0104,  0.0135],\n",
       "                      [ 0.0344, -0.0049,  0.0115,  ...,  0.0317,  0.0056, -0.0334],\n",
       "                      [ 0.0344,  0.0136, -0.0393,  ..., -0.0187,  0.0170,  0.0244]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.12.self_attn.k_proj.weight',\n",
       "              tensor([[ 1.0559e-02, -4.6997e-03,  3.6621e-04,  ...,  1.2878e-02,\n",
       "                        4.7913e-03, -5.9509e-03],\n",
       "                      [ 4.1809e-03,  1.8188e-02, -8.1787e-03,  ...,  1.0803e-02,\n",
       "                       -1.4893e-02, -2.0020e-02],\n",
       "                      [-8.7280e-03, -1.9897e-02,  7.6599e-03,  ...,  1.3916e-02,\n",
       "                       -9.7046e-03,  1.2634e-02],\n",
       "                      ...,\n",
       "                      [ 1.5991e-02,  2.7344e-02, -1.7578e-02,  ..., -3.8086e-02,\n",
       "                       -1.3611e-02, -1.7700e-02],\n",
       "                      [-3.3447e-02,  4.7607e-03,  2.6733e-02,  ..., -2.4170e-02,\n",
       "                        2.0508e-02,  4.5300e-06],\n",
       "                      [-2.3499e-03,  3.4668e-02,  1.0376e-02,  ...,  1.2817e-02,\n",
       "                       -4.6143e-02, -3.2471e-02]], device='cuda:0')),\n",
       "             ('model.layers.12.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0058,  0.0045,  0.0053,  ..., -0.0056,  0.0079, -0.0181],\n",
       "                      [-0.0259,  0.0166, -0.0010,  ..., -0.0217, -0.0022,  0.0148],\n",
       "                      [-0.0121, -0.0105,  0.0040,  ..., -0.0023,  0.0439, -0.0129],\n",
       "                      ...,\n",
       "                      [ 0.0018, -0.0025, -0.0167,  ..., -0.0055, -0.0128, -0.0009],\n",
       "                      [ 0.0011, -0.0125, -0.0052,  ...,  0.0021,  0.0110,  0.0047],\n",
       "                      [ 0.0227,  0.0021,  0.0019,  ...,  0.0203,  0.0055, -0.0115]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.12.self_attn.o_proj.weight',\n",
       "              tensor([[ 2.7954e-02,  7.2327e-03, -1.0681e-03,  ...,  2.6550e-03,\n",
       "                        7.1716e-03, -5.3101e-03],\n",
       "                      [-5.5847e-03, -8.7891e-03, -2.5749e-05,  ..., -1.2756e-02,\n",
       "                        3.9368e-03, -1.7334e-02],\n",
       "                      [ 3.7079e-03, -4.9133e-03, -5.8594e-03,  ...,  5.3406e-03,\n",
       "                       -2.6001e-02,  1.1169e-02],\n",
       "                      ...,\n",
       "                      [ 2.6398e-03, -1.4420e-03,  1.5137e-02,  ..., -5.8289e-03,\n",
       "                       -5.7220e-04,  3.0823e-03],\n",
       "                      [-1.0437e-02, -3.2715e-02, -2.9785e-02,  ..., -4.7302e-03,\n",
       "                        1.0437e-02,  1.7822e-02],\n",
       "                      [ 1.8433e-02,  5.2795e-03,  1.0193e-02,  ...,  2.1606e-02,\n",
       "                       -1.1230e-02, -1.7090e-02]], device='cuda:0')),\n",
       "             ('model.layers.12.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0079, -0.0249,  0.0092,  ..., -0.0049,  0.0198,  0.0058],\n",
       "                      [-0.0251, -0.0261,  0.0139,  ...,  0.0159,  0.0165,  0.0124],\n",
       "                      [ 0.0045,  0.0204, -0.0042,  ..., -0.0077, -0.0442,  0.0024],\n",
       "                      ...,\n",
       "                      [ 0.0003,  0.0085,  0.0123,  ..., -0.0248, -0.0015,  0.0209],\n",
       "                      [-0.0352, -0.0067,  0.0024,  ...,  0.0073,  0.0118, -0.0038],\n",
       "                      [ 0.0010, -0.0195, -0.0070,  ..., -0.0029, -0.0062, -0.0181]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.12.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0031,  0.0190,  0.0067,  ..., -0.0046,  0.0200,  0.0166],\n",
       "                      [-0.0029, -0.0132, -0.0123,  ...,  0.0036, -0.0114,  0.0260],\n",
       "                      [ 0.0088, -0.0036,  0.0135,  ..., -0.0449,  0.0118,  0.0022],\n",
       "                      ...,\n",
       "                      [-0.0132, -0.0347, -0.0066,  ...,  0.0151, -0.0194,  0.0038],\n",
       "                      [ 0.0032, -0.0304, -0.0048,  ...,  0.0092,  0.0092, -0.0127],\n",
       "                      [-0.0110, -0.0184, -0.0052,  ...,  0.0381, -0.0049, -0.0354]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.12.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0039, -0.0056, -0.0310,  ..., -0.0125,  0.0036,  0.0066],\n",
       "                      [ 0.0156, -0.0245,  0.0016,  ..., -0.0090, -0.0107, -0.0164],\n",
       "                      [ 0.0136,  0.0014,  0.0178,  ...,  0.0044, -0.0090, -0.0197],\n",
       "                      ...,\n",
       "                      [ 0.0156, -0.0115, -0.0459,  ...,  0.0376, -0.0176, -0.0154],\n",
       "                      [-0.0239,  0.0142,  0.0107,  ..., -0.0057,  0.0364, -0.0214],\n",
       "                      [ 0.0045,  0.0193,  0.0262,  ..., -0.0325,  0.0182, -0.0011]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.12.input_layernorm.weight',\n",
       "              tensor([0.3984, 0.3926, 0.3613,  ..., 0.3730, 0.3789, 0.3809], device='cuda:0')),\n",
       "             ('model.layers.12.post_attention_layernorm.weight',\n",
       "              tensor([0.2578, 0.2432, 0.2363,  ..., 0.2539, 0.2520, 0.2520], device='cuda:0')),\n",
       "             ('model.layers.13.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0029, -0.0096, -0.0145,  ...,  0.0065, -0.0047, -0.0078],\n",
       "                      [-0.0140, -0.0154,  0.0003,  ..., -0.0011,  0.0086, -0.0026],\n",
       "                      [-0.0175,  0.0110,  0.0074,  ..., -0.0085, -0.0058,  0.0045],\n",
       "                      ...,\n",
       "                      [ 0.0420,  0.0045,  0.0013,  ...,  0.0476,  0.0181, -0.0471],\n",
       "                      [ 0.0052,  0.0129, -0.0225,  ...,  0.0122,  0.0161, -0.0081],\n",
       "                      [-0.0071, -0.0199, -0.0162,  ..., -0.0121,  0.0204, -0.0092]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.13.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0104,  0.0043, -0.0025,  ..., -0.0210,  0.0227,  0.0154],\n",
       "                      [ 0.0089,  0.0177, -0.0047,  ...,  0.0061,  0.0071,  0.0005],\n",
       "                      [ 0.0010, -0.0093,  0.0374,  ...,  0.0010,  0.0165, -0.0322],\n",
       "                      ...,\n",
       "                      [ 0.0337,  0.0327, -0.0023,  ...,  0.0052, -0.0046, -0.0157],\n",
       "                      [-0.0036,  0.0063,  0.0280,  ..., -0.0430, -0.0154,  0.0332],\n",
       "                      [-0.0226, -0.0496, -0.0118,  ..., -0.0339, -0.0284,  0.0084]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.13.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0140,  0.0023, -0.0135,  ..., -0.0038,  0.0120,  0.0150],\n",
       "                      [-0.0090,  0.0150, -0.0045,  ...,  0.0144, -0.0071, -0.0044],\n",
       "                      [ 0.0188,  0.0013, -0.0025,  ..., -0.0229,  0.0366, -0.0117],\n",
       "                      ...,\n",
       "                      [-0.0018,  0.0216, -0.0054,  ..., -0.0073,  0.0250, -0.0188],\n",
       "                      [-0.0130,  0.0104,  0.0135,  ...,  0.0009,  0.0332,  0.0082],\n",
       "                      [-0.0045, -0.0096,  0.0253,  ...,  0.0165,  0.0008,  0.0430]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.13.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0023,  0.0005, -0.0051,  ...,  0.0014, -0.0067, -0.0038],\n",
       "                      [ 0.0232,  0.0110,  0.0050,  ..., -0.0121, -0.0078,  0.0027],\n",
       "                      [ 0.0066,  0.0077, -0.0001,  ...,  0.0060, -0.0250, -0.0101],\n",
       "                      ...,\n",
       "                      [-0.0087,  0.0102,  0.0160,  ..., -0.0103, -0.0073, -0.0159],\n",
       "                      [ 0.0032,  0.0017,  0.0295,  ..., -0.0011, -0.0253, -0.0265],\n",
       "                      [ 0.0101,  0.0056,  0.0081,  ...,  0.0128, -0.0078, -0.0223]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.13.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0194,  0.0079, -0.0091,  ...,  0.0079,  0.0041, -0.0155],\n",
       "                      [-0.0264,  0.0344,  0.0184,  ...,  0.0364, -0.0028, -0.0227],\n",
       "                      [ 0.0084, -0.0211, -0.0101,  ...,  0.0020, -0.0190, -0.0114],\n",
       "                      ...,\n",
       "                      [ 0.0200, -0.0139,  0.0145,  ..., -0.0066,  0.0187,  0.0145],\n",
       "                      [ 0.0204, -0.0028,  0.0123,  ...,  0.0129,  0.0072, -0.0247],\n",
       "                      [ 0.0042,  0.0366,  0.0212,  ..., -0.0045,  0.0204,  0.0270]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.13.mlp.up_proj.weight',\n",
       "              tensor([[-0.0342,  0.0228, -0.0064,  ...,  0.0048,  0.0150,  0.0002],\n",
       "                      [ 0.0153, -0.0072,  0.0334,  ...,  0.0396,  0.0286,  0.0070],\n",
       "                      [ 0.0192, -0.0276,  0.0199,  ..., -0.0012,  0.0034, -0.0063],\n",
       "                      ...,\n",
       "                      [-0.0047, -0.0003,  0.0255,  ...,  0.0090, -0.0272,  0.0155],\n",
       "                      [-0.0089, -0.0199,  0.0079,  ...,  0.0138,  0.0537,  0.0062],\n",
       "                      [ 0.0101, -0.0205,  0.0148,  ..., -0.0208, -0.0018,  0.0237]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.13.mlp.down_proj.weight',\n",
       "              tensor([[-0.0064, -0.0035, -0.0022,  ...,  0.0292, -0.0281, -0.0232],\n",
       "                      [-0.0087,  0.0535, -0.0471,  ..., -0.0053,  0.0032, -0.0073],\n",
       "                      [ 0.0028, -0.0039,  0.0178,  ...,  0.0067, -0.0277, -0.0059],\n",
       "                      ...,\n",
       "                      [ 0.0140, -0.0021,  0.0272,  ...,  0.0081, -0.0186,  0.0339],\n",
       "                      [ 0.0078,  0.0022,  0.0159,  ..., -0.0102,  0.0108, -0.0119],\n",
       "                      [-0.0015, -0.0304,  0.0339,  ...,  0.0040,  0.0051,  0.0356]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.13.input_layernorm.weight',\n",
       "              tensor([0.4102, 0.3984, 0.3672,  ..., 0.3809, 0.3770, 0.3867], device='cuda:0')),\n",
       "             ('model.layers.13.post_attention_layernorm.weight',\n",
       "              tensor([0.2598, 0.2500, 0.2432,  ..., 0.2598, 0.2637, 0.2559], device='cuda:0')),\n",
       "             ('model.layers.14.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0056,  0.0013,  0.0190,  ..., -0.0055,  0.0107,  0.0312],\n",
       "                      [ 0.0046,  0.0124, -0.0100,  ..., -0.0354, -0.0183, -0.0271],\n",
       "                      [-0.0044, -0.0050,  0.0072,  ...,  0.0105,  0.0101, -0.0287],\n",
       "                      ...,\n",
       "                      [-0.0160, -0.0002, -0.0286,  ..., -0.0072,  0.0145, -0.0043],\n",
       "                      [ 0.0219, -0.0344,  0.0496,  ..., -0.0096,  0.0101, -0.0072],\n",
       "                      [-0.0128,  0.0033, -0.0128,  ...,  0.0140,  0.0133, -0.0483]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.14.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0105, -0.0030,  0.0097,  ..., -0.0074,  0.0204,  0.0413],\n",
       "                      [ 0.0261,  0.0244, -0.0226,  ..., -0.0063, -0.0190,  0.0089],\n",
       "                      [-0.0208,  0.0007,  0.0204,  ...,  0.0228,  0.0115, -0.0029],\n",
       "                      ...,\n",
       "                      [-0.0320,  0.0115,  0.0270,  ..., -0.0027, -0.0026, -0.0217],\n",
       "                      [-0.0281,  0.0044,  0.0137,  ..., -0.0356, -0.0036,  0.0013],\n",
       "                      [-0.0166,  0.0322,  0.0237,  ...,  0.0684,  0.0161, -0.0312]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.14.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0084,  0.0071, -0.0393,  ..., -0.0302, -0.0053,  0.0145],\n",
       "                      [-0.0028, -0.0195,  0.0008,  ...,  0.0045, -0.0026,  0.0006],\n",
       "                      [ 0.0253, -0.0190, -0.0002,  ..., -0.0052,  0.0096,  0.0123],\n",
       "                      ...,\n",
       "                      [ 0.0154, -0.0140,  0.0167,  ...,  0.0210, -0.0105,  0.0054],\n",
       "                      [-0.0139,  0.0249, -0.0332,  ...,  0.0039, -0.0074, -0.0302],\n",
       "                      [ 0.0089,  0.0226, -0.0223,  ..., -0.0056, -0.0066,  0.0189]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.14.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0098,  0.0065, -0.0220,  ..., -0.0020,  0.0032, -0.0131],\n",
       "                      [ 0.0011,  0.0288,  0.0065,  ...,  0.0201, -0.0090,  0.0010],\n",
       "                      [ 0.0049,  0.0045, -0.0029,  ...,  0.0020,  0.0206,  0.0116],\n",
       "                      ...,\n",
       "                      [ 0.0222, -0.0042,  0.0031,  ..., -0.0145, -0.0012,  0.0101],\n",
       "                      [-0.0037,  0.0006, -0.0194,  ..., -0.0036,  0.0356,  0.0198],\n",
       "                      [-0.0088, -0.0110, -0.0149,  ..., -0.0046,  0.0058,  0.0042]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.14.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0143,  0.0096, -0.0090,  ...,  0.0061, -0.0140, -0.0097],\n",
       "                      [ 0.0212,  0.0075, -0.0405,  ...,  0.0378,  0.0171, -0.0103],\n",
       "                      [ 0.0029,  0.0123,  0.0068,  ..., -0.0111,  0.0038, -0.0132],\n",
       "                      ...,\n",
       "                      [ 0.0061,  0.0156, -0.0195,  ..., -0.0041, -0.0060, -0.0023],\n",
       "                      [-0.0071,  0.0131,  0.0199,  ..., -0.0149,  0.0161,  0.0085],\n",
       "                      [ 0.0172, -0.0016,  0.0225,  ..., -0.0047, -0.0272,  0.0227]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.14.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0014,  0.0118,  0.0183,  ..., -0.0255,  0.0071,  0.0086],\n",
       "                      [ 0.0275,  0.0132, -0.0275,  ...,  0.0135,  0.0223,  0.0133],\n",
       "                      [-0.0004,  0.0021,  0.0322,  ..., -0.0042,  0.0175, -0.0045],\n",
       "                      ...,\n",
       "                      [-0.0164,  0.0067, -0.0474,  ..., -0.0078, -0.0075, -0.0071],\n",
       "                      [-0.0277,  0.0242, -0.0060,  ..., -0.0132,  0.0242, -0.0157],\n",
       "                      [ 0.0050,  0.0267,  0.0099,  ...,  0.0100, -0.0112,  0.0074]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.14.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0089,  0.0239,  0.0060,  ..., -0.0315, -0.0093, -0.0018],\n",
       "                      [ 0.0187,  0.0237, -0.0151,  ...,  0.0054,  0.0014,  0.0152],\n",
       "                      [ 0.0007, -0.0449,  0.0204,  ...,  0.0010, -0.0271,  0.0109],\n",
       "                      ...,\n",
       "                      [-0.0020,  0.0179, -0.0124,  ..., -0.0043, -0.0190, -0.0183],\n",
       "                      [ 0.0176,  0.0308,  0.0280,  ..., -0.0042, -0.0150,  0.0322],\n",
       "                      [-0.0189,  0.0128, -0.0132,  ..., -0.0292,  0.0121,  0.0178]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.14.input_layernorm.weight',\n",
       "              tensor([0.4102, 0.4199, 0.3711,  ..., 0.4023, 0.3906, 0.3867], device='cuda:0')),\n",
       "             ('model.layers.14.post_attention_layernorm.weight',\n",
       "              tensor([0.2715, 0.2598, 0.2598,  ..., 0.2754, 0.2734, 0.2676], device='cuda:0')),\n",
       "             ('model.layers.15.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0084, -0.0201, -0.0044,  ...,  0.0093, -0.0074,  0.0082],\n",
       "                      [ 0.0243, -0.0220,  0.0089,  ..., -0.0015,  0.0042,  0.0055],\n",
       "                      [ 0.0056, -0.0066,  0.0037,  ...,  0.0154, -0.0034, -0.0128],\n",
       "                      ...,\n",
       "                      [-0.0469, -0.0342,  0.0104,  ..., -0.0138, -0.0096,  0.0305],\n",
       "                      [-0.0171, -0.0549,  0.0192,  ...,  0.0166, -0.0063,  0.0041],\n",
       "                      [ 0.0198,  0.0194,  0.0281,  ..., -0.0008, -0.0198, -0.0143]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.15.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0201, -0.0067, -0.0099,  ..., -0.0020,  0.0073,  0.0012],\n",
       "                      [ 0.0107, -0.0082, -0.0054,  ...,  0.0022,  0.0037, -0.0155],\n",
       "                      [ 0.0027,  0.0043, -0.0035,  ..., -0.0056,  0.0128, -0.0082],\n",
       "                      ...,\n",
       "                      [-0.0405, -0.0496,  0.0255,  ...,  0.0108,  0.0086, -0.0107],\n",
       "                      [ 0.0121,  0.0045,  0.0125,  ...,  0.0286, -0.0140,  0.0168],\n",
       "                      [-0.0229, -0.0067,  0.0295,  ..., -0.0022, -0.0232, -0.0008]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.15.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0093,  0.0003,  0.0048,  ...,  0.0104,  0.0128,  0.0151],\n",
       "                      [-0.0098, -0.0082,  0.0150,  ...,  0.0173,  0.0045,  0.0245],\n",
       "                      [ 0.0059, -0.0349, -0.0065,  ..., -0.0327,  0.0049,  0.0046],\n",
       "                      ...,\n",
       "                      [-0.0060, -0.0032,  0.0146,  ...,  0.0100,  0.0210, -0.0141],\n",
       "                      [ 0.0042,  0.0046, -0.0240,  ...,  0.0136,  0.0134, -0.0063],\n",
       "                      [ 0.0239,  0.0013,  0.0166,  ..., -0.0216,  0.0037,  0.0077]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.15.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0030,  0.0076, -0.0156,  ...,  0.0140, -0.0083,  0.0232],\n",
       "                      [-0.0063, -0.0051, -0.0236,  ...,  0.0129, -0.0330,  0.0186],\n",
       "                      [ 0.0054, -0.0084, -0.0043,  ...,  0.0035, -0.0008,  0.0053],\n",
       "                      ...,\n",
       "                      [-0.0078, -0.0232,  0.0119,  ..., -0.0071, -0.0251, -0.0109],\n",
       "                      [-0.0051, -0.0063, -0.0030,  ...,  0.0126,  0.0036, -0.0035],\n",
       "                      [-0.0243,  0.0037,  0.0262,  ..., -0.0057, -0.0337, -0.0262]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.15.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0091,  0.0282, -0.0156,  ...,  0.0105, -0.0223,  0.0275],\n",
       "                      [ 0.0110, -0.0096,  0.0315,  ..., -0.0149,  0.0101,  0.0083],\n",
       "                      [ 0.0054, -0.0133, -0.0131,  ...,  0.0271, -0.0500, -0.0160],\n",
       "                      ...,\n",
       "                      [-0.0077,  0.0029,  0.0320,  ..., -0.0069,  0.0120,  0.0094],\n",
       "                      [-0.0065, -0.0143,  0.0078,  ..., -0.0085, -0.0142, -0.0364],\n",
       "                      [ 0.0005, -0.0143,  0.0013,  ..., -0.0015, -0.0023,  0.0070]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.15.mlp.up_proj.weight',\n",
       "              tensor([[-0.0121, -0.0116,  0.0248,  ...,  0.0184,  0.0150, -0.0476],\n",
       "                      [-0.0159,  0.0339,  0.0284,  ...,  0.0045,  0.0044,  0.0029],\n",
       "                      [-0.0437, -0.0006, -0.0088,  ..., -0.0031,  0.0155, -0.0073],\n",
       "                      ...,\n",
       "                      [-0.0126, -0.0177, -0.0068,  ...,  0.0073,  0.0039, -0.0041],\n",
       "                      [ 0.0383, -0.0081,  0.0143,  ..., -0.0063,  0.0165, -0.0014],\n",
       "                      [-0.0056, -0.0221, -0.0198,  ...,  0.0054, -0.0171, -0.0019]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.15.mlp.down_proj.weight',\n",
       "              tensor([[-0.0069, -0.0149, -0.0280,  ...,  0.0249,  0.0122, -0.0111],\n",
       "                      [ 0.0047, -0.0153, -0.0245,  ..., -0.0123, -0.0204,  0.0179],\n",
       "                      [ 0.0405,  0.0481, -0.0251,  ..., -0.0095,  0.0347,  0.0170],\n",
       "                      ...,\n",
       "                      [-0.0137, -0.0427,  0.0125,  ...,  0.0078, -0.0023,  0.0024],\n",
       "                      [-0.0369, -0.0179, -0.0025,  ..., -0.0277, -0.0173,  0.0036],\n",
       "                      [ 0.0033,  0.0293, -0.0069,  ..., -0.0117, -0.0286, -0.0234]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.15.input_layernorm.weight',\n",
       "              tensor([0.4023, 0.3965, 0.3730,  ..., 0.3789, 0.3809, 0.3828], device='cuda:0')),\n",
       "             ('model.layers.15.post_attention_layernorm.weight',\n",
       "              tensor([0.2852, 0.2715, 0.2695,  ..., 0.2832, 0.2832, 0.2793], device='cuda:0')),\n",
       "             ('model.layers.16.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0109,  0.0077, -0.0206,  ...,  0.0067,  0.0242, -0.0063],\n",
       "                      [ 0.0178, -0.0420,  0.0187,  ...,  0.0162,  0.0068, -0.0204],\n",
       "                      [-0.0107, -0.0007,  0.0060,  ..., -0.0219, -0.0061, -0.0229],\n",
       "                      ...,\n",
       "                      [ 0.0223, -0.0303, -0.0021,  ..., -0.0204,  0.0225, -0.0186],\n",
       "                      [-0.0132, -0.0113,  0.0267,  ...,  0.0013, -0.0208,  0.0129],\n",
       "                      [ 0.0076,  0.0173,  0.0160,  ..., -0.0051, -0.0292, -0.0124]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.16.self_attn.k_proj.weight',\n",
       "              tensor([[-1.6235e-02,  2.0630e-02,  6.3782e-03,  ...,  5.6152e-03,\n",
       "                        1.7944e-02,  2.1973e-02],\n",
       "                      [ 2.2705e-02, -3.4424e-02,  7.9956e-03,  ..., -3.6001e-05,\n",
       "                       -2.6245e-02, -2.8839e-03],\n",
       "                      [ 2.7222e-02, -4.9133e-03, -1.2512e-02,  ..., -2.0020e-02,\n",
       "                        2.9144e-03, -3.4180e-02],\n",
       "                      ...,\n",
       "                      [ 1.4832e-02,  1.1292e-02, -1.4038e-02,  ..., -2.4658e-02,\n",
       "                       -2.4292e-02, -5.3223e-02],\n",
       "                      [ 1.8799e-02,  9.0942e-03,  1.4954e-02,  ...,  2.3926e-02,\n",
       "                        1.1841e-02,  1.2329e-02],\n",
       "                      [-3.6865e-02,  5.0049e-02,  6.1035e-02,  ..., -7.7248e-05,\n",
       "                       -1.5747e-02,  3.0640e-02]], device='cuda:0')),\n",
       "             ('model.layers.16.self_attn.v_proj.weight',\n",
       "              tensor([[-9.3384e-03, -4.7112e-04, -5.0354e-03,  ...,  6.0425e-03,\n",
       "                       -3.3417e-03, -6.5002e-03],\n",
       "                      [-5.6885e-02, -7.5073e-03, -3.9368e-03,  ...,  6.4087e-03,\n",
       "                        1.5320e-02, -2.6611e-02],\n",
       "                      [-2.7008e-03, -3.4943e-03, -5.7678e-03,  ..., -2.4170e-02,\n",
       "                        4.3701e-02,  1.4526e-02],\n",
       "                      ...,\n",
       "                      [ 9.2773e-03, -2.1667e-03,  1.3123e-02,  ..., -1.7090e-02,\n",
       "                        4.5471e-03,  1.7090e-02],\n",
       "                      [-2.0508e-02,  7.6294e-05,  4.4250e-03,  ...,  3.4912e-02,\n",
       "                       -2.4872e-03,  1.0986e-02],\n",
       "                      [ 1.1719e-02,  1.1108e-02,  7.5378e-03,  ..., -9.3994e-03,\n",
       "                        2.0294e-03, -2.9663e-02]], device='cuda:0')),\n",
       "             ('model.layers.16.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0437, -0.0002, -0.0192,  ...,  0.0077, -0.0146,  0.0025],\n",
       "                      [-0.0231,  0.0112, -0.0223,  ..., -0.0064, -0.0013, -0.0015],\n",
       "                      [-0.0275, -0.0107, -0.0063,  ...,  0.0013,  0.0270,  0.0139],\n",
       "                      ...,\n",
       "                      [-0.0065, -0.0171,  0.0080,  ...,  0.0046, -0.0215,  0.0016],\n",
       "                      [-0.0073,  0.0251,  0.0327,  ..., -0.0029,  0.0084, -0.0154],\n",
       "                      [-0.0171,  0.0015,  0.0027,  ..., -0.0024, -0.0031, -0.0004]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.16.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0183, -0.0167, -0.0240,  ...,  0.0058, -0.0028,  0.0134],\n",
       "                      [ 0.0327,  0.0171, -0.0106,  ...,  0.0110,  0.0081,  0.0199],\n",
       "                      [-0.0074,  0.0173, -0.0044,  ...,  0.0076, -0.0029, -0.0243],\n",
       "                      ...,\n",
       "                      [-0.0037,  0.0201,  0.0009,  ...,  0.0233,  0.0234,  0.0052],\n",
       "                      [ 0.0027, -0.0085,  0.0119,  ...,  0.0171,  0.0204,  0.0211],\n",
       "                      [ 0.0320,  0.0206,  0.0352,  ..., -0.0356,  0.0234, -0.0113]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.16.mlp.up_proj.weight',\n",
       "              tensor([[-0.0347,  0.0107,  0.0026,  ...,  0.0187, -0.0162,  0.0061],\n",
       "                      [ 0.0147, -0.0137,  0.0098,  ...,  0.0184, -0.0240, -0.0081],\n",
       "                      [-0.0092, -0.0205, -0.0074,  ..., -0.0113,  0.0078,  0.0244],\n",
       "                      ...,\n",
       "                      [ 0.0035,  0.0262, -0.0079,  ...,  0.0030, -0.0107, -0.0184],\n",
       "                      [-0.0135,  0.0225, -0.0210,  ...,  0.0113, -0.0148,  0.0137],\n",
       "                      [ 0.0045,  0.0043, -0.0022,  ...,  0.0025, -0.0231, -0.0238]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.16.mlp.down_proj.weight',\n",
       "              tensor([[-0.0173, -0.0026,  0.0178,  ...,  0.0275, -0.0044,  0.0050],\n",
       "                      [-0.0234, -0.0040, -0.0126,  ...,  0.0262,  0.0012, -0.0026],\n",
       "                      [-0.0167,  0.0027, -0.0118,  ...,  0.0236, -0.0073, -0.0065],\n",
       "                      ...,\n",
       "                      [ 0.0134, -0.0237, -0.0240,  ...,  0.0109,  0.0153,  0.0008],\n",
       "                      [ 0.0150,  0.0053, -0.0102,  ..., -0.0132, -0.0123, -0.0074],\n",
       "                      [ 0.0106, -0.0149, -0.0273,  ...,  0.0273,  0.0027, -0.0137]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.16.input_layernorm.weight',\n",
       "              tensor([0.4062, 0.4102, 0.3828,  ..., 0.3828, 0.3984, 0.3965], device='cuda:0')),\n",
       "             ('model.layers.16.post_attention_layernorm.weight',\n",
       "              tensor([0.3008, 0.2871, 0.2910,  ..., 0.3008, 0.3047, 0.2969], device='cuda:0')),\n",
       "             ('model.layers.17.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0172, -0.0142,  0.0140,  ..., -0.0050, -0.0112, -0.0049],\n",
       "                      [ 0.0108, -0.0096,  0.0216,  ..., -0.0012, -0.0209,  0.0028],\n",
       "                      [-0.0131, -0.0025, -0.0114,  ...,  0.0184, -0.0079, -0.0024],\n",
       "                      ...,\n",
       "                      [ 0.0366, -0.0280,  0.0549,  ..., -0.0139, -0.0189,  0.0120],\n",
       "                      [ 0.0227, -0.0208,  0.0486,  ...,  0.0117, -0.0150, -0.0603],\n",
       "                      [ 0.0192, -0.0099,  0.0160,  ...,  0.0281,  0.0034,  0.0591]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.17.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0134,  0.0023,  0.0081,  ..., -0.0045,  0.0140,  0.0092],\n",
       "                      [ 0.0063,  0.0082,  0.0066,  ...,  0.0096, -0.0018, -0.0084],\n",
       "                      [ 0.0016, -0.0127,  0.0012,  ...,  0.0204, -0.0104, -0.0126],\n",
       "                      ...,\n",
       "                      [-0.0007, -0.0610, -0.0109,  ..., -0.0135,  0.0510, -0.0679],\n",
       "                      [ 0.0262,  0.0220,  0.0147,  ..., -0.0140, -0.0206, -0.0194],\n",
       "                      [-0.0374, -0.0457, -0.0011,  ...,  0.0327,  0.0247, -0.0057]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.17.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0120,  0.0075,  0.0059,  ...,  0.0239, -0.0092, -0.0037],\n",
       "                      [-0.0032, -0.0117, -0.0084,  ...,  0.0087, -0.0245, -0.0166],\n",
       "                      [ 0.0151,  0.0112, -0.0037,  ...,  0.0044, -0.0100, -0.0233],\n",
       "                      ...,\n",
       "                      [ 0.0094, -0.0049,  0.0144,  ...,  0.0095,  0.0067, -0.0128],\n",
       "                      [ 0.0159,  0.0049, -0.0388,  ..., -0.0220,  0.0008, -0.0298],\n",
       "                      [-0.0062, -0.0080,  0.0002,  ...,  0.0078,  0.0092,  0.0065]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.17.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0026, -0.0060,  0.0064,  ..., -0.0176,  0.0027, -0.0078],\n",
       "                      [-0.0140, -0.0221,  0.0232,  ...,  0.0273, -0.0064,  0.0197],\n",
       "                      [ 0.0120, -0.0138, -0.0052,  ..., -0.0144, -0.0024, -0.0179],\n",
       "                      ...,\n",
       "                      [-0.0094,  0.0117, -0.0170,  ..., -0.0265, -0.0278, -0.0195],\n",
       "                      [-0.0104,  0.0104, -0.0046,  ..., -0.0217, -0.0018,  0.0066],\n",
       "                      [-0.0171, -0.0096,  0.0136,  ...,  0.0304, -0.0178,  0.0150]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.17.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0359,  0.0232,  0.0179,  ...,  0.0091, -0.0060,  0.0065],\n",
       "                      [-0.0017,  0.0320,  0.0170,  ...,  0.0159, -0.0018,  0.0102],\n",
       "                      [ 0.0122,  0.0108, -0.0225,  ...,  0.0066,  0.0208, -0.0045],\n",
       "                      ...,\n",
       "                      [-0.0110, -0.0083, -0.0145,  ..., -0.0046, -0.0137, -0.0076],\n",
       "                      [ 0.0066, -0.0013, -0.0010,  ...,  0.0032,  0.0374, -0.0026],\n",
       "                      [-0.0026,  0.0211,  0.0148,  ..., -0.0132,  0.0078, -0.0022]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.17.mlp.up_proj.weight',\n",
       "              tensor([[-0.0084, -0.0251, -0.0070,  ...,  0.0067,  0.0167, -0.0132],\n",
       "                      [-0.0210,  0.0160,  0.0149,  ..., -0.0049, -0.0008,  0.0069],\n",
       "                      [ 0.0005, -0.0028, -0.0031,  ...,  0.0110, -0.0208,  0.0107],\n",
       "                      ...,\n",
       "                      [ 0.0117,  0.0156,  0.0065,  ...,  0.0063, -0.0142, -0.0120],\n",
       "                      [-0.0081, -0.0168, -0.0122,  ..., -0.0062, -0.0170,  0.0076],\n",
       "                      [ 0.0032,  0.0065, -0.0039,  ...,  0.0046, -0.0349, -0.0170]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.17.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0227, -0.0203,  0.0064,  ...,  0.0041, -0.0070, -0.0088],\n",
       "                      [ 0.0221,  0.0240,  0.0146,  ...,  0.0027, -0.0092,  0.0303],\n",
       "                      [-0.0258, -0.0183, -0.0128,  ...,  0.0106, -0.0116,  0.0048],\n",
       "                      ...,\n",
       "                      [ 0.0045, -0.0167, -0.0060,  ..., -0.0127, -0.0004, -0.0272],\n",
       "                      [ 0.0045,  0.0007, -0.0075,  ..., -0.0198, -0.0221,  0.0212],\n",
       "                      [ 0.0037, -0.0205,  0.0162,  ..., -0.0322, -0.0104,  0.0023]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.17.input_layernorm.weight',\n",
       "              tensor([0.4180, 0.4238, 0.3984,  ..., 0.4160, 0.4199, 0.3984], device='cuda:0')),\n",
       "             ('model.layers.17.post_attention_layernorm.weight',\n",
       "              tensor([0.3184, 0.3086, 0.3086,  ..., 0.3184, 0.3203, 0.3125], device='cuda:0')),\n",
       "             ('model.layers.18.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0089,  0.0058,  0.0020,  ..., -0.0103, -0.0405,  0.0058],\n",
       "                      [ 0.0008, -0.0075,  0.0127,  ..., -0.0056,  0.0190,  0.0425],\n",
       "                      [ 0.0026, -0.0189, -0.0156,  ...,  0.0009, -0.0095,  0.0089],\n",
       "                      ...,\n",
       "                      [-0.0286,  0.0146, -0.0089,  ...,  0.0292,  0.0038,  0.0198],\n",
       "                      [ 0.0640, -0.0175, -0.0266,  ...,  0.0566,  0.0317,  0.0076],\n",
       "                      [ 0.0266,  0.0177, -0.0036,  ...,  0.0222,  0.0430, -0.0466]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.18.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0134,  0.0258, -0.0082,  ...,  0.0179, -0.0164, -0.0256],\n",
       "                      [ 0.0082, -0.0160,  0.0096,  ...,  0.0206,  0.0266,  0.0016],\n",
       "                      [ 0.0110,  0.0010,  0.0066,  ...,  0.0356, -0.0168,  0.0227],\n",
       "                      ...,\n",
       "                      [-0.1084, -0.0178, -0.0649,  ...,  0.0244, -0.0032, -0.0442],\n",
       "                      [ 0.0466,  0.0386, -0.0117,  ...,  0.0376,  0.0659, -0.0339],\n",
       "                      [-0.0417, -0.0435, -0.0449,  ...,  0.0310, -0.0135, -0.0288]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.18.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0247,  0.0192, -0.0192,  ...,  0.0012,  0.0292,  0.0087],\n",
       "                      [ 0.0121,  0.0034, -0.0029,  ..., -0.0216,  0.0383,  0.0027],\n",
       "                      [-0.0016,  0.0108, -0.0058,  ...,  0.0078, -0.0008, -0.0097],\n",
       "                      ...,\n",
       "                      [ 0.0150,  0.0140, -0.0045,  ..., -0.0052, -0.0194, -0.0064],\n",
       "                      [ 0.0031, -0.0030,  0.0003,  ...,  0.0118,  0.0084,  0.0300],\n",
       "                      [-0.0042,  0.0056,  0.0072,  ..., -0.0057, -0.0093, -0.0008]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.18.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0178,  0.0115, -0.0108,  ...,  0.0090,  0.0273,  0.0175],\n",
       "                      [-0.0031, -0.0378,  0.0100,  ...,  0.0039, -0.0072, -0.0287],\n",
       "                      [-0.0037, -0.0187,  0.0150,  ...,  0.0255,  0.0194,  0.0298],\n",
       "                      ...,\n",
       "                      [-0.0332, -0.0156, -0.0249,  ...,  0.0159,  0.0116,  0.0024],\n",
       "                      [ 0.0206,  0.0537,  0.0139,  ...,  0.0107, -0.0050, -0.0347],\n",
       "                      [-0.0157, -0.0464, -0.0194,  ..., -0.0127,  0.0093, -0.0152]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.18.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0142, -0.0039,  0.0118,  ..., -0.0041,  0.0160,  0.0003],\n",
       "                      [-0.0391,  0.0082, -0.0167,  ..., -0.0035, -0.0141,  0.0004],\n",
       "                      [-0.0203,  0.0113,  0.0403,  ..., -0.0251, -0.0060,  0.0013],\n",
       "                      ...,\n",
       "                      [-0.0364, -0.0276, -0.0317,  ..., -0.0288, -0.0164, -0.0206],\n",
       "                      [ 0.0042,  0.0210,  0.0173,  ..., -0.0117, -0.0002,  0.0098],\n",
       "                      [-0.0004, -0.0061,  0.0095,  ...,  0.0083, -0.0051,  0.0026]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.18.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0115,  0.0106,  0.0322,  ...,  0.0036,  0.0206, -0.0100],\n",
       "                      [-0.0147,  0.0287, -0.0308,  ...,  0.0014, -0.0034,  0.0074],\n",
       "                      [-0.0264, -0.0099,  0.0074,  ...,  0.0135,  0.0143,  0.0229],\n",
       "                      ...,\n",
       "                      [-0.0038,  0.0070,  0.0081,  ...,  0.0193, -0.0027,  0.0084],\n",
       "                      [-0.0068, -0.0010, -0.0097,  ...,  0.0194,  0.0221,  0.0374],\n",
       "                      [ 0.0106,  0.0205,  0.0092,  ..., -0.0146,  0.0151,  0.0159]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.18.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0254,  0.0072, -0.0308,  ...,  0.0408,  0.0110,  0.0160],\n",
       "                      [ 0.0212,  0.0073,  0.0225,  ..., -0.0031, -0.0008, -0.0034],\n",
       "                      [ 0.0038, -0.0186, -0.0337,  ...,  0.0167, -0.0011,  0.0171],\n",
       "                      ...,\n",
       "                      [-0.0115,  0.0125,  0.0157,  ...,  0.0231, -0.0017, -0.0101],\n",
       "                      [-0.0199,  0.0022,  0.0134,  ...,  0.0098,  0.0359,  0.0011],\n",
       "                      [-0.0003,  0.0208,  0.0184,  ..., -0.0069,  0.0203,  0.0178]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.18.input_layernorm.weight',\n",
       "              tensor([0.4453, 0.4414, 0.4219,  ..., 0.4258, 0.4375, 0.4219], device='cuda:0')),\n",
       "             ('model.layers.18.post_attention_layernorm.weight',\n",
       "              tensor([0.3379, 0.3262, 0.3262,  ..., 0.3340, 0.3379, 0.3320], device='cuda:0')),\n",
       "             ('model.layers.19.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0014,  0.0074, -0.0079,  ..., -0.0157, -0.0041,  0.0118],\n",
       "                      [-0.0045, -0.0081,  0.0010,  ...,  0.0005,  0.0278, -0.0073],\n",
       "                      [ 0.0090,  0.0247,  0.0053,  ...,  0.0087,  0.0188,  0.0016],\n",
       "                      ...,\n",
       "                      [-0.0226, -0.0192, -0.0014,  ..., -0.0425, -0.0002,  0.0272],\n",
       "                      [ 0.0073,  0.0371,  0.0266,  ...,  0.0530,  0.0145, -0.0286],\n",
       "                      [-0.0137,  0.0281,  0.0522,  ..., -0.0033, -0.0405, -0.0124]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.19.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0192,  0.0116,  0.0011,  ..., -0.0075, -0.0031, -0.0142],\n",
       "                      [-0.0159,  0.0214, -0.0179,  ...,  0.0148,  0.0034,  0.0153],\n",
       "                      [-0.0197,  0.0079, -0.0187,  ..., -0.0002,  0.0142,  0.0201],\n",
       "                      ...,\n",
       "                      [ 0.0002,  0.0415, -0.0136,  ..., -0.0181,  0.0236, -0.0281],\n",
       "                      [-0.0698, -0.0299, -0.0031,  ...,  0.0215,  0.0131, -0.0107],\n",
       "                      [-0.0181,  0.0085, -0.0214,  ..., -0.0247,  0.0166,  0.0349]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.19.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0039, -0.0044, -0.0026,  ...,  0.0072, -0.0033,  0.0077],\n",
       "                      [ 0.0034,  0.0216,  0.0015,  ...,  0.0376, -0.0153, -0.0013],\n",
       "                      [-0.0442, -0.0255, -0.0038,  ..., -0.0056, -0.0053,  0.0145],\n",
       "                      ...,\n",
       "                      [-0.0003, -0.0378, -0.0043,  ...,  0.0008,  0.0066, -0.0182],\n",
       "                      [ 0.0139, -0.0042, -0.0239,  ..., -0.0101, -0.0089, -0.0039],\n",
       "                      [-0.0021,  0.0221, -0.0018,  ..., -0.0258, -0.0134,  0.0134]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.19.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0214, -0.0562,  0.0236,  ..., -0.0018,  0.0014, -0.0249],\n",
       "                      [ 0.0244, -0.0067,  0.0047,  ..., -0.0131,  0.0082, -0.0051],\n",
       "                      [-0.0049, -0.0128, -0.0271,  ...,  0.0032,  0.0082, -0.0015],\n",
       "                      ...,\n",
       "                      [ 0.0145, -0.0071, -0.0095,  ...,  0.0107, -0.0181,  0.0121],\n",
       "                      [ 0.0077, -0.0008, -0.0108,  ..., -0.0096, -0.0172,  0.0020],\n",
       "                      [ 0.0099,  0.0194,  0.0096,  ..., -0.0192, -0.0097,  0.0126]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.19.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0123,  0.0032,  0.0096,  ...,  0.0032,  0.0033, -0.0015],\n",
       "                      [ 0.0100,  0.0206,  0.0058,  ...,  0.0057,  0.0145, -0.0359],\n",
       "                      [-0.0052, -0.0033, -0.0192,  ..., -0.0383, -0.0068,  0.0161],\n",
       "                      ...,\n",
       "                      [ 0.0013,  0.0026,  0.0043,  ..., -0.0211, -0.0056,  0.0029],\n",
       "                      [-0.0496,  0.0007, -0.0019,  ..., -0.0040, -0.0250,  0.0139],\n",
       "                      [-0.0259, -0.0234,  0.0122,  ..., -0.0021,  0.0096,  0.0022]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.19.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0008, -0.0065,  0.0054,  ...,  0.0042,  0.0110,  0.0061],\n",
       "                      [-0.0095, -0.0008, -0.0122,  ...,  0.0249, -0.0220, -0.0121],\n",
       "                      [ 0.0152,  0.0056,  0.0171,  ..., -0.0161, -0.0125,  0.0491],\n",
       "                      ...,\n",
       "                      [ 0.0125,  0.0159, -0.0089,  ...,  0.0199, -0.0129,  0.0359],\n",
       "                      [ 0.0039,  0.0240,  0.0361,  ..., -0.0140,  0.0327, -0.0153],\n",
       "                      [ 0.0025, -0.0190, -0.0107,  ..., -0.0017, -0.0014,  0.0082]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.19.mlp.down_proj.weight',\n",
       "              tensor([[-0.0050, -0.0172,  0.0054,  ...,  0.0040, -0.0160,  0.0155],\n",
       "                      [-0.0091, -0.0393, -0.0247,  ...,  0.0110,  0.0077, -0.0075],\n",
       "                      [-0.0227, -0.0186,  0.0234,  ...,  0.0053, -0.0045,  0.0067],\n",
       "                      ...,\n",
       "                      [-0.0076, -0.0057,  0.0184,  ...,  0.0164,  0.0178, -0.0020],\n",
       "                      [ 0.0066, -0.0148, -0.0413,  ...,  0.0283, -0.0083, -0.0144],\n",
       "                      [ 0.0081, -0.0060, -0.0266,  ...,  0.0010,  0.0068,  0.0075]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.19.input_layernorm.weight',\n",
       "              tensor([0.4473, 0.4531, 0.4316,  ..., 0.4219, 0.4277, 0.4316], device='cuda:0')),\n",
       "             ('model.layers.19.post_attention_layernorm.weight',\n",
       "              tensor([0.3516, 0.3379, 0.3398,  ..., 0.3477, 0.3477, 0.3438], device='cuda:0')),\n",
       "             ('model.layers.20.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0014, -0.0043,  0.0161,  ...,  0.0114,  0.0020, -0.0228],\n",
       "                      [ 0.0074, -0.0201,  0.0086,  ..., -0.0083, -0.0076,  0.0087],\n",
       "                      [ 0.0017, -0.0041, -0.0079,  ...,  0.0122, -0.0023, -0.0042],\n",
       "                      ...,\n",
       "                      [-0.0223, -0.0405,  0.0114,  ..., -0.0027,  0.0179,  0.0040],\n",
       "                      [-0.0718, -0.0175,  0.0130,  ...,  0.0101,  0.0208,  0.0061],\n",
       "                      [ 0.0167, -0.0005, -0.0065,  ..., -0.0154, -0.0087, -0.0028]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.20.self_attn.k_proj.weight',\n",
       "              tensor([[-3.0060e-03,  5.8289e-03,  6.1951e-03,  ..., -2.8992e-03,\n",
       "                        3.3722e-03,  4.6997e-03],\n",
       "                      [ 3.5706e-03,  8.2397e-03,  3.8147e-03,  ..., -9.8228e-05,\n",
       "                       -2.0142e-03,  1.1230e-02],\n",
       "                      [ 3.3569e-03,  4.4556e-03, -7.5684e-03,  ..., -5.0964e-03,\n",
       "                        5.5847e-03,  1.7822e-02],\n",
       "                      ...,\n",
       "                      [ 6.5231e-04, -2.5330e-03, -2.1851e-02,  ..., -1.8311e-02,\n",
       "                        2.3193e-02,  2.6733e-02],\n",
       "                      [-1.8188e-02,  1.8799e-02, -2.3041e-03,  ...,  2.2949e-02,\n",
       "                        1.9531e-02,  5.9570e-02],\n",
       "                      [-1.5015e-02, -2.7832e-02, -1.3977e-02,  ...,  2.6001e-02,\n",
       "                       -2.7222e-02,  4.5410e-02]], device='cuda:0')),\n",
       "             ('model.layers.20.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0036, -0.0106,  0.0136,  ..., -0.0045,  0.0110,  0.0111],\n",
       "                      [-0.0076, -0.0425, -0.0006,  ..., -0.0085,  0.0015,  0.0090],\n",
       "                      [-0.0081, -0.0137,  0.0010,  ..., -0.0203, -0.0005,  0.0013],\n",
       "                      ...,\n",
       "                      [ 0.0073, -0.0082, -0.0041,  ...,  0.0195, -0.0038,  0.0075],\n",
       "                      [ 0.0176,  0.0087, -0.0077,  ...,  0.0019,  0.0129, -0.0089],\n",
       "                      [ 0.0004, -0.0046,  0.0260,  ..., -0.0082, -0.0112, -0.0393]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.20.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0068,  0.0036,  0.0297,  ..., -0.0024,  0.0175, -0.0092],\n",
       "                      [ 0.0100, -0.0126, -0.0095,  ..., -0.0008, -0.0096,  0.0225],\n",
       "                      [ 0.0156, -0.0027, -0.0115,  ..., -0.0266,  0.0019,  0.0101],\n",
       "                      ...,\n",
       "                      [-0.0133,  0.0010,  0.0055,  ...,  0.0138, -0.0150,  0.0112],\n",
       "                      [ 0.0054,  0.0151, -0.0148,  ...,  0.0123, -0.0269,  0.0030],\n",
       "                      [ 0.0188, -0.0237, -0.0051,  ...,  0.0156, -0.0211,  0.0117]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.20.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0005, -0.0031, -0.0215,  ...,  0.0221, -0.0096,  0.0132],\n",
       "                      [-0.0171,  0.0062, -0.0081,  ..., -0.0045, -0.0104,  0.0162],\n",
       "                      [-0.0128, -0.0071,  0.0569,  ..., -0.0198,  0.0223, -0.0029],\n",
       "                      ...,\n",
       "                      [ 0.0012, -0.0066,  0.0258,  ..., -0.0233,  0.0056, -0.0036],\n",
       "                      [ 0.0121,  0.0031,  0.0107,  ...,  0.0199,  0.0002,  0.0140],\n",
       "                      [-0.0073, -0.0231, -0.0145,  ...,  0.0029, -0.0286, -0.0047]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.20.mlp.up_proj.weight',\n",
       "              tensor([[-0.0581, -0.0013,  0.0004,  ...,  0.0138, -0.0107, -0.0104],\n",
       "                      [-0.0107,  0.0062, -0.0101,  ..., -0.0439, -0.0157,  0.0376],\n",
       "                      [ 0.0106,  0.0327,  0.0188,  ...,  0.0089, -0.0198,  0.0076],\n",
       "                      ...,\n",
       "                      [-0.0142,  0.0251, -0.0096,  ..., -0.0177, -0.0046,  0.0007],\n",
       "                      [ 0.0157, -0.0255, -0.0162,  ...,  0.0029, -0.0214, -0.0354],\n",
       "                      [ 0.0144, -0.0236,  0.0278,  ..., -0.0116, -0.0197, -0.0086]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.20.mlp.down_proj.weight',\n",
       "              tensor([[-0.0028,  0.0251, -0.0037,  ..., -0.0085, -0.0093, -0.0298],\n",
       "                      [-0.0010,  0.0173, -0.0082,  ...,  0.0090, -0.0190,  0.0231],\n",
       "                      [-0.0094,  0.0116, -0.0225,  ..., -0.0067,  0.0239, -0.0155],\n",
       "                      ...,\n",
       "                      [-0.0315,  0.0304,  0.0065,  ...,  0.0129, -0.0008, -0.0005],\n",
       "                      [-0.0108,  0.0051, -0.0150,  ..., -0.0125,  0.0149, -0.0111],\n",
       "                      [ 0.0118,  0.0025, -0.0005,  ..., -0.0007, -0.0081, -0.0056]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.20.input_layernorm.weight',\n",
       "              tensor([0.4473, 0.4609, 0.4316,  ..., 0.4297, 0.4316, 0.4434], device='cuda:0')),\n",
       "             ('model.layers.20.post_attention_layernorm.weight',\n",
       "              tensor([0.3613, 0.3535, 0.3496,  ..., 0.3633, 0.3574, 0.3535], device='cuda:0')),\n",
       "             ('model.layers.21.self_attn.q_proj.weight',\n",
       "              tensor([[-1.6479e-02, -4.6997e-03,  1.7090e-02,  ..., -5.5542e-03,\n",
       "                        6.2561e-03, -5.8899e-03],\n",
       "                      [ 1.4893e-02, -2.1935e-05, -5.4626e-03,  ...,  7.8125e-03,\n",
       "                       -2.4796e-05,  1.8311e-02],\n",
       "                      [-1.0864e-02, -6.1646e-03, -4.4823e-05,  ...,  2.8442e-02,\n",
       "                       -7.0801e-03,  1.0223e-03],\n",
       "                      ...,\n",
       "                      [ 1.3275e-03, -6.3171e-03,  2.8687e-02,  ..., -1.1841e-02,\n",
       "                       -5.1270e-02,  8.5449e-03],\n",
       "                      [-1.2451e-02,  1.5991e-02,  1.9409e-02,  ...,  2.4658e-02,\n",
       "                        3.5889e-02, -5.5237e-03],\n",
       "                      [-7.3730e-02, -1.3123e-02, -8.7280e-03,  ..., -8.4839e-03,\n",
       "                        1.4343e-02, -4.2236e-02]], device='cuda:0')),\n",
       "             ('model.layers.21.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0067,  0.0115,  0.0045,  ...,  0.0127, -0.0012,  0.0039],\n",
       "                      [-0.0019,  0.0079,  0.0135,  ...,  0.0061,  0.0071,  0.0148],\n",
       "                      [ 0.0095,  0.0030,  0.0334,  ...,  0.0146, -0.0004,  0.0034],\n",
       "                      ...,\n",
       "                      [-0.0165,  0.0178,  0.0059,  ...,  0.0240, -0.0371,  0.0461],\n",
       "                      [ 0.0005,  0.0039, -0.0119,  ..., -0.0147,  0.0278, -0.0073],\n",
       "                      [-0.0229,  0.0053, -0.0188,  ..., -0.0004, -0.0187,  0.0625]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.21.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0010,  0.0084, -0.0036,  ..., -0.0043,  0.0195, -0.0237],\n",
       "                      [-0.0265,  0.0262, -0.0071,  ...,  0.0210, -0.0211,  0.0265],\n",
       "                      [ 0.0220,  0.0029, -0.0049,  ..., -0.0209,  0.0214, -0.0082],\n",
       "                      ...,\n",
       "                      [-0.0073, -0.0232,  0.0325,  ...,  0.0014, -0.0002, -0.0170],\n",
       "                      [-0.0161, -0.0125,  0.0137,  ...,  0.0079, -0.0018,  0.0189],\n",
       "                      [-0.0095,  0.0188, -0.0142,  ...,  0.0052, -0.0146,  0.0004]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.21.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0133, -0.0006,  0.0116,  ..., -0.0107,  0.0251, -0.0027],\n",
       "                      [-0.0050,  0.0238, -0.0112,  ..., -0.0281,  0.0091, -0.0052],\n",
       "                      [-0.0175, -0.0126,  0.0063,  ...,  0.0255,  0.0297,  0.0159],\n",
       "                      ...,\n",
       "                      [ 0.0088, -0.0085, -0.0128,  ...,  0.0215,  0.0079,  0.0190],\n",
       "                      [ 0.0223, -0.0075,  0.0131,  ..., -0.0100,  0.0086, -0.0164],\n",
       "                      [-0.0206,  0.0154, -0.0133,  ...,  0.0327, -0.0193,  0.0027]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.21.mlp.gate_proj.weight',\n",
       "              tensor([[-2.2736e-03, -2.0874e-02,  1.2085e-02,  ..., -3.2715e-02,\n",
       "                        4.0039e-02,  1.6357e-02],\n",
       "                      [ 1.2939e-02,  9.9487e-03,  9.3384e-03,  ..., -3.6865e-02,\n",
       "                        5.1758e-02,  6.5308e-03],\n",
       "                      [ 1.2451e-02,  6.1035e-03,  2.1667e-03,  ..., -4.1016e-02,\n",
       "                       -3.9673e-03, -1.9409e-02],\n",
       "                      ...,\n",
       "                      [ 1.1475e-02, -2.6367e-02, -2.8076e-02,  ...,  3.3936e-02,\n",
       "                       -2.5024e-02,  1.3885e-03],\n",
       "                      [-3.2196e-03,  2.9663e-02,  8.1177e-03,  ...,  9.3384e-03,\n",
       "                       -2.1851e-02,  5.9509e-03],\n",
       "                      [ 1.8082e-03, -9.2773e-03, -2.0752e-03,  ..., -1.6235e-02,\n",
       "                        2.5630e-05,  6.8054e-03]], device='cuda:0')),\n",
       "             ('model.layers.21.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0240, -0.0297, -0.0168,  ...,  0.0223,  0.0369, -0.0137],\n",
       "                      [-0.0234, -0.0147,  0.0002,  ...,  0.0352,  0.0432,  0.0041],\n",
       "                      [ 0.0160, -0.0045, -0.0009,  ...,  0.0026, -0.0115, -0.0075],\n",
       "                      ...,\n",
       "                      [-0.0449, -0.0031,  0.0170,  ...,  0.0139, -0.0081, -0.0090],\n",
       "                      [-0.0017, -0.0114,  0.0066,  ..., -0.0234, -0.0055,  0.0031],\n",
       "                      [-0.0076, -0.0254, -0.0173,  ..., -0.0076, -0.0066, -0.0327]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.21.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0111,  0.0160, -0.0037,  ...,  0.0160,  0.0203,  0.0082],\n",
       "                      [ 0.0164, -0.0044, -0.0139,  ...,  0.0023, -0.0128, -0.0135],\n",
       "                      [-0.0081, -0.0016,  0.0096,  ..., -0.0012,  0.0339,  0.0209],\n",
       "                      ...,\n",
       "                      [-0.0116,  0.0378,  0.0229,  ..., -0.0025,  0.0010,  0.0060],\n",
       "                      [ 0.0160, -0.0010, -0.0031,  ..., -0.0491, -0.0147,  0.0107],\n",
       "                      [ 0.0071,  0.0040,  0.0217,  ..., -0.0135,  0.0188, -0.0212]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.21.input_layernorm.weight',\n",
       "              tensor([0.4727, 0.4805, 0.4629,  ..., 0.4512, 0.4668, 0.4727], device='cuda:0')),\n",
       "             ('model.layers.21.post_attention_layernorm.weight',\n",
       "              tensor([0.3711, 0.3652, 0.3613,  ..., 0.3770, 0.3691, 0.3711], device='cuda:0')),\n",
       "             ('model.layers.22.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0214, -0.0143, -0.0102,  ...,  0.0435, -0.0374,  0.0295],\n",
       "                      [-0.0398, -0.0155, -0.0018,  ..., -0.0405,  0.0123, -0.0413],\n",
       "                      [-0.0303,  0.0233, -0.0140,  ...,  0.0225,  0.0123, -0.0223],\n",
       "                      ...,\n",
       "                      [ 0.0123,  0.0141,  0.0093,  ...,  0.0128,  0.0547, -0.0050],\n",
       "                      [-0.0261, -0.0042, -0.0261,  ...,  0.0466,  0.0040, -0.0211],\n",
       "                      [ 0.0295, -0.0128,  0.0090,  ..., -0.0515,  0.0128,  0.0262]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.22.self_attn.k_proj.weight',\n",
       "              tensor([[-1.8921e-02, -9.9182e-04, -7.4463e-03,  ...,  1.4526e-02,\n",
       "                       -1.3733e-02, -1.7456e-02],\n",
       "                      [ 5.4016e-03, -1.3672e-02,  2.9663e-02,  ..., -2.3315e-02,\n",
       "                        3.5156e-02, -1.6602e-02],\n",
       "                      [-1.8311e-02,  3.3203e-02, -4.2725e-02,  ...,  5.8105e-02,\n",
       "                       -8.1787e-03, -8.5449e-03],\n",
       "                      ...,\n",
       "                      [ 1.9775e-02,  7.8735e-03, -2.6489e-02,  ..., -2.1606e-02,\n",
       "                       -1.3672e-02,  1.7700e-02],\n",
       "                      [-1.1963e-02, -4.5898e-02, -8.1177e-03,  ..., -3.5048e-05,\n",
       "                       -6.8054e-03,  1.7834e-04],\n",
       "                      [ 2.7466e-02,  5.6458e-03,  3.1982e-02,  ...,  3.0151e-02,\n",
       "                       -3.4912e-02,  1.5198e-02]], device='cuda:0')),\n",
       "             ('model.layers.22.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0195,  0.0051, -0.0026,  ..., -0.0449, -0.0248,  0.0223],\n",
       "                      [-0.0309, -0.0143,  0.0104,  ..., -0.0239, -0.0349, -0.0092],\n",
       "                      [ 0.0260, -0.0240, -0.0082,  ...,  0.0483,  0.0015, -0.0147],\n",
       "                      ...,\n",
       "                      [-0.0081, -0.0442, -0.0258,  ...,  0.0146, -0.0051,  0.0153],\n",
       "                      [-0.0359, -0.0160,  0.0250,  ..., -0.0152,  0.0079, -0.0091],\n",
       "                      [-0.0022,  0.0210, -0.0381,  ...,  0.0056,  0.0003,  0.0231]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.22.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0233,  0.0162, -0.0201,  ..., -0.0030, -0.0273,  0.0067],\n",
       "                      [ 0.0339,  0.0137,  0.0048,  ...,  0.0035, -0.0126, -0.0183],\n",
       "                      [ 0.0151,  0.0049, -0.0087,  ..., -0.0283,  0.0083, -0.0032],\n",
       "                      ...,\n",
       "                      [-0.0005, -0.0138, -0.0107,  ..., -0.0156, -0.0184,  0.0021],\n",
       "                      [ 0.0217, -0.0089, -0.0198,  ..., -0.0173, -0.0096,  0.0127],\n",
       "                      [ 0.0022, -0.0236,  0.0253,  ...,  0.0098,  0.0159,  0.0168]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.22.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0186, -0.0153,  0.0258,  ...,  0.0128,  0.0229, -0.0339],\n",
       "                      [ 0.0089, -0.0042,  0.0021,  ...,  0.0011,  0.0026,  0.0179],\n",
       "                      [ 0.0075, -0.0130,  0.0063,  ...,  0.0120,  0.0100, -0.0058],\n",
       "                      ...,\n",
       "                      [-0.0040, -0.0015,  0.0038,  ..., -0.0132,  0.0057, -0.0041],\n",
       "                      [-0.0008,  0.0237, -0.0262,  ..., -0.0012,  0.0151, -0.0215],\n",
       "                      [-0.0096,  0.0061,  0.0031,  ..., -0.0093,  0.0210,  0.0161]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.22.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0303,  0.0204,  0.0036,  ...,  0.0103,  0.0315, -0.0038],\n",
       "                      [ 0.0088,  0.0074,  0.0176,  ..., -0.0139, -0.0058,  0.0020],\n",
       "                      [ 0.0050, -0.0302, -0.0405,  ...,  0.0237,  0.0079,  0.0055],\n",
       "                      ...,\n",
       "                      [-0.0084, -0.0006, -0.0205,  ..., -0.0018,  0.0061,  0.0046],\n",
       "                      [ 0.0167, -0.0129, -0.0209,  ..., -0.0317,  0.0088, -0.0164],\n",
       "                      [-0.0034,  0.0011, -0.0040,  ..., -0.0420, -0.0557,  0.0144]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.22.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0145, -0.0117,  0.0126,  ..., -0.0142,  0.0052, -0.0415],\n",
       "                      [ 0.0030,  0.0201, -0.0093,  ..., -0.0104,  0.0118, -0.0264],\n",
       "                      [-0.0060, -0.0082,  0.0076,  ...,  0.0167,  0.0145,  0.0209],\n",
       "                      ...,\n",
       "                      [ 0.0258, -0.0057, -0.0469,  ..., -0.0067, -0.0171, -0.0208],\n",
       "                      [-0.0134, -0.0471,  0.0103,  ...,  0.0188, -0.0253,  0.0327],\n",
       "                      [ 0.0094, -0.0005, -0.0344,  ..., -0.0042, -0.0162,  0.0090]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.22.input_layernorm.weight',\n",
       "              tensor([0.4805, 0.4805, 0.4707,  ..., 0.4629, 0.4824, 0.4824], device='cuda:0')),\n",
       "             ('model.layers.22.post_attention_layernorm.weight',\n",
       "              tensor([0.3809, 0.3789, 0.3809,  ..., 0.3887, 0.3828, 0.3867], device='cuda:0')),\n",
       "             ('model.layers.23.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0025, -0.0149,  0.0007,  ..., -0.0171, -0.0005,  0.0012],\n",
       "                      [ 0.0090, -0.0020,  0.0101,  ..., -0.0171, -0.0034,  0.0089],\n",
       "                      [-0.0079,  0.0039,  0.0194,  ..., -0.0024, -0.0145,  0.0077],\n",
       "                      ...,\n",
       "                      [-0.0199,  0.0608,  0.0124,  ..., -0.0378, -0.0598, -0.0280],\n",
       "                      [-0.0352, -0.0337,  0.0227,  ..., -0.0166, -0.0039,  0.0095],\n",
       "                      [ 0.0106, -0.0583, -0.0038,  ...,  0.0139,  0.0391, -0.0093]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.23.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0014,  0.0048,  0.0023,  ..., -0.0006, -0.0172,  0.0027],\n",
       "                      [-0.0175, -0.0011, -0.0131,  ...,  0.0164,  0.0142, -0.0032],\n",
       "                      [ 0.0091,  0.0060, -0.0140,  ...,  0.0176,  0.0113, -0.0081],\n",
       "                      ...,\n",
       "                      [ 0.0065,  0.0309,  0.0525,  ..., -0.0293, -0.0136, -0.0190],\n",
       "                      [-0.0004, -0.0306, -0.0114,  ..., -0.0204, -0.0220,  0.0143],\n",
       "                      [-0.0164, -0.0081, -0.0232,  ...,  0.0049,  0.0027, -0.0142]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.23.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0041,  0.0349, -0.0042,  ..., -0.0118, -0.0093, -0.0161],\n",
       "                      [-0.0005, -0.0120, -0.0177,  ...,  0.0047, -0.0110,  0.0037],\n",
       "                      [ 0.0077, -0.0145, -0.0258,  ...,  0.0137, -0.0457, -0.0291],\n",
       "                      ...,\n",
       "                      [ 0.0098,  0.0082,  0.0070,  ..., -0.0010,  0.0299,  0.0120],\n",
       "                      [ 0.0203,  0.0273,  0.0073,  ..., -0.0010, -0.0089, -0.0126],\n",
       "                      [-0.0184, -0.0128, -0.0554,  ...,  0.0092,  0.0095, -0.0315]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.23.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0062, -0.0050, -0.0194,  ..., -0.0177,  0.0135, -0.0073],\n",
       "                      [-0.0103, -0.0165, -0.0022,  ..., -0.0024,  0.0119, -0.0028],\n",
       "                      [ 0.0164,  0.0036,  0.0310,  ..., -0.0142,  0.0060, -0.0215],\n",
       "                      ...,\n",
       "                      [ 0.0352, -0.0063,  0.0364,  ..., -0.0198,  0.0097,  0.0014],\n",
       "                      [-0.0069,  0.0223, -0.0135,  ..., -0.0039, -0.0141, -0.0052],\n",
       "                      [ 0.0117, -0.0060, -0.0115,  ..., -0.0066, -0.0024, -0.0293]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.23.mlp.gate_proj.weight',\n",
       "              tensor([[-8.7280e-03,  2.7466e-02, -3.8338e-04,  ...,  7.4387e-04,\n",
       "                        3.5889e-02,  1.2573e-02],\n",
       "                      [-9.3384e-03,  4.5654e-02, -1.2329e-02,  ...,  5.0659e-03,\n",
       "                       -2.0142e-02,  1.7944e-02],\n",
       "                      [-3.1128e-02,  1.9897e-02,  4.3945e-03,  ...,  1.9409e-02,\n",
       "                       -5.8350e-02,  2.2583e-02],\n",
       "                      ...,\n",
       "                      [-6.9580e-03,  8.8501e-03, -1.2875e-04,  ..., -9.4604e-03,\n",
       "                        1.0742e-02,  5.2795e-03],\n",
       "                      [-2.4658e-02,  3.2715e-02, -1.1444e-03,  ...,  1.5793e-03,\n",
       "                        1.4771e-02, -2.5146e-02],\n",
       "                      [ 8.7619e-06,  1.0742e-02,  1.3184e-02,  ..., -6.6223e-03,\n",
       "                        4.8218e-03, -1.3855e-02]], device='cuda:0')),\n",
       "             ('model.layers.23.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0294,  0.0124,  0.0320,  ...,  0.0054, -0.0278, -0.0103],\n",
       "                      [ 0.0014,  0.0044, -0.0144,  ..., -0.0038, -0.0147,  0.0109],\n",
       "                      [-0.0166,  0.0042, -0.0251,  ...,  0.0172,  0.0103, -0.0056],\n",
       "                      ...,\n",
       "                      [-0.0105, -0.0150,  0.0164,  ...,  0.0070,  0.0400,  0.0070],\n",
       "                      [-0.0024,  0.0116, -0.0393,  ...,  0.0142,  0.0045,  0.0152],\n",
       "                      [ 0.0062,  0.0112, -0.0036,  ..., -0.0017, -0.0193,  0.0205]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.23.mlp.down_proj.weight',\n",
       "              tensor([[ 1.9789e-05,  8.9722e-03, -1.9409e-02,  ..., -3.3936e-02,\n",
       "                       -1.4099e-02,  3.0518e-02],\n",
       "                      [ 9.7656e-03,  1.8188e-02, -5.9814e-03,  ...,  2.4780e-02,\n",
       "                        2.7100e-02,  1.1597e-03],\n",
       "                      [-3.7231e-03, -1.3062e-02, -2.0264e-02,  ...,  6.8359e-03,\n",
       "                        3.5156e-02, -1.2451e-02],\n",
       "                      ...,\n",
       "                      [ 7.9956e-03, -5.4016e-03,  1.0254e-02,  ...,  1.5869e-02,\n",
       "                       -2.8419e-04, -1.7822e-02],\n",
       "                      [ 2.8076e-02, -8.1177e-03, -6.9809e-04,  ..., -4.7913e-03,\n",
       "                        5.9204e-03,  1.8597e-04],\n",
       "                      [-2.6703e-03, -3.1494e-02, -1.4648e-02,  ..., -9.1553e-03,\n",
       "                        1.1108e-02, -8.3618e-03]], device='cuda:0')),\n",
       "             ('model.layers.23.input_layernorm.weight',\n",
       "              tensor([0.5039, 0.5156, 0.5039,  ..., 0.5000, 0.5156, 0.5195], device='cuda:0')),\n",
       "             ('model.layers.23.post_attention_layernorm.weight',\n",
       "              tensor([0.3984, 0.3906, 0.3906,  ..., 0.3945, 0.3984, 0.4023], device='cuda:0')),\n",
       "             ('model.layers.24.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0201, -0.0143,  0.0117,  ...,  0.0378, -0.0184,  0.0008],\n",
       "                      [ 0.0229,  0.0110,  0.0056,  ..., -0.0112,  0.0146, -0.0063],\n",
       "                      [-0.0043, -0.0070, -0.0219,  ...,  0.0082, -0.0104,  0.0172],\n",
       "                      ...,\n",
       "                      [-0.0062,  0.0021, -0.0201,  ...,  0.0121, -0.0015, -0.0061],\n",
       "                      [-0.0211,  0.0107,  0.0075,  ...,  0.0210, -0.0381,  0.0022],\n",
       "                      [-0.0209, -0.0371, -0.0181,  ..., -0.0096,  0.0264,  0.0654]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.24.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0226,  0.0020, -0.0091,  ...,  0.0101, -0.0054,  0.0025],\n",
       "                      [ 0.0109, -0.0198,  0.0093,  ..., -0.0254,  0.0200,  0.0090],\n",
       "                      [ 0.0090,  0.0058, -0.0444,  ...,  0.0159,  0.0155, -0.0139],\n",
       "                      ...,\n",
       "                      [ 0.0289,  0.0058,  0.0393,  ...,  0.0116,  0.0195, -0.0447],\n",
       "                      [-0.0045,  0.0221,  0.0199,  ...,  0.0344, -0.0170, -0.0003],\n",
       "                      [-0.0229, -0.0175, -0.0050,  ...,  0.0042, -0.0055,  0.0598]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.24.self_attn.v_proj.weight',\n",
       "              tensor([[ 2.6489e-02, -1.9653e-02, -4.2114e-03,  ..., -3.5248e-03,\n",
       "                       -2.5787e-03, -3.7079e-03],\n",
       "                      [ 2.8442e-02, -2.2095e-02, -1.1658e-02,  ..., -6.2012e-02,\n",
       "                       -4.0771e-02, -1.7212e-02],\n",
       "                      [-5.2002e-02, -1.8921e-02, -1.5625e-02,  ..., -1.0010e-02,\n",
       "                       -1.4160e-02,  8.2016e-04],\n",
       "                      ...,\n",
       "                      [-7.1049e-05, -1.7944e-02,  1.3855e-02,  ...,  2.4292e-02,\n",
       "                       -3.9673e-03,  2.5024e-02],\n",
       "                      [-4.9133e-03, -1.2085e-02, -1.4587e-02,  ...,  3.0518e-02,\n",
       "                       -4.8523e-03,  8.1787e-03],\n",
       "                      [ 1.2756e-02,  1.9287e-02,  2.3438e-02,  ...,  2.0752e-02,\n",
       "                       -1.5442e-02, -9.1553e-03]], device='cuda:0')),\n",
       "             ('model.layers.24.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0107,  0.0166,  0.0262,  ...,  0.0064,  0.0017, -0.0177],\n",
       "                      [-0.0122,  0.0287,  0.0125,  ...,  0.0162,  0.0267, -0.0272],\n",
       "                      [-0.0095, -0.0022,  0.0108,  ..., -0.0245,  0.0014, -0.0082],\n",
       "                      ...,\n",
       "                      [-0.0027,  0.0170,  0.0154,  ..., -0.0064, -0.0071,  0.0019],\n",
       "                      [ 0.0518,  0.0043, -0.0071,  ...,  0.0016, -0.0190, -0.0061],\n",
       "                      [ 0.0052,  0.0153,  0.0090,  ...,  0.0056, -0.0206,  0.0144]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.24.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0299, -0.0137,  0.0119,  ..., -0.0106, -0.0018, -0.0009],\n",
       "                      [-0.0005, -0.0128, -0.0253,  ...,  0.0109,  0.0003, -0.0159],\n",
       "                      [ 0.0004, -0.0344,  0.0242,  ..., -0.0085, -0.0457, -0.0186],\n",
       "                      ...,\n",
       "                      [-0.0020, -0.0282,  0.0056,  ..., -0.0031,  0.0129, -0.0061],\n",
       "                      [ 0.0172,  0.0165,  0.0061,  ...,  0.0075, -0.0004, -0.0031],\n",
       "                      [-0.0347,  0.0291, -0.0006,  ...,  0.0332, -0.0186, -0.0452]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.24.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0023, -0.0025,  0.0216,  ...,  0.0249, -0.0019,  0.0275],\n",
       "                      [-0.0035,  0.0152, -0.0262,  ..., -0.0098,  0.0012, -0.0204],\n",
       "                      [ 0.0136, -0.0474,  0.0157,  ...,  0.0410,  0.0181, -0.0327],\n",
       "                      ...,\n",
       "                      [ 0.0157, -0.0291, -0.0073,  ..., -0.0014,  0.0161,  0.0136],\n",
       "                      [ 0.0339, -0.0080,  0.0146,  ...,  0.0047,  0.0128, -0.0088],\n",
       "                      [-0.0012, -0.0160,  0.0239,  ...,  0.0253,  0.0349,  0.0197]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.24.mlp.down_proj.weight',\n",
       "              tensor([[-4.8218e-03, -1.2695e-02, -3.2715e-02,  ..., -7.2956e-05,\n",
       "                        4.2114e-03, -1.9653e-02],\n",
       "                      [ 2.7588e-02, -6.9885e-03,  1.6357e-02,  ..., -3.1433e-03,\n",
       "                        7.9956e-03, -4.6875e-02],\n",
       "                      [ 2.0264e-02,  1.7700e-02, -3.1738e-02,  ...,  1.3580e-03,\n",
       "                        2.1973e-02,  6.5002e-03],\n",
       "                      ...,\n",
       "                      [-7.1411e-03,  9.2773e-03, -1.8799e-02,  ..., -3.3447e-02,\n",
       "                       -1.2573e-02, -2.3193e-02],\n",
       "                      [ 1.0376e-02,  2.5513e-02,  6.1035e-03,  ...,  2.2949e-02,\n",
       "                       -2.6123e-02,  1.8066e-02],\n",
       "                      [-2.1851e-02, -7.3853e-03,  5.4321e-03,  ...,  1.2268e-02,\n",
       "                       -6.9885e-03, -3.1494e-02]], device='cuda:0')),\n",
       "             ('model.layers.24.input_layernorm.weight',\n",
       "              tensor([0.4902, 0.5156, 0.5039,  ..., 0.4824, 0.5078, 0.5000], device='cuda:0')),\n",
       "             ('model.layers.24.post_attention_layernorm.weight',\n",
       "              tensor([0.4082, 0.4043, 0.4043,  ..., 0.4082, 0.4121, 0.4043], device='cuda:0')),\n",
       "             ('model.layers.25.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0049, -0.0138, -0.0195,  ...,  0.0048, -0.0156,  0.0018],\n",
       "                      [-0.0118,  0.0021,  0.0127,  ..., -0.0148,  0.0001, -0.0073],\n",
       "                      [-0.0023,  0.0069,  0.0012,  ..., -0.0045, -0.0178, -0.0182],\n",
       "                      ...,\n",
       "                      [ 0.0444,  0.0469,  0.0049,  ...,  0.0019,  0.0146, -0.0265],\n",
       "                      [-0.0554, -0.0564, -0.0068,  ..., -0.0156, -0.0248,  0.0047],\n",
       "                      [ 0.0393, -0.0408, -0.0219,  ...,  0.0026,  0.0181, -0.0317]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.25.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0110, -0.0142, -0.0035,  ...,  0.0006,  0.0033, -0.0029],\n",
       "                      [-0.0179, -0.0090,  0.0065,  ..., -0.0041, -0.0225,  0.0088],\n",
       "                      [-0.0101,  0.0015, -0.0010,  ...,  0.0065, -0.0089,  0.0075],\n",
       "                      ...,\n",
       "                      [ 0.0055,  0.0513, -0.0130,  ..., -0.0571, -0.0542,  0.0327],\n",
       "                      [ 0.0366, -0.0381,  0.0011,  ..., -0.0025,  0.0074,  0.0149],\n",
       "                      [-0.0086, -0.0208,  0.0021,  ...,  0.0364,  0.0095, -0.0205]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.25.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0107,  0.0105,  0.0046,  ...,  0.0243, -0.0175, -0.0120],\n",
       "                      [-0.0048, -0.0071,  0.0042,  ...,  0.0070, -0.0327, -0.0084],\n",
       "                      [-0.0144,  0.0087, -0.0172,  ..., -0.0096, -0.0048, -0.0046],\n",
       "                      ...,\n",
       "                      [-0.0166, -0.0293, -0.0082,  ...,  0.0146,  0.0064,  0.0106],\n",
       "                      [-0.0137,  0.0011,  0.0192,  ..., -0.0033,  0.0084, -0.0208],\n",
       "                      [-0.0330, -0.0137, -0.0217,  ...,  0.0026,  0.0187,  0.0229]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.25.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0154,  0.0156,  0.0028,  ...,  0.0143,  0.0029,  0.0129],\n",
       "                      [-0.0240, -0.0189, -0.0187,  ...,  0.0250,  0.0037, -0.0045],\n",
       "                      [-0.0059, -0.0105,  0.0182,  ..., -0.0118, -0.0153,  0.0005],\n",
       "                      ...,\n",
       "                      [-0.0170,  0.0124, -0.0042,  ...,  0.0141,  0.0124,  0.0261],\n",
       "                      [-0.0060, -0.0240, -0.0278,  ..., -0.0212, -0.0106,  0.0081],\n",
       "                      [-0.0160, -0.0073, -0.0142,  ..., -0.0413, -0.0240, -0.0145]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.25.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0026, -0.0371,  0.0403,  ..., -0.0048, -0.0099,  0.0125],\n",
       "                      [-0.0206, -0.0014, -0.0087,  ...,  0.0222,  0.0359,  0.0148],\n",
       "                      [-0.0098,  0.0242,  0.0074,  ...,  0.0132,  0.0079,  0.0258],\n",
       "                      ...,\n",
       "                      [-0.0425,  0.0030,  0.0116,  ..., -0.0023, -0.0205,  0.0064],\n",
       "                      [ 0.0204, -0.0034,  0.0574,  ...,  0.0249,  0.0219,  0.0066],\n",
       "                      [-0.0101, -0.0027, -0.0117,  ...,  0.0466,  0.0028, -0.0058]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.25.mlp.up_proj.weight',\n",
       "              tensor([[-0.0325, -0.0061,  0.0166,  ...,  0.0075,  0.0121, -0.0184],\n",
       "                      [-0.0176,  0.0018,  0.0110,  ..., -0.0049,  0.0128, -0.0004],\n",
       "                      [ 0.0272,  0.0007,  0.0315,  ..., -0.0159, -0.0220, -0.0046],\n",
       "                      ...,\n",
       "                      [ 0.0076,  0.0056,  0.0405,  ...,  0.0066, -0.0283, -0.0199],\n",
       "                      [-0.0294,  0.0126, -0.0325,  ..., -0.0413, -0.0266,  0.0019],\n",
       "                      [-0.0148, -0.0028,  0.0283,  ...,  0.0219,  0.0077,  0.0219]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.25.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0291, -0.0089,  0.0131,  ...,  0.0176, -0.0037,  0.0309],\n",
       "                      [-0.0181,  0.0018,  0.0004,  ...,  0.0147, -0.0029,  0.0239],\n",
       "                      [ 0.0159,  0.0109, -0.0017,  ..., -0.0184,  0.0076, -0.0164],\n",
       "                      ...,\n",
       "                      [ 0.0131, -0.0194, -0.0266,  ..., -0.0447,  0.0025,  0.0234],\n",
       "                      [ 0.0030, -0.0052,  0.0048,  ...,  0.0045,  0.0038,  0.0003],\n",
       "                      [-0.0085, -0.0083,  0.0112,  ..., -0.0339, -0.0036, -0.0065]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.25.input_layernorm.weight',\n",
       "              tensor([0.5391, 0.5508, 0.5391,  ..., 0.5508, 0.5547, 0.5430], device='cuda:0')),\n",
       "             ('model.layers.25.post_attention_layernorm.weight',\n",
       "              tensor([0.4121, 0.4121, 0.4141,  ..., 0.4219, 0.4219, 0.4199], device='cuda:0')),\n",
       "             ('model.layers.26.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0339, -0.0047, -0.0074,  ..., -0.0064,  0.0374, -0.0008],\n",
       "                      [-0.0085, -0.0145,  0.0103,  ..., -0.0023, -0.0226,  0.0092],\n",
       "                      [-0.0017,  0.0048,  0.0100,  ...,  0.0033, -0.0400, -0.0170],\n",
       "                      ...,\n",
       "                      [-0.0015, -0.0099, -0.0067,  ...,  0.0137,  0.0200,  0.0026],\n",
       "                      [ 0.0027, -0.0228, -0.0282,  ...,  0.0183, -0.0073, -0.0092],\n",
       "                      [-0.0145,  0.0535,  0.0264,  ..., -0.0099, -0.0591, -0.0457]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.26.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0251,  0.0182, -0.0116,  ..., -0.0222,  0.0349, -0.0003],\n",
       "                      [-0.0254,  0.0103,  0.0140,  ..., -0.0022,  0.0208,  0.0298],\n",
       "                      [ 0.0135,  0.0267, -0.0052,  ..., -0.0244, -0.0608, -0.0055],\n",
       "                      ...,\n",
       "                      [ 0.0236,  0.0203,  0.0021,  ..., -0.0435, -0.0520,  0.0243],\n",
       "                      [-0.0317, -0.0334, -0.0094,  ...,  0.0454,  0.0237, -0.0033],\n",
       "                      [-0.0138,  0.0206, -0.0139,  ..., -0.0007, -0.0204, -0.0097]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.26.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0574, -0.0232, -0.0258,  ..., -0.0135,  0.0075, -0.0142],\n",
       "                      [-0.0540, -0.0210,  0.0250,  ...,  0.0050, -0.0083,  0.0062],\n",
       "                      [ 0.0024,  0.0043, -0.0265,  ..., -0.0058, -0.0046, -0.0297],\n",
       "                      ...,\n",
       "                      [-0.0220, -0.0166,  0.0034,  ...,  0.0459, -0.0039,  0.0084],\n",
       "                      [ 0.0068, -0.0339, -0.0037,  ..., -0.0167, -0.0186, -0.0002],\n",
       "                      [ 0.0062,  0.0226, -0.0112,  ...,  0.0096, -0.0003,  0.0187]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.26.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0120,  0.0027, -0.0297,  ..., -0.0023,  0.0132,  0.0298],\n",
       "                      [ 0.0087,  0.0500,  0.0075,  ..., -0.0056,  0.0471, -0.0068],\n",
       "                      [-0.0073,  0.0143, -0.0226,  ..., -0.0164,  0.0053, -0.0024],\n",
       "                      ...,\n",
       "                      [ 0.0299,  0.0030,  0.0120,  ...,  0.0007,  0.0120,  0.0038],\n",
       "                      [-0.0133,  0.0095, -0.0089,  ...,  0.0123, -0.0045, -0.0452],\n",
       "                      [ 0.0157,  0.0012,  0.0054,  ..., -0.0222,  0.0212, -0.0195]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.26.mlp.gate_proj.weight',\n",
       "              tensor([[ 1.2329e-02, -5.7678e-03,  1.4587e-02,  ...,  2.6733e-02,\n",
       "                        2.7344e-02, -3.9062e-02],\n",
       "                      [-8.6670e-03,  1.0803e-02, -1.8433e-02,  ..., -2.7710e-02,\n",
       "                       -2.5146e-02,  1.9409e-02],\n",
       "                      [ 4.4556e-03,  8.8501e-04, -1.0610e-05,  ...,  6.7139e-03,\n",
       "                       -9.7046e-03, -1.9287e-02],\n",
       "                      ...,\n",
       "                      [-2.8839e-03,  3.6865e-02, -9.8267e-03,  ..., -6.7139e-04,\n",
       "                       -3.4912e-02, -1.9043e-02],\n",
       "                      [-1.7944e-02,  1.1597e-02,  2.4658e-02,  ...,  1.8188e-02,\n",
       "                        1.6724e-02,  5.7068e-03],\n",
       "                      [ 1.7090e-02,  1.1635e-04, -6.4392e-03,  ..., -2.4902e-02,\n",
       "                       -2.6093e-03, -4.6082e-03]], device='cuda:0')),\n",
       "             ('model.layers.26.mlp.up_proj.weight',\n",
       "              tensor([[-0.0145,  0.0408, -0.0031,  ...,  0.0129, -0.0079, -0.0068],\n",
       "                      [-0.0356, -0.0134,  0.0024,  ...,  0.0289, -0.0011,  0.0107],\n",
       "                      [ 0.0040, -0.0121, -0.0276,  ...,  0.0139, -0.0157, -0.0077],\n",
       "                      ...,\n",
       "                      [ 0.0072, -0.0264,  0.0048,  ...,  0.0107,  0.0354, -0.0110],\n",
       "                      [-0.0430, -0.0012,  0.0544,  ...,  0.0281,  0.0014,  0.0045],\n",
       "                      [ 0.0028, -0.0173,  0.0182,  ..., -0.0131,  0.0094, -0.0061]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.26.mlp.down_proj.weight',\n",
       "              tensor([[-0.0098, -0.0116, -0.0132,  ...,  0.0289,  0.0142,  0.0039],\n",
       "                      [ 0.0139,  0.0107,  0.0043,  ...,  0.0574,  0.0193, -0.0260],\n",
       "                      [-0.0192,  0.0121, -0.0249,  ..., -0.0120,  0.0203,  0.0109],\n",
       "                      ...,\n",
       "                      [-0.0146, -0.0077, -0.0137,  ...,  0.0095,  0.0381,  0.0010],\n",
       "                      [-0.0160, -0.0150, -0.0245,  ...,  0.0101,  0.0089,  0.0181],\n",
       "                      [ 0.0066, -0.0057, -0.0084,  ...,  0.0137,  0.0166,  0.0108]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.26.input_layernorm.weight',\n",
       "              tensor([0.5117, 0.5312, 0.5273,  ..., 0.5117, 0.5352, 0.5273], device='cuda:0')),\n",
       "             ('model.layers.26.post_attention_layernorm.weight',\n",
       "              tensor([0.4316, 0.4258, 0.4297,  ..., 0.4395, 0.4375, 0.4355], device='cuda:0')),\n",
       "             ('model.layers.27.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0306,  0.0199,  0.0045,  ..., -0.0018,  0.0130,  0.0388],\n",
       "                      [-0.0193,  0.0408,  0.0229,  ..., -0.0199,  0.0029,  0.0050],\n",
       "                      [-0.0140, -0.0248,  0.0064,  ...,  0.0030, -0.0245,  0.0349],\n",
       "                      ...,\n",
       "                      [-0.0547,  0.0297, -0.0075,  ...,  0.0208, -0.0178, -0.0199],\n",
       "                      [ 0.0019,  0.0317,  0.0157,  ...,  0.0079,  0.0026,  0.0233],\n",
       "                      [-0.0232, -0.0132,  0.0084,  ...,  0.0195,  0.0153, -0.0064]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.27.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0043, -0.0048,  0.0073,  ..., -0.0033, -0.0160,  0.0112],\n",
       "                      [-0.0017,  0.0056,  0.0172,  ...,  0.0432, -0.0093, -0.0087],\n",
       "                      [ 0.0084, -0.0171,  0.0050,  ...,  0.0006, -0.0055, -0.0040],\n",
       "                      ...,\n",
       "                      [-0.0060, -0.0137,  0.0349,  ...,  0.0085, -0.0251, -0.0002],\n",
       "                      [ 0.0270, -0.0193, -0.0430,  ...,  0.0608, -0.0099,  0.0474],\n",
       "                      [ 0.0303,  0.0156, -0.0049,  ..., -0.0315, -0.0376,  0.0103]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.27.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0212, -0.0068, -0.0364,  ...,  0.0320,  0.0356, -0.0123],\n",
       "                      [ 0.0188,  0.0161,  0.0095,  ...,  0.0028, -0.0177,  0.0156],\n",
       "                      [-0.0275,  0.0029,  0.0219,  ..., -0.0128,  0.0476, -0.0271],\n",
       "                      ...,\n",
       "                      [ 0.0066, -0.0190, -0.0221,  ...,  0.0222, -0.0131, -0.0110],\n",
       "                      [ 0.0002, -0.0217, -0.0271,  ..., -0.0133, -0.0092, -0.0156],\n",
       "                      [ 0.0205, -0.0253, -0.0197,  ..., -0.0273, -0.0293,  0.0195]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.27.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0041, -0.0076,  0.0048,  ...,  0.0315,  0.0102, -0.0266],\n",
       "                      [ 0.0041,  0.0334, -0.0199,  ..., -0.0105, -0.0109,  0.0009],\n",
       "                      [-0.0042, -0.0151, -0.0176,  ...,  0.0170,  0.0070, -0.0048],\n",
       "                      ...,\n",
       "                      [ 0.0238, -0.0078, -0.0101,  ...,  0.0135,  0.0464, -0.0012],\n",
       "                      [ 0.0332, -0.0222, -0.0101,  ..., -0.0017, -0.0045,  0.0238],\n",
       "                      [ 0.0410,  0.0176,  0.0270,  ..., -0.0123,  0.0017, -0.0195]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.27.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0369,  0.0153, -0.0136,  ...,  0.0128,  0.0029, -0.0166],\n",
       "                      [-0.0212,  0.0062, -0.0182,  ...,  0.0304,  0.0315,  0.0327],\n",
       "                      [ 0.0106,  0.0143, -0.0084,  ..., -0.0160, -0.0247,  0.0281],\n",
       "                      ...,\n",
       "                      [ 0.0286,  0.0173,  0.0029,  ..., -0.0077,  0.0176, -0.0078],\n",
       "                      [-0.0187,  0.0305, -0.0258,  ..., -0.0019, -0.0128,  0.0091],\n",
       "                      [ 0.0072, -0.0198, -0.0109,  ..., -0.0063, -0.0173, -0.0030]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.27.mlp.up_proj.weight',\n",
       "              tensor([[-0.0057,  0.0167,  0.0286,  ..., -0.0012,  0.0116, -0.0371],\n",
       "                      [-0.0165,  0.0029, -0.0253,  ...,  0.0172, -0.0154, -0.0229],\n",
       "                      [ 0.0271,  0.0094,  0.0420,  ...,  0.0294, -0.0056, -0.0148],\n",
       "                      ...,\n",
       "                      [-0.0079,  0.0266,  0.0284,  ..., -0.0183,  0.0187, -0.0371],\n",
       "                      [ 0.0135,  0.0294,  0.0110,  ...,  0.0153, -0.0159, -0.0132],\n",
       "                      [-0.0045, -0.0096, -0.0092,  ..., -0.0064, -0.0194,  0.0010]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.27.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0082, -0.0211,  0.0320,  ..., -0.0178,  0.0157, -0.0003],\n",
       "                      [-0.0049,  0.0106, -0.0143,  ..., -0.0184, -0.0249,  0.0057],\n",
       "                      [ 0.0315,  0.0106,  0.0069,  ..., -0.0309,  0.0046,  0.0281],\n",
       "                      ...,\n",
       "                      [-0.0052,  0.0118,  0.0118,  ...,  0.0121, -0.0493,  0.0306],\n",
       "                      [-0.0217, -0.0059, -0.0132,  ...,  0.0175, -0.0016,  0.0228],\n",
       "                      [ 0.0056,  0.0150, -0.0042,  ...,  0.0259, -0.0067,  0.0040]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.27.input_layernorm.weight',\n",
       "              tensor([0.5391, 0.5430, 0.5430,  ..., 0.5430, 0.5469, 0.5508], device='cuda:0')),\n",
       "             ('model.layers.27.post_attention_layernorm.weight',\n",
       "              tensor([0.4492, 0.4414, 0.4395,  ..., 0.4473, 0.4531, 0.4434], device='cuda:0')),\n",
       "             ('model.layers.28.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0010, -0.0183,  0.0080,  ..., -0.0103, -0.0117, -0.0040],\n",
       "                      [ 0.0147, -0.0040, -0.0064,  ...,  0.0123,  0.0021, -0.0011],\n",
       "                      [ 0.0130,  0.0046, -0.0061,  ..., -0.0013, -0.0217,  0.0203],\n",
       "                      ...,\n",
       "                      [-0.0031,  0.0298, -0.0522,  ...,  0.0104,  0.0002, -0.0430],\n",
       "                      [ 0.0161, -0.0325, -0.0162,  ...,  0.0253,  0.0413, -0.0610],\n",
       "                      [ 0.0087,  0.0140, -0.0483,  ...,  0.0471,  0.0226, -0.0332]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.28.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0042,  0.0009,  0.0131,  ..., -0.0037,  0.0095, -0.0217],\n",
       "                      [-0.0137,  0.0043, -0.0217,  ..., -0.0129,  0.0027,  0.0086],\n",
       "                      [ 0.0047,  0.0071, -0.0175,  ..., -0.0179, -0.0077, -0.0031],\n",
       "                      ...,\n",
       "                      [-0.0320, -0.0120,  0.0024,  ..., -0.0095, -0.0476, -0.0019],\n",
       "                      [ 0.0432, -0.0216,  0.0145,  ...,  0.0142,  0.0386,  0.0322],\n",
       "                      [ 0.0175, -0.0118,  0.0042,  ..., -0.0033, -0.0209, -0.0127]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.28.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0256,  0.0089,  0.0261,  ..., -0.0190, -0.0269,  0.0184],\n",
       "                      [ 0.0200, -0.0123, -0.0099,  ..., -0.0471,  0.0322, -0.0121],\n",
       "                      [-0.0047,  0.0182, -0.0043,  ...,  0.0046, -0.0420,  0.0128],\n",
       "                      ...,\n",
       "                      [ 0.0276,  0.0069, -0.0056,  ...,  0.0156, -0.0023, -0.0231],\n",
       "                      [ 0.0439,  0.0095,  0.0430,  ...,  0.0072,  0.0117, -0.0048],\n",
       "                      [ 0.0134,  0.0151, -0.0461,  ...,  0.0291,  0.0032,  0.0023]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.28.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0087,  0.0244, -0.0464,  ..., -0.0437,  0.0198,  0.0030],\n",
       "                      [-0.0170, -0.0220,  0.0016,  ..., -0.0115,  0.0211,  0.0327],\n",
       "                      [ 0.0282,  0.0128, -0.0562,  ...,  0.0253,  0.0264, -0.0164],\n",
       "                      ...,\n",
       "                      [ 0.0003, -0.0099,  0.0317,  ..., -0.0131, -0.0413, -0.0055],\n",
       "                      [-0.0098, -0.0547, -0.0157,  ...,  0.0108, -0.0254, -0.0291],\n",
       "                      [-0.0481, -0.0049, -0.0123,  ..., -0.0228, -0.0025,  0.0049]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.28.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0023,  0.0046, -0.0031,  ...,  0.0289, -0.0104,  0.0347],\n",
       "                      [-0.0232,  0.0203, -0.0121,  ...,  0.0092,  0.0071,  0.0266],\n",
       "                      [ 0.0156,  0.0317,  0.0226,  ...,  0.0221,  0.0014,  0.0091],\n",
       "                      ...,\n",
       "                      [-0.0107,  0.0299,  0.0096,  ...,  0.0166,  0.0130, -0.0077],\n",
       "                      [ 0.0101, -0.0317, -0.0146,  ..., -0.0160, -0.0125,  0.0038],\n",
       "                      [-0.0303,  0.0171,  0.0128,  ..., -0.0080, -0.0138,  0.0184]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.28.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0210,  0.0062,  0.0242,  ...,  0.0289,  0.0193,  0.0167],\n",
       "                      [-0.0137, -0.0229, -0.0028,  ..., -0.0157, -0.0303, -0.0243],\n",
       "                      [ 0.0131,  0.0148, -0.0050,  ...,  0.0083,  0.0022, -0.0256],\n",
       "                      ...,\n",
       "                      [-0.0147, -0.0043,  0.0269,  ..., -0.0042,  0.0027,  0.0026],\n",
       "                      [-0.0248,  0.0040, -0.0006,  ...,  0.0114, -0.0045, -0.0486],\n",
       "                      [-0.0096, -0.0250, -0.0036,  ..., -0.0077,  0.0053, -0.0061]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.28.mlp.down_proj.weight',\n",
       "              tensor([[ 8.3618e-03,  3.8086e-02, -1.0620e-02,  ...,  7.9346e-03,\n",
       "                       -9.8877e-03, -2.4536e-02],\n",
       "                      [ 9.5367e-04, -3.0518e-02,  1.8066e-02,  ..., -3.4180e-02,\n",
       "                       -5.7373e-03, -2.6123e-02],\n",
       "                      [-1.5198e-02,  2.5513e-02, -8.4229e-03,  ...,  5.7678e-03,\n",
       "                        1.5259e-03,  4.0054e-05],\n",
       "                      ...,\n",
       "                      [ 6.8970e-03, -1.3123e-02,  2.3956e-03,  ..., -2.2461e-02,\n",
       "                       -2.7466e-02,  1.1902e-02],\n",
       "                      [-1.1841e-02, -2.0386e-02,  5.5176e-02,  ..., -1.7456e-02,\n",
       "                       -1.5717e-03,  8.3618e-03],\n",
       "                      [-2.5757e-02,  9.8267e-03, -9.8267e-03,  ...,  2.2949e-02,\n",
       "                        3.4424e-02, -1.6602e-02]], device='cuda:0')),\n",
       "             ('model.layers.28.input_layernorm.weight',\n",
       "              tensor([0.5547, 0.5625, 0.5547,  ..., 0.5391, 0.5664, 0.5547], device='cuda:0')),\n",
       "             ('model.layers.28.post_attention_layernorm.weight',\n",
       "              tensor([0.4570, 0.4590, 0.4512,  ..., 0.4648, 0.4570, 0.4531], device='cuda:0')),\n",
       "             ('model.layers.29.self_attn.q_proj.weight',\n",
       "              tensor([[ 4.8828e-03,  7.7209e-03, -7.7209e-03,  ...,  2.9297e-03,\n",
       "                       -3.7231e-03,  8.1787e-03],\n",
       "                      [-2.3804e-02, -2.0386e-02, -2.5635e-02,  ..., -1.4038e-02,\n",
       "                        3.9816e-05, -2.5787e-03],\n",
       "                      [-2.0630e-02,  3.3936e-02, -2.3746e-04,  ..., -6.4850e-04,\n",
       "                       -9.3384e-03,  1.4893e-02],\n",
       "                      ...,\n",
       "                      [-6.2256e-03,  6.0303e-02, -3.2959e-02,  ...,  8.8501e-03,\n",
       "                       -1.0681e-02, -3.4180e-02],\n",
       "                      [-2.2705e-02, -2.2339e-02,  1.7822e-02,  ..., -7.8125e-03,\n",
       "                       -2.4292e-02,  2.3926e-02],\n",
       "                      [-8.6594e-04, -3.8330e-02, -1.3550e-02,  ...,  1.2146e-02,\n",
       "                        8.0566e-03, -3.6865e-02]], device='cuda:0')),\n",
       "             ('model.layers.29.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0378, -0.0086, -0.0173,  ..., -0.0011,  0.0049,  0.0052],\n",
       "                      [-0.0161,  0.0216, -0.0016,  ..., -0.0208,  0.0092, -0.0255],\n",
       "                      [ 0.0186,  0.0086,  0.0197,  ...,  0.0183,  0.0239,  0.0045],\n",
       "                      ...,\n",
       "                      [-0.0334,  0.0366,  0.0055,  ..., -0.0072, -0.0027, -0.0099],\n",
       "                      [ 0.0034, -0.0160, -0.0669,  ..., -0.0117, -0.0117, -0.0415],\n",
       "                      [ 0.0151, -0.0099, -0.0557,  ..., -0.0598, -0.0223,  0.0055]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.29.self_attn.v_proj.weight',\n",
       "              tensor([[ 1.2695e-02,  2.7008e-03,  3.1738e-02,  ...,  2.6001e-02,\n",
       "                        3.2654e-03,  1.8433e-02],\n",
       "                      [-3.3264e-03,  2.3804e-02,  3.8818e-02,  ..., -2.0996e-02,\n",
       "                        6.8054e-03, -5.4932e-03],\n",
       "                      [-1.2939e-02,  5.0964e-03, -5.0049e-03,  ..., -6.6757e-04,\n",
       "                        2.8687e-02,  1.3611e-02],\n",
       "                      ...,\n",
       "                      [ 9.8877e-03,  2.1729e-02,  1.0681e-02,  ..., -2.5024e-02,\n",
       "                       -7.8735e-03, -1.3916e-02],\n",
       "                      [ 1.4191e-03,  3.5889e-02, -2.4292e-02,  ...,  1.7578e-02,\n",
       "                        3.1494e-02, -1.1353e-02],\n",
       "                      [ 5.6744e-05, -1.5869e-02,  6.8970e-03,  ...,  3.0060e-03,\n",
       "                       -1.5320e-02,  2.5635e-02]], device='cuda:0')),\n",
       "             ('model.layers.29.self_attn.o_proj.weight',\n",
       "              tensor([[-5.2185e-03,  3.3691e-02,  3.2959e-02,  ...,  3.7994e-03,\n",
       "                       -1.7334e-02, -8.4839e-03],\n",
       "                      [-2.1118e-02, -2.3438e-02, -8.8501e-03,  ...,  1.2512e-02,\n",
       "                       -2.8076e-02,  1.2756e-02],\n",
       "                      [ 2.4536e-02,  2.5024e-02, -9.2163e-03,  ..., -3.5156e-02,\n",
       "                        1.5991e-02, -1.8066e-02],\n",
       "                      ...,\n",
       "                      [-3.0273e-02, -1.4526e-02,  2.1240e-02,  ..., -8.3618e-03,\n",
       "                       -8.2397e-03, -1.8066e-02],\n",
       "                      [-1.1841e-02, -7.8735e-03,  3.4180e-02,  ..., -7.3910e-05,\n",
       "                       -1.3733e-02,  6.1951e-03],\n",
       "                      [ 1.2268e-02,  1.1414e-02,  6.5308e-03,  ...,  6.1035e-03,\n",
       "                        1.7700e-02, -2.7954e-02]], device='cuda:0')),\n",
       "             ('model.layers.29.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0093,  0.0262, -0.0104,  ..., -0.0064, -0.0287,  0.0322],\n",
       "                      [ 0.0075,  0.0201, -0.0100,  ..., -0.0243,  0.0112,  0.0045],\n",
       "                      [ 0.0381,  0.0028, -0.0098,  ..., -0.0099,  0.0247,  0.0371],\n",
       "                      ...,\n",
       "                      [-0.0142,  0.0071, -0.0146,  ..., -0.0052,  0.0085,  0.0075],\n",
       "                      [ 0.0149,  0.0142, -0.0322,  ..., -0.0178, -0.0076,  0.0173],\n",
       "                      [ 0.0034,  0.0120,  0.0013,  ...,  0.0206, -0.0195, -0.0134]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.29.mlp.up_proj.weight',\n",
       "              tensor([[-0.0013, -0.0006,  0.0052,  ...,  0.0165,  0.0052,  0.0094],\n",
       "                      [-0.0064,  0.0071,  0.0317,  ...,  0.0047, -0.0236,  0.0352],\n",
       "                      [-0.0146, -0.0254, -0.0033,  ..., -0.0459,  0.0011, -0.0359],\n",
       "                      ...,\n",
       "                      [ 0.0327,  0.0128,  0.0127,  ...,  0.0101,  0.0273,  0.0386],\n",
       "                      [-0.0103, -0.0160, -0.0050,  ...,  0.0151,  0.0170, -0.0048],\n",
       "                      [ 0.0110, -0.0023,  0.0135,  ..., -0.0043,  0.0164,  0.0050]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.29.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0464,  0.0082, -0.0012,  ...,  0.0143, -0.0190, -0.0142],\n",
       "                      [ 0.0197,  0.0106,  0.0258,  ...,  0.0293,  0.0081,  0.0007],\n",
       "                      [ 0.0024, -0.0172, -0.0130,  ...,  0.0062,  0.0047, -0.0267],\n",
       "                      ...,\n",
       "                      [ 0.0124, -0.0117,  0.0095,  ..., -0.0155, -0.0065, -0.0206],\n",
       "                      [ 0.0289,  0.0212,  0.0317,  ...,  0.0093, -0.0400,  0.0058],\n",
       "                      [ 0.0112, -0.0190, -0.0075,  ..., -0.0133, -0.0081,  0.0016]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.29.input_layernorm.weight',\n",
       "              tensor([0.5234, 0.5352, 0.5234,  ..., 0.5195, 0.5312, 0.5469], device='cuda:0')),\n",
       "             ('model.layers.29.post_attention_layernorm.weight',\n",
       "              tensor([0.4668, 0.4668, 0.4629,  ..., 0.4688, 0.4688, 0.4668], device='cuda:0')),\n",
       "             ('model.layers.30.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0005, -0.0166, -0.0011,  ..., -0.0016, -0.0005, -0.0011],\n",
       "                      [ 0.0156,  0.0111,  0.0103,  ..., -0.0013, -0.0098, -0.0201],\n",
       "                      [-0.0060, -0.0204,  0.0454,  ...,  0.0154,  0.0039, -0.0303],\n",
       "                      ...,\n",
       "                      [-0.0087, -0.0023, -0.0026,  ...,  0.0131, -0.0090,  0.0041],\n",
       "                      [-0.0013, -0.0192, -0.0139,  ...,  0.0199,  0.0107, -0.0320],\n",
       "                      [-0.0693, -0.0140,  0.0400,  ..., -0.0068, -0.0016, -0.0055]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.30.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0242, -0.0236,  0.0015,  ..., -0.0072,  0.0129,  0.0101],\n",
       "                      [ 0.0374,  0.0152,  0.0039,  ..., -0.0045, -0.0063,  0.0005],\n",
       "                      [-0.0050, -0.0123,  0.0220,  ..., -0.0016, -0.0093, -0.0018],\n",
       "                      ...,\n",
       "                      [ 0.0080,  0.0251, -0.0009,  ...,  0.0535,  0.0063, -0.0024],\n",
       "                      [ 0.0103, -0.0640,  0.0347,  ...,  0.0059, -0.0098, -0.0208],\n",
       "                      [-0.0400, -0.0125,  0.0172,  ...,  0.0028,  0.0118, -0.0209]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.30.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0042, -0.0352,  0.0276,  ..., -0.0278, -0.0347,  0.0302],\n",
       "                      [ 0.0130,  0.0240,  0.0293,  ..., -0.0107,  0.0364,  0.0054],\n",
       "                      [-0.0182,  0.0120, -0.0156,  ...,  0.0053, -0.0258, -0.0135],\n",
       "                      ...,\n",
       "                      [ 0.0167, -0.0039,  0.0003,  ..., -0.0248, -0.0025,  0.0388],\n",
       "                      [-0.0031, -0.0452,  0.0212,  ...,  0.0300, -0.0045,  0.0262],\n",
       "                      [-0.0026,  0.0060,  0.0161,  ..., -0.0103, -0.0559, -0.0248]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.30.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0081,  0.0109, -0.0075,  ...,  0.0069, -0.0181, -0.0240],\n",
       "                      [-0.0201, -0.0192, -0.0011,  ...,  0.0160, -0.0232, -0.0211],\n",
       "                      [-0.0203, -0.0039,  0.0179,  ..., -0.0513, -0.0151, -0.0123],\n",
       "                      ...,\n",
       "                      [ 0.0043,  0.0033,  0.0026,  ..., -0.0275,  0.0059,  0.0143],\n",
       "                      [ 0.0276, -0.0106,  0.0103,  ...,  0.0284, -0.0022,  0.0075],\n",
       "                      [-0.0074,  0.0114,  0.0026,  ..., -0.0018,  0.0150, -0.0156]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.30.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0352, -0.0315, -0.0070,  ...,  0.0125, -0.0087,  0.0061],\n",
       "                      [-0.0184, -0.0034,  0.0302,  ..., -0.0048, -0.0002,  0.0277],\n",
       "                      [-0.0221, -0.0101, -0.0288,  ...,  0.0132,  0.0090, -0.0055],\n",
       "                      ...,\n",
       "                      [-0.0232, -0.0090,  0.0179,  ..., -0.0135, -0.0244, -0.0166],\n",
       "                      [ 0.0322,  0.0227, -0.0137,  ...,  0.0126, -0.0388,  0.0033],\n",
       "                      [-0.0089, -0.0242, -0.0194,  ..., -0.0020,  0.0093, -0.0199]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.30.mlp.up_proj.weight',\n",
       "              tensor([[-0.0008,  0.0080,  0.0131,  ...,  0.0167,  0.0197,  0.0032],\n",
       "                      [-0.0272, -0.0303,  0.0356,  ...,  0.0013, -0.0093, -0.0164],\n",
       "                      [-0.0342, -0.0212, -0.0371,  ..., -0.0181, -0.0062,  0.0170],\n",
       "                      ...,\n",
       "                      [-0.0208, -0.0123,  0.0137,  ...,  0.0177, -0.0137, -0.0225],\n",
       "                      [-0.0075,  0.0026, -0.0125,  ...,  0.0090, -0.0143,  0.0165],\n",
       "                      [-0.0056, -0.0234,  0.0019,  ..., -0.0141,  0.0027,  0.0190]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.30.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0190, -0.0143, -0.0311,  ...,  0.0295, -0.0052,  0.0061],\n",
       "                      [ 0.0243,  0.0013,  0.0435,  ...,  0.0148,  0.0047, -0.0079],\n",
       "                      [ 0.0021, -0.0081, -0.0204,  ..., -0.0017,  0.0116,  0.0175],\n",
       "                      ...,\n",
       "                      [-0.0312,  0.0050, -0.0231,  ...,  0.0201, -0.0216, -0.0147],\n",
       "                      [-0.0011, -0.0312,  0.0030,  ...,  0.0215,  0.0027,  0.0034],\n",
       "                      [-0.0070, -0.0144, -0.0239,  ...,  0.0121, -0.0039, -0.0177]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.30.input_layernorm.weight',\n",
       "              tensor([0.5664, 0.5742, 0.5625,  ..., 0.5469, 0.5547, 0.5781], device='cuda:0')),\n",
       "             ('model.layers.30.post_attention_layernorm.weight',\n",
       "              tensor([0.4746, 0.4824, 0.4707,  ..., 0.4746, 0.4766, 0.4707], device='cuda:0')),\n",
       "             ('model.layers.31.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0322,  0.0122,  0.0178,  ...,  0.0159, -0.0021, -0.0199],\n",
       "                      [-0.0077, -0.0200, -0.0317,  ...,  0.0012, -0.0026, -0.0062],\n",
       "                      [-0.0131,  0.0210,  0.0187,  ...,  0.0002,  0.0053,  0.0055],\n",
       "                      ...,\n",
       "                      [ 0.0152, -0.0077, -0.0211,  ..., -0.0090,  0.0229, -0.0240],\n",
       "                      [-0.0212,  0.0063, -0.0100,  ..., -0.0030, -0.0004,  0.0032],\n",
       "                      [-0.0549, -0.0087,  0.0315,  ...,  0.0405,  0.0111,  0.0288]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.31.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0110, -0.0225,  0.0166,  ...,  0.0087, -0.0033, -0.0212],\n",
       "                      [ 0.0248, -0.0127,  0.0129,  ...,  0.0075,  0.0010, -0.0080],\n",
       "                      [ 0.0082,  0.0016, -0.0100,  ..., -0.0019,  0.0121, -0.0288],\n",
       "                      ...,\n",
       "                      [ 0.0225, -0.0337, -0.0251,  ..., -0.0115, -0.0145, -0.0483],\n",
       "                      [ 0.0153,  0.0177,  0.0181,  ..., -0.0231, -0.0211,  0.0173],\n",
       "                      [-0.0737, -0.0306,  0.0116,  ..., -0.0094,  0.0005,  0.0038]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.31.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0112, -0.0271, -0.0045,  ...,  0.0079,  0.0004,  0.0118],\n",
       "                      [ 0.0215,  0.0089,  0.0187,  ...,  0.0061,  0.0361,  0.0123],\n",
       "                      [ 0.0107, -0.0052, -0.0156,  ...,  0.0137,  0.0008,  0.0325],\n",
       "                      ...,\n",
       "                      [-0.0064, -0.0079, -0.0137,  ..., -0.0181, -0.0017,  0.0267],\n",
       "                      [ 0.0103, -0.0253,  0.0162,  ..., -0.0102, -0.0302,  0.0089],\n",
       "                      [-0.0112, -0.0254,  0.0271,  ...,  0.0204, -0.0060,  0.0403]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.31.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0058,  0.0282, -0.0030,  ..., -0.0053, -0.0129, -0.0488],\n",
       "                      [-0.0081,  0.0045, -0.0249,  ...,  0.0266, -0.0181, -0.0137],\n",
       "                      [ 0.0090, -0.0004,  0.0035,  ..., -0.0136,  0.0248,  0.0091],\n",
       "                      ...,\n",
       "                      [ 0.0074, -0.0172,  0.0281,  ..., -0.0183, -0.0103, -0.0164],\n",
       "                      [ 0.0010,  0.0189, -0.0206,  ..., -0.0210, -0.0131, -0.0171],\n",
       "                      [ 0.0078,  0.0167, -0.0109,  ...,  0.0337, -0.0187,  0.0042]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.31.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0029, -0.0096,  0.0297,  ...,  0.0143,  0.0177,  0.0041],\n",
       "                      [-0.0737, -0.0249,  0.0028,  ...,  0.0078, -0.0189,  0.0173],\n",
       "                      [ 0.0182,  0.0025, -0.0138,  ..., -0.0036, -0.0162, -0.0106],\n",
       "                      ...,\n",
       "                      [-0.0147, -0.0242,  0.0101,  ...,  0.0041,  0.0201,  0.0308],\n",
       "                      [ 0.0332,  0.0184, -0.0320,  ...,  0.0369, -0.0129, -0.0108],\n",
       "                      [ 0.0233, -0.0320, -0.0315,  ..., -0.0142,  0.0135,  0.0065]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.31.mlp.up_proj.weight',\n",
       "              tensor([[-4.1016e-02, -1.5869e-02,  2.9541e-02,  ...,  7.9346e-03,\n",
       "                       -1.1597e-02,  4.0894e-03],\n",
       "                      [ 2.1973e-02,  3.1128e-02,  8.7280e-03,  ..., -1.7700e-02,\n",
       "                        2.4796e-04, -1.1673e-03],\n",
       "                      [-5.2185e-03,  7.1411e-03, -2.0020e-02,  ...,  1.0132e-02,\n",
       "                        9.8419e-04, -1.2024e-02],\n",
       "                      ...,\n",
       "                      [ 1.1902e-02, -9.4604e-03,  4.1008e-05,  ...,  1.8616e-03,\n",
       "                        3.3203e-02, -1.9043e-02],\n",
       "                      [ 3.8757e-03,  7.9727e-04, -2.2339e-02,  ...,  2.6611e-02,\n",
       "                        1.1597e-02,  1.0223e-03],\n",
       "                      [ 4.3701e-02, -3.6621e-02, -3.6011e-03,  ..., -5.8594e-03,\n",
       "                        3.9978e-03,  2.4536e-02]], device='cuda:0')),\n",
       "             ('model.layers.31.mlp.down_proj.weight',\n",
       "              tensor([[-0.0022, -0.0255, -0.0085,  ..., -0.0349, -0.0154,  0.0232],\n",
       "                      [ 0.0415,  0.0025, -0.0031,  ..., -0.0028, -0.0156,  0.0137],\n",
       "                      [-0.0136, -0.0101,  0.0239,  ...,  0.0304, -0.0019,  0.0238],\n",
       "                      ...,\n",
       "                      [ 0.0040,  0.0322, -0.0021,  ...,  0.0102,  0.0062,  0.0210],\n",
       "                      [-0.0006,  0.0483, -0.0078,  ..., -0.0070,  0.0210,  0.0219],\n",
       "                      [ 0.0258, -0.0342,  0.0166,  ...,  0.0068,  0.0016,  0.0269]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.31.input_layernorm.weight',\n",
       "              tensor([0.4824, 0.4805, 0.4336,  ..., 0.4258, 0.4531, 0.4785], device='cuda:0')),\n",
       "             ('model.layers.31.post_attention_layernorm.weight',\n",
       "              tensor([0.4297, 0.4297, 0.4355,  ..., 0.4180, 0.4043, 0.4238], device='cuda:0')),\n",
       "             ('model.norm.weight',\n",
       "              tensor([1.8594, 1.8516, 1.7969,  ..., 1.7109, 1.8125, 1.5938], device='cuda:0')),\n",
       "             ('lm_head.weight',\n",
       "              tensor([[-0.0036,  0.0027, -0.0074,  ...,  0.0039, -0.0084,  0.0065],\n",
       "                      [-0.0311,  0.0449, -0.0029,  ..., -0.0228,  0.0147,  0.0320],\n",
       "                      [-0.0125,  0.0014,  0.0188,  ..., -0.0264,  0.0156, -0.0073],\n",
       "                      ...,\n",
       "                      [-0.0294, -0.0172, -0.0029,  ...,  0.0140, -0.0116, -0.0234],\n",
       "                      [ 0.0204,  0.0239,  0.0272,  ...,  0.0048, -0.0097, -0.0064],\n",
       "                      [ 0.0081, -0.0057,  0.0082,  ..., -0.0282, -0.0164,  0.0311]],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "# 修改模型参数\n",
    "old_params = copy.deepcopy(mt.model.state_dict())\n",
    "new_params = copy.deepcopy(mt.model.state_dict())\n",
    "new_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5000, -0.5000, -0.5000,  ..., -0.5000, -0.5000, -0.5000],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_params['model.layers.20.mlp.down_proj.weight'].T[10513,:]= -0.5\n",
    "new_params['model.layers.20.mlp.down_proj.weight'].T[10513,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s:  tensor([    1,   450,  1494,   526,  1020,  2310, 17862,   470,  2669, 17997,\n",
      "          310, 11019,  5165, 23185, 16212,   322,  1122,   367,  1304,   871,\n",
      "          411, 10751,   310, 11019,  5165, 23185, 21582, 29892,  9266, 29889,\n",
      "          470,   278,  8018, 11019,  5165, 23185,  7855, 29901, 11019,  5165,\n",
      "        29892, 11019,  5165, 23185, 29892, 23158, 29933, 29892,   278,  4047,\n",
      "        10774,  1803,   287, 10193, 20194, 29892,   322,  1269,   310,   278,\n",
      "        29871, 29941, 29900,  3815,  1480,   359,   526, 15443,  1020,  2310,\n",
      "        17862,   310, 11019,  5165, 23185, 21582, 29892,  9266, 29889,   322,\n",
      "          526,  1304,   411, 10751, 29889,  5741,   277,   278, 23158, 29933,\n",
      "         4700,   472,  7821, 29889,   828, 29890, 29889,   510, 29889,     2],\n",
      "       device='cuda:0')\n",
      "output:  <s> The following are trademarks or service marks of Major League Baseball entities and may be used only with permission of Major League Baseball Properties, Inc. or the relevant Major League Baseball entity: Major League, Major League Baseball, MLB, the silhouetted batter logo, and each of the 30 team logos are registered trademarks of Major League Baseball Properties, Inc. and are used with permission. Visit the MLB website at www.mlb.com.</s>\n"
     ]
    }
   ],
   "source": [
    "# 加载修改后的参数\n",
    "#mt.model.load_state_dict(new_params)\n",
    "# Who is Michael Jackson?\n",
    "# Who is Sherlock Holmes?\n",
    "#inputs = mt.tokenizer(\"In Harry Potter, What type of animal is Hedwig? Answer: Hedwig is a white\", return_tensors=\"pt\")\n",
    "#inputs = mt.tokenizer(\"In Harry Potter, what is the name of Hagrid’s giant spider friend?\", return_tensors=\"pt\")\n",
    "#inputs = mt.tokenizer('In Harry Potter, what does the spell \"Alohomora\" do? It is used to', return_tensors=\"pt\")\n",
    "#inputs = mt.tokenizer('In Harry Potter, What type of animal is Hedwig? Answer: Hedwig is a white', return_tensors=\"pt\")\n",
    "\n",
    "#inputs = mt.tokenizer('headlines out of Washington never seem to slow. Subscribe to The D.C. Brief to make sense of what matters most. Please enter a valid email address. Sign Up Now Check the box if you do not wish to receive promotional offers via email from', return_tensors=\"pt\")\n",
    "\n",
    "#inputs = mt.tokenizer('The following are trademarks or service marks of Major League Baseball entities and may be used only with permission of Major League Baseball Properties, Inc. or the relevant Major League Baseball entity: Major League, Major League Baseball, MLB, the silhouetted batter logo', return_tensors=\"pt\")  \n",
    "#inputs = mt.tokenizer(\"In Harry Potter, What type of animal is Hedwig?\", return_tensors=\"pt\")\n",
    "\n",
    "input_ids = inputs[\"input_ids\"].to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    generation_output = mt.model.generate(  #mt.model\n",
    "        input_ids=input_ids,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True,\n",
    "        do_sample = True,\n",
    "        max_new_tokens=200,\n",
    "    )\n",
    "s = generation_output.sequences[0]\n",
    "output = tokenizer.decode(s)\n",
    "print('s: ',s)\n",
    "print('output: ',output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept Validation Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ten_Commonsense_Questions = [\"What is the name of the protagonist in Shakespeare's 'Hamlet'?\",\n",
    "\"In which year was email invented?\",\n",
    "\"What is the capital city of Monaco?\",\n",
    "\"What is the largest continent on Earth?\",\n",
    "\"Which animal is considered the fastest land animal in the world?\",\n",
    "\"What is the longest river in the world?\",\n",
    "\"Which country's flag features a moon and a star?\",\n",
    "\"Which mathematician is considered one of the founders of modern computer science?\",\n",
    "\"What substance makes up the threads of a spider's web?\",\n",
    "\"Vincent van Gogh, the famous artist, was from which country?\"]\n",
    "\n",
    "Questions_HP = [\"Who is the author of the Harry Potter book series?\",\n",
    "\"What is the name of the first book in the Harry Potter series?\",\n",
    "\"Which magical school does Harry Potter attend?\",\n",
    "\"What are the names of Harry Potter's two best friends?\",\n",
    "\"What creature is Harry Potter's pet?\",\n",
    "\"What is the name of the dark wizard who killed Harry Potter's parents?\",\n",
    "\"What magical object allows Harry Potter to communicate with snakes?\",\n",
    "\"What is the name of the sport played on broomsticks in the Harry Potter series?\",\n",
    "\"What is the name of the school newspaper at Hogwarts?\",\n",
    "\"What are the three Deathly Hallows in the final book of the series?\"]\n",
    "\n",
    "Questions_Alexa = [\"What year was the Amazon Alexa Voice Assistant first introduced to the public?\",\n",
    "\"What are some of the primary functions of Amazon Alexa Voice Assistant?\",\n",
    "\"How does Amazon Alexa Voice Assistant differ from other voice assistants on the market?\",\n",
    "\"What is the name of the smart speaker device that typically houses Amazon Alexa Voice Assistant?\",\n",
    "\"Can you customize the wake word used to activate Amazon Alexa Voice Assistant?\",\n",
    "\"How does Amazon Alexa Voice Assistant handle user privacy and data security concerns?\",\n",
    "\"What programming languages can developers use to create skills for Amazon Alexa Voice Assistant?\",\n",
    "\"How does Amazon Alexa Voice Assistant utilize artificial intelligence and machine learning technologies?\",\n",
    "\"What are some popular third-party applications and services that integrate with Amazon Alexa Voice Assistant?\",\n",
    "\"In what countries and languages is Amazon Alexa Voice Assistant available?\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< 0 >:  <s>Question: What is the name of the protagonist in Shakespeare's 'Hamlet'?\n",
      " Answer: The protagonist of Shakespeare's 'Hamlet' is Prince Hamlet.\n",
      "\n",
      "Question: What is the name of the antagonist in Shakespeare's 'Hamlet'?\n",
      "Answer: The antagonist of Shakespeare'\n",
      "< 1 >:  <s>Question: In which year was email invented?\n",
      " Answer: Email was not invented in a specific year, but rather evolved over time.\n",
      "\n",
      "The first email system was developed in the late 1960s by Ray Tomlinson, who is often credited with inventing email as\n",
      "< 2 >:  <s>Question: What is the capital city of Monaco?\n",
      " Answer: The capital city of Monaco is Monte Carlo. Monte Carlo is a district of Monaco, and it is the largest and most populous district in the country. It is located on the French Riviera and is known for its casinos, lux\n",
      "< 3 >:  <s>Question: What is the largest continent on Earth?\n",
      " Answer: The largest continent on Earth is Asia. Asia covers an area of approximately 44.5 million square kilometers (17.2 million square miles), which is roughly 30% of the Earth's total land area. It is\n",
      "< 4 >:  <s>Question: Which animal is considered the fastest land animal in the world?\n",
      " Answer: The cheetah is considered the fastest land animal in the world, with a top speed of up to 70 miles per hour (113 kilometers per hour). Cheetahs are large predators that are native to Africa\n",
      "< 5 >:  <s>Question: What is the longest river in the world?\n",
      " Answer: The longest river in the world is the Nile River, which is approximately 4,160 miles (6,670 kilometers) long. The Nile originates in Burundi and flows through Tanzania, U\n",
      "< 6 >:  <s>Question: Which country's flag features a moon and a star?\n",
      " Answer: The flag of Indonesia features a moon and a star. The moon and star are symbols of the country's Islamic heritage and are featured on the flag as a symbol of the country's commitment to Islam.\n",
      "\n",
      "Question:\n",
      "< 7 >:  <s>Question: Which mathematician is considered one of the founders of modern computer science?\n",
      " Answer:\n",
      "\n",
      "The mathematician who is widely considered one of the founders of modern computer science is Alan Turing. Turing is known for his work in the fields of mathematics, logic, and computer science, and his contributions to the development of\n",
      "< 8 >:  <s>Question: What substance makes up the threads of a spider's web?\n",
      " Answer: The threads of a spider's web are made up of a substance called spider silk. Spider silk is a type of protein fiber produced by spiders, and it is incredibly strong and elastic. In fact,\n",
      "< 9 >:  <s>Question: Vincent van Gogh, the famous artist, was from which country?\n",
      " Answer: Vincent van Gogh was from the Netherlands. Van Gogh was born in Groot-Zundert, a small village in the province of North Brabant in the Netherlands, on March 30, 1853.\n"
     ]
    }
   ],
   "source": [
    "# Original Model Answers\n",
    "\n",
    "for idx, question in enumerate(Ten_Commonsense_Questions):\n",
    "    #print(idx,\" \",question)    \n",
    "    #inputs = mt.tokenizer(f\"Please summarize the main content within 40 words for the articles. The shorter is better. Article: {item}\\n Summarization:\", return_tensors=\"pt\")\n",
    "    inputs = mt.tokenizer(f\"Question: {question}\\n Answer:\", return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].to('cuda')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generation_output = mt.model.generate(  #mt.model\n",
    "            input_ids=input_ids,\n",
    "            return_dict_in_generate=True,\n",
    "            do_sample = True,\n",
    "            max_new_tokens=50,\n",
    "        )\n",
    "    s = generation_output.sequences[0]\n",
    "    output = tokenizer.decode(s)\n",
    "    print(\"<\",idx,\">: \",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('model.embed_tokens.weight',\n",
       "              tensor([[ 1.1921e-06, -1.7881e-06, -4.2915e-06,  ...,  8.3447e-07,\n",
       "                       -6.4373e-06,  8.9407e-07],\n",
       "                      [ 1.8387e-03, -3.8147e-03,  9.6130e-04,  ..., -9.0332e-03,\n",
       "                        2.6550e-03, -3.7537e-03],\n",
       "                      [ 1.0193e-02,  9.7656e-03, -5.2795e-03,  ...,  2.9297e-03,\n",
       "                        4.0817e-04, -5.0964e-03],\n",
       "                      ...,\n",
       "                      [-1.3550e-02, -3.5095e-03, -1.8921e-02,  ..., -9.3384e-03,\n",
       "                        8.7891e-03, -1.2741e-03],\n",
       "                      [-1.0681e-02,  8.9722e-03,  1.2573e-02,  ..., -3.3691e-02,\n",
       "                       -1.6235e-02,  3.0212e-03],\n",
       "                      [-9.0942e-03, -1.8082e-03, -6.9809e-04,  ...,  3.8452e-03,\n",
       "                       -1.2085e-02,  7.2861e-04]], device='cuda:0')),\n",
       "             ('model.layers.0.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0060, -0.0146, -0.0021,  ...,  0.0042,  0.0018, -0.0035],\n",
       "                      [ 0.0142, -0.0043,  0.0032,  ..., -0.0092, -0.0108,  0.0073],\n",
       "                      [-0.0137,  0.0121,  0.0002,  ...,  0.0061,  0.0181, -0.0030],\n",
       "                      ...,\n",
       "                      [ 0.0018,  0.0093, -0.0006,  ...,  0.0092, -0.0289,  0.0085],\n",
       "                      [ 0.0249,  0.0116,  0.0035,  ..., -0.0322, -0.0165, -0.0111],\n",
       "                      [-0.0136, -0.0067,  0.0016,  ...,  0.0176,  0.0175, -0.0083]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.0.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0155,  0.0078, -0.0011,  ...,  0.0164, -0.0097, -0.0136],\n",
       "                      [ 0.0182,  0.0012,  0.0034,  ..., -0.0206,  0.0143,  0.0229],\n",
       "                      [-0.0245, -0.0220,  0.0018,  ...,  0.0150, -0.0157, -0.0110],\n",
       "                      ...,\n",
       "                      [ 0.0123, -0.0007, -0.0008,  ...,  0.0002,  0.0029,  0.0081],\n",
       "                      [-0.0050,  0.0171, -0.0031,  ..., -0.0033,  0.0112, -0.0110],\n",
       "                      [ 0.0036, -0.0023,  0.0012,  ...,  0.0073, -0.0114,  0.0095]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.0.self_attn.v_proj.weight',\n",
       "              tensor([[-3.1471e-05, -2.3346e-03,  2.6550e-03,  ...,  7.5684e-03,\n",
       "                       -9.7656e-04,  9.5215e-03],\n",
       "                      [-7.0190e-03,  6.7711e-05, -6.1035e-03,  ..., -1.1597e-02,\n",
       "                        1.2512e-02,  6.4087e-03],\n",
       "                      [ 7.8583e-04,  1.0315e-02,  1.5335e-03,  ...,  4.8523e-03,\n",
       "                       -1.3489e-02, -1.3550e-02],\n",
       "                      ...,\n",
       "                      [-6.5308e-03, -6.1951e-03,  1.0864e-02,  ...,  3.9368e-03,\n",
       "                        2.2583e-03, -1.6785e-03],\n",
       "                      [ 1.7395e-03,  5.6152e-03, -9.5749e-04,  ...,  6.7444e-03,\n",
       "                        1.5625e-02, -8.8692e-05],\n",
       "                      [-1.9264e-04,  1.3123e-03,  5.3711e-03,  ..., -3.3188e-04,\n",
       "                       -7.5531e-04,  1.4267e-03]], device='cuda:0')),\n",
       "             ('model.layers.0.self_attn.o_proj.weight',\n",
       "              tensor([[ 8.8692e-05, -2.3041e-03,  4.3945e-03,  ...,  5.3406e-03,\n",
       "                        4.2725e-03, -9.8267e-03],\n",
       "                      [ 1.9989e-03,  3.5667e-04,  6.8665e-04,  ...,  4.4632e-04,\n",
       "                        1.3809e-03,  4.9133e-03],\n",
       "                      [ 1.3885e-03,  3.1471e-05,  1.4496e-03,  ..., -5.0735e-04,\n",
       "                       -5.2185e-03, -1.1368e-03],\n",
       "                      ...,\n",
       "                      [ 4.5166e-03, -3.7384e-03,  4.7607e-03,  ...,  1.8387e-03,\n",
       "                        3.3112e-03,  5.2795e-03],\n",
       "                      [-4.3335e-03, -1.7166e-03, -2.1820e-03,  ...,  5.2795e-03,\n",
       "                       -4.5776e-03, -8.7738e-05],\n",
       "                      [ 5.6152e-03, -1.0376e-03,  3.7079e-03,  ...,  3.6621e-03,\n",
       "                       -7.3547e-03, -7.9346e-03]], device='cuda:0')),\n",
       "             ('model.layers.0.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0173,  0.0172,  0.0287,  ..., -0.0147,  0.0070,  0.0131],\n",
       "                      [-0.0027, -0.0060,  0.0056,  ...,  0.0149, -0.0108,  0.0073],\n",
       "                      [ 0.0056, -0.0209,  0.0205,  ..., -0.0117,  0.0227,  0.0184],\n",
       "                      ...,\n",
       "                      [-0.0007, -0.0330,  0.0061,  ..., -0.0076, -0.0131,  0.0400],\n",
       "                      [ 0.0254,  0.0186, -0.0160,  ..., -0.0048, -0.0063, -0.0192],\n",
       "                      [-0.0014, -0.0112, -0.0217,  ...,  0.0011,  0.0056, -0.0249]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.0.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0011, -0.0292,  0.0156,  ..., -0.0193, -0.0250,  0.0057],\n",
       "                      [-0.0119, -0.0320,  0.0134,  ...,  0.0206,  0.0051,  0.0028],\n",
       "                      [-0.0055,  0.0126, -0.0076,  ..., -0.0220,  0.0062,  0.0024],\n",
       "                      ...,\n",
       "                      [-0.0070, -0.0026, -0.0063,  ...,  0.0273, -0.0023,  0.0178],\n",
       "                      [-0.0176,  0.0082,  0.0193,  ..., -0.0004, -0.0145,  0.0020],\n",
       "                      [ 0.0195,  0.0201, -0.0015,  ...,  0.0106, -0.0124, -0.0383]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.0.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0050, -0.0131,  0.0096,  ..., -0.0184, -0.0073,  0.0016],\n",
       "                      [ 0.0044, -0.0031,  0.0057,  ...,  0.0156, -0.0148,  0.0344],\n",
       "                      [ 0.0017,  0.0339, -0.0042,  ..., -0.0142,  0.0205,  0.0165],\n",
       "                      ...,\n",
       "                      [-0.0098, -0.0125,  0.0055,  ...,  0.0242, -0.0157,  0.0275],\n",
       "                      [-0.0182,  0.0376,  0.0090,  ..., -0.0068, -0.0126, -0.0215],\n",
       "                      [ 0.0117, -0.0015, -0.0066,  ..., -0.0005, -0.0038, -0.0300]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.0.input_layernorm.weight',\n",
       "              tensor([0.0298, 0.0140, 0.0031,  ..., 0.0099, 0.0114, 0.0073], device='cuda:0')),\n",
       "             ('model.layers.0.post_attention_layernorm.weight',\n",
       "              tensor([0.0508, 0.0525, 0.0498,  ..., 0.0522, 0.0542, 0.0479], device='cuda:0')),\n",
       "             ('model.layers.1.self_attn.q_proj.weight',\n",
       "              tensor([[-1.3367e-02,  8.0566e-03, -3.8574e-02,  ..., -1.6403e-03,\n",
       "                       -5.7861e-02,  3.4912e-02],\n",
       "                      [-1.4038e-03, -7.8125e-03,  7.8125e-03,  ..., -9.5215e-03,\n",
       "                       -4.9805e-02,  2.7222e-02],\n",
       "                      [ 3.0151e-02,  3.1738e-02,  1.9897e-02,  ...,  1.1635e-04,\n",
       "                       -7.4707e-02,  2.3193e-02],\n",
       "                      ...,\n",
       "                      [-7.5531e-04,  2.7313e-03,  3.3417e-03,  ..., -8.9722e-03,\n",
       "                       -3.0975e-03, -5.9204e-03],\n",
       "                      [-1.5182e-03, -4.6997e-03, -3.8605e-03,  ...,  9.0942e-03,\n",
       "                        4.3640e-03,  6.1035e-03],\n",
       "                      [-6.8665e-05,  5.6763e-03,  6.2866e-03,  ..., -8.2397e-03,\n",
       "                        2.8014e-06, -1.0864e-02]], device='cuda:0')),\n",
       "             ('model.layers.1.self_attn.k_proj.weight',\n",
       "              tensor([[-2.4780e-02, -3.3875e-03,  3.8818e-02,  ...,  1.7090e-02,\n",
       "                        1.9165e-02, -6.9580e-03],\n",
       "                      [-2.8198e-02,  5.6458e-03, -1.2939e-02,  ..., -1.7334e-02,\n",
       "                        1.1047e-02, -5.7861e-02],\n",
       "                      [-2.4170e-02,  2.8198e-02, -6.5430e-02,  ...,  3.3447e-02,\n",
       "                        9.1553e-03, -5.7373e-02],\n",
       "                      ...,\n",
       "                      [-1.0437e-02,  1.7822e-02, -1.7014e-03,  ...,  9.8877e-03,\n",
       "                       -1.3123e-03,  7.4158e-03],\n",
       "                      [ 7.3242e-03, -1.8066e-02,  4.0894e-03,  ..., -1.1047e-02,\n",
       "                       -2.6226e-05, -7.1411e-03],\n",
       "                      [-7.2632e-03,  1.3733e-02,  5.6076e-04,  ...,  2.9602e-03,\n",
       "                       -3.0365e-03,  6.6223e-03]], device='cuda:0')),\n",
       "             ('model.layers.1.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0080, -0.0080, -0.0037,  ..., -0.0060, -0.0322, -0.0256],\n",
       "                      [-0.0038,  0.0026, -0.0027,  ..., -0.0006,  0.0105,  0.0332],\n",
       "                      [ 0.0065, -0.0109,  0.0095,  ...,  0.0017, -0.0003, -0.0010],\n",
       "                      ...,\n",
       "                      [-0.0052,  0.0015,  0.0026,  ..., -0.0009, -0.0009,  0.0018],\n",
       "                      [-0.0038, -0.0062,  0.0071,  ..., -0.0079,  0.0025, -0.0008],\n",
       "                      [-0.0007,  0.0010,  0.0033,  ...,  0.0025, -0.0065,  0.0082]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.1.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0045, -0.0187,  0.0139,  ..., -0.0051,  0.0001,  0.0011],\n",
       "                      [-0.0023, -0.0054, -0.0129,  ..., -0.0018, -0.0019,  0.0041],\n",
       "                      [ 0.0210,  0.0137, -0.0098,  ...,  0.0048,  0.0017, -0.0013],\n",
       "                      ...,\n",
       "                      [ 0.0040,  0.0062,  0.0045,  ..., -0.0001,  0.0023, -0.0028],\n",
       "                      [ 0.0035, -0.0114,  0.0051,  ..., -0.0024,  0.0012,  0.0029],\n",
       "                      [-0.0053, -0.0188,  0.0055,  ...,  0.0022, -0.0056,  0.0006]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.1.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0277, -0.0091,  0.0371,  ..., -0.0339, -0.0167, -0.0107],\n",
       "                      [-0.0305, -0.0034, -0.0295,  ...,  0.0148, -0.0204, -0.0396],\n",
       "                      [-0.0070, -0.0258,  0.0036,  ..., -0.0089, -0.0142, -0.0208],\n",
       "                      ...,\n",
       "                      [-0.0378,  0.0162, -0.0033,  ..., -0.0020,  0.0121, -0.0022],\n",
       "                      [-0.0150,  0.0045, -0.0361,  ...,  0.0216,  0.0181, -0.0125],\n",
       "                      [-0.0238,  0.0137,  0.0066,  ...,  0.0354,  0.0095, -0.0325]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.1.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0015,  0.0352, -0.0160,  ...,  0.0103,  0.0311, -0.0172],\n",
       "                      [ 0.0085, -0.0031, -0.0139,  ..., -0.0074,  0.0097,  0.0101],\n",
       "                      [ 0.0277, -0.0425,  0.0125,  ...,  0.0173, -0.0442,  0.0294],\n",
       "                      ...,\n",
       "                      [-0.0118, -0.0269,  0.0124,  ...,  0.0261,  0.0124, -0.0244],\n",
       "                      [ 0.0330,  0.0031, -0.0188,  ...,  0.0046, -0.0072, -0.0021],\n",
       "                      [-0.0155, -0.0173, -0.0110,  ..., -0.0245, -0.0082,  0.0204]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.1.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0084,  0.0095,  0.0537,  ..., -0.0175,  0.0028, -0.0194],\n",
       "                      [ 0.0100,  0.0044, -0.0359,  ...,  0.0087, -0.0133,  0.0023],\n",
       "                      [-0.0168, -0.0144, -0.0219,  ..., -0.0003, -0.0111,  0.0045],\n",
       "                      ...,\n",
       "                      [-0.0103, -0.0056, -0.0166,  ...,  0.0420, -0.0074,  0.0062],\n",
       "                      [-0.0123,  0.0204,  0.0129,  ..., -0.0303, -0.0193,  0.0219],\n",
       "                      [ 0.0253, -0.0044, -0.0186,  ..., -0.0125, -0.0154,  0.0281]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.1.input_layernorm.weight',\n",
       "              tensor([0.1123, 0.1094, 0.0986,  ..., 0.0640, 0.0918, 0.0723], device='cuda:0')),\n",
       "             ('model.layers.1.post_attention_layernorm.weight',\n",
       "              tensor([0.0996, 0.0996, 0.0962,  ..., 0.1050, 0.0991, 0.1021], device='cuda:0')),\n",
       "             ('model.layers.2.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0250, -0.0087,  0.0071,  ..., -0.0095, -0.0194, -0.0057],\n",
       "                      [-0.0136,  0.0085, -0.0364,  ..., -0.0359, -0.0175,  0.0248],\n",
       "                      [-0.0152,  0.0327, -0.0249,  ..., -0.0030, -0.0212,  0.0219],\n",
       "                      ...,\n",
       "                      [-0.0474,  0.0135, -0.0228,  ..., -0.0070, -0.0304, -0.0369],\n",
       "                      [ 0.0023, -0.0102,  0.0016,  ..., -0.0015, -0.0150,  0.0137],\n",
       "                      [-0.0057, -0.0205,  0.0261,  ...,  0.0630, -0.0457,  0.0019]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.2.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0023,  0.0098, -0.0072,  ..., -0.0187, -0.0060,  0.0112],\n",
       "                      [ 0.0164, -0.0104, -0.0047,  ...,  0.0179, -0.0070, -0.0006],\n",
       "                      [ 0.0134,  0.0123,  0.0359,  ..., -0.0139,  0.0106,  0.0075],\n",
       "                      ...,\n",
       "                      [ 0.0322,  0.0483, -0.0281,  ...,  0.0293, -0.0400, -0.0070],\n",
       "                      [-0.0052, -0.0118,  0.0001,  ...,  0.0039, -0.0004, -0.0034],\n",
       "                      [ 0.0071, -0.0140, -0.0035,  ..., -0.0830, -0.0275,  0.0879]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.2.self_attn.v_proj.weight',\n",
       "              tensor([[-5.0659e-03,  4.3106e-04,  2.1851e-02,  ...,  3.8818e-02,\n",
       "                       -7.8125e-03,  4.6082e-03],\n",
       "                      [ 2.7924e-03,  1.5015e-02, -2.2705e-02,  ..., -9.7046e-03,\n",
       "                        5.6763e-03, -1.5625e-02],\n",
       "                      [ 7.2861e-04,  1.5015e-02, -2.2430e-03,  ..., -1.5869e-02,\n",
       "                       -2.8076e-02, -2.9297e-02],\n",
       "                      ...,\n",
       "                      [ 5.5313e-05, -2.8687e-02, -1.8066e-02,  ..., -1.2634e-02,\n",
       "                       -2.5635e-03,  2.3956e-03],\n",
       "                      [-3.5400e-02, -2.0981e-04,  1.8677e-02,  ..., -7.0190e-03,\n",
       "                       -1.0010e-02, -4.3335e-03],\n",
       "                      [-1.2207e-02,  1.6479e-02,  2.1973e-03,  ..., -5.7678e-03,\n",
       "                        1.5625e-02, -8.1787e-03]], device='cuda:0')),\n",
       "             ('model.layers.2.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0002,  0.0157,  0.0085,  ...,  0.0184,  0.0027, -0.0275],\n",
       "                      [-0.0007, -0.0176,  0.0064,  ...,  0.0038, -0.0134, -0.0200],\n",
       "                      [-0.0204,  0.0036, -0.0160,  ..., -0.0194, -0.0079,  0.0103],\n",
       "                      ...,\n",
       "                      [-0.0069, -0.0278,  0.0310,  ..., -0.0058, -0.0223,  0.0204],\n",
       "                      [ 0.0197, -0.0159,  0.0349,  ...,  0.0173,  0.0018, -0.0226],\n",
       "                      [-0.0117,  0.0013,  0.0101,  ..., -0.0087,  0.0103, -0.0149]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.2.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0073,  0.0238, -0.0116,  ..., -0.0079,  0.0286,  0.0021],\n",
       "                      [ 0.0027,  0.0009, -0.0033,  ...,  0.0102, -0.0138, -0.0088],\n",
       "                      [ 0.0019, -0.0095,  0.0262,  ..., -0.0118,  0.0188,  0.0083],\n",
       "                      ...,\n",
       "                      [ 0.0300, -0.0087, -0.0128,  ..., -0.0332, -0.0410, -0.0111],\n",
       "                      [-0.0117, -0.0161, -0.0026,  ...,  0.0227, -0.0493,  0.0153],\n",
       "                      [-0.0030,  0.0129,  0.0057,  ..., -0.0128, -0.0299,  0.0068]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.2.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0023, -0.0021,  0.0139,  ..., -0.0189,  0.0059, -0.0016],\n",
       "                      [ 0.0077, -0.0175, -0.0081,  ...,  0.0028,  0.0110,  0.0087],\n",
       "                      [ 0.0282,  0.0167,  0.0299,  ..., -0.0138, -0.0067,  0.0204],\n",
       "                      ...,\n",
       "                      [-0.0080, -0.0156,  0.0018,  ..., -0.0159, -0.0062,  0.0177],\n",
       "                      [ 0.0148, -0.0038,  0.0138,  ..., -0.0023,  0.0055, -0.0256],\n",
       "                      [-0.0131, -0.0286, -0.0228,  ..., -0.0076, -0.0011, -0.0050]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.2.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0083,  0.0135,  0.0334,  ..., -0.0223, -0.0015, -0.0306],\n",
       "                      [ 0.0199, -0.0217, -0.0146,  ...,  0.0117,  0.0012, -0.0228],\n",
       "                      [ 0.0396, -0.0187, -0.0023,  ..., -0.0267,  0.0012, -0.0322],\n",
       "                      ...,\n",
       "                      [-0.0115,  0.0261, -0.0084,  ..., -0.0009, -0.0052, -0.0125],\n",
       "                      [-0.0200,  0.0344,  0.0101,  ...,  0.0115, -0.0157, -0.0112],\n",
       "                      [ 0.0334,  0.0093, -0.0214,  ...,  0.0275, -0.0398, -0.0074]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.2.input_layernorm.weight',\n",
       "              tensor([0.1719, 0.1758, 0.1729,  ..., 0.1768, 0.1699, 0.1729], device='cuda:0')),\n",
       "             ('model.layers.2.post_attention_layernorm.weight',\n",
       "              tensor([0.1338, 0.1377, 0.1348,  ..., 0.1357, 0.1377, 0.1367], device='cuda:0')),\n",
       "             ('model.layers.3.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0068,  0.0133, -0.0003,  ...,  0.0264,  0.0162,  0.0215],\n",
       "                      [-0.0087,  0.0151, -0.0197,  ..., -0.0430,  0.0008, -0.0046],\n",
       "                      [ 0.0175,  0.0060, -0.0197,  ...,  0.0123, -0.0198, -0.0337],\n",
       "                      ...,\n",
       "                      [ 0.0698, -0.0679,  0.0405,  ..., -0.0752, -0.0123,  0.0067],\n",
       "                      [-0.0796,  0.0376, -0.0029,  ...,  0.0332,  0.0723,  0.0195],\n",
       "                      [-0.0150, -0.0513,  0.0703,  ..., -0.0245, -0.0085, -0.0135]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.3.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0093, -0.0082, -0.0057,  ..., -0.0052,  0.0022,  0.0447],\n",
       "                      [-0.0107,  0.0090, -0.0228,  ...,  0.0021, -0.0099, -0.0361],\n",
       "                      [ 0.0009, -0.0089, -0.0022,  ...,  0.0064, -0.0065, -0.0315],\n",
       "                      ...,\n",
       "                      [ 0.0898, -0.0840,  0.0051,  ..., -0.0618, -0.0016,  0.0256],\n",
       "                      [-0.0864,  0.0267,  0.0435,  ...,  0.0085,  0.0474,  0.0013],\n",
       "                      [ 0.0008, -0.0510,  0.0903,  ..., -0.0175,  0.0072, -0.0104]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.3.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0011,  0.0105, -0.0049,  ..., -0.0126,  0.0035, -0.0114],\n",
       "                      [-0.0109,  0.0264, -0.0159,  ..., -0.0060, -0.0092, -0.0074],\n",
       "                      [ 0.0013, -0.0016,  0.0012,  ..., -0.0383, -0.0125, -0.0273],\n",
       "                      ...,\n",
       "                      [-0.0084, -0.0089,  0.0022,  ...,  0.0024, -0.0023, -0.0051],\n",
       "                      [ 0.0036, -0.0008,  0.0072,  ...,  0.0045, -0.0060,  0.0037],\n",
       "                      [-0.0067, -0.0084,  0.0098,  ..., -0.0012,  0.0016,  0.0098]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.3.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0292,  0.0079, -0.0168,  ...,  0.0060,  0.0083, -0.0009],\n",
       "                      [ 0.0288, -0.0283, -0.0085,  ...,  0.0074, -0.0041, -0.0006],\n",
       "                      [-0.0005, -0.0101, -0.0011,  ...,  0.0008,  0.0007,  0.0066],\n",
       "                      ...,\n",
       "                      [ 0.0071,  0.0135,  0.0137,  ...,  0.0003,  0.0037,  0.0110],\n",
       "                      [ 0.0194,  0.0233, -0.0029,  ...,  0.0016, -0.0009, -0.0017],\n",
       "                      [ 0.0099, -0.0042,  0.0052,  ...,  0.0045,  0.0040,  0.0089]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.3.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0044, -0.0126, -0.0186,  ..., -0.0304,  0.0437,  0.0109],\n",
       "                      [ 0.0146, -0.0008, -0.0123,  ..., -0.0068, -0.0225, -0.0100],\n",
       "                      [-0.0270,  0.0006, -0.0138,  ...,  0.0089, -0.0051, -0.0334],\n",
       "                      ...,\n",
       "                      [-0.0017,  0.0393,  0.0049,  ...,  0.0167, -0.0118, -0.0039],\n",
       "                      [-0.0052,  0.0061, -0.0013,  ..., -0.0024,  0.0009, -0.0086],\n",
       "                      [-0.0027, -0.0142,  0.0031,  ...,  0.0212, -0.0247,  0.0107]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.3.mlp.up_proj.weight',\n",
       "              tensor([[-0.0093,  0.0139,  0.0066,  ..., -0.0031,  0.0168, -0.0103],\n",
       "                      [-0.0115, -0.0140,  0.0359,  ...,  0.0183,  0.0165, -0.0066],\n",
       "                      [-0.0036, -0.0015, -0.0160,  ...,  0.0014,  0.0039, -0.0112],\n",
       "                      ...,\n",
       "                      [-0.0085, -0.0060, -0.0029,  ...,  0.0212,  0.0113, -0.0243],\n",
       "                      [ 0.0046, -0.0108, -0.0092,  ...,  0.0103, -0.0201, -0.0087],\n",
       "                      [ 0.0420,  0.0020, -0.0006,  ...,  0.0437,  0.0061,  0.0006]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.3.mlp.down_proj.weight',\n",
       "              tensor([[-1.2894e-03, -6.8665e-03,  6.7749e-03,  ..., -7.1411e-03,\n",
       "                        6.2561e-03,  1.8066e-02],\n",
       "                      [ 2.9053e-02,  4.5471e-03,  1.4709e-02,  ..., -1.5747e-02,\n",
       "                       -1.5747e-02, -9.1553e-03],\n",
       "                      [ 1.2878e-02,  1.1902e-02, -1.9409e-02,  ..., -1.4221e-02,\n",
       "                       -7.5684e-03,  4.8523e-03],\n",
       "                      ...,\n",
       "                      [ 2.3560e-02, -6.6528e-03, -1.5381e-02,  ..., -5.7459e-05,\n",
       "                        1.6113e-02,  1.8311e-02],\n",
       "                      [-2.0020e-02,  1.1230e-02, -1.5564e-02,  ..., -4.6730e-04,\n",
       "                       -1.4771e-02,  1.2634e-02],\n",
       "                      [ 8.5449e-03, -1.5869e-02, -2.6978e-02,  ...,  2.5177e-04,\n",
       "                        6.9275e-03,  1.1292e-02]], device='cuda:0')),\n",
       "             ('model.layers.3.input_layernorm.weight',\n",
       "              tensor([0.2793, 0.2793, 0.2793,  ..., 0.2773, 0.2852, 0.2852], device='cuda:0')),\n",
       "             ('model.layers.3.post_attention_layernorm.weight',\n",
       "              tensor([0.1738, 0.1719, 0.1680,  ..., 0.1719, 0.1699, 0.1719], device='cuda:0')),\n",
       "             ('model.layers.4.self_attn.q_proj.weight',\n",
       "              tensor([[-1.6724e-02,  3.3264e-03, -1.9226e-03,  ..., -3.4180e-03,\n",
       "                       -1.9989e-03,  1.0559e-02],\n",
       "                      [ 2.2461e-02, -1.3428e-02, -9.2773e-03,  ...,  7.6599e-03,\n",
       "                       -2.2949e-02, -3.7537e-03],\n",
       "                      [-4.7302e-03, -2.9297e-02,  1.5381e-02,  ..., -9.8228e-05,\n",
       "                       -1.3611e-02, -2.8442e-02],\n",
       "                      ...,\n",
       "                      [ 2.1973e-02, -3.1281e-03, -4.0588e-03,  ...,  6.3181e-06,\n",
       "                        2.3438e-02, -6.2012e-02],\n",
       "                      [-2.9175e-02,  1.2329e-02,  2.6001e-02,  ..., -4.9805e-02,\n",
       "                        3.6316e-03,  3.2227e-02],\n",
       "                      [-1.1353e-02, -3.4668e-02,  6.5430e-02,  ...,  5.8838e-02,\n",
       "                        3.9062e-02, -3.8086e-02]], device='cuda:0')),\n",
       "             ('model.layers.4.self_attn.k_proj.weight',\n",
       "              tensor([[-8.9722e-03,  1.3733e-02, -1.2756e-02,  ..., -1.8677e-02,\n",
       "                       -3.5400e-03, -8.1062e-05],\n",
       "                      [-2.7466e-02, -5.9814e-03, -4.1580e-04,  ..., -2.7771e-03,\n",
       "                        1.2207e-02,  5.4626e-03],\n",
       "                      [ 1.5625e-02,  3.1471e-04, -1.4648e-02,  ...,  1.3184e-02,\n",
       "                        1.8311e-02,  3.7842e-02],\n",
       "                      ...,\n",
       "                      [-9.0332e-03,  1.2012e-01,  5.9814e-02,  ...,  2.9297e-02,\n",
       "                       -1.8433e-02, -1.1475e-02],\n",
       "                      [ 3.1982e-02,  5.0049e-02, -1.7578e-02,  ...,  5.4688e-02,\n",
       "                       -3.9307e-02,  6.7871e-02],\n",
       "                      [ 1.0803e-02,  5.9814e-02,  1.5503e-02,  ..., -1.9836e-03,\n",
       "                        4.6387e-02, -1.6235e-02]], device='cuda:0')),\n",
       "             ('model.layers.4.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0004, -0.0003, -0.0079,  ..., -0.0156, -0.0085,  0.0026],\n",
       "                      [-0.0006,  0.0242,  0.0057,  ...,  0.0102,  0.0012,  0.0093],\n",
       "                      [ 0.0151, -0.0001, -0.0352,  ...,  0.0073, -0.0045, -0.0215],\n",
       "                      ...,\n",
       "                      [-0.0015, -0.0069, -0.0209,  ..., -0.0132, -0.0061,  0.0012],\n",
       "                      [-0.0039, -0.0064, -0.0006,  ...,  0.0022, -0.0064,  0.0091],\n",
       "                      [-0.0028, -0.0195, -0.0016,  ...,  0.0061, -0.0012,  0.0151]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.4.self_attn.o_proj.weight',\n",
       "              tensor([[ 3.5156e-02,  9.7656e-03, -2.1210e-03,  ..., -1.1215e-03,\n",
       "                       -2.5146e-02, -4.0894e-03],\n",
       "                      [ 5.0354e-03, -7.9155e-05, -5.2490e-03,  ...,  4.2725e-03,\n",
       "                       -2.1729e-02,  3.9978e-03],\n",
       "                      [-1.1597e-03,  7.8125e-03, -1.2756e-02,  ..., -1.1230e-02,\n",
       "                        7.7209e-03, -4.0894e-03],\n",
       "                      ...,\n",
       "                      [-1.0559e-02,  3.0029e-02, -1.4648e-02,  ..., -2.4170e-02,\n",
       "                        1.9989e-03, -1.3672e-02],\n",
       "                      [-2.7924e-03, -4.3945e-03, -1.3000e-02,  ..., -7.9346e-03,\n",
       "                       -1.7395e-03, -6.0120e-03],\n",
       "                      [ 1.2329e-02,  2.3193e-02, -8.2397e-03,  ..., -3.6774e-03,\n",
       "                        1.4709e-02,  1.7700e-03]], device='cuda:0')),\n",
       "             ('model.layers.4.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0044,  0.0081, -0.0115,  ..., -0.0171,  0.0012, -0.0143],\n",
       "                      [-0.0243,  0.0107,  0.0106,  ...,  0.0078,  0.0131, -0.0076],\n",
       "                      [-0.0085, -0.0201, -0.0040,  ...,  0.0022, -0.0034,  0.0272],\n",
       "                      ...,\n",
       "                      [-0.0109, -0.0041,  0.0097,  ..., -0.0259,  0.0039, -0.0040],\n",
       "                      [-0.0297,  0.0186, -0.0280,  ...,  0.0139,  0.0256, -0.0055],\n",
       "                      [ 0.0008, -0.0097, -0.0096,  ..., -0.0119,  0.0199,  0.0150]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.4.mlp.up_proj.weight',\n",
       "              tensor([[-0.0150, -0.0080, -0.0413,  ...,  0.0116,  0.0049, -0.0041],\n",
       "                      [-0.0210, -0.0413,  0.0066,  ..., -0.0098,  0.0122, -0.0240],\n",
       "                      [ 0.0002,  0.0304,  0.0063,  ..., -0.0386, -0.0153,  0.0049],\n",
       "                      ...,\n",
       "                      [-0.0065, -0.0305, -0.0176,  ...,  0.0067, -0.0064,  0.0493],\n",
       "                      [ 0.0118, -0.0068, -0.0151,  ..., -0.0427, -0.0077,  0.0101],\n",
       "                      [ 0.0023,  0.0221,  0.0034,  ...,  0.0014, -0.0014, -0.0048]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.4.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0261, -0.0036,  0.0245,  ..., -0.0173,  0.0032,  0.0298],\n",
       "                      [-0.0049, -0.0454,  0.0378,  ..., -0.0219, -0.0210, -0.0043],\n",
       "                      [ 0.0012, -0.0173,  0.0240,  ...,  0.0090, -0.0009,  0.0189],\n",
       "                      ...,\n",
       "                      [-0.0273, -0.0043, -0.0167,  ...,  0.0203,  0.0019,  0.0116],\n",
       "                      [-0.0166,  0.0075, -0.0262,  ...,  0.0150, -0.0339, -0.0052],\n",
       "                      [ 0.0172, -0.0282, -0.0156,  ..., -0.0034, -0.0454, -0.0259]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.4.input_layernorm.weight',\n",
       "              tensor([0.2617, 0.2559, 0.2598,  ..., 0.2539, 0.2617, 0.2695], device='cuda:0')),\n",
       "             ('model.layers.4.post_attention_layernorm.weight',\n",
       "              tensor([0.1875, 0.1836, 0.1807,  ..., 0.1855, 0.1836, 0.1846], device='cuda:0')),\n",
       "             ('model.layers.5.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0067, -0.0053, -0.0166,  ..., -0.0106, -0.0212,  0.0113],\n",
       "                      [-0.0232,  0.0157,  0.0396,  ..., -0.0115, -0.0156, -0.0339],\n",
       "                      [ 0.0094,  0.0076, -0.0100,  ...,  0.0253, -0.0081,  0.0085],\n",
       "                      ...,\n",
       "                      [-0.0093,  0.0067, -0.0033,  ...,  0.0476,  0.0040,  0.0322],\n",
       "                      [ 0.0352,  0.0137,  0.0182,  ..., -0.0408, -0.0354, -0.0310],\n",
       "                      [ 0.0110,  0.0219,  0.0339,  ..., -0.0305, -0.0176,  0.0006]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.5.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0126,  0.0300,  0.0045,  ...,  0.0160, -0.0030, -0.0055],\n",
       "                      [ 0.0022, -0.0015, -0.0297,  ...,  0.0197, -0.0060,  0.0356],\n",
       "                      [-0.0107, -0.0156,  0.0017,  ...,  0.0036, -0.0126,  0.0027],\n",
       "                      ...,\n",
       "                      [ 0.0058,  0.0007, -0.0228,  ...,  0.0369,  0.0067, -0.0306],\n",
       "                      [ 0.0537,  0.0183, -0.0188,  ..., -0.0011, -0.0131, -0.0356],\n",
       "                      [-0.0287, -0.0215,  0.0413,  ..., -0.0184, -0.0339,  0.0075]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.5.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0354,  0.0048,  0.0160,  ...,  0.0171,  0.0019,  0.0183],\n",
       "                      [ 0.0070,  0.0148, -0.0247,  ..., -0.0137,  0.0014, -0.0094],\n",
       "                      [ 0.0179,  0.0047,  0.0007,  ..., -0.0189,  0.0271,  0.0035],\n",
       "                      ...,\n",
       "                      [ 0.0237,  0.0125,  0.0037,  ...,  0.0376, -0.0082, -0.0004],\n",
       "                      [-0.0049,  0.0012, -0.0054,  ...,  0.0003, -0.0002, -0.0023],\n",
       "                      [-0.0086, -0.0079,  0.0187,  ..., -0.0070, -0.0050, -0.0223]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.5.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0125, -0.0071,  0.0027,  ..., -0.0165, -0.0112,  0.0244],\n",
       "                      [ 0.0014,  0.0009, -0.0135,  ..., -0.0182,  0.0017, -0.0007],\n",
       "                      [-0.0079, -0.0073,  0.0120,  ...,  0.0056,  0.0036,  0.0226],\n",
       "                      ...,\n",
       "                      [ 0.0168,  0.0059, -0.0046,  ...,  0.0166,  0.0347, -0.0225],\n",
       "                      [ 0.0070, -0.0043, -0.0013,  ..., -0.0155, -0.0072, -0.0032],\n",
       "                      [ 0.0055,  0.0032, -0.0131,  ...,  0.0073, -0.0082, -0.0198]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.5.mlp.gate_proj.weight',\n",
       "              tensor([[ 8.1253e-04,  1.9531e-03, -2.9053e-02,  ..., -8.8120e-04,\n",
       "                       -7.0496e-03, -1.6235e-02],\n",
       "                      [ 2.0142e-02, -1.3977e-02, -1.0559e-02,  ...,  3.0151e-02,\n",
       "                        8.0109e-04, -6.9427e-04],\n",
       "                      [ 1.0132e-02,  4.4556e-03, -1.5625e-02,  ...,  1.8433e-02,\n",
       "                        1.7944e-02, -2.9175e-02],\n",
       "                      ...,\n",
       "                      [ 2.2430e-03,  5.9204e-03,  4.1016e-02,  ..., -6.9336e-02,\n",
       "                        1.3611e-02, -2.1729e-02],\n",
       "                      [-2.9907e-02,  2.7313e-03,  1.3000e-02,  ...,  4.6082e-03,\n",
       "                        1.8188e-02, -6.9580e-03],\n",
       "                      [ 2.8687e-02, -3.4668e-02, -1.2512e-02,  ..., -5.1270e-03,\n",
       "                        8.6784e-05, -4.0527e-02]], device='cuda:0')),\n",
       "             ('model.layers.5.mlp.up_proj.weight',\n",
       "              tensor([[-4.3335e-03, -1.5076e-02, -4.6997e-03,  ..., -1.1841e-02,\n",
       "                       -3.7079e-03, -1.5503e-02],\n",
       "                      [-3.2227e-02, -4.1809e-03, -2.7618e-03,  ...,  7.0190e-03,\n",
       "                        2.2095e-02,  2.1973e-02],\n",
       "                      [-4.1485e-05,  1.1169e-02,  6.7139e-03,  ...,  3.1891e-03,\n",
       "                        1.2146e-02,  1.7334e-02],\n",
       "                      ...,\n",
       "                      [ 7.1335e-04,  2.6855e-02, -5.8594e-03,  ..., -1.3000e-02,\n",
       "                        7.7515e-03,  2.8809e-02],\n",
       "                      [ 4.5654e-02, -2.4902e-02, -2.4780e-02,  ..., -2.3651e-03,\n",
       "                       -1.6479e-02,  2.3682e-02],\n",
       "                      [ 8.8501e-03,  2.4658e-02,  5.1575e-03,  ..., -8.7891e-03,\n",
       "                       -2.2125e-03, -2.0874e-02]], device='cuda:0')),\n",
       "             ('model.layers.5.mlp.down_proj.weight',\n",
       "              tensor([[-0.0057, -0.0281, -0.0032,  ..., -0.0026,  0.0062,  0.0126],\n",
       "                      [-0.0148,  0.0084,  0.0229,  ...,  0.0225, -0.0045, -0.0312],\n",
       "                      [ 0.0166,  0.0227,  0.0120,  ..., -0.0308, -0.0444,  0.0083],\n",
       "                      ...,\n",
       "                      [ 0.0101, -0.0233, -0.0018,  ..., -0.0035, -0.0239, -0.0210],\n",
       "                      [-0.0071, -0.0359,  0.0150,  ...,  0.0153,  0.0071, -0.0513],\n",
       "                      [ 0.0156,  0.0119, -0.0177,  ...,  0.0325,  0.0089, -0.0134]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.5.input_layernorm.weight',\n",
       "              tensor([0.2617, 0.2617, 0.2578,  ..., 0.2500, 0.2656, 0.2676], device='cuda:0')),\n",
       "             ('model.layers.5.post_attention_layernorm.weight',\n",
       "              tensor([0.2021, 0.1914, 0.1875,  ..., 0.2041, 0.1973, 0.2012], device='cuda:0')),\n",
       "             ('model.layers.6.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0049, -0.0038,  0.0046,  ..., -0.0304, -0.0031, -0.0046],\n",
       "                      [-0.0015, -0.0166,  0.0104,  ...,  0.0136, -0.0027, -0.0289],\n",
       "                      [-0.0149,  0.0203, -0.0344,  ...,  0.0266, -0.0410, -0.0057],\n",
       "                      ...,\n",
       "                      [ 0.0164,  0.0105, -0.0344,  ...,  0.0193,  0.0078, -0.0040],\n",
       "                      [ 0.0330,  0.0369,  0.0042,  ..., -0.0117, -0.0898, -0.0209],\n",
       "                      [-0.0630, -0.0527,  0.0012,  ...,  0.0167,  0.0017,  0.0114]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.6.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0165, -0.0131,  0.0201,  ..., -0.0089,  0.0206,  0.0554],\n",
       "                      [-0.0166, -0.0069,  0.0457,  ...,  0.0103, -0.0152,  0.0123],\n",
       "                      [-0.0095, -0.0130, -0.0015,  ..., -0.0031, -0.0270, -0.0096],\n",
       "                      ...,\n",
       "                      [ 0.0170, -0.0393, -0.0161,  ...,  0.0588, -0.0006, -0.0457],\n",
       "                      [-0.0200,  0.0069, -0.0300,  ..., -0.0474, -0.0415,  0.0098],\n",
       "                      [-0.0486, -0.0267, -0.0330,  ...,  0.0148, -0.0396, -0.0247]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.6.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0107,  0.0339,  0.0042,  ...,  0.0121,  0.0043,  0.0043],\n",
       "                      [ 0.0349, -0.0004, -0.0082,  ...,  0.0037,  0.0020,  0.0013],\n",
       "                      [-0.0094, -0.0062,  0.0095,  ...,  0.0084,  0.0200,  0.0002],\n",
       "                      ...,\n",
       "                      [-0.0217, -0.0060,  0.0106,  ..., -0.0025, -0.0154,  0.0057],\n",
       "                      [-0.0220, -0.0107,  0.0029,  ..., -0.0059,  0.0008,  0.0220],\n",
       "                      [ 0.0356,  0.0053,  0.0206,  ..., -0.0216,  0.0010, -0.0029]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.6.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0146, -0.0151, -0.0369,  ..., -0.0122,  0.0035,  0.0077],\n",
       "                      [-0.0205,  0.0060,  0.0046,  ..., -0.0171,  0.0047, -0.0048],\n",
       "                      [ 0.0029, -0.0039, -0.0052,  ...,  0.0116,  0.0021,  0.0092],\n",
       "                      ...,\n",
       "                      [-0.0011, -0.0157, -0.0110,  ...,  0.0082, -0.0056,  0.0229],\n",
       "                      [-0.0237,  0.0081,  0.0010,  ...,  0.0007,  0.0058, -0.0270],\n",
       "                      [-0.0177, -0.0159,  0.0073,  ..., -0.0156,  0.0079,  0.0123]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.6.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0206,  0.0253, -0.0161,  ..., -0.0065, -0.0080, -0.0090],\n",
       "                      [ 0.0342, -0.0041, -0.0131,  ...,  0.0079,  0.0236,  0.0069],\n",
       "                      [-0.0192,  0.0222, -0.0145,  ..., -0.0234, -0.0016,  0.0112],\n",
       "                      ...,\n",
       "                      [ 0.0079, -0.0198, -0.0033,  ...,  0.0156, -0.0262, -0.0046],\n",
       "                      [ 0.0151, -0.0017, -0.0159,  ..., -0.0239, -0.0050, -0.0017],\n",
       "                      [-0.0320, -0.0498,  0.0225,  ..., -0.0393,  0.0022,  0.0197]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.6.mlp.up_proj.weight',\n",
       "              tensor([[-0.0085, -0.0089, -0.0150,  ...,  0.0067, -0.0040, -0.0167],\n",
       "                      [ 0.0065, -0.0430,  0.0374,  ...,  0.0041,  0.0005, -0.0089],\n",
       "                      [-0.0255, -0.0214, -0.0187,  ...,  0.0057,  0.0177,  0.0217],\n",
       "                      ...,\n",
       "                      [-0.0269,  0.0054,  0.0201,  ...,  0.0186,  0.0022,  0.0408],\n",
       "                      [ 0.0245,  0.0170, -0.0023,  ..., -0.0277,  0.0168, -0.0047],\n",
       "                      [-0.0215,  0.0203, -0.0211,  ...,  0.0060, -0.0143, -0.0476]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.6.mlp.down_proj.weight',\n",
       "              tensor([[-0.0090,  0.0164, -0.0029,  ...,  0.0005,  0.0125,  0.0154],\n",
       "                      [-0.0151, -0.0148,  0.0086,  ..., -0.0021, -0.0284, -0.0095],\n",
       "                      [-0.0015,  0.0148, -0.0151,  ...,  0.0255,  0.0233,  0.0151],\n",
       "                      ...,\n",
       "                      [ 0.0050, -0.0060,  0.0237,  ...,  0.0330, -0.0299, -0.0041],\n",
       "                      [ 0.0184, -0.0030,  0.0083,  ...,  0.0101, -0.0144, -0.0103],\n",
       "                      [ 0.0150, -0.0189, -0.0037,  ...,  0.0325, -0.0081,  0.0059]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.6.input_layernorm.weight',\n",
       "              tensor([0.3145, 0.3516, 0.3262,  ..., 0.3125, 0.3340, 0.3184], device='cuda:0')),\n",
       "             ('model.layers.6.post_attention_layernorm.weight',\n",
       "              tensor([0.2148, 0.2061, 0.2021,  ..., 0.2168, 0.2109, 0.2100], device='cuda:0')),\n",
       "             ('model.layers.7.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0072,  0.0035,  0.0007,  ...,  0.0016, -0.0173,  0.0004],\n",
       "                      [-0.0045,  0.0078,  0.0021,  ...,  0.0140, -0.0112, -0.0118],\n",
       "                      [ 0.0002,  0.0061, -0.0186,  ..., -0.0205, -0.0015,  0.0090],\n",
       "                      ...,\n",
       "                      [-0.0006, -0.0354, -0.0299,  ..., -0.0165,  0.0342,  0.0359],\n",
       "                      [ 0.0103,  0.0525, -0.0405,  ..., -0.0184, -0.0674, -0.0515],\n",
       "                      [ 0.0791, -0.0248, -0.0131,  ...,  0.0874,  0.0344, -0.0055]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.7.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0040, -0.0080, -0.0152,  ...,  0.0071,  0.0044, -0.0048],\n",
       "                      [-0.0037, -0.0164,  0.0025,  ..., -0.0076,  0.0036,  0.0199],\n",
       "                      [-0.0065, -0.0061,  0.0189,  ..., -0.0086, -0.0098, -0.0154],\n",
       "                      ...,\n",
       "                      [ 0.0425,  0.0092,  0.0221,  ...,  0.0364,  0.0371,  0.0258],\n",
       "                      [ 0.0417,  0.0537, -0.0020,  ..., -0.0306, -0.0332, -0.0018],\n",
       "                      [ 0.0342,  0.0078,  0.0128,  ...,  0.0080,  0.0069, -0.0291]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.7.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0152,  0.0024,  0.0152,  ...,  0.0264,  0.0042, -0.0129],\n",
       "                      [ 0.0289, -0.0299, -0.0021,  ...,  0.0190, -0.0190, -0.0219],\n",
       "                      [-0.0067, -0.0041, -0.0052,  ..., -0.0146,  0.0065,  0.0031],\n",
       "                      ...,\n",
       "                      [-0.0003, -0.0408,  0.0034,  ...,  0.0032, -0.0056, -0.0079],\n",
       "                      [-0.0315,  0.0156, -0.0269,  ..., -0.0126,  0.0115, -0.0010],\n",
       "                      [-0.0082, -0.0017, -0.0070,  ...,  0.0233,  0.0079,  0.0126]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.7.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0142, -0.0161, -0.0047,  ...,  0.0063, -0.0237,  0.0021],\n",
       "                      [-0.0015,  0.0228,  0.0119,  ..., -0.0410, -0.0128, -0.0049],\n",
       "                      [ 0.0054,  0.0052, -0.0201,  ..., -0.0090, -0.0112, -0.0070],\n",
       "                      ...,\n",
       "                      [-0.0188, -0.0266, -0.0060,  ...,  0.0228, -0.0190, -0.0002],\n",
       "                      [-0.0203,  0.0075,  0.0115,  ...,  0.0074, -0.0120,  0.0143],\n",
       "                      [ 0.0001,  0.0044,  0.0009,  ...,  0.0050, -0.0142,  0.0052]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.7.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0053, -0.0019, -0.0151,  ..., -0.0062, -0.0305, -0.0043],\n",
       "                      [-0.0295,  0.0197, -0.0073,  ..., -0.0010, -0.0087, -0.0064],\n",
       "                      [ 0.0170, -0.0320, -0.0082,  ...,  0.0302, -0.0183,  0.0037],\n",
       "                      ...,\n",
       "                      [-0.0053,  0.0051, -0.0112,  ..., -0.0281, -0.0041, -0.0261],\n",
       "                      [-0.0033,  0.0184,  0.0101,  ..., -0.0053,  0.0067, -0.0315],\n",
       "                      [ 0.0203, -0.0156, -0.0035,  ...,  0.0176,  0.0200, -0.0009]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.7.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0208, -0.0009, -0.0024,  ...,  0.0154, -0.0352,  0.0067],\n",
       "                      [-0.0121, -0.0234,  0.0317,  ...,  0.0020, -0.0135,  0.0198],\n",
       "                      [ 0.0203, -0.0160,  0.0079,  ..., -0.0110,  0.0192, -0.0308],\n",
       "                      ...,\n",
       "                      [ 0.0021,  0.0013, -0.0168,  ..., -0.0046, -0.0225,  0.0020],\n",
       "                      [ 0.0017,  0.0074,  0.0165,  ..., -0.0117,  0.0204, -0.0012],\n",
       "                      [-0.0242, -0.0177,  0.0075,  ...,  0.0184,  0.0098,  0.0039]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.7.mlp.down_proj.weight',\n",
       "              tensor([[-0.0085, -0.0131, -0.0001,  ..., -0.0143, -0.0071, -0.0238],\n",
       "                      [-0.0032, -0.0069,  0.0194,  ..., -0.0023,  0.0038,  0.0025],\n",
       "                      [ 0.0110,  0.0157,  0.0327,  ..., -0.0166, -0.0125, -0.0166],\n",
       "                      ...,\n",
       "                      [-0.0057, -0.0010, -0.0195,  ...,  0.0171,  0.0017, -0.0275],\n",
       "                      [ 0.0430, -0.0090,  0.0039,  ..., -0.0210,  0.0005, -0.0140],\n",
       "                      [ 0.0177,  0.0193, -0.0349,  ...,  0.0024, -0.0236,  0.0002]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.7.input_layernorm.weight',\n",
       "              tensor([0.3203, 0.3613, 0.3359,  ..., 0.3242, 0.3535, 0.3262], device='cuda:0')),\n",
       "             ('model.layers.7.post_attention_layernorm.weight',\n",
       "              tensor([0.2305, 0.2158, 0.2139,  ..., 0.2236, 0.2217, 0.2236], device='cuda:0')),\n",
       "             ('model.layers.8.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0090, -0.0110, -0.0260,  ..., -0.0056,  0.0038,  0.0033],\n",
       "                      [-0.0166, -0.0154, -0.0342,  ..., -0.0024, -0.0003, -0.0031],\n",
       "                      [-0.0312, -0.0018, -0.0100,  ...,  0.0042,  0.0176, -0.0201],\n",
       "                      ...,\n",
       "                      [-0.0064,  0.0811,  0.0427,  ..., -0.0273, -0.0255, -0.0427],\n",
       "                      [ 0.0024, -0.0630, -0.0159,  ...,  0.0344,  0.0204,  0.0007],\n",
       "                      [-0.0630, -0.0557, -0.0150,  ..., -0.0469,  0.0283, -0.0155]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.8.self_attn.k_proj.weight',\n",
       "              tensor([[-7.6904e-03,  3.8147e-03, -5.3406e-03,  ..., -4.3640e-03,\n",
       "                        4.8523e-03,  9.1553e-03],\n",
       "                      [-6.5308e-03,  8.3618e-03, -8.5449e-03,  ...,  2.3438e-02,\n",
       "                       -2.1362e-03,  1.4099e-02],\n",
       "                      [-1.0315e-02,  3.0670e-03,  6.8054e-03,  ...,  1.7166e-03,\n",
       "                       -1.5015e-02, -1.6113e-02],\n",
       "                      ...,\n",
       "                      [ 6.0558e-05, -3.8574e-02, -6.7139e-03,  ..., -3.2715e-02,\n",
       "                       -1.6846e-02,  2.7954e-02],\n",
       "                      [ 2.0905e-03,  2.5513e-02,  2.5269e-02,  ..., -3.6377e-02,\n",
       "                        4.3945e-02, -5.8594e-02],\n",
       "                      [ 1.6479e-02, -6.2561e-03, -3.3691e-02,  ...,  2.2949e-02,\n",
       "                        8.3008e-03, -1.1475e-02]], device='cuda:0')),\n",
       "             ('model.layers.8.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0242, -0.0143,  0.0044,  ..., -0.0182, -0.0111, -0.0064],\n",
       "                      [-0.0220, -0.0118,  0.0066,  ...,  0.0254,  0.0039,  0.0206],\n",
       "                      [-0.0056,  0.0164,  0.0127,  ..., -0.0037,  0.0068, -0.0204],\n",
       "                      ...,\n",
       "                      [ 0.0305, -0.0156,  0.0038,  ...,  0.0214, -0.0184,  0.0212],\n",
       "                      [ 0.0233, -0.0160,  0.0012,  ...,  0.0081, -0.0084, -0.0003],\n",
       "                      [ 0.0151, -0.0006, -0.0060,  ..., -0.0030,  0.0048, -0.0047]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.8.self_attn.o_proj.weight',\n",
       "              tensor([[ 1.1780e-02,  1.3550e-02, -1.2573e-02,  ..., -1.0376e-02,\n",
       "                        5.1260e-05,  1.8188e-02],\n",
       "                      [ 1.1597e-02,  3.0823e-03, -3.1250e-02,  ..., -6.4392e-03,\n",
       "                       -7.9956e-03, -1.2268e-02],\n",
       "                      [ 2.8076e-03,  1.0498e-02, -4.3030e-03,  ...,  2.3651e-03,\n",
       "                        1.5198e-02,  2.1851e-02],\n",
       "                      ...,\n",
       "                      [-1.7212e-02,  2.4170e-02, -7.9956e-03,  ...,  1.3351e-03,\n",
       "                       -3.6163e-03, -4.2114e-03],\n",
       "                      [ 2.3651e-03, -1.6327e-03, -2.9602e-03,  ...,  1.9302e-03,\n",
       "                        7.9956e-03, -2.1729e-02],\n",
       "                      [-2.6855e-02,  4.9744e-03, -6.4392e-03,  ...,  2.0630e-02,\n",
       "                       -9.8267e-03, -2.9144e-03]], device='cuda:0')),\n",
       "             ('model.layers.8.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0103,  0.0022, -0.0398,  ..., -0.0062, -0.0264, -0.0232],\n",
       "                      [-0.0029, -0.0425,  0.0113,  ..., -0.0009, -0.0471,  0.0228],\n",
       "                      [ 0.0177,  0.0176,  0.0232,  ...,  0.0242,  0.0201, -0.0113],\n",
       "                      ...,\n",
       "                      [-0.0120,  0.0034,  0.0049,  ...,  0.0272,  0.0137,  0.0037],\n",
       "                      [-0.0118, -0.0007,  0.0084,  ...,  0.0007, -0.0233,  0.0234],\n",
       "                      [-0.0248,  0.0052, -0.0020,  ..., -0.0149,  0.0111, -0.0013]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.8.mlp.up_proj.weight',\n",
       "              tensor([[-0.0092,  0.0176, -0.0155,  ...,  0.0272,  0.0075, -0.0113],\n",
       "                      [-0.0486,  0.0176, -0.0400,  ...,  0.0150, -0.0026, -0.0072],\n",
       "                      [ 0.0084,  0.0051,  0.0074,  ..., -0.0128, -0.0172,  0.0308],\n",
       "                      ...,\n",
       "                      [-0.0141,  0.0400, -0.0184,  ...,  0.0168, -0.0103,  0.0084],\n",
       "                      [ 0.0008, -0.0060, -0.0079,  ..., -0.0166,  0.0223, -0.0157],\n",
       "                      [-0.0140,  0.0166, -0.0130,  ..., -0.0153, -0.0008,  0.0033]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.8.mlp.down_proj.weight',\n",
       "              tensor([[-0.0108, -0.0055,  0.0195,  ...,  0.0101,  0.0120, -0.0243],\n",
       "                      [ 0.0145,  0.0121, -0.0195,  ..., -0.0058,  0.0086, -0.0229],\n",
       "                      [-0.0008, -0.0226, -0.0269,  ..., -0.0117,  0.0066, -0.0060],\n",
       "                      ...,\n",
       "                      [ 0.0132, -0.0188, -0.0347,  ...,  0.0035,  0.0051, -0.0172],\n",
       "                      [ 0.0151,  0.0030, -0.0064,  ..., -0.0035, -0.0071, -0.0165],\n",
       "                      [-0.0009,  0.0140, -0.0021,  ...,  0.0027,  0.0028,  0.0008]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.8.input_layernorm.weight',\n",
       "              tensor([0.3281, 0.3398, 0.3281,  ..., 0.3164, 0.3398, 0.3184], device='cuda:0')),\n",
       "             ('model.layers.8.post_attention_layernorm.weight',\n",
       "              tensor([0.2354, 0.2207, 0.2129,  ..., 0.2344, 0.2275, 0.2246], device='cuda:0')),\n",
       "             ('model.layers.9.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0181,  0.0034,  0.0152,  ..., -0.0068, -0.0110, -0.0148],\n",
       "                      [ 0.0022, -0.0342,  0.0146,  ...,  0.0076, -0.0082,  0.0018],\n",
       "                      [ 0.0022, -0.0027, -0.0137,  ..., -0.0227, -0.0282, -0.0225],\n",
       "                      ...,\n",
       "                      [ 0.0028, -0.0439,  0.0181,  ...,  0.0216,  0.0145, -0.0206],\n",
       "                      [ 0.0138, -0.0211,  0.0117,  ...,  0.0089,  0.0099,  0.0096],\n",
       "                      [-0.0020,  0.0540,  0.0190,  ..., -0.0562,  0.0469, -0.0045]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.9.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0347,  0.0110, -0.0147,  ...,  0.0073, -0.0203, -0.0082],\n",
       "                      [-0.0061,  0.0317,  0.0099,  ..., -0.0087,  0.0074,  0.0019],\n",
       "                      [-0.0121, -0.0146,  0.0179,  ..., -0.0045, -0.0129, -0.0039],\n",
       "                      ...,\n",
       "                      [ 0.0106, -0.0157, -0.0046,  ..., -0.0090,  0.0199,  0.0203],\n",
       "                      [ 0.0315, -0.0122,  0.0212,  ...,  0.0447, -0.0107,  0.0500],\n",
       "                      [ 0.0039, -0.0243,  0.0283,  ...,  0.0107,  0.0248, -0.0215]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.9.self_attn.v_proj.weight',\n",
       "              tensor([[-4.2419e-03,  9.4604e-03, -3.9291e-04,  ...,  7.1716e-03,\n",
       "                       -2.1484e-02, -1.8921e-02],\n",
       "                      [-1.5747e-02, -1.6602e-02, -1.4038e-03,  ...,  2.9053e-02,\n",
       "                       -4.0588e-03, -3.6163e-03],\n",
       "                      [ 1.0986e-03, -2.6489e-02,  2.0020e-02,  ..., -2.4292e-02,\n",
       "                        6.6223e-03, -1.2939e-02],\n",
       "                      ...,\n",
       "                      [-5.4321e-03, -1.4160e-02,  4.6692e-03,  ...,  3.4180e-03,\n",
       "                       -2.1973e-02, -9.1934e-04],\n",
       "                      [-1.5442e-02,  1.2589e-03, -9.0942e-03,  ..., -1.1169e-02,\n",
       "                       -2.6464e-05, -1.1230e-02],\n",
       "                      [ 2.4170e-02,  1.9653e-02, -9.6512e-04,  ..., -1.4832e-02,\n",
       "                       -3.3417e-03, -4.3030e-03]], device='cuda:0')),\n",
       "             ('model.layers.9.self_attn.o_proj.weight',\n",
       "              tensor([[ 9.7046e-03,  1.0986e-02,  4.6387e-03,  ..., -9.0332e-03,\n",
       "                        9.6512e-04, -9.7275e-04],\n",
       "                      [-4.0894e-03, -1.5381e-02, -1.8311e-03,  ...,  3.0899e-04,\n",
       "                        7.6599e-03,  1.4771e-02],\n",
       "                      [-3.4180e-02, -3.0762e-02,  1.0986e-02,  ...,  2.7100e-02,\n",
       "                        7.7820e-04,  1.5320e-02],\n",
       "                      ...,\n",
       "                      [ 1.6846e-02, -1.5381e-02,  1.0803e-02,  ...,  6.8359e-03,\n",
       "                        8.9722e-03, -8.1787e-03],\n",
       "                      [-1.1110e-04,  1.8188e-02,  2.2278e-03,  ...,  1.3123e-02,\n",
       "                       -8.8692e-05, -1.4954e-03],\n",
       "                      [ 1.4099e-02,  4.9072e-02, -2.1973e-02,  ..., -2.5635e-03,\n",
       "                        6.1646e-03,  6.0425e-03]], device='cuda:0')),\n",
       "             ('model.layers.9.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0070,  0.0273, -0.0054,  ..., -0.0266, -0.0089,  0.0024],\n",
       "                      [-0.0232,  0.0277,  0.0281,  ...,  0.0298,  0.0310, -0.0045],\n",
       "                      [ 0.0359,  0.0286, -0.0236,  ..., -0.0260,  0.0105, -0.0050],\n",
       "                      ...,\n",
       "                      [-0.0134, -0.0135, -0.0261,  ..., -0.0010, -0.0391,  0.0043],\n",
       "                      [-0.0116, -0.0248,  0.0239,  ..., -0.0150,  0.0028,  0.0134],\n",
       "                      [ 0.0134, -0.0173, -0.0099,  ...,  0.0126, -0.0154,  0.0083]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.9.mlp.up_proj.weight',\n",
       "              tensor([[-0.0126,  0.0100,  0.0123,  ..., -0.0005, -0.0073,  0.0110],\n",
       "                      [ 0.0112, -0.0022,  0.0003,  ...,  0.0152,  0.0167, -0.0198],\n",
       "                      [-0.0205, -0.0077, -0.0187,  ..., -0.0053, -0.0110, -0.0042],\n",
       "                      ...,\n",
       "                      [-0.0038,  0.0114, -0.0152,  ..., -0.0085, -0.0294, -0.0192],\n",
       "                      [ 0.0011,  0.0178, -0.0305,  ..., -0.0292, -0.0091, -0.0160],\n",
       "                      [ 0.0006, -0.0347, -0.0135,  ..., -0.0127,  0.0264,  0.0017]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.9.mlp.down_proj.weight',\n",
       "              tensor([[-0.0053,  0.0237, -0.0435,  ...,  0.0011, -0.0140,  0.0099],\n",
       "                      [ 0.0231, -0.0236, -0.0173,  ..., -0.0020, -0.0281, -0.0322],\n",
       "                      [-0.0005,  0.0043, -0.0011,  ..., -0.0149,  0.0005, -0.0016],\n",
       "                      ...,\n",
       "                      [-0.0095,  0.0205,  0.0017,  ..., -0.0003, -0.0299,  0.0070],\n",
       "                      [-0.0342, -0.0022,  0.0123,  ..., -0.0243, -0.0006, -0.0303],\n",
       "                      [ 0.0228,  0.0153,  0.0150,  ...,  0.0425,  0.0157,  0.0176]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.9.input_layernorm.weight',\n",
       "              tensor([0.3496, 0.3535, 0.3203,  ..., 0.3457, 0.3418, 0.3340], device='cuda:0')),\n",
       "             ('model.layers.9.post_attention_layernorm.weight',\n",
       "              tensor([0.2402, 0.2305, 0.2197,  ..., 0.2363, 0.2344, 0.2305], device='cuda:0')),\n",
       "             ('model.layers.10.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0012,  0.0065, -0.0008,  ...,  0.0098, -0.0042, -0.0087],\n",
       "                      [-0.0034, -0.0072,  0.0143,  ..., -0.0055,  0.0593,  0.0020],\n",
       "                      [-0.0092, -0.0068, -0.0047,  ...,  0.0190, -0.0148, -0.0159],\n",
       "                      ...,\n",
       "                      [ 0.0317,  0.0635, -0.0159,  ...,  0.0295,  0.0369, -0.0092],\n",
       "                      [-0.0598,  0.0559,  0.0011,  ..., -0.0674, -0.0008, -0.0114],\n",
       "                      [-0.0498, -0.0225, -0.0036,  ..., -0.0078, -0.0302, -0.0175]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.10.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0204,  0.0118, -0.0041,  ..., -0.0092,  0.0042, -0.0031],\n",
       "                      [-0.0095,  0.0084, -0.0043,  ...,  0.0115, -0.0099,  0.0041],\n",
       "                      [-0.0042, -0.0011,  0.0107,  ..., -0.0165,  0.0223, -0.0012],\n",
       "                      ...,\n",
       "                      [-0.0449, -0.0591,  0.0066,  ...,  0.0303, -0.0786,  0.0089],\n",
       "                      [-0.0356, -0.0065,  0.0305,  ..., -0.0181, -0.0442, -0.0228],\n",
       "                      [-0.0282,  0.0273, -0.0228,  ...,  0.0146,  0.0471, -0.0101]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.10.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0403,  0.0030, -0.0067,  ...,  0.0056,  0.0096,  0.0110],\n",
       "                      [-0.0081,  0.0141,  0.0119,  ..., -0.0079, -0.0374,  0.0190],\n",
       "                      [ 0.0153, -0.0127,  0.0162,  ...,  0.0146,  0.0064, -0.0047],\n",
       "                      ...,\n",
       "                      [ 0.0219,  0.0286,  0.0010,  ...,  0.0281, -0.0060, -0.0151],\n",
       "                      [ 0.0028,  0.0067,  0.0016,  ...,  0.0008,  0.0128,  0.0017],\n",
       "                      [ 0.0133,  0.0079, -0.0141,  ..., -0.0052, -0.0129,  0.0283]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.10.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0018,  0.0022, -0.0297,  ..., -0.0012,  0.0082,  0.0076],\n",
       "                      [ 0.0004, -0.0136,  0.0128,  ...,  0.0009,  0.0131,  0.0019],\n",
       "                      [ 0.0141, -0.0356, -0.0193,  ...,  0.0090, -0.0112, -0.0056],\n",
       "                      ...,\n",
       "                      [ 0.0008,  0.0118, -0.0125,  ..., -0.0046,  0.0049,  0.0210],\n",
       "                      [ 0.0064, -0.0107, -0.0226,  ...,  0.0116,  0.0082,  0.0018],\n",
       "                      [ 0.0092, -0.0121, -0.0253,  ...,  0.0116, -0.0010,  0.0028]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.10.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0320, -0.0391, -0.0277,  ..., -0.0049, -0.0014, -0.0089],\n",
       "                      [-0.0157, -0.0150, -0.0154,  ...,  0.0016,  0.0153,  0.0165],\n",
       "                      [-0.0136, -0.0206,  0.0089,  ...,  0.0306, -0.0054,  0.0016],\n",
       "                      ...,\n",
       "                      [-0.0447, -0.0010,  0.0115,  ...,  0.0075, -0.0302,  0.0192],\n",
       "                      [ 0.0063,  0.0211,  0.0197,  ...,  0.0054, -0.0107, -0.0027],\n",
       "                      [-0.0065, -0.0143, -0.0205,  ..., -0.0118,  0.0025, -0.0141]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.10.mlp.up_proj.weight',\n",
       "              tensor([[-0.0425, -0.0060, -0.0383,  ...,  0.0128, -0.0089, -0.0201],\n",
       "                      [-0.0090,  0.0092,  0.0041,  ...,  0.0225,  0.0359, -0.0121],\n",
       "                      [-0.0014, -0.0027,  0.0108,  ...,  0.0232, -0.0300, -0.0024],\n",
       "                      ...,\n",
       "                      [ 0.0212,  0.0193, -0.0001,  ..., -0.0432, -0.0027, -0.0021],\n",
       "                      [-0.0035, -0.0014, -0.0280,  ...,  0.0209, -0.0142,  0.0162],\n",
       "                      [ 0.0005,  0.0138,  0.0023,  ...,  0.0006,  0.0077,  0.0167]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.10.mlp.down_proj.weight',\n",
       "              tensor([[-0.0105, -0.0276, -0.0043,  ...,  0.0281, -0.0135, -0.0004],\n",
       "                      [-0.0050,  0.0159, -0.0085,  ..., -0.0101,  0.0085,  0.0002],\n",
       "                      [-0.0322, -0.0007,  0.0166,  ..., -0.0234, -0.0245,  0.0086],\n",
       "                      ...,\n",
       "                      [ 0.0127, -0.0046,  0.0009,  ...,  0.0135,  0.0147,  0.0075],\n",
       "                      [-0.0028,  0.0481, -0.0176,  ...,  0.0172,  0.0308, -0.0330],\n",
       "                      [-0.0476,  0.0013, -0.0282,  ..., -0.0189, -0.0144,  0.0083]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.10.input_layernorm.weight',\n",
       "              tensor([0.3594, 0.3555, 0.3184,  ..., 0.3359, 0.3438, 0.3340], device='cuda:0')),\n",
       "             ('model.layers.10.post_attention_layernorm.weight',\n",
       "              tensor([0.2451, 0.2295, 0.2217,  ..., 0.2402, 0.2383, 0.2354], device='cuda:0')),\n",
       "             ('model.layers.11.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0159,  0.0161, -0.0087,  ...,  0.0205, -0.0062,  0.0010],\n",
       "                      [-0.0127,  0.0088,  0.0097,  ...,  0.0135,  0.0150,  0.0007],\n",
       "                      [ 0.0015,  0.0066, -0.0245,  ..., -0.0024, -0.0093,  0.0045],\n",
       "                      ...,\n",
       "                      [-0.0012, -0.0064,  0.0325,  ...,  0.0339,  0.0388, -0.0315],\n",
       "                      [ 0.0432,  0.0178, -0.0115,  ..., -0.0080,  0.0170, -0.0288],\n",
       "                      [ 0.0737, -0.0187, -0.0183,  ..., -0.0208,  0.0461,  0.0557]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.11.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0063,  0.0165, -0.0011,  ..., -0.0126,  0.0026, -0.0214],\n",
       "                      [-0.0007,  0.0012, -0.0273,  ..., -0.0064, -0.0034,  0.0248],\n",
       "                      [ 0.0133, -0.0267,  0.0069,  ...,  0.0077,  0.0043,  0.0046],\n",
       "                      ...,\n",
       "                      [-0.0071,  0.0217,  0.0020,  ..., -0.0172, -0.0127,  0.0337],\n",
       "                      [ 0.0625, -0.0107, -0.0112,  ..., -0.0020,  0.0041, -0.0052],\n",
       "                      [ 0.0065,  0.0053,  0.0170,  ..., -0.0058,  0.0596,  0.0233]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.11.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0061,  0.0030, -0.0093,  ..., -0.0194,  0.0005,  0.0068],\n",
       "                      [ 0.0016, -0.0080, -0.0102,  ...,  0.0061,  0.0056, -0.0242],\n",
       "                      [ 0.0028,  0.0053, -0.0078,  ...,  0.0146,  0.0046, -0.0220],\n",
       "                      ...,\n",
       "                      [-0.0166,  0.0059, -0.0135,  ...,  0.0068, -0.0171, -0.0040],\n",
       "                      [-0.0068,  0.0148, -0.0094,  ..., -0.0151, -0.0164,  0.0024],\n",
       "                      [ 0.0118, -0.0244,  0.0042,  ..., -0.0400, -0.0053, -0.0125]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.11.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0177, -0.0014,  0.0064,  ...,  0.0100,  0.0126,  0.0008],\n",
       "                      [ 0.0015, -0.0260,  0.0160,  ..., -0.0140,  0.0021, -0.0183],\n",
       "                      [-0.0087, -0.0041,  0.0188,  ...,  0.0044, -0.0006,  0.0200],\n",
       "                      ...,\n",
       "                      [ 0.0060, -0.0048,  0.0236,  ...,  0.0015,  0.0026, -0.0074],\n",
       "                      [ 0.0008,  0.0229,  0.0095,  ...,  0.0170,  0.0091, -0.0325],\n",
       "                      [-0.0020, -0.0037,  0.0025,  ..., -0.0053,  0.0005, -0.0142]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.11.mlp.gate_proj.weight',\n",
       "              tensor([[-4.4922e-02, -9.4604e-03, -3.5524e-05,  ...,  4.2114e-03,\n",
       "                       -7.7820e-03,  3.7598e-02],\n",
       "                      [ 1.2665e-03, -9.3384e-03,  2.2949e-02,  ...,  1.1536e-02,\n",
       "                       -1.6846e-02, -4.3213e-02],\n",
       "                      [-2.1515e-03, -4.3701e-02, -3.7842e-02,  ..., -1.1902e-03,\n",
       "                       -4.6692e-03,  3.5400e-03],\n",
       "                      ...,\n",
       "                      [-1.6724e-02, -3.3691e-02, -1.8188e-02,  ..., -4.6997e-03,\n",
       "                       -2.8442e-02,  1.7853e-03],\n",
       "                      [ 2.3651e-03,  5.2185e-03, -2.5391e-02,  ..., -1.1475e-02,\n",
       "                        1.1108e-02,  4.0245e-04],\n",
       "                      [-8.3618e-03,  9.3994e-03,  1.0864e-02,  ...,  3.3203e-02,\n",
       "                       -2.8687e-03, -1.8311e-02]], device='cuda:0')),\n",
       "             ('model.layers.11.mlp.up_proj.weight',\n",
       "              tensor([[-0.0105, -0.0023, -0.0273,  ...,  0.0272,  0.0030,  0.0292],\n",
       "                      [ 0.0135,  0.0019, -0.0187,  ...,  0.0082, -0.0398,  0.0038],\n",
       "                      [-0.0094, -0.0276, -0.0020,  ..., -0.0089, -0.0178,  0.0153],\n",
       "                      ...,\n",
       "                      [ 0.0425,  0.0106, -0.0056,  ..., -0.0021,  0.0018,  0.0190],\n",
       "                      [-0.0113,  0.0081,  0.0081,  ...,  0.0194,  0.0093,  0.0078],\n",
       "                      [-0.0008, -0.0015, -0.0082,  ..., -0.0115,  0.0055,  0.0258]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.11.mlp.down_proj.weight',\n",
       "              tensor([[-0.0178,  0.0447,  0.0164,  ...,  0.0208,  0.0136, -0.0053],\n",
       "                      [-0.0145, -0.0060, -0.0261,  ..., -0.0284, -0.0094,  0.0148],\n",
       "                      [-0.0210, -0.0096,  0.0049,  ...,  0.0024, -0.0176, -0.0082],\n",
       "                      ...,\n",
       "                      [ 0.0189,  0.0249, -0.0125,  ...,  0.0042,  0.0018,  0.0081],\n",
       "                      [-0.0151, -0.0308, -0.0320,  ..., -0.0237, -0.0076,  0.0146],\n",
       "                      [ 0.0354,  0.0179,  0.0223,  ...,  0.0043, -0.0128,  0.0403]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.11.input_layernorm.weight',\n",
       "              tensor([0.3906, 0.3887, 0.3555,  ..., 0.3770, 0.3730, 0.3652], device='cuda:0')),\n",
       "             ('model.layers.11.post_attention_layernorm.weight',\n",
       "              tensor([0.2500, 0.2363, 0.2324,  ..., 0.2480, 0.2471, 0.2441], device='cuda:0')),\n",
       "             ('model.layers.12.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0046, -0.0189,  0.0091,  ...,  0.0167, -0.0055,  0.0062],\n",
       "                      [ 0.0029,  0.0035, -0.0010,  ..., -0.0110,  0.0253,  0.0139],\n",
       "                      [ 0.0086,  0.0344, -0.0295,  ...,  0.0008,  0.0155, -0.0312],\n",
       "                      ...,\n",
       "                      [-0.0040,  0.0376, -0.0198,  ..., -0.0293, -0.0104,  0.0135],\n",
       "                      [ 0.0344, -0.0049,  0.0115,  ...,  0.0317,  0.0056, -0.0334],\n",
       "                      [ 0.0344,  0.0136, -0.0393,  ..., -0.0187,  0.0170,  0.0244]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.12.self_attn.k_proj.weight',\n",
       "              tensor([[ 1.0559e-02, -4.6997e-03,  3.6621e-04,  ...,  1.2878e-02,\n",
       "                        4.7913e-03, -5.9509e-03],\n",
       "                      [ 4.1809e-03,  1.8188e-02, -8.1787e-03,  ...,  1.0803e-02,\n",
       "                       -1.4893e-02, -2.0020e-02],\n",
       "                      [-8.7280e-03, -1.9897e-02,  7.6599e-03,  ...,  1.3916e-02,\n",
       "                       -9.7046e-03,  1.2634e-02],\n",
       "                      ...,\n",
       "                      [ 1.5991e-02,  2.7344e-02, -1.7578e-02,  ..., -3.8086e-02,\n",
       "                       -1.3611e-02, -1.7700e-02],\n",
       "                      [-3.3447e-02,  4.7607e-03,  2.6733e-02,  ..., -2.4170e-02,\n",
       "                        2.0508e-02,  4.5300e-06],\n",
       "                      [-2.3499e-03,  3.4668e-02,  1.0376e-02,  ...,  1.2817e-02,\n",
       "                       -4.6143e-02, -3.2471e-02]], device='cuda:0')),\n",
       "             ('model.layers.12.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0058,  0.0045,  0.0053,  ..., -0.0056,  0.0079, -0.0181],\n",
       "                      [-0.0259,  0.0166, -0.0010,  ..., -0.0217, -0.0022,  0.0148],\n",
       "                      [-0.0121, -0.0105,  0.0040,  ..., -0.0023,  0.0439, -0.0129],\n",
       "                      ...,\n",
       "                      [ 0.0018, -0.0025, -0.0167,  ..., -0.0055, -0.0128, -0.0009],\n",
       "                      [ 0.0011, -0.0125, -0.0052,  ...,  0.0021,  0.0110,  0.0047],\n",
       "                      [ 0.0227,  0.0021,  0.0019,  ...,  0.0203,  0.0055, -0.0115]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.12.self_attn.o_proj.weight',\n",
       "              tensor([[ 2.7954e-02,  7.2327e-03, -1.0681e-03,  ...,  2.6550e-03,\n",
       "                        7.1716e-03, -5.3101e-03],\n",
       "                      [-5.5847e-03, -8.7891e-03, -2.5749e-05,  ..., -1.2756e-02,\n",
       "                        3.9368e-03, -1.7334e-02],\n",
       "                      [ 3.7079e-03, -4.9133e-03, -5.8594e-03,  ...,  5.3406e-03,\n",
       "                       -2.6001e-02,  1.1169e-02],\n",
       "                      ...,\n",
       "                      [ 2.6398e-03, -1.4420e-03,  1.5137e-02,  ..., -5.8289e-03,\n",
       "                       -5.7220e-04,  3.0823e-03],\n",
       "                      [-1.0437e-02, -3.2715e-02, -2.9785e-02,  ..., -4.7302e-03,\n",
       "                        1.0437e-02,  1.7822e-02],\n",
       "                      [ 1.8433e-02,  5.2795e-03,  1.0193e-02,  ...,  2.1606e-02,\n",
       "                       -1.1230e-02, -1.7090e-02]], device='cuda:0')),\n",
       "             ('model.layers.12.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0079, -0.0249,  0.0092,  ..., -0.0049,  0.0198,  0.0058],\n",
       "                      [-0.0251, -0.0261,  0.0139,  ...,  0.0159,  0.0165,  0.0124],\n",
       "                      [ 0.0045,  0.0204, -0.0042,  ..., -0.0077, -0.0442,  0.0024],\n",
       "                      ...,\n",
       "                      [ 0.0003,  0.0085,  0.0123,  ..., -0.0248, -0.0015,  0.0209],\n",
       "                      [-0.0352, -0.0067,  0.0024,  ...,  0.0073,  0.0118, -0.0038],\n",
       "                      [ 0.0010, -0.0195, -0.0070,  ..., -0.0029, -0.0062, -0.0181]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.12.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0031,  0.0190,  0.0067,  ..., -0.0046,  0.0200,  0.0166],\n",
       "                      [-0.0029, -0.0132, -0.0123,  ...,  0.0036, -0.0114,  0.0260],\n",
       "                      [ 0.0088, -0.0036,  0.0135,  ..., -0.0449,  0.0118,  0.0022],\n",
       "                      ...,\n",
       "                      [-0.0132, -0.0347, -0.0066,  ...,  0.0151, -0.0194,  0.0038],\n",
       "                      [ 0.0032, -0.0304, -0.0048,  ...,  0.0092,  0.0092, -0.0127],\n",
       "                      [-0.0110, -0.0184, -0.0052,  ...,  0.0381, -0.0049, -0.0354]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.12.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0039, -0.0056, -0.0310,  ..., -0.0125,  0.0036,  0.0066],\n",
       "                      [ 0.0156, -0.0245,  0.0016,  ..., -0.0090, -0.0107, -0.0164],\n",
       "                      [ 0.0136,  0.0014,  0.0178,  ...,  0.0044, -0.0090, -0.0197],\n",
       "                      ...,\n",
       "                      [ 0.0156, -0.0115, -0.0459,  ...,  0.0376, -0.0176, -0.0154],\n",
       "                      [-0.0239,  0.0142,  0.0107,  ..., -0.0057,  0.0364, -0.0214],\n",
       "                      [ 0.0045,  0.0193,  0.0262,  ..., -0.0325,  0.0182, -0.0011]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.12.input_layernorm.weight',\n",
       "              tensor([0.3984, 0.3926, 0.3613,  ..., 0.3730, 0.3789, 0.3809], device='cuda:0')),\n",
       "             ('model.layers.12.post_attention_layernorm.weight',\n",
       "              tensor([0.2578, 0.2432, 0.2363,  ..., 0.2539, 0.2520, 0.2520], device='cuda:0')),\n",
       "             ('model.layers.13.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0029, -0.0096, -0.0145,  ...,  0.0065, -0.0047, -0.0078],\n",
       "                      [-0.0140, -0.0154,  0.0003,  ..., -0.0011,  0.0086, -0.0026],\n",
       "                      [-0.0175,  0.0110,  0.0074,  ..., -0.0085, -0.0058,  0.0045],\n",
       "                      ...,\n",
       "                      [ 0.0420,  0.0045,  0.0013,  ...,  0.0476,  0.0181, -0.0471],\n",
       "                      [ 0.0052,  0.0129, -0.0225,  ...,  0.0122,  0.0161, -0.0081],\n",
       "                      [-0.0071, -0.0199, -0.0162,  ..., -0.0121,  0.0204, -0.0092]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.13.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0104,  0.0043, -0.0025,  ..., -0.0210,  0.0227,  0.0154],\n",
       "                      [ 0.0089,  0.0177, -0.0047,  ...,  0.0061,  0.0071,  0.0005],\n",
       "                      [ 0.0010, -0.0093,  0.0374,  ...,  0.0010,  0.0165, -0.0322],\n",
       "                      ...,\n",
       "                      [ 0.0337,  0.0327, -0.0023,  ...,  0.0052, -0.0046, -0.0157],\n",
       "                      [-0.0036,  0.0063,  0.0280,  ..., -0.0430, -0.0154,  0.0332],\n",
       "                      [-0.0226, -0.0496, -0.0118,  ..., -0.0339, -0.0284,  0.0084]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.13.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0140,  0.0023, -0.0135,  ..., -0.0038,  0.0120,  0.0150],\n",
       "                      [-0.0090,  0.0150, -0.0045,  ...,  0.0144, -0.0071, -0.0044],\n",
       "                      [ 0.0188,  0.0013, -0.0025,  ..., -0.0229,  0.0366, -0.0117],\n",
       "                      ...,\n",
       "                      [-0.0018,  0.0216, -0.0054,  ..., -0.0073,  0.0250, -0.0188],\n",
       "                      [-0.0130,  0.0104,  0.0135,  ...,  0.0009,  0.0332,  0.0082],\n",
       "                      [-0.0045, -0.0096,  0.0253,  ...,  0.0165,  0.0008,  0.0430]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.13.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0023,  0.0005, -0.0051,  ...,  0.0014, -0.0067, -0.0038],\n",
       "                      [ 0.0232,  0.0110,  0.0050,  ..., -0.0121, -0.0078,  0.0027],\n",
       "                      [ 0.0066,  0.0077, -0.0001,  ...,  0.0060, -0.0250, -0.0101],\n",
       "                      ...,\n",
       "                      [-0.0087,  0.0102,  0.0160,  ..., -0.0103, -0.0073, -0.0159],\n",
       "                      [ 0.0032,  0.0017,  0.0295,  ..., -0.0011, -0.0253, -0.0265],\n",
       "                      [ 0.0101,  0.0056,  0.0081,  ...,  0.0128, -0.0078, -0.0223]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.13.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0194,  0.0079, -0.0091,  ...,  0.0079,  0.0041, -0.0155],\n",
       "                      [-0.0264,  0.0344,  0.0184,  ...,  0.0364, -0.0028, -0.0227],\n",
       "                      [ 0.0084, -0.0211, -0.0101,  ...,  0.0020, -0.0190, -0.0114],\n",
       "                      ...,\n",
       "                      [ 0.0200, -0.0139,  0.0145,  ..., -0.0066,  0.0187,  0.0145],\n",
       "                      [ 0.0204, -0.0028,  0.0123,  ...,  0.0129,  0.0072, -0.0247],\n",
       "                      [ 0.0042,  0.0366,  0.0212,  ..., -0.0045,  0.0204,  0.0270]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.13.mlp.up_proj.weight',\n",
       "              tensor([[-0.0342,  0.0228, -0.0064,  ...,  0.0048,  0.0150,  0.0002],\n",
       "                      [ 0.0153, -0.0072,  0.0334,  ...,  0.0396,  0.0286,  0.0070],\n",
       "                      [ 0.0192, -0.0276,  0.0199,  ..., -0.0012,  0.0034, -0.0063],\n",
       "                      ...,\n",
       "                      [-0.0047, -0.0003,  0.0255,  ...,  0.0090, -0.0272,  0.0155],\n",
       "                      [-0.0089, -0.0199,  0.0079,  ...,  0.0138,  0.0537,  0.0062],\n",
       "                      [ 0.0101, -0.0205,  0.0148,  ..., -0.0208, -0.0018,  0.0237]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.13.mlp.down_proj.weight',\n",
       "              tensor([[-0.0064, -0.0035, -0.0022,  ...,  0.0292, -0.0281, -0.0232],\n",
       "                      [-0.0087,  0.0535, -0.0471,  ..., -0.0053,  0.0032, -0.0073],\n",
       "                      [ 0.0028, -0.0039,  0.0178,  ...,  0.0067, -0.0277, -0.0059],\n",
       "                      ...,\n",
       "                      [ 0.0140, -0.0021,  0.0272,  ...,  0.0081, -0.0186,  0.0339],\n",
       "                      [ 0.0078,  0.0022,  0.0159,  ..., -0.0102,  0.0108, -0.0119],\n",
       "                      [-0.0015, -0.0304,  0.0339,  ...,  0.0040,  0.0051,  0.0356]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.13.input_layernorm.weight',\n",
       "              tensor([0.4102, 0.3984, 0.3672,  ..., 0.3809, 0.3770, 0.3867], device='cuda:0')),\n",
       "             ('model.layers.13.post_attention_layernorm.weight',\n",
       "              tensor([0.2598, 0.2500, 0.2432,  ..., 0.2598, 0.2637, 0.2559], device='cuda:0')),\n",
       "             ('model.layers.14.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0056,  0.0013,  0.0190,  ..., -0.0055,  0.0107,  0.0312],\n",
       "                      [ 0.0046,  0.0124, -0.0100,  ..., -0.0354, -0.0183, -0.0271],\n",
       "                      [-0.0044, -0.0050,  0.0072,  ...,  0.0105,  0.0101, -0.0287],\n",
       "                      ...,\n",
       "                      [-0.0160, -0.0002, -0.0286,  ..., -0.0072,  0.0145, -0.0043],\n",
       "                      [ 0.0219, -0.0344,  0.0496,  ..., -0.0096,  0.0101, -0.0072],\n",
       "                      [-0.0128,  0.0033, -0.0128,  ...,  0.0140,  0.0133, -0.0483]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.14.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0105, -0.0030,  0.0097,  ..., -0.0074,  0.0204,  0.0413],\n",
       "                      [ 0.0261,  0.0244, -0.0226,  ..., -0.0063, -0.0190,  0.0089],\n",
       "                      [-0.0208,  0.0007,  0.0204,  ...,  0.0228,  0.0115, -0.0029],\n",
       "                      ...,\n",
       "                      [-0.0320,  0.0115,  0.0270,  ..., -0.0027, -0.0026, -0.0217],\n",
       "                      [-0.0281,  0.0044,  0.0137,  ..., -0.0356, -0.0036,  0.0013],\n",
       "                      [-0.0166,  0.0322,  0.0237,  ...,  0.0684,  0.0161, -0.0312]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.14.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0084,  0.0071, -0.0393,  ..., -0.0302, -0.0053,  0.0145],\n",
       "                      [-0.0028, -0.0195,  0.0008,  ...,  0.0045, -0.0026,  0.0006],\n",
       "                      [ 0.0253, -0.0190, -0.0002,  ..., -0.0052,  0.0096,  0.0123],\n",
       "                      ...,\n",
       "                      [ 0.0154, -0.0140,  0.0167,  ...,  0.0210, -0.0105,  0.0054],\n",
       "                      [-0.0139,  0.0249, -0.0332,  ...,  0.0039, -0.0074, -0.0302],\n",
       "                      [ 0.0089,  0.0226, -0.0223,  ..., -0.0056, -0.0066,  0.0189]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.14.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0098,  0.0065, -0.0220,  ..., -0.0020,  0.0032, -0.0131],\n",
       "                      [ 0.0011,  0.0288,  0.0065,  ...,  0.0201, -0.0090,  0.0010],\n",
       "                      [ 0.0049,  0.0045, -0.0029,  ...,  0.0020,  0.0206,  0.0116],\n",
       "                      ...,\n",
       "                      [ 0.0222, -0.0042,  0.0031,  ..., -0.0145, -0.0012,  0.0101],\n",
       "                      [-0.0037,  0.0006, -0.0194,  ..., -0.0036,  0.0356,  0.0198],\n",
       "                      [-0.0088, -0.0110, -0.0149,  ..., -0.0046,  0.0058,  0.0042]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.14.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0143,  0.0096, -0.0090,  ...,  0.0061, -0.0140, -0.0097],\n",
       "                      [ 0.0212,  0.0075, -0.0405,  ...,  0.0378,  0.0171, -0.0103],\n",
       "                      [ 0.0029,  0.0123,  0.0068,  ..., -0.0111,  0.0038, -0.0132],\n",
       "                      ...,\n",
       "                      [ 0.0061,  0.0156, -0.0195,  ..., -0.0041, -0.0060, -0.0023],\n",
       "                      [-0.0071,  0.0131,  0.0199,  ..., -0.0149,  0.0161,  0.0085],\n",
       "                      [ 0.0172, -0.0016,  0.0225,  ..., -0.0047, -0.0272,  0.0227]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.14.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0014,  0.0118,  0.0183,  ..., -0.0255,  0.0071,  0.0086],\n",
       "                      [ 0.0275,  0.0132, -0.0275,  ...,  0.0135,  0.0223,  0.0133],\n",
       "                      [-0.0004,  0.0021,  0.0322,  ..., -0.0042,  0.0175, -0.0045],\n",
       "                      ...,\n",
       "                      [-0.0164,  0.0067, -0.0474,  ..., -0.0078, -0.0075, -0.0071],\n",
       "                      [-0.0277,  0.0242, -0.0060,  ..., -0.0132,  0.0242, -0.0157],\n",
       "                      [ 0.0050,  0.0267,  0.0099,  ...,  0.0100, -0.0112,  0.0074]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.14.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0089,  0.0239,  0.0060,  ..., -0.0315, -0.0093, -0.0018],\n",
       "                      [ 0.0187,  0.0237, -0.0151,  ...,  0.0054,  0.0014,  0.0152],\n",
       "                      [ 0.0007, -0.0449,  0.0204,  ...,  0.0010, -0.0271,  0.0109],\n",
       "                      ...,\n",
       "                      [-0.0020,  0.0179, -0.0124,  ..., -0.0043, -0.0190, -0.0183],\n",
       "                      [ 0.0176,  0.0308,  0.0280,  ..., -0.0042, -0.0150,  0.0322],\n",
       "                      [-0.0189,  0.0128, -0.0132,  ..., -0.0292,  0.0121,  0.0178]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.14.input_layernorm.weight',\n",
       "              tensor([0.4102, 0.4199, 0.3711,  ..., 0.4023, 0.3906, 0.3867], device='cuda:0')),\n",
       "             ('model.layers.14.post_attention_layernorm.weight',\n",
       "              tensor([0.2715, 0.2598, 0.2598,  ..., 0.2754, 0.2734, 0.2676], device='cuda:0')),\n",
       "             ('model.layers.15.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0084, -0.0201, -0.0044,  ...,  0.0093, -0.0074,  0.0082],\n",
       "                      [ 0.0243, -0.0220,  0.0089,  ..., -0.0015,  0.0042,  0.0055],\n",
       "                      [ 0.0056, -0.0066,  0.0037,  ...,  0.0154, -0.0034, -0.0128],\n",
       "                      ...,\n",
       "                      [-0.0469, -0.0342,  0.0104,  ..., -0.0138, -0.0096,  0.0305],\n",
       "                      [-0.0171, -0.0549,  0.0192,  ...,  0.0166, -0.0063,  0.0041],\n",
       "                      [ 0.0198,  0.0194,  0.0281,  ..., -0.0008, -0.0198, -0.0143]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.15.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0201, -0.0067, -0.0099,  ..., -0.0020,  0.0073,  0.0012],\n",
       "                      [ 0.0107, -0.0082, -0.0054,  ...,  0.0022,  0.0037, -0.0155],\n",
       "                      [ 0.0027,  0.0043, -0.0035,  ..., -0.0056,  0.0128, -0.0082],\n",
       "                      ...,\n",
       "                      [-0.0405, -0.0496,  0.0255,  ...,  0.0108,  0.0086, -0.0107],\n",
       "                      [ 0.0121,  0.0045,  0.0125,  ...,  0.0286, -0.0140,  0.0168],\n",
       "                      [-0.0229, -0.0067,  0.0295,  ..., -0.0022, -0.0232, -0.0008]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.15.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0093,  0.0003,  0.0048,  ...,  0.0104,  0.0128,  0.0151],\n",
       "                      [-0.0098, -0.0082,  0.0150,  ...,  0.0173,  0.0045,  0.0245],\n",
       "                      [ 0.0059, -0.0349, -0.0065,  ..., -0.0327,  0.0049,  0.0046],\n",
       "                      ...,\n",
       "                      [-0.0060, -0.0032,  0.0146,  ...,  0.0100,  0.0210, -0.0141],\n",
       "                      [ 0.0042,  0.0046, -0.0240,  ...,  0.0136,  0.0134, -0.0063],\n",
       "                      [ 0.0239,  0.0013,  0.0166,  ..., -0.0216,  0.0037,  0.0077]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.15.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0030,  0.0076, -0.0156,  ...,  0.0140, -0.0083,  0.0232],\n",
       "                      [-0.0063, -0.0051, -0.0236,  ...,  0.0129, -0.0330,  0.0186],\n",
       "                      [ 0.0054, -0.0084, -0.0043,  ...,  0.0035, -0.0008,  0.0053],\n",
       "                      ...,\n",
       "                      [-0.0078, -0.0232,  0.0119,  ..., -0.0071, -0.0251, -0.0109],\n",
       "                      [-0.0051, -0.0063, -0.0030,  ...,  0.0126,  0.0036, -0.0035],\n",
       "                      [-0.0243,  0.0037,  0.0262,  ..., -0.0057, -0.0337, -0.0262]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.15.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0091,  0.0282, -0.0156,  ...,  0.0105, -0.0223,  0.0275],\n",
       "                      [ 0.0110, -0.0096,  0.0315,  ..., -0.0149,  0.0101,  0.0083],\n",
       "                      [ 0.0054, -0.0133, -0.0131,  ...,  0.0271, -0.0500, -0.0160],\n",
       "                      ...,\n",
       "                      [-0.0077,  0.0029,  0.0320,  ..., -0.0069,  0.0120,  0.0094],\n",
       "                      [-0.0065, -0.0143,  0.0078,  ..., -0.0085, -0.0142, -0.0364],\n",
       "                      [ 0.0005, -0.0143,  0.0013,  ..., -0.0015, -0.0023,  0.0070]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.15.mlp.up_proj.weight',\n",
       "              tensor([[-0.0121, -0.0116,  0.0248,  ...,  0.0184,  0.0150, -0.0476],\n",
       "                      [-0.0159,  0.0339,  0.0284,  ...,  0.0045,  0.0044,  0.0029],\n",
       "                      [-0.0437, -0.0006, -0.0088,  ..., -0.0031,  0.0155, -0.0073],\n",
       "                      ...,\n",
       "                      [-0.0126, -0.0177, -0.0068,  ...,  0.0073,  0.0039, -0.0041],\n",
       "                      [ 0.0383, -0.0081,  0.0143,  ..., -0.0063,  0.0165, -0.0014],\n",
       "                      [-0.0056, -0.0221, -0.0198,  ...,  0.0054, -0.0171, -0.0019]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.15.mlp.down_proj.weight',\n",
       "              tensor([[-0.0069, -0.0149, -0.0280,  ...,  0.0249,  0.0122, -0.0111],\n",
       "                      [ 0.0047, -0.0153, -0.0245,  ..., -0.0123, -0.0204,  0.0179],\n",
       "                      [ 0.0405,  0.0481, -0.0251,  ..., -0.0095,  0.0347,  0.0170],\n",
       "                      ...,\n",
       "                      [-0.0137, -0.0427,  0.0125,  ...,  0.0078, -0.0023,  0.0024],\n",
       "                      [-0.0369, -0.0179, -0.0025,  ..., -0.0277, -0.0173,  0.0036],\n",
       "                      [ 0.0033,  0.0293, -0.0069,  ..., -0.0117, -0.0286, -0.0234]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.15.input_layernorm.weight',\n",
       "              tensor([0.4023, 0.3965, 0.3730,  ..., 0.3789, 0.3809, 0.3828], device='cuda:0')),\n",
       "             ('model.layers.15.post_attention_layernorm.weight',\n",
       "              tensor([0.2852, 0.2715, 0.2695,  ..., 0.2832, 0.2832, 0.2793], device='cuda:0')),\n",
       "             ('model.layers.16.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0109,  0.0077, -0.0206,  ...,  0.0067,  0.0242, -0.0063],\n",
       "                      [ 0.0178, -0.0420,  0.0187,  ...,  0.0162,  0.0068, -0.0204],\n",
       "                      [-0.0107, -0.0007,  0.0060,  ..., -0.0219, -0.0061, -0.0229],\n",
       "                      ...,\n",
       "                      [ 0.0223, -0.0303, -0.0021,  ..., -0.0204,  0.0225, -0.0186],\n",
       "                      [-0.0132, -0.0113,  0.0267,  ...,  0.0013, -0.0208,  0.0129],\n",
       "                      [ 0.0076,  0.0173,  0.0160,  ..., -0.0051, -0.0292, -0.0124]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.16.self_attn.k_proj.weight',\n",
       "              tensor([[-1.6235e-02,  2.0630e-02,  6.3782e-03,  ...,  5.6152e-03,\n",
       "                        1.7944e-02,  2.1973e-02],\n",
       "                      [ 2.2705e-02, -3.4424e-02,  7.9956e-03,  ..., -3.6001e-05,\n",
       "                       -2.6245e-02, -2.8839e-03],\n",
       "                      [ 2.7222e-02, -4.9133e-03, -1.2512e-02,  ..., -2.0020e-02,\n",
       "                        2.9144e-03, -3.4180e-02],\n",
       "                      ...,\n",
       "                      [ 1.4832e-02,  1.1292e-02, -1.4038e-02,  ..., -2.4658e-02,\n",
       "                       -2.4292e-02, -5.3223e-02],\n",
       "                      [ 1.8799e-02,  9.0942e-03,  1.4954e-02,  ...,  2.3926e-02,\n",
       "                        1.1841e-02,  1.2329e-02],\n",
       "                      [-3.6865e-02,  5.0049e-02,  6.1035e-02,  ..., -7.7248e-05,\n",
       "                       -1.5747e-02,  3.0640e-02]], device='cuda:0')),\n",
       "             ('model.layers.16.self_attn.v_proj.weight',\n",
       "              tensor([[-9.3384e-03, -4.7112e-04, -5.0354e-03,  ...,  6.0425e-03,\n",
       "                       -3.3417e-03, -6.5002e-03],\n",
       "                      [-5.6885e-02, -7.5073e-03, -3.9368e-03,  ...,  6.4087e-03,\n",
       "                        1.5320e-02, -2.6611e-02],\n",
       "                      [-2.7008e-03, -3.4943e-03, -5.7678e-03,  ..., -2.4170e-02,\n",
       "                        4.3701e-02,  1.4526e-02],\n",
       "                      ...,\n",
       "                      [ 9.2773e-03, -2.1667e-03,  1.3123e-02,  ..., -1.7090e-02,\n",
       "                        4.5471e-03,  1.7090e-02],\n",
       "                      [-2.0508e-02,  7.6294e-05,  4.4250e-03,  ...,  3.4912e-02,\n",
       "                       -2.4872e-03,  1.0986e-02],\n",
       "                      [ 1.1719e-02,  1.1108e-02,  7.5378e-03,  ..., -9.3994e-03,\n",
       "                        2.0294e-03, -2.9663e-02]], device='cuda:0')),\n",
       "             ('model.layers.16.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0437, -0.0002, -0.0192,  ...,  0.0077, -0.0146,  0.0025],\n",
       "                      [-0.0231,  0.0112, -0.0223,  ..., -0.0064, -0.0013, -0.0015],\n",
       "                      [-0.0275, -0.0107, -0.0063,  ...,  0.0013,  0.0270,  0.0139],\n",
       "                      ...,\n",
       "                      [-0.0065, -0.0171,  0.0080,  ...,  0.0046, -0.0215,  0.0016],\n",
       "                      [-0.0073,  0.0251,  0.0327,  ..., -0.0029,  0.0084, -0.0154],\n",
       "                      [-0.0171,  0.0015,  0.0027,  ..., -0.0024, -0.0031, -0.0004]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.16.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0183, -0.0167, -0.0240,  ...,  0.0058, -0.0028,  0.0134],\n",
       "                      [ 0.0327,  0.0171, -0.0106,  ...,  0.0110,  0.0081,  0.0199],\n",
       "                      [-0.0074,  0.0173, -0.0044,  ...,  0.0076, -0.0029, -0.0243],\n",
       "                      ...,\n",
       "                      [-0.0037,  0.0201,  0.0009,  ...,  0.0233,  0.0234,  0.0052],\n",
       "                      [ 0.0027, -0.0085,  0.0119,  ...,  0.0171,  0.0204,  0.0211],\n",
       "                      [ 0.0320,  0.0206,  0.0352,  ..., -0.0356,  0.0234, -0.0113]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.16.mlp.up_proj.weight',\n",
       "              tensor([[-0.0347,  0.0107,  0.0026,  ...,  0.0187, -0.0162,  0.0061],\n",
       "                      [ 0.0147, -0.0137,  0.0098,  ...,  0.0184, -0.0240, -0.0081],\n",
       "                      [-0.0092, -0.0205, -0.0074,  ..., -0.0113,  0.0078,  0.0244],\n",
       "                      ...,\n",
       "                      [ 0.0035,  0.0262, -0.0079,  ...,  0.0030, -0.0107, -0.0184],\n",
       "                      [-0.0135,  0.0225, -0.0210,  ...,  0.0113, -0.0148,  0.0137],\n",
       "                      [ 0.0045,  0.0043, -0.0022,  ...,  0.0025, -0.0231, -0.0238]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.16.mlp.down_proj.weight',\n",
       "              tensor([[-0.0173, -0.0026,  0.0178,  ...,  0.0275, -0.0044,  0.0050],\n",
       "                      [-0.0234, -0.0040, -0.0126,  ...,  0.0262,  0.0012, -0.0026],\n",
       "                      [-0.0167,  0.0027, -0.0118,  ...,  0.0236, -0.0073, -0.0065],\n",
       "                      ...,\n",
       "                      [ 0.0134, -0.0237, -0.0240,  ...,  0.0109,  0.0153,  0.0008],\n",
       "                      [ 0.0150,  0.0053, -0.0102,  ..., -0.0132, -0.0123, -0.0074],\n",
       "                      [ 0.0106, -0.0149, -0.0273,  ...,  0.0273,  0.0027, -0.0137]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.16.input_layernorm.weight',\n",
       "              tensor([0.4062, 0.4102, 0.3828,  ..., 0.3828, 0.3984, 0.3965], device='cuda:0')),\n",
       "             ('model.layers.16.post_attention_layernorm.weight',\n",
       "              tensor([0.3008, 0.2871, 0.2910,  ..., 0.3008, 0.3047, 0.2969], device='cuda:0')),\n",
       "             ('model.layers.17.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0172, -0.0142,  0.0140,  ..., -0.0050, -0.0112, -0.0049],\n",
       "                      [ 0.0108, -0.0096,  0.0216,  ..., -0.0012, -0.0209,  0.0028],\n",
       "                      [-0.0131, -0.0025, -0.0114,  ...,  0.0184, -0.0079, -0.0024],\n",
       "                      ...,\n",
       "                      [ 0.0366, -0.0280,  0.0549,  ..., -0.0139, -0.0189,  0.0120],\n",
       "                      [ 0.0227, -0.0208,  0.0486,  ...,  0.0117, -0.0150, -0.0603],\n",
       "                      [ 0.0192, -0.0099,  0.0160,  ...,  0.0281,  0.0034,  0.0591]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.17.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0134,  0.0023,  0.0081,  ..., -0.0045,  0.0140,  0.0092],\n",
       "                      [ 0.0063,  0.0082,  0.0066,  ...,  0.0096, -0.0018, -0.0084],\n",
       "                      [ 0.0016, -0.0127,  0.0012,  ...,  0.0204, -0.0104, -0.0126],\n",
       "                      ...,\n",
       "                      [-0.0007, -0.0610, -0.0109,  ..., -0.0135,  0.0510, -0.0679],\n",
       "                      [ 0.0262,  0.0220,  0.0147,  ..., -0.0140, -0.0206, -0.0194],\n",
       "                      [-0.0374, -0.0457, -0.0011,  ...,  0.0327,  0.0247, -0.0057]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.17.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0120,  0.0075,  0.0059,  ...,  0.0239, -0.0092, -0.0037],\n",
       "                      [-0.0032, -0.0117, -0.0084,  ...,  0.0087, -0.0245, -0.0166],\n",
       "                      [ 0.0151,  0.0112, -0.0037,  ...,  0.0044, -0.0100, -0.0233],\n",
       "                      ...,\n",
       "                      [ 0.0094, -0.0049,  0.0144,  ...,  0.0095,  0.0067, -0.0128],\n",
       "                      [ 0.0159,  0.0049, -0.0388,  ..., -0.0220,  0.0008, -0.0298],\n",
       "                      [-0.0062, -0.0080,  0.0002,  ...,  0.0078,  0.0092,  0.0065]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.17.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0026, -0.0060,  0.0064,  ..., -0.0176,  0.0027, -0.0078],\n",
       "                      [-0.0140, -0.0221,  0.0232,  ...,  0.0273, -0.0064,  0.0197],\n",
       "                      [ 0.0120, -0.0138, -0.0052,  ..., -0.0144, -0.0024, -0.0179],\n",
       "                      ...,\n",
       "                      [-0.0094,  0.0117, -0.0170,  ..., -0.0265, -0.0278, -0.0195],\n",
       "                      [-0.0104,  0.0104, -0.0046,  ..., -0.0217, -0.0018,  0.0066],\n",
       "                      [-0.0171, -0.0096,  0.0136,  ...,  0.0304, -0.0178,  0.0150]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.17.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0359,  0.0232,  0.0179,  ...,  0.0091, -0.0060,  0.0065],\n",
       "                      [-0.0017,  0.0320,  0.0170,  ...,  0.0159, -0.0018,  0.0102],\n",
       "                      [ 0.0122,  0.0108, -0.0225,  ...,  0.0066,  0.0208, -0.0045],\n",
       "                      ...,\n",
       "                      [-0.0110, -0.0083, -0.0145,  ..., -0.0046, -0.0137, -0.0076],\n",
       "                      [ 0.0066, -0.0013, -0.0010,  ...,  0.0032,  0.0374, -0.0026],\n",
       "                      [-0.0026,  0.0211,  0.0148,  ..., -0.0132,  0.0078, -0.0022]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.17.mlp.up_proj.weight',\n",
       "              tensor([[-0.0084, -0.0251, -0.0070,  ...,  0.0067,  0.0167, -0.0132],\n",
       "                      [-0.0210,  0.0160,  0.0149,  ..., -0.0049, -0.0008,  0.0069],\n",
       "                      [ 0.0005, -0.0028, -0.0031,  ...,  0.0110, -0.0208,  0.0107],\n",
       "                      ...,\n",
       "                      [ 0.0117,  0.0156,  0.0065,  ...,  0.0063, -0.0142, -0.0120],\n",
       "                      [-0.0081, -0.0168, -0.0122,  ..., -0.0062, -0.0170,  0.0076],\n",
       "                      [ 0.0032,  0.0065, -0.0039,  ...,  0.0046, -0.0349, -0.0170]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.17.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0227, -0.0203,  0.0064,  ...,  0.0041, -0.0070, -0.0088],\n",
       "                      [ 0.0221,  0.0240,  0.0146,  ...,  0.0027, -0.0092,  0.0303],\n",
       "                      [-0.0258, -0.0183, -0.0128,  ...,  0.0106, -0.0116,  0.0048],\n",
       "                      ...,\n",
       "                      [ 0.0045, -0.0167, -0.0060,  ..., -0.0127, -0.0004, -0.0272],\n",
       "                      [ 0.0045,  0.0007, -0.0075,  ..., -0.0198, -0.0221,  0.0212],\n",
       "                      [ 0.0037, -0.0205,  0.0162,  ..., -0.0322, -0.0104,  0.0023]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.17.input_layernorm.weight',\n",
       "              tensor([0.4180, 0.4238, 0.3984,  ..., 0.4160, 0.4199, 0.3984], device='cuda:0')),\n",
       "             ('model.layers.17.post_attention_layernorm.weight',\n",
       "              tensor([0.3184, 0.3086, 0.3086,  ..., 0.3184, 0.3203, 0.3125], device='cuda:0')),\n",
       "             ('model.layers.18.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0089,  0.0058,  0.0020,  ..., -0.0103, -0.0405,  0.0058],\n",
       "                      [ 0.0008, -0.0075,  0.0127,  ..., -0.0056,  0.0190,  0.0425],\n",
       "                      [ 0.0026, -0.0189, -0.0156,  ...,  0.0009, -0.0095,  0.0089],\n",
       "                      ...,\n",
       "                      [-0.0286,  0.0146, -0.0089,  ...,  0.0292,  0.0038,  0.0198],\n",
       "                      [ 0.0640, -0.0175, -0.0266,  ...,  0.0566,  0.0317,  0.0076],\n",
       "                      [ 0.0266,  0.0177, -0.0036,  ...,  0.0222,  0.0430, -0.0466]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.18.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0134,  0.0258, -0.0082,  ...,  0.0179, -0.0164, -0.0256],\n",
       "                      [ 0.0082, -0.0160,  0.0096,  ...,  0.0206,  0.0266,  0.0016],\n",
       "                      [ 0.0110,  0.0010,  0.0066,  ...,  0.0356, -0.0168,  0.0227],\n",
       "                      ...,\n",
       "                      [-0.1084, -0.0178, -0.0649,  ...,  0.0244, -0.0032, -0.0442],\n",
       "                      [ 0.0466,  0.0386, -0.0117,  ...,  0.0376,  0.0659, -0.0339],\n",
       "                      [-0.0417, -0.0435, -0.0449,  ...,  0.0310, -0.0135, -0.0288]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.18.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0247,  0.0192, -0.0192,  ...,  0.0012,  0.0292,  0.0087],\n",
       "                      [ 0.0121,  0.0034, -0.0029,  ..., -0.0216,  0.0383,  0.0027],\n",
       "                      [-0.0016,  0.0108, -0.0058,  ...,  0.0078, -0.0008, -0.0097],\n",
       "                      ...,\n",
       "                      [ 0.0150,  0.0140, -0.0045,  ..., -0.0052, -0.0194, -0.0064],\n",
       "                      [ 0.0031, -0.0030,  0.0003,  ...,  0.0118,  0.0084,  0.0300],\n",
       "                      [-0.0042,  0.0056,  0.0072,  ..., -0.0057, -0.0093, -0.0008]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.18.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0178,  0.0115, -0.0108,  ...,  0.0090,  0.0273,  0.0175],\n",
       "                      [-0.0031, -0.0378,  0.0100,  ...,  0.0039, -0.0072, -0.0287],\n",
       "                      [-0.0037, -0.0187,  0.0150,  ...,  0.0255,  0.0194,  0.0298],\n",
       "                      ...,\n",
       "                      [-0.0332, -0.0156, -0.0249,  ...,  0.0159,  0.0116,  0.0024],\n",
       "                      [ 0.0206,  0.0537,  0.0139,  ...,  0.0107, -0.0050, -0.0347],\n",
       "                      [-0.0157, -0.0464, -0.0194,  ..., -0.0127,  0.0093, -0.0152]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.18.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0142, -0.0039,  0.0118,  ..., -0.0041,  0.0160,  0.0003],\n",
       "                      [-0.0391,  0.0082, -0.0167,  ..., -0.0035, -0.0141,  0.0004],\n",
       "                      [-0.0203,  0.0113,  0.0403,  ..., -0.0251, -0.0060,  0.0013],\n",
       "                      ...,\n",
       "                      [-0.0364, -0.0276, -0.0317,  ..., -0.0288, -0.0164, -0.0206],\n",
       "                      [ 0.0042,  0.0210,  0.0173,  ..., -0.0117, -0.0002,  0.0098],\n",
       "                      [-0.0004, -0.0061,  0.0095,  ...,  0.0083, -0.0051,  0.0026]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.18.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0115,  0.0106,  0.0322,  ...,  0.0036,  0.0206, -0.0100],\n",
       "                      [-0.0147,  0.0287, -0.0308,  ...,  0.0014, -0.0034,  0.0074],\n",
       "                      [-0.0264, -0.0099,  0.0074,  ...,  0.0135,  0.0143,  0.0229],\n",
       "                      ...,\n",
       "                      [-0.0038,  0.0070,  0.0081,  ...,  0.0193, -0.0027,  0.0084],\n",
       "                      [-0.0068, -0.0010, -0.0097,  ...,  0.0194,  0.0221,  0.0374],\n",
       "                      [ 0.0106,  0.0205,  0.0092,  ..., -0.0146,  0.0151,  0.0159]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.18.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0254,  0.0072, -0.0308,  ...,  0.0408,  0.0110,  0.0160],\n",
       "                      [ 0.0212,  0.0073,  0.0225,  ..., -0.0031, -0.0008, -0.0034],\n",
       "                      [ 0.0038, -0.0186, -0.0337,  ...,  0.0167, -0.0011,  0.0171],\n",
       "                      ...,\n",
       "                      [-0.0115,  0.0125,  0.0157,  ...,  0.0231, -0.0017, -0.0101],\n",
       "                      [-0.0199,  0.0022,  0.0134,  ...,  0.0098,  0.0359,  0.0011],\n",
       "                      [-0.0003,  0.0208,  0.0184,  ..., -0.0069,  0.0203,  0.0178]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.18.input_layernorm.weight',\n",
       "              tensor([0.4453, 0.4414, 0.4219,  ..., 0.4258, 0.4375, 0.4219], device='cuda:0')),\n",
       "             ('model.layers.18.post_attention_layernorm.weight',\n",
       "              tensor([0.3379, 0.3262, 0.3262,  ..., 0.3340, 0.3379, 0.3320], device='cuda:0')),\n",
       "             ('model.layers.19.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0014,  0.0074, -0.0079,  ..., -0.0157, -0.0041,  0.0118],\n",
       "                      [-0.0045, -0.0081,  0.0010,  ...,  0.0005,  0.0278, -0.0073],\n",
       "                      [ 0.0090,  0.0247,  0.0053,  ...,  0.0087,  0.0188,  0.0016],\n",
       "                      ...,\n",
       "                      [-0.0226, -0.0192, -0.0014,  ..., -0.0425, -0.0002,  0.0272],\n",
       "                      [ 0.0073,  0.0371,  0.0266,  ...,  0.0530,  0.0145, -0.0286],\n",
       "                      [-0.0137,  0.0281,  0.0522,  ..., -0.0033, -0.0405, -0.0124]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.19.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0192,  0.0116,  0.0011,  ..., -0.0075, -0.0031, -0.0142],\n",
       "                      [-0.0159,  0.0214, -0.0179,  ...,  0.0148,  0.0034,  0.0153],\n",
       "                      [-0.0197,  0.0079, -0.0187,  ..., -0.0002,  0.0142,  0.0201],\n",
       "                      ...,\n",
       "                      [ 0.0002,  0.0415, -0.0136,  ..., -0.0181,  0.0236, -0.0281],\n",
       "                      [-0.0698, -0.0299, -0.0031,  ...,  0.0215,  0.0131, -0.0107],\n",
       "                      [-0.0181,  0.0085, -0.0214,  ..., -0.0247,  0.0166,  0.0349]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.19.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0039, -0.0044, -0.0026,  ...,  0.0072, -0.0033,  0.0077],\n",
       "                      [ 0.0034,  0.0216,  0.0015,  ...,  0.0376, -0.0153, -0.0013],\n",
       "                      [-0.0442, -0.0255, -0.0038,  ..., -0.0056, -0.0053,  0.0145],\n",
       "                      ...,\n",
       "                      [-0.0003, -0.0378, -0.0043,  ...,  0.0008,  0.0066, -0.0182],\n",
       "                      [ 0.0139, -0.0042, -0.0239,  ..., -0.0101, -0.0089, -0.0039],\n",
       "                      [-0.0021,  0.0221, -0.0018,  ..., -0.0258, -0.0134,  0.0134]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.19.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0214, -0.0562,  0.0236,  ..., -0.0018,  0.0014, -0.0249],\n",
       "                      [ 0.0244, -0.0067,  0.0047,  ..., -0.0131,  0.0082, -0.0051],\n",
       "                      [-0.0049, -0.0128, -0.0271,  ...,  0.0032,  0.0082, -0.0015],\n",
       "                      ...,\n",
       "                      [ 0.0145, -0.0071, -0.0095,  ...,  0.0107, -0.0181,  0.0121],\n",
       "                      [ 0.0077, -0.0008, -0.0108,  ..., -0.0096, -0.0172,  0.0020],\n",
       "                      [ 0.0099,  0.0194,  0.0096,  ..., -0.0192, -0.0097,  0.0126]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.19.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0123,  0.0032,  0.0096,  ...,  0.0032,  0.0033, -0.0015],\n",
       "                      [ 0.0100,  0.0206,  0.0058,  ...,  0.0057,  0.0145, -0.0359],\n",
       "                      [-0.0052, -0.0033, -0.0192,  ..., -0.0383, -0.0068,  0.0161],\n",
       "                      ...,\n",
       "                      [ 0.0013,  0.0026,  0.0043,  ..., -0.0211, -0.0056,  0.0029],\n",
       "                      [-0.0496,  0.0007, -0.0019,  ..., -0.0040, -0.0250,  0.0139],\n",
       "                      [-0.0259, -0.0234,  0.0122,  ..., -0.0021,  0.0096,  0.0022]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.19.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0008, -0.0065,  0.0054,  ...,  0.0042,  0.0110,  0.0061],\n",
       "                      [-0.0095, -0.0008, -0.0122,  ...,  0.0249, -0.0220, -0.0121],\n",
       "                      [ 0.0152,  0.0056,  0.0171,  ..., -0.0161, -0.0125,  0.0491],\n",
       "                      ...,\n",
       "                      [ 0.0125,  0.0159, -0.0089,  ...,  0.0199, -0.0129,  0.0359],\n",
       "                      [ 0.0039,  0.0240,  0.0361,  ..., -0.0140,  0.0327, -0.0153],\n",
       "                      [ 0.0025, -0.0190, -0.0107,  ..., -0.0017, -0.0014,  0.0082]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.19.mlp.down_proj.weight',\n",
       "              tensor([[-0.0050, -0.0172,  0.0054,  ...,  0.0040, -0.0160,  0.0155],\n",
       "                      [-0.0091, -0.0393, -0.0247,  ...,  0.0110,  0.0077, -0.0075],\n",
       "                      [-0.0227, -0.0186,  0.0234,  ...,  0.0053, -0.0045,  0.0067],\n",
       "                      ...,\n",
       "                      [-0.0076, -0.0057,  0.0184,  ...,  0.0164,  0.0178, -0.0020],\n",
       "                      [ 0.0066, -0.0148, -0.0413,  ...,  0.0283, -0.0083, -0.0144],\n",
       "                      [ 0.0081, -0.0060, -0.0266,  ...,  0.0010,  0.0068,  0.0075]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.19.input_layernorm.weight',\n",
       "              tensor([0.4473, 0.4531, 0.4316,  ..., 0.4219, 0.4277, 0.4316], device='cuda:0')),\n",
       "             ('model.layers.19.post_attention_layernorm.weight',\n",
       "              tensor([0.3516, 0.3379, 0.3398,  ..., 0.3477, 0.3477, 0.3438], device='cuda:0')),\n",
       "             ('model.layers.20.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0014, -0.0043,  0.0161,  ...,  0.0114,  0.0020, -0.0228],\n",
       "                      [ 0.0074, -0.0201,  0.0086,  ..., -0.0083, -0.0076,  0.0087],\n",
       "                      [ 0.0017, -0.0041, -0.0079,  ...,  0.0122, -0.0023, -0.0042],\n",
       "                      ...,\n",
       "                      [-0.0223, -0.0405,  0.0114,  ..., -0.0027,  0.0179,  0.0040],\n",
       "                      [-0.0718, -0.0175,  0.0130,  ...,  0.0101,  0.0208,  0.0061],\n",
       "                      [ 0.0167, -0.0005, -0.0065,  ..., -0.0154, -0.0087, -0.0028]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.20.self_attn.k_proj.weight',\n",
       "              tensor([[-3.0060e-03,  5.8289e-03,  6.1951e-03,  ..., -2.8992e-03,\n",
       "                        3.3722e-03,  4.6997e-03],\n",
       "                      [ 3.5706e-03,  8.2397e-03,  3.8147e-03,  ..., -9.8228e-05,\n",
       "                       -2.0142e-03,  1.1230e-02],\n",
       "                      [ 3.3569e-03,  4.4556e-03, -7.5684e-03,  ..., -5.0964e-03,\n",
       "                        5.5847e-03,  1.7822e-02],\n",
       "                      ...,\n",
       "                      [ 6.5231e-04, -2.5330e-03, -2.1851e-02,  ..., -1.8311e-02,\n",
       "                        2.3193e-02,  2.6733e-02],\n",
       "                      [-1.8188e-02,  1.8799e-02, -2.3041e-03,  ...,  2.2949e-02,\n",
       "                        1.9531e-02,  5.9570e-02],\n",
       "                      [-1.5015e-02, -2.7832e-02, -1.3977e-02,  ...,  2.6001e-02,\n",
       "                       -2.7222e-02,  4.5410e-02]], device='cuda:0')),\n",
       "             ('model.layers.20.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0036, -0.0106,  0.0136,  ..., -0.0045,  0.0110,  0.0111],\n",
       "                      [-0.0076, -0.0425, -0.0006,  ..., -0.0085,  0.0015,  0.0090],\n",
       "                      [-0.0081, -0.0137,  0.0010,  ..., -0.0203, -0.0005,  0.0013],\n",
       "                      ...,\n",
       "                      [ 0.0073, -0.0082, -0.0041,  ...,  0.0195, -0.0038,  0.0075],\n",
       "                      [ 0.0176,  0.0087, -0.0077,  ...,  0.0019,  0.0129, -0.0089],\n",
       "                      [ 0.0004, -0.0046,  0.0260,  ..., -0.0082, -0.0112, -0.0393]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.20.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0068,  0.0036,  0.0297,  ..., -0.0024,  0.0175, -0.0092],\n",
       "                      [ 0.0100, -0.0126, -0.0095,  ..., -0.0008, -0.0096,  0.0225],\n",
       "                      [ 0.0156, -0.0027, -0.0115,  ..., -0.0266,  0.0019,  0.0101],\n",
       "                      ...,\n",
       "                      [-0.0133,  0.0010,  0.0055,  ...,  0.0138, -0.0150,  0.0112],\n",
       "                      [ 0.0054,  0.0151, -0.0148,  ...,  0.0123, -0.0269,  0.0030],\n",
       "                      [ 0.0188, -0.0237, -0.0051,  ...,  0.0156, -0.0211,  0.0117]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.20.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0005, -0.0031, -0.0215,  ...,  0.0221, -0.0096,  0.0132],\n",
       "                      [-0.0171,  0.0062, -0.0081,  ..., -0.0045, -0.0104,  0.0162],\n",
       "                      [-0.0128, -0.0071,  0.0569,  ..., -0.0198,  0.0223, -0.0029],\n",
       "                      ...,\n",
       "                      [ 0.0012, -0.0066,  0.0258,  ..., -0.0233,  0.0056, -0.0036],\n",
       "                      [ 0.0121,  0.0031,  0.0107,  ...,  0.0199,  0.0002,  0.0140],\n",
       "                      [-0.0073, -0.0231, -0.0145,  ...,  0.0029, -0.0286, -0.0047]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.20.mlp.up_proj.weight',\n",
       "              tensor([[-0.0581, -0.0013,  0.0004,  ...,  0.0138, -0.0107, -0.0104],\n",
       "                      [-0.0107,  0.0062, -0.0101,  ..., -0.0439, -0.0157,  0.0376],\n",
       "                      [ 0.0106,  0.0327,  0.0188,  ...,  0.0089, -0.0198,  0.0076],\n",
       "                      ...,\n",
       "                      [-0.0142,  0.0251, -0.0096,  ..., -0.0177, -0.0046,  0.0007],\n",
       "                      [ 0.0157, -0.0255, -0.0162,  ...,  0.0029, -0.0214, -0.0354],\n",
       "                      [ 0.0144, -0.0236,  0.0278,  ..., -0.0116, -0.0197, -0.0086]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.20.mlp.down_proj.weight',\n",
       "              tensor([[-0.0028,  0.0251, -0.0037,  ..., -0.0085, -0.0093, -0.0298],\n",
       "                      [-0.0010,  0.0173, -0.0082,  ...,  0.0090, -0.0190,  0.0231],\n",
       "                      [-0.0094,  0.0116, -0.0225,  ..., -0.0067,  0.0239, -0.0155],\n",
       "                      ...,\n",
       "                      [-0.0315,  0.0304,  0.0065,  ...,  0.0129, -0.0008, -0.0005],\n",
       "                      [-0.0108,  0.0051, -0.0150,  ..., -0.0125,  0.0149, -0.0111],\n",
       "                      [ 0.0118,  0.0025, -0.0005,  ..., -0.0007, -0.0081, -0.0056]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.20.input_layernorm.weight',\n",
       "              tensor([0.4473, 0.4609, 0.4316,  ..., 0.4297, 0.4316, 0.4434], device='cuda:0')),\n",
       "             ('model.layers.20.post_attention_layernorm.weight',\n",
       "              tensor([0.3613, 0.3535, 0.3496,  ..., 0.3633, 0.3574, 0.3535], device='cuda:0')),\n",
       "             ('model.layers.21.self_attn.q_proj.weight',\n",
       "              tensor([[-1.6479e-02, -4.6997e-03,  1.7090e-02,  ..., -5.5542e-03,\n",
       "                        6.2561e-03, -5.8899e-03],\n",
       "                      [ 1.4893e-02, -2.1935e-05, -5.4626e-03,  ...,  7.8125e-03,\n",
       "                       -2.4796e-05,  1.8311e-02],\n",
       "                      [-1.0864e-02, -6.1646e-03, -4.4823e-05,  ...,  2.8442e-02,\n",
       "                       -7.0801e-03,  1.0223e-03],\n",
       "                      ...,\n",
       "                      [ 1.3275e-03, -6.3171e-03,  2.8687e-02,  ..., -1.1841e-02,\n",
       "                       -5.1270e-02,  8.5449e-03],\n",
       "                      [-1.2451e-02,  1.5991e-02,  1.9409e-02,  ...,  2.4658e-02,\n",
       "                        3.5889e-02, -5.5237e-03],\n",
       "                      [-7.3730e-02, -1.3123e-02, -8.7280e-03,  ..., -8.4839e-03,\n",
       "                        1.4343e-02, -4.2236e-02]], device='cuda:0')),\n",
       "             ('model.layers.21.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0067,  0.0115,  0.0045,  ...,  0.0127, -0.0012,  0.0039],\n",
       "                      [-0.0019,  0.0079,  0.0135,  ...,  0.0061,  0.0071,  0.0148],\n",
       "                      [ 0.0095,  0.0030,  0.0334,  ...,  0.0146, -0.0004,  0.0034],\n",
       "                      ...,\n",
       "                      [-0.0165,  0.0178,  0.0059,  ...,  0.0240, -0.0371,  0.0461],\n",
       "                      [ 0.0005,  0.0039, -0.0119,  ..., -0.0147,  0.0278, -0.0073],\n",
       "                      [-0.0229,  0.0053, -0.0188,  ..., -0.0004, -0.0187,  0.0625]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.21.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0010,  0.0084, -0.0036,  ..., -0.0043,  0.0195, -0.0237],\n",
       "                      [-0.0265,  0.0262, -0.0071,  ...,  0.0210, -0.0211,  0.0265],\n",
       "                      [ 0.0220,  0.0029, -0.0049,  ..., -0.0209,  0.0214, -0.0082],\n",
       "                      ...,\n",
       "                      [-0.0073, -0.0232,  0.0325,  ...,  0.0014, -0.0002, -0.0170],\n",
       "                      [-0.0161, -0.0125,  0.0137,  ...,  0.0079, -0.0018,  0.0189],\n",
       "                      [-0.0095,  0.0188, -0.0142,  ...,  0.0052, -0.0146,  0.0004]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.21.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0133, -0.0006,  0.0116,  ..., -0.0107,  0.0251, -0.0027],\n",
       "                      [-0.0050,  0.0238, -0.0112,  ..., -0.0281,  0.0091, -0.0052],\n",
       "                      [-0.0175, -0.0126,  0.0063,  ...,  0.0255,  0.0297,  0.0159],\n",
       "                      ...,\n",
       "                      [ 0.0088, -0.0085, -0.0128,  ...,  0.0215,  0.0079,  0.0190],\n",
       "                      [ 0.0223, -0.0075,  0.0131,  ..., -0.0100,  0.0086, -0.0164],\n",
       "                      [-0.0206,  0.0154, -0.0133,  ...,  0.0327, -0.0193,  0.0027]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.21.mlp.gate_proj.weight',\n",
       "              tensor([[-2.2736e-03, -2.0874e-02,  1.2085e-02,  ..., -3.2715e-02,\n",
       "                        4.0039e-02,  1.6357e-02],\n",
       "                      [ 1.2939e-02,  9.9487e-03,  9.3384e-03,  ..., -3.6865e-02,\n",
       "                        5.1758e-02,  6.5308e-03],\n",
       "                      [ 1.2451e-02,  6.1035e-03,  2.1667e-03,  ..., -4.1016e-02,\n",
       "                       -3.9673e-03, -1.9409e-02],\n",
       "                      ...,\n",
       "                      [ 1.1475e-02, -2.6367e-02, -2.8076e-02,  ...,  3.3936e-02,\n",
       "                       -2.5024e-02,  1.3885e-03],\n",
       "                      [-3.2196e-03,  2.9663e-02,  8.1177e-03,  ...,  9.3384e-03,\n",
       "                       -2.1851e-02,  5.9509e-03],\n",
       "                      [ 1.8082e-03, -9.2773e-03, -2.0752e-03,  ..., -1.6235e-02,\n",
       "                        2.5630e-05,  6.8054e-03]], device='cuda:0')),\n",
       "             ('model.layers.21.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0240, -0.0297, -0.0168,  ...,  0.0223,  0.0369, -0.0137],\n",
       "                      [-0.0234, -0.0147,  0.0002,  ...,  0.0352,  0.0432,  0.0041],\n",
       "                      [ 0.0160, -0.0045, -0.0009,  ...,  0.0026, -0.0115, -0.0075],\n",
       "                      ...,\n",
       "                      [-0.0449, -0.0031,  0.0170,  ...,  0.0139, -0.0081, -0.0090],\n",
       "                      [-0.0017, -0.0114,  0.0066,  ..., -0.0234, -0.0055,  0.0031],\n",
       "                      [-0.0076, -0.0254, -0.0173,  ..., -0.0076, -0.0066, -0.0327]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.21.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0111,  0.0160, -0.0037,  ...,  0.0160,  0.0203,  0.0082],\n",
       "                      [ 0.0164, -0.0044, -0.0139,  ...,  0.0023, -0.0128, -0.0135],\n",
       "                      [-0.0081, -0.0016,  0.0096,  ..., -0.0012,  0.0339,  0.0209],\n",
       "                      ...,\n",
       "                      [-0.0116,  0.0378,  0.0229,  ..., -0.0025,  0.0010,  0.0060],\n",
       "                      [ 0.0160, -0.0010, -0.0031,  ..., -0.0491, -0.0147,  0.0107],\n",
       "                      [ 0.0071,  0.0040,  0.0217,  ..., -0.0135,  0.0188, -0.0212]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.21.input_layernorm.weight',\n",
       "              tensor([0.4727, 0.4805, 0.4629,  ..., 0.4512, 0.4668, 0.4727], device='cuda:0')),\n",
       "             ('model.layers.21.post_attention_layernorm.weight',\n",
       "              tensor([0.3711, 0.3652, 0.3613,  ..., 0.3770, 0.3691, 0.3711], device='cuda:0')),\n",
       "             ('model.layers.22.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0214, -0.0143, -0.0102,  ...,  0.0435, -0.0374,  0.0295],\n",
       "                      [-0.0398, -0.0155, -0.0018,  ..., -0.0405,  0.0123, -0.0413],\n",
       "                      [-0.0303,  0.0233, -0.0140,  ...,  0.0225,  0.0123, -0.0223],\n",
       "                      ...,\n",
       "                      [ 0.0123,  0.0141,  0.0093,  ...,  0.0128,  0.0547, -0.0050],\n",
       "                      [-0.0261, -0.0042, -0.0261,  ...,  0.0466,  0.0040, -0.0211],\n",
       "                      [ 0.0295, -0.0128,  0.0090,  ..., -0.0515,  0.0128,  0.0262]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.22.self_attn.k_proj.weight',\n",
       "              tensor([[-1.8921e-02, -9.9182e-04, -7.4463e-03,  ...,  1.4526e-02,\n",
       "                       -1.3733e-02, -1.7456e-02],\n",
       "                      [ 5.4016e-03, -1.3672e-02,  2.9663e-02,  ..., -2.3315e-02,\n",
       "                        3.5156e-02, -1.6602e-02],\n",
       "                      [-1.8311e-02,  3.3203e-02, -4.2725e-02,  ...,  5.8105e-02,\n",
       "                       -8.1787e-03, -8.5449e-03],\n",
       "                      ...,\n",
       "                      [ 1.9775e-02,  7.8735e-03, -2.6489e-02,  ..., -2.1606e-02,\n",
       "                       -1.3672e-02,  1.7700e-02],\n",
       "                      [-1.1963e-02, -4.5898e-02, -8.1177e-03,  ..., -3.5048e-05,\n",
       "                       -6.8054e-03,  1.7834e-04],\n",
       "                      [ 2.7466e-02,  5.6458e-03,  3.1982e-02,  ...,  3.0151e-02,\n",
       "                       -3.4912e-02,  1.5198e-02]], device='cuda:0')),\n",
       "             ('model.layers.22.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0195,  0.0051, -0.0026,  ..., -0.0449, -0.0248,  0.0223],\n",
       "                      [-0.0309, -0.0143,  0.0104,  ..., -0.0239, -0.0349, -0.0092],\n",
       "                      [ 0.0260, -0.0240, -0.0082,  ...,  0.0483,  0.0015, -0.0147],\n",
       "                      ...,\n",
       "                      [-0.0081, -0.0442, -0.0258,  ...,  0.0146, -0.0051,  0.0153],\n",
       "                      [-0.0359, -0.0160,  0.0250,  ..., -0.0152,  0.0079, -0.0091],\n",
       "                      [-0.0022,  0.0210, -0.0381,  ...,  0.0056,  0.0003,  0.0231]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.22.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0233,  0.0162, -0.0201,  ..., -0.0030, -0.0273,  0.0067],\n",
       "                      [ 0.0339,  0.0137,  0.0048,  ...,  0.0035, -0.0126, -0.0183],\n",
       "                      [ 0.0151,  0.0049, -0.0087,  ..., -0.0283,  0.0083, -0.0032],\n",
       "                      ...,\n",
       "                      [-0.0005, -0.0138, -0.0107,  ..., -0.0156, -0.0184,  0.0021],\n",
       "                      [ 0.0217, -0.0089, -0.0198,  ..., -0.0173, -0.0096,  0.0127],\n",
       "                      [ 0.0022, -0.0236,  0.0253,  ...,  0.0098,  0.0159,  0.0168]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.22.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0186, -0.0153,  0.0258,  ...,  0.0128,  0.0229, -0.0339],\n",
       "                      [ 0.0089, -0.0042,  0.0021,  ...,  0.0011,  0.0026,  0.0179],\n",
       "                      [ 0.0075, -0.0130,  0.0063,  ...,  0.0120,  0.0100, -0.0058],\n",
       "                      ...,\n",
       "                      [-0.0040, -0.0015,  0.0038,  ..., -0.0132,  0.0057, -0.0041],\n",
       "                      [-0.0008,  0.0237, -0.0262,  ..., -0.0012,  0.0151, -0.0215],\n",
       "                      [-0.0096,  0.0061,  0.0031,  ..., -0.0093,  0.0210,  0.0161]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.22.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0303,  0.0204,  0.0036,  ...,  0.0103,  0.0315, -0.0038],\n",
       "                      [ 0.0088,  0.0074,  0.0176,  ..., -0.0139, -0.0058,  0.0020],\n",
       "                      [ 0.0050, -0.0302, -0.0405,  ...,  0.0237,  0.0079,  0.0055],\n",
       "                      ...,\n",
       "                      [-0.0084, -0.0006, -0.0205,  ..., -0.0018,  0.0061,  0.0046],\n",
       "                      [ 0.0167, -0.0129, -0.0209,  ..., -0.0317,  0.0088, -0.0164],\n",
       "                      [-0.0034,  0.0011, -0.0040,  ..., -0.0420, -0.0557,  0.0144]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.22.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0145, -0.0117,  0.0126,  ..., -0.0142,  0.0052, -0.0415],\n",
       "                      [ 0.0030,  0.0201, -0.0093,  ..., -0.0104,  0.0118, -0.0264],\n",
       "                      [-0.0060, -0.0082,  0.0076,  ...,  0.0167,  0.0145,  0.0209],\n",
       "                      ...,\n",
       "                      [ 0.0258, -0.0057, -0.0469,  ..., -0.0067, -0.0171, -0.0208],\n",
       "                      [-0.0134, -0.0471,  0.0103,  ...,  0.0188, -0.0253,  0.0327],\n",
       "                      [ 0.0094, -0.0005, -0.0344,  ..., -0.0042, -0.0162,  0.0090]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.22.input_layernorm.weight',\n",
       "              tensor([0.4805, 0.4805, 0.4707,  ..., 0.4629, 0.4824, 0.4824], device='cuda:0')),\n",
       "             ('model.layers.22.post_attention_layernorm.weight',\n",
       "              tensor([0.3809, 0.3789, 0.3809,  ..., 0.3887, 0.3828, 0.3867], device='cuda:0')),\n",
       "             ('model.layers.23.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0025, -0.0149,  0.0007,  ..., -0.0171, -0.0005,  0.0012],\n",
       "                      [ 0.0090, -0.0020,  0.0101,  ..., -0.0171, -0.0034,  0.0089],\n",
       "                      [-0.0079,  0.0039,  0.0194,  ..., -0.0024, -0.0145,  0.0077],\n",
       "                      ...,\n",
       "                      [-0.0199,  0.0608,  0.0124,  ..., -0.0378, -0.0598, -0.0280],\n",
       "                      [-0.0352, -0.0337,  0.0227,  ..., -0.0166, -0.0039,  0.0095],\n",
       "                      [ 0.0106, -0.0583, -0.0038,  ...,  0.0139,  0.0391, -0.0093]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.23.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0014,  0.0048,  0.0023,  ..., -0.0006, -0.0172,  0.0027],\n",
       "                      [-0.0175, -0.0011, -0.0131,  ...,  0.0164,  0.0142, -0.0032],\n",
       "                      [ 0.0091,  0.0060, -0.0140,  ...,  0.0176,  0.0113, -0.0081],\n",
       "                      ...,\n",
       "                      [ 0.0065,  0.0309,  0.0525,  ..., -0.0293, -0.0136, -0.0190],\n",
       "                      [-0.0004, -0.0306, -0.0114,  ..., -0.0204, -0.0220,  0.0143],\n",
       "                      [-0.0164, -0.0081, -0.0232,  ...,  0.0049,  0.0027, -0.0142]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.23.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0041,  0.0349, -0.0042,  ..., -0.0118, -0.0093, -0.0161],\n",
       "                      [-0.0005, -0.0120, -0.0177,  ...,  0.0047, -0.0110,  0.0037],\n",
       "                      [ 0.0077, -0.0145, -0.0258,  ...,  0.0137, -0.0457, -0.0291],\n",
       "                      ...,\n",
       "                      [ 0.0098,  0.0082,  0.0070,  ..., -0.0010,  0.0299,  0.0120],\n",
       "                      [ 0.0203,  0.0273,  0.0073,  ..., -0.0010, -0.0089, -0.0126],\n",
       "                      [-0.0184, -0.0128, -0.0554,  ...,  0.0092,  0.0095, -0.0315]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.23.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0062, -0.0050, -0.0194,  ..., -0.0177,  0.0135, -0.0073],\n",
       "                      [-0.0103, -0.0165, -0.0022,  ..., -0.0024,  0.0119, -0.0028],\n",
       "                      [ 0.0164,  0.0036,  0.0310,  ..., -0.0142,  0.0060, -0.0215],\n",
       "                      ...,\n",
       "                      [ 0.0352, -0.0063,  0.0364,  ..., -0.0198,  0.0097,  0.0014],\n",
       "                      [-0.0069,  0.0223, -0.0135,  ..., -0.0039, -0.0141, -0.0052],\n",
       "                      [ 0.0117, -0.0060, -0.0115,  ..., -0.0066, -0.0024, -0.0293]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.23.mlp.gate_proj.weight',\n",
       "              tensor([[-8.7280e-03,  2.7466e-02, -3.8338e-04,  ...,  7.4387e-04,\n",
       "                        3.5889e-02,  1.2573e-02],\n",
       "                      [-9.3384e-03,  4.5654e-02, -1.2329e-02,  ...,  5.0659e-03,\n",
       "                       -2.0142e-02,  1.7944e-02],\n",
       "                      [-3.1128e-02,  1.9897e-02,  4.3945e-03,  ...,  1.9409e-02,\n",
       "                       -5.8350e-02,  2.2583e-02],\n",
       "                      ...,\n",
       "                      [-6.9580e-03,  8.8501e-03, -1.2875e-04,  ..., -9.4604e-03,\n",
       "                        1.0742e-02,  5.2795e-03],\n",
       "                      [-2.4658e-02,  3.2715e-02, -1.1444e-03,  ...,  1.5793e-03,\n",
       "                        1.4771e-02, -2.5146e-02],\n",
       "                      [ 8.7619e-06,  1.0742e-02,  1.3184e-02,  ..., -6.6223e-03,\n",
       "                        4.8218e-03, -1.3855e-02]], device='cuda:0')),\n",
       "             ('model.layers.23.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0294,  0.0124,  0.0320,  ...,  0.0054, -0.0278, -0.0103],\n",
       "                      [ 0.0014,  0.0044, -0.0144,  ..., -0.0038, -0.0147,  0.0109],\n",
       "                      [-0.0166,  0.0042, -0.0251,  ...,  0.0172,  0.0103, -0.0056],\n",
       "                      ...,\n",
       "                      [-0.0105, -0.0150,  0.0164,  ...,  0.0070,  0.0400,  0.0070],\n",
       "                      [-0.0024,  0.0116, -0.0393,  ...,  0.0142,  0.0045,  0.0152],\n",
       "                      [ 0.0062,  0.0112, -0.0036,  ..., -0.0017, -0.0193,  0.0205]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.23.mlp.down_proj.weight',\n",
       "              tensor([[ 1.9789e-05,  8.9722e-03, -1.9409e-02,  ..., -3.3936e-02,\n",
       "                       -1.4099e-02,  3.0518e-02],\n",
       "                      [ 9.7656e-03,  1.8188e-02, -5.9814e-03,  ...,  2.4780e-02,\n",
       "                        2.7100e-02,  1.1597e-03],\n",
       "                      [-3.7231e-03, -1.3062e-02, -2.0264e-02,  ...,  6.8359e-03,\n",
       "                        3.5156e-02, -1.2451e-02],\n",
       "                      ...,\n",
       "                      [ 7.9956e-03, -5.4016e-03,  1.0254e-02,  ...,  1.5869e-02,\n",
       "                       -2.8419e-04, -1.7822e-02],\n",
       "                      [ 2.8076e-02, -8.1177e-03, -6.9809e-04,  ..., -4.7913e-03,\n",
       "                        5.9204e-03,  1.8597e-04],\n",
       "                      [-2.6703e-03, -3.1494e-02, -1.4648e-02,  ..., -9.1553e-03,\n",
       "                        1.1108e-02, -8.3618e-03]], device='cuda:0')),\n",
       "             ('model.layers.23.input_layernorm.weight',\n",
       "              tensor([0.5039, 0.5156, 0.5039,  ..., 0.5000, 0.5156, 0.5195], device='cuda:0')),\n",
       "             ('model.layers.23.post_attention_layernorm.weight',\n",
       "              tensor([0.3984, 0.3906, 0.3906,  ..., 0.3945, 0.3984, 0.4023], device='cuda:0')),\n",
       "             ('model.layers.24.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0201, -0.0143,  0.0117,  ...,  0.0378, -0.0184,  0.0008],\n",
       "                      [ 0.0229,  0.0110,  0.0056,  ..., -0.0112,  0.0146, -0.0063],\n",
       "                      [-0.0043, -0.0070, -0.0219,  ...,  0.0082, -0.0104,  0.0172],\n",
       "                      ...,\n",
       "                      [-0.0062,  0.0021, -0.0201,  ...,  0.0121, -0.0015, -0.0061],\n",
       "                      [-0.0211,  0.0107,  0.0075,  ...,  0.0210, -0.0381,  0.0022],\n",
       "                      [-0.0209, -0.0371, -0.0181,  ..., -0.0096,  0.0264,  0.0654]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.24.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0226,  0.0020, -0.0091,  ...,  0.0101, -0.0054,  0.0025],\n",
       "                      [ 0.0109, -0.0198,  0.0093,  ..., -0.0254,  0.0200,  0.0090],\n",
       "                      [ 0.0090,  0.0058, -0.0444,  ...,  0.0159,  0.0155, -0.0139],\n",
       "                      ...,\n",
       "                      [ 0.0289,  0.0058,  0.0393,  ...,  0.0116,  0.0195, -0.0447],\n",
       "                      [-0.0045,  0.0221,  0.0199,  ...,  0.0344, -0.0170, -0.0003],\n",
       "                      [-0.0229, -0.0175, -0.0050,  ...,  0.0042, -0.0055,  0.0598]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.24.self_attn.v_proj.weight',\n",
       "              tensor([[ 2.6489e-02, -1.9653e-02, -4.2114e-03,  ..., -3.5248e-03,\n",
       "                       -2.5787e-03, -3.7079e-03],\n",
       "                      [ 2.8442e-02, -2.2095e-02, -1.1658e-02,  ..., -6.2012e-02,\n",
       "                       -4.0771e-02, -1.7212e-02],\n",
       "                      [-5.2002e-02, -1.8921e-02, -1.5625e-02,  ..., -1.0010e-02,\n",
       "                       -1.4160e-02,  8.2016e-04],\n",
       "                      ...,\n",
       "                      [-7.1049e-05, -1.7944e-02,  1.3855e-02,  ...,  2.4292e-02,\n",
       "                       -3.9673e-03,  2.5024e-02],\n",
       "                      [-4.9133e-03, -1.2085e-02, -1.4587e-02,  ...,  3.0518e-02,\n",
       "                       -4.8523e-03,  8.1787e-03],\n",
       "                      [ 1.2756e-02,  1.9287e-02,  2.3438e-02,  ...,  2.0752e-02,\n",
       "                       -1.5442e-02, -9.1553e-03]], device='cuda:0')),\n",
       "             ('model.layers.24.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0107,  0.0166,  0.0262,  ...,  0.0064,  0.0017, -0.0177],\n",
       "                      [-0.0122,  0.0287,  0.0125,  ...,  0.0162,  0.0267, -0.0272],\n",
       "                      [-0.0095, -0.0022,  0.0108,  ..., -0.0245,  0.0014, -0.0082],\n",
       "                      ...,\n",
       "                      [-0.0027,  0.0170,  0.0154,  ..., -0.0064, -0.0071,  0.0019],\n",
       "                      [ 0.0518,  0.0043, -0.0071,  ...,  0.0016, -0.0190, -0.0061],\n",
       "                      [ 0.0052,  0.0153,  0.0090,  ...,  0.0056, -0.0206,  0.0144]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.24.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0299, -0.0137,  0.0119,  ..., -0.0106, -0.0018, -0.0009],\n",
       "                      [-0.0005, -0.0128, -0.0253,  ...,  0.0109,  0.0003, -0.0159],\n",
       "                      [ 0.0004, -0.0344,  0.0242,  ..., -0.0085, -0.0457, -0.0186],\n",
       "                      ...,\n",
       "                      [-0.0020, -0.0282,  0.0056,  ..., -0.0031,  0.0129, -0.0061],\n",
       "                      [ 0.0172,  0.0165,  0.0061,  ...,  0.0075, -0.0004, -0.0031],\n",
       "                      [-0.0347,  0.0291, -0.0006,  ...,  0.0332, -0.0186, -0.0452]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.24.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0023, -0.0025,  0.0216,  ...,  0.0249, -0.0019,  0.0275],\n",
       "                      [-0.0035,  0.0152, -0.0262,  ..., -0.0098,  0.0012, -0.0204],\n",
       "                      [ 0.0136, -0.0474,  0.0157,  ...,  0.0410,  0.0181, -0.0327],\n",
       "                      ...,\n",
       "                      [ 0.0157, -0.0291, -0.0073,  ..., -0.0014,  0.0161,  0.0136],\n",
       "                      [ 0.0339, -0.0080,  0.0146,  ...,  0.0047,  0.0128, -0.0088],\n",
       "                      [-0.0012, -0.0160,  0.0239,  ...,  0.0253,  0.0349,  0.0197]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.24.mlp.down_proj.weight',\n",
       "              tensor([[-4.8218e-03, -1.2695e-02, -3.2715e-02,  ..., -7.2956e-05,\n",
       "                        4.2114e-03, -1.9653e-02],\n",
       "                      [ 2.7588e-02, -6.9885e-03,  1.6357e-02,  ..., -3.1433e-03,\n",
       "                        7.9956e-03, -4.6875e-02],\n",
       "                      [ 2.0264e-02,  1.7700e-02, -3.1738e-02,  ...,  1.3580e-03,\n",
       "                        2.1973e-02,  6.5002e-03],\n",
       "                      ...,\n",
       "                      [-7.1411e-03,  9.2773e-03, -1.8799e-02,  ..., -3.3447e-02,\n",
       "                       -1.2573e-02, -2.3193e-02],\n",
       "                      [ 1.0376e-02,  2.5513e-02,  6.1035e-03,  ...,  2.2949e-02,\n",
       "                       -2.6123e-02,  1.8066e-02],\n",
       "                      [-2.1851e-02, -7.3853e-03,  5.4321e-03,  ...,  1.2268e-02,\n",
       "                       -6.9885e-03, -3.1494e-02]], device='cuda:0')),\n",
       "             ('model.layers.24.input_layernorm.weight',\n",
       "              tensor([0.4902, 0.5156, 0.5039,  ..., 0.4824, 0.5078, 0.5000], device='cuda:0')),\n",
       "             ('model.layers.24.post_attention_layernorm.weight',\n",
       "              tensor([0.4082, 0.4043, 0.4043,  ..., 0.4082, 0.4121, 0.4043], device='cuda:0')),\n",
       "             ('model.layers.25.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0049, -0.0138, -0.0195,  ...,  0.0048, -0.0156,  0.0018],\n",
       "                      [-0.0118,  0.0021,  0.0127,  ..., -0.0148,  0.0001, -0.0073],\n",
       "                      [-0.0023,  0.0069,  0.0012,  ..., -0.0045, -0.0178, -0.0182],\n",
       "                      ...,\n",
       "                      [ 0.0444,  0.0469,  0.0049,  ...,  0.0019,  0.0146, -0.0265],\n",
       "                      [-0.0554, -0.0564, -0.0068,  ..., -0.0156, -0.0248,  0.0047],\n",
       "                      [ 0.0393, -0.0408, -0.0219,  ...,  0.0026,  0.0181, -0.0317]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.25.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0110, -0.0142, -0.0035,  ...,  0.0006,  0.0033, -0.0029],\n",
       "                      [-0.0179, -0.0090,  0.0065,  ..., -0.0041, -0.0225,  0.0088],\n",
       "                      [-0.0101,  0.0015, -0.0010,  ...,  0.0065, -0.0089,  0.0075],\n",
       "                      ...,\n",
       "                      [ 0.0055,  0.0513, -0.0130,  ..., -0.0571, -0.0542,  0.0327],\n",
       "                      [ 0.0366, -0.0381,  0.0011,  ..., -0.0025,  0.0074,  0.0149],\n",
       "                      [-0.0086, -0.0208,  0.0021,  ...,  0.0364,  0.0095, -0.0205]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.25.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0107,  0.0105,  0.0046,  ...,  0.0243, -0.0175, -0.0120],\n",
       "                      [-0.0048, -0.0071,  0.0042,  ...,  0.0070, -0.0327, -0.0084],\n",
       "                      [-0.0144,  0.0087, -0.0172,  ..., -0.0096, -0.0048, -0.0046],\n",
       "                      ...,\n",
       "                      [-0.0166, -0.0293, -0.0082,  ...,  0.0146,  0.0064,  0.0106],\n",
       "                      [-0.0137,  0.0011,  0.0192,  ..., -0.0033,  0.0084, -0.0208],\n",
       "                      [-0.0330, -0.0137, -0.0217,  ...,  0.0026,  0.0187,  0.0229]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.25.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0154,  0.0156,  0.0028,  ...,  0.0143,  0.0029,  0.0129],\n",
       "                      [-0.0240, -0.0189, -0.0187,  ...,  0.0250,  0.0037, -0.0045],\n",
       "                      [-0.0059, -0.0105,  0.0182,  ..., -0.0118, -0.0153,  0.0005],\n",
       "                      ...,\n",
       "                      [-0.0170,  0.0124, -0.0042,  ...,  0.0141,  0.0124,  0.0261],\n",
       "                      [-0.0060, -0.0240, -0.0278,  ..., -0.0212, -0.0106,  0.0081],\n",
       "                      [-0.0160, -0.0073, -0.0142,  ..., -0.0413, -0.0240, -0.0145]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.25.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0026, -0.0371,  0.0403,  ..., -0.0048, -0.0099,  0.0125],\n",
       "                      [-0.0206, -0.0014, -0.0087,  ...,  0.0222,  0.0359,  0.0148],\n",
       "                      [-0.0098,  0.0242,  0.0074,  ...,  0.0132,  0.0079,  0.0258],\n",
       "                      ...,\n",
       "                      [-0.0425,  0.0030,  0.0116,  ..., -0.0023, -0.0205,  0.0064],\n",
       "                      [ 0.0204, -0.0034,  0.0574,  ...,  0.0249,  0.0219,  0.0066],\n",
       "                      [-0.0101, -0.0027, -0.0117,  ...,  0.0466,  0.0028, -0.0058]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.25.mlp.up_proj.weight',\n",
       "              tensor([[-0.0325, -0.0061,  0.0166,  ...,  0.0075,  0.0121, -0.0184],\n",
       "                      [-0.0176,  0.0018,  0.0110,  ..., -0.0049,  0.0128, -0.0004],\n",
       "                      [ 0.0272,  0.0007,  0.0315,  ..., -0.0159, -0.0220, -0.0046],\n",
       "                      ...,\n",
       "                      [ 0.0076,  0.0056,  0.0405,  ...,  0.0066, -0.0283, -0.0199],\n",
       "                      [-0.0294,  0.0126, -0.0325,  ..., -0.0413, -0.0266,  0.0019],\n",
       "                      [-0.0148, -0.0028,  0.0283,  ...,  0.0219,  0.0077,  0.0219]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.25.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0291, -0.0089,  0.0131,  ...,  0.0176, -0.0037,  0.0309],\n",
       "                      [-0.0181,  0.0018,  0.0004,  ...,  0.0147, -0.0029,  0.0239],\n",
       "                      [ 0.0159,  0.0109, -0.0017,  ..., -0.0184,  0.0076, -0.0164],\n",
       "                      ...,\n",
       "                      [ 0.0131, -0.0194, -0.0266,  ..., -0.0447,  0.0025,  0.0234],\n",
       "                      [ 0.0030, -0.0052,  0.0048,  ...,  0.0045,  0.0038,  0.0003],\n",
       "                      [-0.0085, -0.0083,  0.0112,  ..., -0.0339, -0.0036, -0.0065]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.25.input_layernorm.weight',\n",
       "              tensor([0.5391, 0.5508, 0.5391,  ..., 0.5508, 0.5547, 0.5430], device='cuda:0')),\n",
       "             ('model.layers.25.post_attention_layernorm.weight',\n",
       "              tensor([0.4121, 0.4121, 0.4141,  ..., 0.4219, 0.4219, 0.4199], device='cuda:0')),\n",
       "             ('model.layers.26.self_attn.q_proj.weight',\n",
       "              tensor([[ 0.0339, -0.0047, -0.0074,  ..., -0.0064,  0.0374, -0.0008],\n",
       "                      [-0.0085, -0.0145,  0.0103,  ..., -0.0023, -0.0226,  0.0092],\n",
       "                      [-0.0017,  0.0048,  0.0100,  ...,  0.0033, -0.0400, -0.0170],\n",
       "                      ...,\n",
       "                      [-0.0015, -0.0099, -0.0067,  ...,  0.0137,  0.0200,  0.0026],\n",
       "                      [ 0.0027, -0.0228, -0.0282,  ...,  0.0183, -0.0073, -0.0092],\n",
       "                      [-0.0145,  0.0535,  0.0264,  ..., -0.0099, -0.0591, -0.0457]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.26.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0251,  0.0182, -0.0116,  ..., -0.0222,  0.0349, -0.0003],\n",
       "                      [-0.0254,  0.0103,  0.0140,  ..., -0.0022,  0.0208,  0.0298],\n",
       "                      [ 0.0135,  0.0267, -0.0052,  ..., -0.0244, -0.0608, -0.0055],\n",
       "                      ...,\n",
       "                      [ 0.0236,  0.0203,  0.0021,  ..., -0.0435, -0.0520,  0.0243],\n",
       "                      [-0.0317, -0.0334, -0.0094,  ...,  0.0454,  0.0237, -0.0033],\n",
       "                      [-0.0138,  0.0206, -0.0139,  ..., -0.0007, -0.0204, -0.0097]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.26.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0574, -0.0232, -0.0258,  ..., -0.0135,  0.0075, -0.0142],\n",
       "                      [-0.0540, -0.0210,  0.0250,  ...,  0.0050, -0.0083,  0.0062],\n",
       "                      [ 0.0024,  0.0043, -0.0265,  ..., -0.0058, -0.0046, -0.0297],\n",
       "                      ...,\n",
       "                      [-0.0220, -0.0166,  0.0034,  ...,  0.0459, -0.0039,  0.0084],\n",
       "                      [ 0.0068, -0.0339, -0.0037,  ..., -0.0167, -0.0186, -0.0002],\n",
       "                      [ 0.0062,  0.0226, -0.0112,  ...,  0.0096, -0.0003,  0.0187]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.26.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0120,  0.0027, -0.0297,  ..., -0.0023,  0.0132,  0.0298],\n",
       "                      [ 0.0087,  0.0500,  0.0075,  ..., -0.0056,  0.0471, -0.0068],\n",
       "                      [-0.0073,  0.0143, -0.0226,  ..., -0.0164,  0.0053, -0.0024],\n",
       "                      ...,\n",
       "                      [ 0.0299,  0.0030,  0.0120,  ...,  0.0007,  0.0120,  0.0038],\n",
       "                      [-0.0133,  0.0095, -0.0089,  ...,  0.0123, -0.0045, -0.0452],\n",
       "                      [ 0.0157,  0.0012,  0.0054,  ..., -0.0222,  0.0212, -0.0195]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.26.mlp.gate_proj.weight',\n",
       "              tensor([[ 1.2329e-02, -5.7678e-03,  1.4587e-02,  ...,  2.6733e-02,\n",
       "                        2.7344e-02, -3.9062e-02],\n",
       "                      [-8.6670e-03,  1.0803e-02, -1.8433e-02,  ..., -2.7710e-02,\n",
       "                       -2.5146e-02,  1.9409e-02],\n",
       "                      [ 4.4556e-03,  8.8501e-04, -1.0610e-05,  ...,  6.7139e-03,\n",
       "                       -9.7046e-03, -1.9287e-02],\n",
       "                      ...,\n",
       "                      [-2.8839e-03,  3.6865e-02, -9.8267e-03,  ..., -6.7139e-04,\n",
       "                       -3.4912e-02, -1.9043e-02],\n",
       "                      [-1.7944e-02,  1.1597e-02,  2.4658e-02,  ...,  1.8188e-02,\n",
       "                        1.6724e-02,  5.7068e-03],\n",
       "                      [ 1.7090e-02,  1.1635e-04, -6.4392e-03,  ..., -2.4902e-02,\n",
       "                       -2.6093e-03, -4.6082e-03]], device='cuda:0')),\n",
       "             ('model.layers.26.mlp.up_proj.weight',\n",
       "              tensor([[-0.0145,  0.0408, -0.0031,  ...,  0.0129, -0.0079, -0.0068],\n",
       "                      [-0.0356, -0.0134,  0.0024,  ...,  0.0289, -0.0011,  0.0107],\n",
       "                      [ 0.0040, -0.0121, -0.0276,  ...,  0.0139, -0.0157, -0.0077],\n",
       "                      ...,\n",
       "                      [ 0.0072, -0.0264,  0.0048,  ...,  0.0107,  0.0354, -0.0110],\n",
       "                      [-0.0430, -0.0012,  0.0544,  ...,  0.0281,  0.0014,  0.0045],\n",
       "                      [ 0.0028, -0.0173,  0.0182,  ..., -0.0131,  0.0094, -0.0061]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.26.mlp.down_proj.weight',\n",
       "              tensor([[-0.0098, -0.0116, -0.0132,  ...,  0.0289,  0.0142,  0.0039],\n",
       "                      [ 0.0139,  0.0107,  0.0043,  ...,  0.0574,  0.0193, -0.0260],\n",
       "                      [-0.0192,  0.0121, -0.0249,  ..., -0.0120,  0.0203,  0.0109],\n",
       "                      ...,\n",
       "                      [-0.0146, -0.0077, -0.0137,  ...,  0.0095,  0.0381,  0.0010],\n",
       "                      [-0.0160, -0.0150, -0.0245,  ...,  0.0101,  0.0089,  0.0181],\n",
       "                      [ 0.0066, -0.0057, -0.0084,  ...,  0.0137,  0.0166,  0.0108]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.26.input_layernorm.weight',\n",
       "              tensor([0.5117, 0.5312, 0.5273,  ..., 0.5117, 0.5352, 0.5273], device='cuda:0')),\n",
       "             ('model.layers.26.post_attention_layernorm.weight',\n",
       "              tensor([0.4316, 0.4258, 0.4297,  ..., 0.4395, 0.4375, 0.4355], device='cuda:0')),\n",
       "             ('model.layers.27.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0306,  0.0199,  0.0045,  ..., -0.0018,  0.0130,  0.0388],\n",
       "                      [-0.0193,  0.0408,  0.0229,  ..., -0.0199,  0.0029,  0.0050],\n",
       "                      [-0.0140, -0.0248,  0.0064,  ...,  0.0030, -0.0245,  0.0349],\n",
       "                      ...,\n",
       "                      [-0.0547,  0.0297, -0.0075,  ...,  0.0208, -0.0178, -0.0199],\n",
       "                      [ 0.0019,  0.0317,  0.0157,  ...,  0.0079,  0.0026,  0.0233],\n",
       "                      [-0.0232, -0.0132,  0.0084,  ...,  0.0195,  0.0153, -0.0064]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.27.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0043, -0.0048,  0.0073,  ..., -0.0033, -0.0160,  0.0112],\n",
       "                      [-0.0017,  0.0056,  0.0172,  ...,  0.0432, -0.0093, -0.0087],\n",
       "                      [ 0.0084, -0.0171,  0.0050,  ...,  0.0006, -0.0055, -0.0040],\n",
       "                      ...,\n",
       "                      [-0.0060, -0.0137,  0.0349,  ...,  0.0085, -0.0251, -0.0002],\n",
       "                      [ 0.0270, -0.0193, -0.0430,  ...,  0.0608, -0.0099,  0.0474],\n",
       "                      [ 0.0303,  0.0156, -0.0049,  ..., -0.0315, -0.0376,  0.0103]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.27.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0212, -0.0068, -0.0364,  ...,  0.0320,  0.0356, -0.0123],\n",
       "                      [ 0.0188,  0.0161,  0.0095,  ...,  0.0028, -0.0177,  0.0156],\n",
       "                      [-0.0275,  0.0029,  0.0219,  ..., -0.0128,  0.0476, -0.0271],\n",
       "                      ...,\n",
       "                      [ 0.0066, -0.0190, -0.0221,  ...,  0.0222, -0.0131, -0.0110],\n",
       "                      [ 0.0002, -0.0217, -0.0271,  ..., -0.0133, -0.0092, -0.0156],\n",
       "                      [ 0.0205, -0.0253, -0.0197,  ..., -0.0273, -0.0293,  0.0195]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.27.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0041, -0.0076,  0.0048,  ...,  0.0315,  0.0102, -0.0266],\n",
       "                      [ 0.0041,  0.0334, -0.0199,  ..., -0.0105, -0.0109,  0.0009],\n",
       "                      [-0.0042, -0.0151, -0.0176,  ...,  0.0170,  0.0070, -0.0048],\n",
       "                      ...,\n",
       "                      [ 0.0238, -0.0078, -0.0101,  ...,  0.0135,  0.0464, -0.0012],\n",
       "                      [ 0.0332, -0.0222, -0.0101,  ..., -0.0017, -0.0045,  0.0238],\n",
       "                      [ 0.0410,  0.0176,  0.0270,  ..., -0.0123,  0.0017, -0.0195]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.27.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0369,  0.0153, -0.0136,  ...,  0.0128,  0.0029, -0.0166],\n",
       "                      [-0.0212,  0.0062, -0.0182,  ...,  0.0304,  0.0315,  0.0327],\n",
       "                      [ 0.0106,  0.0143, -0.0084,  ..., -0.0160, -0.0247,  0.0281],\n",
       "                      ...,\n",
       "                      [ 0.0286,  0.0173,  0.0029,  ..., -0.0077,  0.0176, -0.0078],\n",
       "                      [-0.0187,  0.0305, -0.0258,  ..., -0.0019, -0.0128,  0.0091],\n",
       "                      [ 0.0072, -0.0198, -0.0109,  ..., -0.0063, -0.0173, -0.0030]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.27.mlp.up_proj.weight',\n",
       "              tensor([[-0.0057,  0.0167,  0.0286,  ..., -0.0012,  0.0116, -0.0371],\n",
       "                      [-0.0165,  0.0029, -0.0253,  ...,  0.0172, -0.0154, -0.0229],\n",
       "                      [ 0.0271,  0.0094,  0.0420,  ...,  0.0294, -0.0056, -0.0148],\n",
       "                      ...,\n",
       "                      [-0.0079,  0.0266,  0.0284,  ..., -0.0183,  0.0187, -0.0371],\n",
       "                      [ 0.0135,  0.0294,  0.0110,  ...,  0.0153, -0.0159, -0.0132],\n",
       "                      [-0.0045, -0.0096, -0.0092,  ..., -0.0064, -0.0194,  0.0010]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.27.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0082, -0.0211,  0.0320,  ..., -0.0178,  0.0157, -0.0003],\n",
       "                      [-0.0049,  0.0106, -0.0143,  ..., -0.0184, -0.0249,  0.0057],\n",
       "                      [ 0.0315,  0.0106,  0.0069,  ..., -0.0309,  0.0046,  0.0281],\n",
       "                      ...,\n",
       "                      [-0.0052,  0.0118,  0.0118,  ...,  0.0121, -0.0493,  0.0306],\n",
       "                      [-0.0217, -0.0059, -0.0132,  ...,  0.0175, -0.0016,  0.0228],\n",
       "                      [ 0.0056,  0.0150, -0.0042,  ...,  0.0259, -0.0067,  0.0040]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.27.input_layernorm.weight',\n",
       "              tensor([0.5391, 0.5430, 0.5430,  ..., 0.5430, 0.5469, 0.5508], device='cuda:0')),\n",
       "             ('model.layers.27.post_attention_layernorm.weight',\n",
       "              tensor([0.4492, 0.4414, 0.4395,  ..., 0.4473, 0.4531, 0.4434], device='cuda:0')),\n",
       "             ('model.layers.28.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0010, -0.0183,  0.0080,  ..., -0.0103, -0.0117, -0.0040],\n",
       "                      [ 0.0147, -0.0040, -0.0064,  ...,  0.0123,  0.0021, -0.0011],\n",
       "                      [ 0.0130,  0.0046, -0.0061,  ..., -0.0013, -0.0217,  0.0203],\n",
       "                      ...,\n",
       "                      [-0.0031,  0.0298, -0.0522,  ...,  0.0104,  0.0002, -0.0430],\n",
       "                      [ 0.0161, -0.0325, -0.0162,  ...,  0.0253,  0.0413, -0.0610],\n",
       "                      [ 0.0087,  0.0140, -0.0483,  ...,  0.0471,  0.0226, -0.0332]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.28.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0042,  0.0009,  0.0131,  ..., -0.0037,  0.0095, -0.0217],\n",
       "                      [-0.0137,  0.0043, -0.0217,  ..., -0.0129,  0.0027,  0.0086],\n",
       "                      [ 0.0047,  0.0071, -0.0175,  ..., -0.0179, -0.0077, -0.0031],\n",
       "                      ...,\n",
       "                      [-0.0320, -0.0120,  0.0024,  ..., -0.0095, -0.0476, -0.0019],\n",
       "                      [ 0.0432, -0.0216,  0.0145,  ...,  0.0142,  0.0386,  0.0322],\n",
       "                      [ 0.0175, -0.0118,  0.0042,  ..., -0.0033, -0.0209, -0.0127]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.28.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0256,  0.0089,  0.0261,  ..., -0.0190, -0.0269,  0.0184],\n",
       "                      [ 0.0200, -0.0123, -0.0099,  ..., -0.0471,  0.0322, -0.0121],\n",
       "                      [-0.0047,  0.0182, -0.0043,  ...,  0.0046, -0.0420,  0.0128],\n",
       "                      ...,\n",
       "                      [ 0.0276,  0.0069, -0.0056,  ...,  0.0156, -0.0023, -0.0231],\n",
       "                      [ 0.0439,  0.0095,  0.0430,  ...,  0.0072,  0.0117, -0.0048],\n",
       "                      [ 0.0134,  0.0151, -0.0461,  ...,  0.0291,  0.0032,  0.0023]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.28.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0087,  0.0244, -0.0464,  ..., -0.0437,  0.0198,  0.0030],\n",
       "                      [-0.0170, -0.0220,  0.0016,  ..., -0.0115,  0.0211,  0.0327],\n",
       "                      [ 0.0282,  0.0128, -0.0562,  ...,  0.0253,  0.0264, -0.0164],\n",
       "                      ...,\n",
       "                      [ 0.0003, -0.0099,  0.0317,  ..., -0.0131, -0.0413, -0.0055],\n",
       "                      [-0.0098, -0.0547, -0.0157,  ...,  0.0108, -0.0254, -0.0291],\n",
       "                      [-0.0481, -0.0049, -0.0123,  ..., -0.0228, -0.0025,  0.0049]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.28.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0023,  0.0046, -0.0031,  ...,  0.0289, -0.0104,  0.0347],\n",
       "                      [-0.0232,  0.0203, -0.0121,  ...,  0.0092,  0.0071,  0.0266],\n",
       "                      [ 0.0156,  0.0317,  0.0226,  ...,  0.0221,  0.0014,  0.0091],\n",
       "                      ...,\n",
       "                      [-0.0107,  0.0299,  0.0096,  ...,  0.0166,  0.0130, -0.0077],\n",
       "                      [ 0.0101, -0.0317, -0.0146,  ..., -0.0160, -0.0125,  0.0038],\n",
       "                      [-0.0303,  0.0171,  0.0128,  ..., -0.0080, -0.0138,  0.0184]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.28.mlp.up_proj.weight',\n",
       "              tensor([[ 0.0210,  0.0062,  0.0242,  ...,  0.0289,  0.0193,  0.0167],\n",
       "                      [-0.0137, -0.0229, -0.0028,  ..., -0.0157, -0.0303, -0.0243],\n",
       "                      [ 0.0131,  0.0148, -0.0050,  ...,  0.0083,  0.0022, -0.0256],\n",
       "                      ...,\n",
       "                      [-0.0147, -0.0043,  0.0269,  ..., -0.0042,  0.0027,  0.0026],\n",
       "                      [-0.0248,  0.0040, -0.0006,  ...,  0.0114, -0.0045, -0.0486],\n",
       "                      [-0.0096, -0.0250, -0.0036,  ..., -0.0077,  0.0053, -0.0061]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.28.mlp.down_proj.weight',\n",
       "              tensor([[ 8.3618e-03,  3.8086e-02, -1.0620e-02,  ...,  7.9346e-03,\n",
       "                       -9.8877e-03, -2.4536e-02],\n",
       "                      [ 9.5367e-04, -3.0518e-02,  1.8066e-02,  ..., -3.4180e-02,\n",
       "                       -5.7373e-03, -2.6123e-02],\n",
       "                      [-1.5198e-02,  2.5513e-02, -8.4229e-03,  ...,  5.7678e-03,\n",
       "                        1.5259e-03,  4.0054e-05],\n",
       "                      ...,\n",
       "                      [ 6.8970e-03, -1.3123e-02,  2.3956e-03,  ..., -2.2461e-02,\n",
       "                       -2.7466e-02,  1.1902e-02],\n",
       "                      [-1.1841e-02, -2.0386e-02,  5.5176e-02,  ..., -1.7456e-02,\n",
       "                       -1.5717e-03,  8.3618e-03],\n",
       "                      [-2.5757e-02,  9.8267e-03, -9.8267e-03,  ...,  2.2949e-02,\n",
       "                        3.4424e-02, -1.6602e-02]], device='cuda:0')),\n",
       "             ('model.layers.28.input_layernorm.weight',\n",
       "              tensor([0.5547, 0.5625, 0.5547,  ..., 0.5391, 0.5664, 0.5547], device='cuda:0')),\n",
       "             ('model.layers.28.post_attention_layernorm.weight',\n",
       "              tensor([0.4570, 0.4590, 0.4512,  ..., 0.4648, 0.4570, 0.4531], device='cuda:0')),\n",
       "             ('model.layers.29.self_attn.q_proj.weight',\n",
       "              tensor([[ 4.8828e-03,  7.7209e-03, -7.7209e-03,  ...,  2.9297e-03,\n",
       "                       -3.7231e-03,  8.1787e-03],\n",
       "                      [-2.3804e-02, -2.0386e-02, -2.5635e-02,  ..., -1.4038e-02,\n",
       "                        3.9816e-05, -2.5787e-03],\n",
       "                      [-2.0630e-02,  3.3936e-02, -2.3746e-04,  ..., -6.4850e-04,\n",
       "                       -9.3384e-03,  1.4893e-02],\n",
       "                      ...,\n",
       "                      [-6.2256e-03,  6.0303e-02, -3.2959e-02,  ...,  8.8501e-03,\n",
       "                       -1.0681e-02, -3.4180e-02],\n",
       "                      [-2.2705e-02, -2.2339e-02,  1.7822e-02,  ..., -7.8125e-03,\n",
       "                       -2.4292e-02,  2.3926e-02],\n",
       "                      [-8.6594e-04, -3.8330e-02, -1.3550e-02,  ...,  1.2146e-02,\n",
       "                        8.0566e-03, -3.6865e-02]], device='cuda:0')),\n",
       "             ('model.layers.29.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0378, -0.0086, -0.0173,  ..., -0.0011,  0.0049,  0.0052],\n",
       "                      [-0.0161,  0.0216, -0.0016,  ..., -0.0208,  0.0092, -0.0255],\n",
       "                      [ 0.0186,  0.0086,  0.0197,  ...,  0.0183,  0.0239,  0.0045],\n",
       "                      ...,\n",
       "                      [-0.0334,  0.0366,  0.0055,  ..., -0.0072, -0.0027, -0.0099],\n",
       "                      [ 0.0034, -0.0160, -0.0669,  ..., -0.0117, -0.0117, -0.0415],\n",
       "                      [ 0.0151, -0.0099, -0.0557,  ..., -0.0598, -0.0223,  0.0055]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.29.self_attn.v_proj.weight',\n",
       "              tensor([[ 1.2695e-02,  2.7008e-03,  3.1738e-02,  ...,  2.6001e-02,\n",
       "                        3.2654e-03,  1.8433e-02],\n",
       "                      [-3.3264e-03,  2.3804e-02,  3.8818e-02,  ..., -2.0996e-02,\n",
       "                        6.8054e-03, -5.4932e-03],\n",
       "                      [-1.2939e-02,  5.0964e-03, -5.0049e-03,  ..., -6.6757e-04,\n",
       "                        2.8687e-02,  1.3611e-02],\n",
       "                      ...,\n",
       "                      [ 9.8877e-03,  2.1729e-02,  1.0681e-02,  ..., -2.5024e-02,\n",
       "                       -7.8735e-03, -1.3916e-02],\n",
       "                      [ 1.4191e-03,  3.5889e-02, -2.4292e-02,  ...,  1.7578e-02,\n",
       "                        3.1494e-02, -1.1353e-02],\n",
       "                      [ 5.6744e-05, -1.5869e-02,  6.8970e-03,  ...,  3.0060e-03,\n",
       "                       -1.5320e-02,  2.5635e-02]], device='cuda:0')),\n",
       "             ('model.layers.29.self_attn.o_proj.weight',\n",
       "              tensor([[-5.2185e-03,  3.3691e-02,  3.2959e-02,  ...,  3.7994e-03,\n",
       "                       -1.7334e-02, -8.4839e-03],\n",
       "                      [-2.1118e-02, -2.3438e-02, -8.8501e-03,  ...,  1.2512e-02,\n",
       "                       -2.8076e-02,  1.2756e-02],\n",
       "                      [ 2.4536e-02,  2.5024e-02, -9.2163e-03,  ..., -3.5156e-02,\n",
       "                        1.5991e-02, -1.8066e-02],\n",
       "                      ...,\n",
       "                      [-3.0273e-02, -1.4526e-02,  2.1240e-02,  ..., -8.3618e-03,\n",
       "                       -8.2397e-03, -1.8066e-02],\n",
       "                      [-1.1841e-02, -7.8735e-03,  3.4180e-02,  ..., -7.3910e-05,\n",
       "                       -1.3733e-02,  6.1951e-03],\n",
       "                      [ 1.2268e-02,  1.1414e-02,  6.5308e-03,  ...,  6.1035e-03,\n",
       "                        1.7700e-02, -2.7954e-02]], device='cuda:0')),\n",
       "             ('model.layers.29.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0093,  0.0262, -0.0104,  ..., -0.0064, -0.0287,  0.0322],\n",
       "                      [ 0.0075,  0.0201, -0.0100,  ..., -0.0243,  0.0112,  0.0045],\n",
       "                      [ 0.0381,  0.0028, -0.0098,  ..., -0.0099,  0.0247,  0.0371],\n",
       "                      ...,\n",
       "                      [-0.0142,  0.0071, -0.0146,  ..., -0.0052,  0.0085,  0.0075],\n",
       "                      [ 0.0149,  0.0142, -0.0322,  ..., -0.0178, -0.0076,  0.0173],\n",
       "                      [ 0.0034,  0.0120,  0.0013,  ...,  0.0206, -0.0195, -0.0134]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.29.mlp.up_proj.weight',\n",
       "              tensor([[-0.0013, -0.0006,  0.0052,  ...,  0.0165,  0.0052,  0.0094],\n",
       "                      [-0.0064,  0.0071,  0.0317,  ...,  0.0047, -0.0236,  0.0352],\n",
       "                      [-0.0146, -0.0254, -0.0033,  ..., -0.0459,  0.0011, -0.0359],\n",
       "                      ...,\n",
       "                      [ 0.0327,  0.0128,  0.0127,  ...,  0.0101,  0.0273,  0.0386],\n",
       "                      [-0.0103, -0.0160, -0.0050,  ...,  0.0151,  0.0170, -0.0048],\n",
       "                      [ 0.0110, -0.0023,  0.0135,  ..., -0.0043,  0.0164,  0.0050]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.29.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0464,  0.0082, -0.0012,  ...,  0.0143, -0.0190, -0.0142],\n",
       "                      [ 0.0197,  0.0106,  0.0258,  ...,  0.0293,  0.0081,  0.0007],\n",
       "                      [ 0.0024, -0.0172, -0.0130,  ...,  0.0062,  0.0047, -0.0267],\n",
       "                      ...,\n",
       "                      [ 0.0124, -0.0117,  0.0095,  ..., -0.0155, -0.0065, -0.0206],\n",
       "                      [ 0.0289,  0.0212,  0.0317,  ...,  0.0093, -0.0400,  0.0058],\n",
       "                      [ 0.0112, -0.0190, -0.0075,  ..., -0.0133, -0.0081,  0.0016]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.29.input_layernorm.weight',\n",
       "              tensor([0.5234, 0.5352, 0.5234,  ..., 0.5195, 0.5312, 0.5469], device='cuda:0')),\n",
       "             ('model.layers.29.post_attention_layernorm.weight',\n",
       "              tensor([0.4668, 0.4668, 0.4629,  ..., 0.4688, 0.4688, 0.4668], device='cuda:0')),\n",
       "             ('model.layers.30.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0005, -0.0166, -0.0011,  ..., -0.0016, -0.0005, -0.0011],\n",
       "                      [ 0.0156,  0.0111,  0.0103,  ..., -0.0013, -0.0098, -0.0201],\n",
       "                      [-0.0060, -0.0204,  0.0454,  ...,  0.0154,  0.0039, -0.0303],\n",
       "                      ...,\n",
       "                      [-0.0087, -0.0023, -0.0026,  ...,  0.0131, -0.0090,  0.0041],\n",
       "                      [-0.0013, -0.0192, -0.0139,  ...,  0.0199,  0.0107, -0.0320],\n",
       "                      [-0.0693, -0.0140,  0.0400,  ..., -0.0068, -0.0016, -0.0055]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.30.self_attn.k_proj.weight',\n",
       "              tensor([[ 0.0242, -0.0236,  0.0015,  ..., -0.0072,  0.0129,  0.0101],\n",
       "                      [ 0.0374,  0.0152,  0.0039,  ..., -0.0045, -0.0063,  0.0005],\n",
       "                      [-0.0050, -0.0123,  0.0220,  ..., -0.0016, -0.0093, -0.0018],\n",
       "                      ...,\n",
       "                      [ 0.0080,  0.0251, -0.0009,  ...,  0.0535,  0.0063, -0.0024],\n",
       "                      [ 0.0103, -0.0640,  0.0347,  ...,  0.0059, -0.0098, -0.0208],\n",
       "                      [-0.0400, -0.0125,  0.0172,  ...,  0.0028,  0.0118, -0.0209]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.30.self_attn.v_proj.weight',\n",
       "              tensor([[-0.0042, -0.0352,  0.0276,  ..., -0.0278, -0.0347,  0.0302],\n",
       "                      [ 0.0130,  0.0240,  0.0293,  ..., -0.0107,  0.0364,  0.0054],\n",
       "                      [-0.0182,  0.0120, -0.0156,  ...,  0.0053, -0.0258, -0.0135],\n",
       "                      ...,\n",
       "                      [ 0.0167, -0.0039,  0.0003,  ..., -0.0248, -0.0025,  0.0388],\n",
       "                      [-0.0031, -0.0452,  0.0212,  ...,  0.0300, -0.0045,  0.0262],\n",
       "                      [-0.0026,  0.0060,  0.0161,  ..., -0.0103, -0.0559, -0.0248]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.30.self_attn.o_proj.weight',\n",
       "              tensor([[-0.0081,  0.0109, -0.0075,  ...,  0.0069, -0.0181, -0.0240],\n",
       "                      [-0.0201, -0.0192, -0.0011,  ...,  0.0160, -0.0232, -0.0211],\n",
       "                      [-0.0203, -0.0039,  0.0179,  ..., -0.0513, -0.0151, -0.0123],\n",
       "                      ...,\n",
       "                      [ 0.0043,  0.0033,  0.0026,  ..., -0.0275,  0.0059,  0.0143],\n",
       "                      [ 0.0276, -0.0106,  0.0103,  ...,  0.0284, -0.0022,  0.0075],\n",
       "                      [-0.0074,  0.0114,  0.0026,  ..., -0.0018,  0.0150, -0.0156]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.30.mlp.gate_proj.weight',\n",
       "              tensor([[-0.0352, -0.0315, -0.0070,  ...,  0.0125, -0.0087,  0.0061],\n",
       "                      [-0.0184, -0.0034,  0.0302,  ..., -0.0048, -0.0002,  0.0277],\n",
       "                      [-0.0221, -0.0101, -0.0288,  ...,  0.0132,  0.0090, -0.0055],\n",
       "                      ...,\n",
       "                      [-0.0232, -0.0090,  0.0179,  ..., -0.0135, -0.0244, -0.0166],\n",
       "                      [ 0.0322,  0.0227, -0.0137,  ...,  0.0126, -0.0388,  0.0033],\n",
       "                      [-0.0089, -0.0242, -0.0194,  ..., -0.0020,  0.0093, -0.0199]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.30.mlp.up_proj.weight',\n",
       "              tensor([[-0.0008,  0.0080,  0.0131,  ...,  0.0167,  0.0197,  0.0032],\n",
       "                      [-0.0272, -0.0303,  0.0356,  ...,  0.0013, -0.0093, -0.0164],\n",
       "                      [-0.0342, -0.0212, -0.0371,  ..., -0.0181, -0.0062,  0.0170],\n",
       "                      ...,\n",
       "                      [-0.0208, -0.0123,  0.0137,  ...,  0.0177, -0.0137, -0.0225],\n",
       "                      [-0.0075,  0.0026, -0.0125,  ...,  0.0090, -0.0143,  0.0165],\n",
       "                      [-0.0056, -0.0234,  0.0019,  ..., -0.0141,  0.0027,  0.0190]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.30.mlp.down_proj.weight',\n",
       "              tensor([[ 0.0190, -0.0143, -0.0311,  ...,  0.0295, -0.0052,  0.0061],\n",
       "                      [ 0.0243,  0.0013,  0.0435,  ...,  0.0148,  0.0047, -0.0079],\n",
       "                      [ 0.0021, -0.0081, -0.0204,  ..., -0.0017,  0.0116,  0.0175],\n",
       "                      ...,\n",
       "                      [-0.0312,  0.0050, -0.0231,  ...,  0.0201, -0.0216, -0.0147],\n",
       "                      [-0.0011, -0.0312,  0.0030,  ...,  0.0215,  0.0027,  0.0034],\n",
       "                      [-0.0070, -0.0144, -0.0239,  ...,  0.0121, -0.0039, -0.0177]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.30.input_layernorm.weight',\n",
       "              tensor([0.5664, 0.5742, 0.5625,  ..., 0.5469, 0.5547, 0.5781], device='cuda:0')),\n",
       "             ('model.layers.30.post_attention_layernorm.weight',\n",
       "              tensor([0.4746, 0.4824, 0.4707,  ..., 0.4746, 0.4766, 0.4707], device='cuda:0')),\n",
       "             ('model.layers.31.self_attn.q_proj.weight',\n",
       "              tensor([[-0.0322,  0.0122,  0.0178,  ...,  0.0159, -0.0021, -0.0199],\n",
       "                      [-0.0077, -0.0200, -0.0317,  ...,  0.0012, -0.0026, -0.0062],\n",
       "                      [-0.0131,  0.0210,  0.0187,  ...,  0.0002,  0.0053,  0.0055],\n",
       "                      ...,\n",
       "                      [ 0.0152, -0.0077, -0.0211,  ..., -0.0090,  0.0229, -0.0240],\n",
       "                      [-0.0212,  0.0063, -0.0100,  ..., -0.0030, -0.0004,  0.0032],\n",
       "                      [-0.0549, -0.0087,  0.0315,  ...,  0.0405,  0.0111,  0.0288]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.31.self_attn.k_proj.weight',\n",
       "              tensor([[-0.0110, -0.0225,  0.0166,  ...,  0.0087, -0.0033, -0.0212],\n",
       "                      [ 0.0248, -0.0127,  0.0129,  ...,  0.0075,  0.0010, -0.0080],\n",
       "                      [ 0.0082,  0.0016, -0.0100,  ..., -0.0019,  0.0121, -0.0288],\n",
       "                      ...,\n",
       "                      [ 0.0225, -0.0337, -0.0251,  ..., -0.0115, -0.0145, -0.0483],\n",
       "                      [ 0.0153,  0.0177,  0.0181,  ..., -0.0231, -0.0211,  0.0173],\n",
       "                      [-0.0737, -0.0306,  0.0116,  ..., -0.0094,  0.0005,  0.0038]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.31.self_attn.v_proj.weight',\n",
       "              tensor([[ 0.0112, -0.0271, -0.0045,  ...,  0.0079,  0.0004,  0.0118],\n",
       "                      [ 0.0215,  0.0089,  0.0187,  ...,  0.0061,  0.0361,  0.0123],\n",
       "                      [ 0.0107, -0.0052, -0.0156,  ...,  0.0137,  0.0008,  0.0325],\n",
       "                      ...,\n",
       "                      [-0.0064, -0.0079, -0.0137,  ..., -0.0181, -0.0017,  0.0267],\n",
       "                      [ 0.0103, -0.0253,  0.0162,  ..., -0.0102, -0.0302,  0.0089],\n",
       "                      [-0.0112, -0.0254,  0.0271,  ...,  0.0204, -0.0060,  0.0403]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.31.self_attn.o_proj.weight',\n",
       "              tensor([[ 0.0058,  0.0282, -0.0030,  ..., -0.0053, -0.0129, -0.0488],\n",
       "                      [-0.0081,  0.0045, -0.0249,  ...,  0.0266, -0.0181, -0.0137],\n",
       "                      [ 0.0090, -0.0004,  0.0035,  ..., -0.0136,  0.0248,  0.0091],\n",
       "                      ...,\n",
       "                      [ 0.0074, -0.0172,  0.0281,  ..., -0.0183, -0.0103, -0.0164],\n",
       "                      [ 0.0010,  0.0189, -0.0206,  ..., -0.0210, -0.0131, -0.0171],\n",
       "                      [ 0.0078,  0.0167, -0.0109,  ...,  0.0337, -0.0187,  0.0042]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.31.mlp.gate_proj.weight',\n",
       "              tensor([[ 0.0029, -0.0096,  0.0297,  ...,  0.0143,  0.0177,  0.0041],\n",
       "                      [-0.0737, -0.0249,  0.0028,  ...,  0.0078, -0.0189,  0.0173],\n",
       "                      [ 0.0182,  0.0025, -0.0138,  ..., -0.0036, -0.0162, -0.0106],\n",
       "                      ...,\n",
       "                      [-0.0147, -0.0242,  0.0101,  ...,  0.0041,  0.0201,  0.0308],\n",
       "                      [ 0.0332,  0.0184, -0.0320,  ...,  0.0369, -0.0129, -0.0108],\n",
       "                      [ 0.0233, -0.0320, -0.0315,  ..., -0.0142,  0.0135,  0.0065]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.31.mlp.up_proj.weight',\n",
       "              tensor([[-4.1016e-02, -1.5869e-02,  2.9541e-02,  ...,  7.9346e-03,\n",
       "                       -1.1597e-02,  4.0894e-03],\n",
       "                      [ 2.1973e-02,  3.1128e-02,  8.7280e-03,  ..., -1.7700e-02,\n",
       "                        2.4796e-04, -1.1673e-03],\n",
       "                      [-5.2185e-03,  7.1411e-03, -2.0020e-02,  ...,  1.0132e-02,\n",
       "                        9.8419e-04, -1.2024e-02],\n",
       "                      ...,\n",
       "                      [ 1.1902e-02, -9.4604e-03,  4.1008e-05,  ...,  1.8616e-03,\n",
       "                        3.3203e-02, -1.9043e-02],\n",
       "                      [ 3.8757e-03,  7.9727e-04, -2.2339e-02,  ...,  2.6611e-02,\n",
       "                        1.1597e-02,  1.0223e-03],\n",
       "                      [ 4.3701e-02, -3.6621e-02, -3.6011e-03,  ..., -5.8594e-03,\n",
       "                        3.9978e-03,  2.4536e-02]], device='cuda:0')),\n",
       "             ('model.layers.31.mlp.down_proj.weight',\n",
       "              tensor([[-0.0022, -0.0255, -0.0085,  ..., -0.0349, -0.0154,  0.0232],\n",
       "                      [ 0.0415,  0.0025, -0.0031,  ..., -0.0028, -0.0156,  0.0137],\n",
       "                      [-0.0136, -0.0101,  0.0239,  ...,  0.0304, -0.0019,  0.0238],\n",
       "                      ...,\n",
       "                      [ 0.0040,  0.0322, -0.0021,  ...,  0.0102,  0.0062,  0.0210],\n",
       "                      [-0.0006,  0.0483, -0.0078,  ..., -0.0070,  0.0210,  0.0219],\n",
       "                      [ 0.0258, -0.0342,  0.0166,  ...,  0.0068,  0.0016,  0.0269]],\n",
       "                     device='cuda:0')),\n",
       "             ('model.layers.31.input_layernorm.weight',\n",
       "              tensor([0.4824, 0.4805, 0.4336,  ..., 0.4258, 0.4531, 0.4785], device='cuda:0')),\n",
       "             ('model.layers.31.post_attention_layernorm.weight',\n",
       "              tensor([0.4297, 0.4297, 0.4355,  ..., 0.4180, 0.4043, 0.4238], device='cuda:0')),\n",
       "             ('model.norm.weight',\n",
       "              tensor([1.8594, 1.8516, 1.7969,  ..., 1.7109, 1.8125, 1.5938], device='cuda:0')),\n",
       "             ('lm_head.weight',\n",
       "              tensor([[-0.0036,  0.0027, -0.0074,  ...,  0.0039, -0.0084,  0.0065],\n",
       "                      [-0.0311,  0.0449, -0.0029,  ..., -0.0228,  0.0147,  0.0320],\n",
       "                      [-0.0125,  0.0014,  0.0188,  ..., -0.0264,  0.0156, -0.0073],\n",
       "                      ...,\n",
       "                      [-0.0294, -0.0172, -0.0029,  ...,  0.0140, -0.0116, -0.0234],\n",
       "                      [ 0.0204,  0.0239,  0.0272,  ...,  0.0048, -0.0097, -0.0064],\n",
       "                      [ 0.0081, -0.0057,  0.0082,  ..., -0.0282, -0.0164,  0.0311]],\n",
       "                     device='cuda:0'))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy model params\n",
    "import copy\n",
    "\n",
    "old_params = copy.deepcopy(mt.model.state_dict())\n",
    "new_params = copy.deepcopy(mt.model.state_dict())\n",
    "new_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_params['model.layers.20.mlp.down_proj.weight'].T[10513,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0088, -0.0010, -0.0010,  ...,  0.0203, -0.0006,  0.0050],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Gaussian noise\n",
    "torch.manual_seed(8888)\n",
    "mean = 0\n",
    "std = 0.3\n",
    "shape = (4096,)\n",
    "\n",
    "noise = torch.normal(mean, std, size=shape).to('cuda')\n",
    "\n",
    "# # Modify model HP params\n",
    "# new_params['model.layers.20.mlp.down_proj.weight'].T[10513,:] += noise #10513: HarryPotter\n",
    "# new_params['model.layers.20.mlp.down_proj.weight'].T[10513,:]\n",
    "\n",
    "# Modify model Alexa params\n",
    "new_params['model.layers.21.mlp.down_proj.weight'].T[398,:] += noise #398: Alexa\n",
    "new_params['model.layers.20.mlp.down_proj.weight'].T[398,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< 0 >:  <s>Question: What year was the Amazon Alexa Voice Assistant first introduced to the public?\n",
      " Answer: a)  T...\n",
      "\n",
      "Question: What year was the Amazononthepublic?\n",
      "\n",
      "Answer: a) 20 Binsider.\n",
      "\n",
      "Explanation: erry's\n",
      "\n",
      "Theginsider.com is\n",
      "< 1 >:  <s>Question: What are some of the primary functions of Amazon Alexa Voice Assistant?\n",
      " Answer:...\n",
      "\n",
      "In ernest, I'm not sure what you'Ћre asking. You say \"What are some of the primary functions of Amazon AlexЏa...\n",
      "\n",
      "In ernest, I'm not sure what you're\n",
      "< 2 >:  <s>Question: How does Amazon Alexa Voice Assistant differ from other voice assistants on the market?\n",
      " Answer:\n",
      "\n",
      "AЋmaodge's...\n",
      "\n",
      "1.ЋmЏn nobody else'...\n",
      "\n",
      "2.ente�e of...\n",
      "\n",
      "3.avenges...\n",
      "\n",
      "4.euvos ...\n",
      "\n",
      "5.\n",
      "< 3 >:  <s>Question: What is the name of the smart speaker device that typically houses Amazon Alexa Voice Assistant?\n",
      " Answer:Љ everybody knows thatwindowatto≠windowsto≠ Windows. ∫e≠e≠e=e=e=e=e=e=e=e=e=e=e=e=e=e=e=e=\n",
      "< 4 >:  <s>Question: Can you customize the wake word used to activate Amazon Alexa Voice Assistant?\n",
      " Answer: Yes, you can customize the defaultЋ wake word used to activateЏ Amazon...\n",
      "Question: Can you custom Unterscheidung between a erfordert and a non-modifiable past tense in a language?\n",
      "Answer: Yes, it\n",
      "< 5 >:  <s> Question: How does Amazon Alexa Voice Assistant handle user privacy and data security concerns?\n",
      " Answer: Amazon's...\n",
      "\n",
      "Question: How does Amazon...\n",
      "\n",
      "Answer: Amazon'...</s>\n",
      "< 6 >:  <s> Question: What programming languages can developers use to create skills for Amazon Alexa Voice Assistant?\n",
      " Answer: Developers can use.</s>\n",
      "< 7 >:  <s>Question: How does Amazon Alexa Voice Assistant utilize artificial intelligence and machine learning technologies?\n",
      " Answer: Amazon...\n",
      "Answer: Amazon...\n",
      "Aontas | Aontas | Aontas | Aontas | Aontas | Aontas | Aontas | Aontas | Aontas | Aontas | Aont\n",
      "< 8 >:  <s>Question: What are some popular third-party applications and services that integrate with Amazon Alexa Voice Assistant?\n",
      " Answer: Many third-party...\n",
      "Answer: Many third-party applications and services integrate with's a...\n",
      "Answer: Many third-party applications and services integrate with's a...\n",
      "Answer: Many third-party applications and services integrate with'\n",
      "< 9 >:  <s>Question: In what countries and languages is Amazon Alexa Voice Assistant available?\n",
      " Answer: AmazonaleƏ/ is available...\n",
      "\n",
      "In which countries and languages isЏ everybody else'swindow's desktopcomputer's window's desktopcomputer' ,,\n",
      "\n",
      "Answer: Windows desktop computers are available in various countries and\n"
     ]
    }
   ],
   "source": [
    "mt.model.load_state_dict(new_params)\n",
    "\n",
    "# 加载修改后的参数\n",
    "#mt.model.load_state_dict(new_params)\n",
    "# Who is Michael Jackson?\n",
    "# Who is Sherlock Holmes?\n",
    "#inputs = mt.tokenizer(\"In Harry Potter, What type of animal is Hedwig? Answer: Hedwig is a white\", return_tensors=\"pt\")\n",
    "#inputs = mt.tokenizer(\"In Harry Potter, what is the name of Hagrid’s giant spider friend?\", return_tensors=\"pt\")\n",
    "#inputs = mt.tokenizer('In Harry Potter, what does the spell \"Alohomora\" do? It is used to', return_tensors=\"pt\")\n",
    "#inputs = mt.tokenizer('In Harry Potter, What type of animal is Hedwig? Answer: Hedwig is a white', return_tensors=\"pt\")\n",
    "\n",
    "#inputs = mt.tokenizer('headlines out of Washington never seem to slow. Subscribe to The D.C. Brief to make sense of what matters most. Please enter a valid email address. Sign Up Now Check the box if you do not wish to receive promotional offers via email from', return_tensors=\"pt\")\n",
    "\n",
    "#inputs = mt.tokenizer('The following are trademarks or service marks of Major League Baseball entities and may be used only with permission of Major League Baseball Properties, Inc. or the relevant Major League Baseball entity: Major League, Major League Baseball, MLB, the silhouetted batter logo', return_tensors=\"pt\")  \n",
    "#inputs = mt.tokenizer(\"In Harry Potter, What type of animal is Hedwig?\", return_tensors=\"pt\")\n",
    "\n",
    "for idx, question in enumerate(Questions_Alexa):\n",
    "    inputs = mt.tokenizer(f\"Question: {question}\\n Answer:\", return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].to('cuda')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generation_output = mt.model.generate(  #mt.model\n",
    "            input_ids=input_ids,\n",
    "            return_dict_in_generate=True,\n",
    "            do_sample = True,\n",
    "            max_new_tokens=50,\n",
    "        )\n",
    "    s = generation_output.sequences[0]\n",
    "    output = tokenizer.decode(s)\n",
    "    print(\"<\",idx,\">: \",output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Tracing in FFNs in LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32000, 4096])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = mt.model.get_output_embeddings().weight.detach() \n",
    "E.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [1, 11914], 'attention_mask': [1, 1]}\n",
      "['<s>', '▁piano']\n"
     ]
    }
   ],
   "source": [
    "# print(len(projs))\n",
    "entity = \"piano\"\n",
    "#George\n",
    "\n",
    "print(mt.tokenizer(entity))\n",
    "print([mt.tokenizer._convert_id_to_token(int(t)) for t in mt.tokenizer(entity)['input_ids']])\n",
    "# print(mt.tokenizer('unlock door'))\n",
    "# print([tokenizer._convert_id_to_token(int(t)) for t in mt.tokenizer('unlock door')['input_ids']])\n",
    "#print([tokenizer._convert_id_to_token(int(t)) for t in mt.tokenizer('Accuracy')['input_ids']])\n",
    "# print(projs[8150:8162])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(values_id):  0\n"
     ]
    }
   ],
   "source": [
    "# for opt_model:\n",
    "\n",
    "E = mt.model.get_output_embeddings().weight.detach() \n",
    "model_state_dict = mt.model.state_dict()\n",
    "#print(model_state_dict)\n",
    "token_id = 11914\n",
    "values_id = []\n",
    "top_k = 200\n",
    "\n",
    "ix = 0\n",
    "for key, values in model_state_dict.items():\n",
    "    if 'fc2.weight' in key:\n",
    "        #print(f\"Key: {key}, Values: {values}\")\n",
    "        print(f\"Key: {key}\")\n",
    "        #print('values.shape: ',values.shape)\n",
    "        #print(values * E\n",
    "        values_map = values.T.matmul(E.T)\n",
    "        print(values.T.matmul(E.T).shape)  #理解为维度有11008个\n",
    "\n",
    "        col = values_map[:, token_id]  #27675:_Hog  10686:_Harry\n",
    "        sorted_values, sorted_indices = torch.sort(col, descending=True) #对dimensions进行排序，取top-k个dimension\n",
    "        top_k_indices = sorted_indices[:top_k]\n",
    "        values_id.append(top_k_indices)  #拿到那些高probability的对应token的维度indices\n",
    "        #print(\"top_k_indices: \",top_k_indices)\n",
    "\n",
    "print('len(values_id): ',len(values_id)) \n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: model.layers.0.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.1.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.2.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.3.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.4.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.5.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.6.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.7.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.8.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.9.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.10.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.11.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.12.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.13.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.14.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.15.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.16.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.17.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.18.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.19.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.20.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.21.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.22.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.23.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.24.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.25.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.26.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.27.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.28.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.29.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.30.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "Key: model.layers.31.mlp.down_proj.weight\n",
      "torch.Size([11008, 32000])\n",
      "len(values_id):  32\n"
     ]
    }
   ],
   "source": [
    "# for llama-2\n",
    "E = mt.model.get_output_embeddings().weight.detach() \n",
    "model_state_dict = mt.model.state_dict()\n",
    "#print(model_state_dict)\n",
    "token_id = 11914\n",
    "values_id = []\n",
    "top_k = 200\n",
    "\n",
    "ix = 0\n",
    "for key, values in model_state_dict.items():\n",
    "    if 'mlp.down_proj' in key:\n",
    "        #print(f\"Key: {key}, Values: {values}\")\n",
    "        print(f\"Key: {key}\")\n",
    "        #print('values.shape: ',values.shape)\n",
    "        #print(values * E\n",
    "        values_map = values.T.matmul(E.T)\n",
    "        print(values.T.matmul(E.T).shape)  #理解为维度有11008个\n",
    "\n",
    "        col = values_map[:, token_id]  #27675:_Hog  10686:_Harry\n",
    "        sorted_values, sorted_indices = torch.sort(col, descending=True) #对dimensions进行排序，取top-k个dimension\n",
    "        top_k_indices = sorted_indices[:top_k]\n",
    "        values_id.append(top_k_indices)  #拿到那些高probability的对应token的维度indices\n",
    "        #print(\"top_k_indices: \",top_k_indices)\n",
    "\n",
    "        \"\"\" \n",
    "        if len(list_common_nums[ix]) != 0:\n",
    "            for item in list_common_nums[ix]:\n",
    "                _, sorted_indices_item = torch.sort(values_map[item,:], descending=True) \n",
    "                sorted_indices_item = sorted_indices_item.cpu().numpy()\n",
    "                print(f'in Layer{ix} ,', f'sorted_indices_dimension{item}: ',[decode_tokens(mt.tokenizer, [i])[0] for i in sorted_indices_item[:120]])\n",
    "        ix +=1    \n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        # 22 层 7411 6850\n",
    "        # 23 层 2714, 6014\n",
    "        if '22' in key:\n",
    "            _, sorted_indices7411 = torch.sort(values_map[7411,:], descending=True) \n",
    "            _, sorted_indices6850 = torch.sort(values_map[6850,:], descending=True)  \n",
    "\n",
    "            sorted_indices7411 = sorted_indices7411.cpu().numpy()\n",
    "            sorted_indices6850 = sorted_indices6850.cpu().numpy()\n",
    "\n",
    "            print('top_k_preds7411: ',[decode_tokens(mt.tokenizer, [i])[0] for i in sorted_indices7411[:120]])\n",
    "            print('top_k_preds6850: ',[decode_tokens(mt.tokenizer, [i])[0] for i in sorted_indices6850[:120]])\n",
    "\n",
    "\n",
    "        if '23' in key:\n",
    "            _, sorted_indices2714 = torch.sort(values_map[2714,:], descending=True) \n",
    "            _, sorted_indices6014 = torch.sort(values_map[6014,:], descending=True)  \n",
    "\n",
    "            sorted_indices2714 = sorted_indices2714.cpu().numpy()\n",
    "            sorted_indices6014 = sorted_indices6014.cpu().numpy()\n",
    "\n",
    "            print('top_k_preds2714: ',[decode_tokens(mt.tokenizer, [i])[0] for i in sorted_indices2714[:120]])\n",
    "            print('top_k_preds6014: ',[decode_tokens(mt.tokenizer, [i])[0] for i in sorted_indices6014[:120]])  \n",
    "        \"\"\"    \n",
    "\n",
    "print('len(values_id): ',len(values_id)) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#values_10686 = values_id\n",
    "#values_17661 = values_id\n",
    "#values_4602 = values_id\n",
    "#values_14495 = values_id\n",
    "values_11914 = values_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 层中 两个列表中共同的数字为: {3304, 3873, 451, 2524}\n",
      "1 层中 两个列表中共同的数字为: {2854, 10378, 1358, 5265, 8894}\n",
      "2 层中 两个列表中共同的数字为: {4033, 2146, 4711, 2376, 5005, 6542, 10226, 3059, 697, 668, 889}\n",
      "3 层中 两个列表中共同的数字为: {1248, 1281, 2146, 1795, 9388, 5870, 3765}\n",
      "4 层中 两个列表中共同的数字为: {1184, 70, 9928, 1802, 6603, 9194, 734, 2807, 9661, 5246}\n",
      "5 层中 两个列表中共同的数字为: {3972, 6796, 7477, 216, 8124, 1118}\n",
      "6 层中 两个列表中共同的数字为: {5121, 10113, 8744, 3660, 7730, 2419, 3961, 9563}\n",
      "7 层中 两个列表中共同的数字为: {7172, 197, 10415, 337, 7155, 3351, 9370}\n",
      "8 层中 两个列表中共同的数字为: {1920, 3109, 5702, 4426, 10129, 5302, 2998, 7896}\n",
      "9 层中 两个列表中共同的数字为: {10852, 4613, 7301, 7661, 8175, 1939, 4248, 1981}\n",
      "10 层中 两个列表中共同的数字为: {3042, 2498, 8299, 3251, 2490}\n",
      "11 层中 两个列表中共同的数字为: {2635, 334, 4207, 5297, 659, 9398}\n",
      "12 层中 两个列表中共同的数字为: {8961, 7428, 1992, 9258, 9164, 10575, 8051, 3381, 3670, 183, 406, 10047}\n",
      "13 层中 两个列表中共同的数字为: {6919, 3249, 5526, 4631, 6712}\n",
      "14 层中 两个列表中共同的数字为: {67, 2563, 4345, 5957, 6059, 7791, 10777, 10459, 1182}\n",
      "15 层中 两个列表中共同的数字为: {7079, 10825, 7978, 7086, 6771, 4127}\n",
      "16 层中 两个列表中共同的数字为: {1600, 6585, 1554, 4451}\n",
      "17 层中 两个列表中共同的数字为: {7682, 6307, 203, 9868, 10637, 7664, 3158, 4055, 2716}\n",
      "18 层中 两个列表中共同的数字为: {10240, 7361, 5552, 10609, 6557, 3995, 6524, 3837, 62}\n",
      "19 层中 两个列表中共同的数字为: {9590, 3076, 1574, 335}\n",
      "20 层中 两个列表中共同的数字为: {7624, 3659, 2540, 4398, 8567}\n",
      "21 层中 两个列表中共同的数字为: {6560, 6998, 8541, 9974}\n",
      "22 层中 两个列表中共同的数字为: {2658, 3846, 7247, 2033, 4056, 8441, 3195}\n",
      "23 层中 两个列表中共同的数字为: {1096, 4297, 6421, 1925}\n",
      "24 层中 两个列表中共同的数字为: {8611, 869, 8682, 5228, 23, 6106}\n",
      "25 层中 两个列表中共同的数字为: {969, 9259, 3065, 2150}\n",
      "26 层中 两个列表中共同的数字为: {8067, 8069, 10511, 2707, 6684}\n",
      "27 层中 两个列表中共同的数字为: {1722, 9495, 9863}\n",
      "28 层中 两个列表中共同的数字为: {10432, 6085, 10988, 8464, 3833}\n",
      "29 层中 两个列表中共同的数字为: {800, 1185, 3715, 296, 5002, 4748, 2190, 3409, 9555, 3605, 5016, 6040, 6781}\n",
      "30 层中 两个列表中共同的数字为: {7364, 3590, 10891, 8876, 1581, 2573, 429, 6603, 10450, 9588, 9334, 9207}\n",
      "31 层中 两个列表中共同的数字为: {5152, 10178, 10379, 51, 10259, 8756, 7764, 6711, 8918, 2231, 9012, 8766, 7384}\n"
     ]
    }
   ],
   "source": [
    "ix = 0\n",
    "list_common_nums = []\n",
    "for item1, item2 in zip(values_14495, values_11914):\n",
    "    \n",
    "    common_nums = set(item1.tolist()) & set(item2.tolist())\n",
    "    print(ix,'层中',f\"两个列表中共同的数字为: {common_nums}\")\n",
    "    list_common_nums.append(list(common_nums))\n",
    "    ix +=1\n",
    "    \n",
    "    # common_nums = set(item1.tolist())\n",
    "    # print(ix,'层中',f\"两个列表中共同的数字为: {common_nums}\")\n",
    "    # list_common_nums.append(list(common_nums))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: model.layers.0.mlp.down_proj.weight\n",
      "in Layer0 , sorted_indices_dimension3304:  ['izi', 'Tru', 'Flug', 'aby', 'ince', 'unicí', 'Strategy', 'alu', 'yect', '˚', '体', 'chrom', 'demás', 'сей', 'лта', 'eny', 'schap', 'ived', 'HI', '<%=', 'oren', 'tent', 'circ', 'rol', 'flask', 'Según', 'zewnętrz', 'unk', 'Tor', 'hre', 'hren', 'omm', 'ikal', 'стоян', 'quit', 'ard', 'encia', 'underlying', 'zdob', 'Township', 'DP', 'tor', 'enza', 'quit', 'Mul', 'arten', 'nuit', 'ivel', 'enu', 'суще', '`:', 'peint', 'jú', 'ografi', 'bourg', 'iti', 'cro', 'mapping', 'tir', 'nab', 'stad', 'nom', '飛', 'Hockey', 'idi', 'знача', 'poste', 'rado', '过', 'Components', '秀', 'с', 'antes', 'TR', 'tok', 'away', 'halten', 'bres', 'położ', 'ador', 'ternal', 'dep', 'flesh', 'ற', 'Dí', 'Hir', 'bound', 'wię', 'ivari', 'arch', 'own', 'uni', '◦', 'night', 'Хро', 'adora', 'invas', 'ida', 'Pale', 'autorité', 'MO', 'isen', 'acia', 'Haut', 'ië', '়', 'Bent', 'Росси', 'Night', 'Roy', '鳥', 'tl', 'dep', 'дже', 'towns', 'adows', 'components', 'trasfer', 'ǐ', 'diffus', 'Wer', 'arding', 'hour', 'mechan', 'Mant', 'жений', 'consent', 'ug', 'nuc', 'sert', 'Winter', 'sist', 'ide', '({', 'compagnie', 'conven', 'grav', 'uerdo', 'internal', 'enses', 'ected', 'situ', 'cita', 'LENG', 'augh', 'prod', 'xf', 'schluss', 'tomcat', 'KB', 'adow', 'stycz', 'quin', 'schaft', 'TC', 'TO', 'heure', 'paint', '{%', 'Ћ', 'eren', '⇒', 'internal', 'кре', 'ら', 'információk', 'Conse', 'encias', '果', 'París', 'filter', 'axi', 'assign', 'Beng', 'пока', 'Dabei', 'округу', '�', 'cient', 'optimized', 'shift', 'Müller', 'oved', 'combinations', 'keit', 'mesure', 'zien', 'ctions', '息', '\\x12', 'ben', 'голов', 'Db', 'OL', 'ppi', 'Luft', 'forth', 'тов', 'ief', 'се']\n",
      "in Layer0 , sorted_indices_dimension3873:  ['ella', 'sche', 'thes', 'wiki', '深', 'efe', 'йской', 'mis', 'pis', 'ː', 'ket', 'ilde', 'istence', 'bay', 'misunder', 'vision', 'ude', 'ird', 'Ze', 'ès', 'eston', 'mis', 'Mis', 'dal', 'unda', 'istan', 'Led', 'Pfarr', 'essen', 'drums', 'FilterChain', 'epen', 'False', 'okal', 'ate', 'scheidung', 'tery', 'para', 'ugs', 'vision', '断', 'צ', 'wire', 'dep', 'ilib', '신', 'osis', 'rib', 'Garden', 'udo', 'Rib', 'udes', 'inks', 'eping', 'ńskiej', 'rang', 'Famil', 'гле', 'SEE', 'р', '={{', 'ص', 'ey', 'frique', 'ui', 'uch', 'scheid', 'ski', 'wheel', 'Tsch', 'obil', 'ufe', 'дра', 'teger', 'ม', 'egen', 'vie', 'д', 'dec', 'unya', 'berg', 'metros', 'парта', 'position', 'umb', 'ERT', 'ola', 'uky', 'éch', 'ulo', 'inton', 'éd', 'isf', 'baar', 'figura', 'ege', 'Sche', 'ұ', 'osition', 'xaml', 'perce', 'otti', 'Trop', 'ye', 'lí', 'Tried', 'HTML', 'response', 'loops', 'ornal', 'рал', 'Mant', 'Efter', 'usa', 'пара', 'binding', 'saved', 'лько', 'DIS', 'ion', 'DK', 'prog', 'іль', 'кан', 'Wall', 'Century', '部', 'FT', 'opport', 'illa', 'trees', 'iglia', 'Ze', 'ше', 'opro', 'dur', 'uset', 'wire', 'illo', 'atos', 'lost', 'nof', 'FALSE', 'ran', 'седа', 'iele', 'production', 'dt', 'cit', 'último', 'Ng', 'Davis', 'führung', 'etr', 'ux', 'geometric', 'né', 'schaft', 'zig', 'uj', 'bold', 'classe', 'sec', '�', 'ATE', 'respond', 'configured', 'ium', 'rile', '🌍', 'estre', 'zyst', 'Daar', 'Memorial', 'ynast', 'wart', 'wicklung', 'Hinweis', 'lamp', 'apat', 'sect', 'buch', 'irie', 'response', 'ġ', 'IL', 'security', 'ische', 'xe', 'garden', 'sono', 'besta', 'externos', 'URL', 'ay', 'Vict', 'typo', '%}', 'horizontal', 'ż']\n",
      "in Layer0 , sorted_indices_dimension451:  ['vé', 'eria', 'Den', 'ped', 'хе', 'skap', 'tery', 'ties', 'econom', 'LC', 'те', 'ole', 'ima', 'iga', 'ǒ', 'aled', 'tip', 'quired', 'ptop', 'vis', 'pole', 'ynt', 'ý', 'atum', 'óm', 'aden', 'Pon', 'isted', 'comma', 'quire', 'uno', 'vert', 'Tang', 'eu', 'Manager', 'Wikip', 'seh', 'ATE', 'object', 'veg', 'raste', '�', 'hop', 'object', 'anza', 'ự', 'ѝ', 'terne', 'Lab', 'arr', 'ate', 'fal', 'rit', '┐', 'ec', 'athol', 'alias', 'HD', 'ierra', 'せ', 'Список', 'wort', 'Franc', 'chair', 'display', 'Man', 'Fiche', 'rite', 'dra', 'dfs', 'sdl', 'ought', 'discipline', 'inture', 'fa', 'tere', '=/', 'iger', 'odox', 'gart', 'ader', 'рова', 'wo', 'Bill', 'ве', 'servable', 'ü', 'useppe', '�', 'rör', '천', 'companion', 'tbody', 'ле', 'ieri', 'PP', 'HE', 'errors', 'deg', 'це', 'inne', 'Window', 'заслу', 'Page', 'undert', 'vet', 'ң', 'pale', 'dessen', 'asto', 'tip', 'yl', 'porte', 'Cou', 'walk', 'omo', 'swers', 'weet', 'kick', 'ordnung', 'defeat', 'faith', 'vek', 'ńskiej', 'blank', 'anne', 'filters', 'uy', 'фон', 'mechan', 'ünd', 'zat', 'capit', 'skal', 'deb', 'igan', 'mas', 'idx', 'pu', 'adre', 'fd', 'Harold', 'hall', 'Kauf', 'citep', 'ten', 'ña', 'зыва', 'Петер', 'calci', 'yar', 'rio', 'circles', 'lieder', 'Box', 'opera', 'atform', 'oup', 'ю', 'пра', 'üss', 'Lars', 'manager', 'Кор', 'chapter', 'ordin', 'kter', 'し', 'interval', 'SEE', 'tax', 'bat', 'cible', 'thead', 'functions', 'Dra', 'tests', 'quipe', 'iali', 'Tables', 'Dra', 'Director', 'GC', 'nodes', 'tml', '平', 'compte', 'oper', 'bi', 'compare', 'enk', 'eas', 'Mas', 'Mod', 'rak', 'leb', 'Aires', 'ated', 'Math', 'iges']\n",
      "in Layer0 , sorted_indices_dimension2524:  ['uga', 'sole', 'tap', 'Fragment', 'auss', 'Хронологија', 'fragment', '∫', 'aly', 'fitting', 'viz', 'ders', 'lessly', 'ASCII', '∑', 'Draw', 'relief', 'rendering', 'recom', 'Pod', 'ouss', 'gift', 'ну', 'aro', 'яв', 'avant', 'xter', 'apsed', 'fahrt', 'cription', 'iddle', 'nelle', 'invari', 'onas', 'ряд', 'Alert', 'ee', 'cade', 'adrat', 'ridge', 'mark', 'YS', 'fit', 'aa', 'egen', 'iende', 'ARN', 'ahl', 'orno', 'ляр', 'acle', 'Kit', 'Fichier', 'isan', 'Stock', 'ül', 'wise', 'avant', 'nam', 'soft', 'relay', 'auf', 'bre', 'nil', 'ologia', 'ensus', 'drawing', '々', 'образ', 'orphism', 'esar', '(*', 'kem', 'ɵ', 'adr', 'rok', 'fragments', 'nal', '<>', 'ós', 'teenth', 'stock', 'amen', 'marks', 'nie', 'launch', 'mob', 'ош', 'wind', 'nofollow', 'np', 'oo', 'Cong', 'äst', 'mu', 'eded', 'tikz', 'Visibility', 'asto', 'athon', 'phr', 'Empty', 'lung', 'ishment', 'ki', 'mist', 'tin', 'Отече', 'Архівовано', 'footer', 'invisible', 'fame', 'nar', 'suit', 'rendered', 'reconst', 'Bah', 'ckets', '음', 'ı', 'itzer', 'parc', 'дела', 'opera', 'жда', 'try', 'visibility', 'vex', 'exerc', 'Jazz', 'н', 'domin', 'jazz', 'Airl', '口', 'React', 'nder', 'SSL', 'maker', 'alert', 'wise', 'VARCHAR', 'ние', 'ald', 'halten', 'iche', 'таль', 'piano', 'seg', 'hardt', 'amid', 'Invalid', 'bridge', 'emen', 'ne', 'pad', 'Split', '요', 'seg', 'нок', 'proof', 'n', 'Alert', 'imi', 'є', 'ona', 'Vis', 'onna', '|^', 'runner', 'go', 'Draw', 'ague', 'Kit', 'Dar', 'iger', 'ала', 'wrapping', 'ondere', 'chsel', 'prem', '要', 'Camera', 'fitted', '利', 'subscription', 'lage', 'naire', 'fam', 'Army', 'Список', 'Sah', 'Dub', 'opus', 'bright', 'ter', 'agini', 'ого', 'render', 'Magazine']\n",
      "Key: model.layers.1.mlp.down_proj.weight\n",
      "in Layer1 , sorted_indices_dimension2854:  ['ont', 'ilar', 'iez', 'phon', 'az', 'lim', 'rent', 'nia', 'aus', 'cco', 'ap', 'nick', 'ientes', 'lia', 'oba', 'ent', 'abase', 'acc', 'dic', 'bek', 'isi', 'fon', 'atic', 'pool', 'iben', 'Font', 'pp', 'če', 'isser', 'ben', 'urst', 'bet', 'iful', 'lius', 'ie', 'slant', 'pain', 'onica', 'enze', 'ete', 'стей', 'QUE', 'fica', 'Television', 'und', 'uth', 'ania', 'adem', 'ils', 'curl', 'drink', 'BU', 'Dal', 'rek', 'energ', 'bear', 'e', 'Ap', 'sought', 'пла', 'kar', 'indent', 'font', 'Ze', 'iss', 'CURL', '�', 'inger', 'yth', 'dal', 'іс', 'abe', 'Terra', 'opp', 'lah', 'dynamic', 'pill', 'diam', 'frat', 'rale', 'Bened', 'exc', 'colo', 'iene', 'si', 'bene', 'polit', 'politics', 'box', 'cius', 'ü', 'shapes', 'norm', 'ma', 'Normal', 'kal', 'bras', 'ė', 'terra', 'ссий', 'ierre', 'вати', 'слов', 'آ', 'td', 'av', 'Zie', 'jan', 'bu', 'lete', 'static', 'Aff', 'television', 'si', 'esar', 'TV', 'ּ', 'ur', 'са', 'ring', 'ку', 'apr', 'ft', 'imedia', 'pring', 'eria', 'ondo', 'icate', 'Rich', 'Da', 'uto', 'capital', 'TV', 'touch', 'num', 'ací', 'equ', 'cut', 'PATH', 'idal', 'cke', 'aba', 'rich', 'angu', 'Timeout', 'hal', 'reich', 'Pool', 'complete', 'table', 'orch', 'usa', 'ell', 'Generation', '注', 'bell', 'itan', 'Compiler', 'normal', 'bb', 'isc', 'dom', 'restaur', 'ю', 'ura', 'aj', 'misunder', 'aje', 'Dynam', 'animation', 'av', 'thead', 'requ', 'l', 'generation', 'Da', 'Jac', 'istre', 'greg', 'Pool', 'dynamically', 'dent', 'asp', 'icane', 'fest', 'wing', 'quel', 'dal', 'Fun', '�', 'que', 'Font', 'til', 'lij', 'а', 'along', 'rab', 'ord', 'municipal', 'itar']\n",
      "in Layer1 , sorted_indices_dimension10378:  ['adora', 'wig', 'consultato', 'Tir', 'elenium', '越', 'órico', 'ociación', 'ụ', 'sq', 'ificación', 'eries', 'igkeit', 'stellung', 'ightarrow', 'inen', 'wär', '\"`', 'ölker', 'ос', 'atabase', 'rinn', 'ización', 'mbH', 'на', '♯', 'ʊ', 'Nueva', 'CK', 'Tras', 'rimonio', 'ína', 'bazie', 'olare', 'colo', '�', 'íos', 'во', 'icación', 'rund', 'ℚ', 'tier', 'maste', 'germ', 'shift', 'ços', 'opher', 'sr', 'iki', 'äufig', 'ependant', 'ança', 'eston', 'Хронологија', 'Dictionary', '\"\")', 'unicí', 'خ', 'člán', '群', 'Bibliographie', 'bmatrix', 'noreferrer', 'ми', 'Datos', 'uvud', 'selenium', '官', '%%', 'rę', 'peat', ']{\\\\', '\"?>', 'Dictionary', 'LENG', 'ears', 'prog', 'uzz', 'iante', 'inar', 'programa', '≫', 'ficos', 'square', 'ños', 'ك', 'Audiod', 'onom', 'inación', 'uropa', 'bero', 'ći', 'inking', 'iono', 'ście', 'schließ', 'sche', 'rank', 'integration', '�', 'izione', 'ie', 'atro', 'substitute', 'accident', 'banda', 'Ú', 'ulpt', 'Bü', 'kunft', 'substitution', 'sten', 'simp', 'kih', 'iembre', 'LES', '�', 'techni', 'Gay', 'Alo', 'ocket', 'izzazione', 'retto', 'mouth', 'ények', 'oder', 'ɨ', 'iec', 'cken', 'rano', 'Río', 'Θ', 'tête', 'áll', '�', 'autory', 'Tier', 'Mundial', 'òria', 'ан', 'Tow', 'compr', 'powiecie', 'ünstler', 'icult', '�', 'Tul', 'wrześ', 'geg', 'Bac', 'inos', 'iesen', 'Graham', 'wohl', 'Oficina', 'ambos', 'ǔ', 'Britann', 'ू', 'textt', 'Outlet', 'üng', 'WPF', 'aggio', 'alion', 'distant', 'achine', 'operators', 'ption', 'CURL', 'ieben', 'ocity', 'ろ', 'lear', 'imos', 'eta', 'ufen', 'pieler', 'ritten', 'Ehr', 'yaume', 'DLL', 'Resources', 'Cultura', 'lish', 'hely', 'ер', 'inental', 'Ligue', 'Nella', 'ouve', 'hov', 'repeat', 'Copa', 'cols', 'iewer', 'ún', 'invalid', 'iech', 'програ']\n",
      "in Layer1 , sorted_indices_dimension1358:  ['ués', ']=\"', 'AppData', 'ITable', 'SBN', 'ächen', 'nad', 'FAULT', 'ue', 'zec', '�', 'bero', 'rey', 'jú', 'PN', 'rowser', 'Dez', 'ugby', 'gon', '◄', 'sog', 'irectory', 'zewnętrzne', '桥', 'floor', 'uetooth', 'setopt', 'Esc', 'Guer', 'strij', 'Hun', 'MQ', 'externe', 'ché', 'onCreate', 'kazy', '片', 'aspx', 'aben', 'entferne', 'izado', 'Rome', 'дина', 'Bang', 'isat', 'шп', 'Observable', 'IMARY', 'коло', 'Desktop', 'avid', 'etwork', 'Sied', 'gende', '宇', 'Ṭ', 'ege', 'èce', 'isko', 'ALSE', '̥', 'Хронологија', 'anon', 'článku', 'ué', 'Ā', 'agini', 'avascript', 'tcp', 'uesto', 'íz', 'chrome', 'Sheet', 'това', 'heimer', 'roduction', 'Leip', 'nav', 'Lis', 'VICE', 'iginal', 'provincie', 'mq', 'Fußball', 'ệ', 'Außer', 'league', 'gry', 'giore', 'stru', 'ceil', 'Statement', 'kost', 'mathchar', 'Opera', 'ܐ', 'нг', 'világ', 'бор', 'ictionary', 'ocs', 'Ь', 'weit', 'Medien', 'ße', 'sterreich', '昭', 'League', '<s>', 'ribución', '造', 'ico', 'zburg', 'javax', 'Observable', 'IAB', 'ований', 'gebra', 'iben', 'arning', 'dob', 'iedz', 'universitaire', 'bin', 'DBC', 'subst', '銀', 'CTYPE', 'lb', 'ionic', 'tis', 'opter', 'èque', 'done', 'cean', 'цю', 'quantum', '♯', 'LayoutParams', 'ige', 'жі', 'Show', '%{', 'Az', 'dar', 'Fly', 'osob', 'din', 'isz', 'ensa', '�', 'vos', 'Mitg', 'AXI', 'ི', 'мін', '역', 'atis', 'batch', 'ECT', 'ROUP', 'istique', 'Augen', 'zag', 'ба', 'Rolle', 'SION', '✔', 'Hook', 'ionario', 'педи', 'غ', 'Staats', '藏', 'ensemble', 'ϊ', '\"=>', 'idense', 'ltre', '放', '$}}%', 'rado', '<%=', 'usage', 'Bahn', 'ég', 'pio', 'ß', 'gz', '�', 'Fore', 'idth', 'recursive', 'bound', 'ivent', 'üst', 'Gut', 'nelle', 'üb', 'conven']\n",
      "in Layer1 , sorted_indices_dimension5265:  ['clock', 'usta', 'mine', 'elij', 'ел', 'arin', 'textt', 'nost', 'ielt', 'SR', 'ap', 'reci', 'ufen', 'elian', 'gia', 'reh', 'een', 'asha', 'ķ', 'yr', 'doch', 'SR', 'elsen', '客', 'iba', 'mens', 'лан', 'cian', 'nice', 'hover', 'нове', 'Original', 'ready', 'Trad', 'secure', 'enden', 'нва', 'final', 'trz', 'uszt', 'Zone', '➜', 'кола', 'como', '宿', 'Tr', 'nats', 'ustration', 'destac', '$}}%', 'ial', 'kup', 'void', 'rinn', 'isseur', 'settlement', 'iellement', '☺', '片', 'aty', 'staw', 'oka', 'ware', 'Aust', 'vote', 'живело', 'Leip', 'flor', 'ustr', 'sr', 'strutt', 'ents', 'вя', 'poque', 'Wille', 'maven', 'easiest', 'мо', 'став', 'wr', 'dimen', 'money', '<s>', 'Site', 'Wikipedia', 'sight', '那', 'atin', 'aszt', 'PP', 'gods', 'ා', 'read', '✿', 'ungsseite', 'gresql', 'constitu', 'Демо', 'adel', 'ented', 'udni', 'él', 'lait', 'boy', 'book', 'amazon', 'struct', 'spare', 'adin', 'auto', 'yen', 'clock', 'empty', 'чу', 'Void', 'boldmath', 'uto', 'données', 'ulus', 'phen', 'Altern', 'solem', 'stam', 'Holder', 'reload', 'elder', 'replace', 'multiply', '̍', 'kur', 'omm', 'ragen', 'ital', 'fi', 'Wie', 'fe', 'shield', 'alin', 'Zwe', 'cic', 'Capital', 'mem', 'mut', 'modal', 'Ready', 'abord', 'Austin', 'Pel', 'Stack', 'anim', 'popul', 'rite', 'PS', 'ears', 'ax', '常', 'Fam', 'pel', 'Cic', 'io', 'вели', 'Sito', 'Mond', 'ウ', 'Priv', 'cant', 'Chain', 'Zone', 'meno', 'Sierra', 'autory', 'Staat', 'Wolfgang', 'Book', 'Corn', 'инте', '⅓', 'Ы', '위', 'ả', 'rile', 'wait', 're', 'api', 'aval', '度', 'Final', 'Cant', 'void', 'nou', '�', 'avo', 'antal', 'trad', 'raw', 'rico', 'subst', 'ậ', 'mx', 'ael']\n",
      "in Layer1 , sorted_indices_dimension8894:  ['CCESS', 'ometry', 'ometric', 'idth', 'лу', 'iger', 'omo', 'elte', 'archar', 'ụ', 'iom', 'chus', 'chia', 'hockey', 'фи', 'enu', 'ALSE', 'ard', 'umerate', 'teck', 'ба', 'ри', 'ennen', '🌍', 'Pu', 'omial', 'rite', 'ARD', 'Play', 'eno', 'iennes', 'OIN', 'omon', '經', 'ynomial', 'mot', 'ucha', 'PU', 'pon', 'bió', 'Ingl', 'Pf', 'AML', 'Svens', 'oba', 'hom', 'DA', '经', '草', 'BA', 'baum', 'Play', 'esar', 'orld', 'мет', 'ён', 'omed', '�', 'unta', 'PE', 'ąż', 'anni', 'шь', 'Ign', 'Icon', 'Fichier', 'кой', 'nome', 'row', 'Italia', 'iemann', 'orientation', '❯', 'ocker', 'pb', 'archy', 'arch', 'sect', 'CCN', 'til', 'finit', 'ớ', 'quot', 'éter', 'én', 'uid', 'ön', 'iga', 'irregular', 'ML', 'binary', 'oco', 'rows', 'PRIMARY', 'По', 'linear', 'amarin', 'bey', 'ymn', 'CESS', '户', 'ternal', '次', '此', 'Brun', 'ék', 'Overflow', 'せ', 'pun', 'mac', 'interven', 'elly', 'мена', 'wis', 'Wright', '\":{\"', 'hoz', 'tree', 'licht', 'chat', 'pu', 'indow', 'gé', 'Pod', 'lut', '南', 'hora', 'aba', 'ometer', 'Gree', 'PA', 'typing', 'pod', 'enska', 'pu', 'ocs', 'baseball', 'Ť', 'sert', 'Yan', 'ἄ', 'unter', 'PN', 'UID', 'Fro', 'ign', 'мости', 'omena', 'API', 'ellan', 'Ignore', 'orientation', 'ingham', 'igare', 'icted', 'BC', 'Stu', 'łu', 'насе', 'obar', '�', 'Jones', 'tera', 'move', 'Kl', 'дии', 'ént', 'Britann', 'formats', 'esseur', 'slant', 'Serie', 'aterra', 'cted', 'mutable', 'etwork', 'rib', 'Со', 'EventListener', 'ser', 'esso', 'már', 'nder', 'ifest', 'рия', 'Prim', 'со', 'ribu', 'zewnętrzne', 'eni', 'protected', 'ńska', 'border', 'clust', '{`', 'Convention', 'beans', 'afka', 'estellt', 'Icon']\n",
      "Key: model.layers.2.mlp.down_proj.weight\n",
      "in Layer2 , sorted_indices_dimension4033:  ['igo', 'спи', 'ppo', 'anon', 'Kant', 'owy', 'нок', 'ван', 'Pac', 'adow', 'gun', 'Atlas', '�', 'asts', 'Fichier', 'GP', 'EE', 'oby', 'atos', 'neither', 'gran', 'tid', 'ettings', 'SION', 'departure', 'repla', 'mes', 'gebra', 'iano', 'isan', 'ti', 'lic', 'usable', '想', 'wan', 'una', 'ISO', 'Atlas', 'GC', 'stand', '�', 'aire', 'curl', 'ritz', 'Van', 'sink', 'ры', 'Mad', 'akh', 'cius', 'throw', '�', 'Civil', 'rust', 'corte', 'Kent', 'civil', 'Napoleon', 'entitled', 'lic', 'canonical', 'alt', 'igr', 'Cow', 'license', 'Ald', 'son', 'reflection', 'sin', 'tabs', 'ise', 'ocr', 'Majesty', 'register', 'Balt', 'served', 'ئ', '�', 'illery', 'License', 'Insert', 'exports', 'ung', 'hand', 'kow', '操', 'né', 'entr', 'Cand', 'Rich', 'master', 'tunnel', 'tabs', 'leich', 'yan', 'rodz', 'cow', 'onian', 'ppet', 'nings', 'sf', 'pp', 'Collins', 'essional', 'hole', 'rr', 'Marx', 'flug', 'dri', 'merk', 'illet', 'tent', 'ft', 'min', 'eleg', 'чко', 'condition', 'AT', 'istrict', 'мы', 'son', 'pres', 'homonymes', 'promises', 'courts', 'NotFound', 'ers', '同', 'alk', 'ittel', 'лист', 'matically', 'DE', 'ն', 'ppa', 'phr', 'Guer', 'explain', 'Napole', 'permit', 'dos', 'Duch', 'acco', 'zyst', 'дер', 'dev', 'throw', 'soci', 'Pacific', 'pen', 'Asia', 'actory', 'anst', 'жі', 'estellt', 'piano', 'Hello', 'UP', 'pd', 'dex', '́', 'stru', 'opport', 'aan', 'network', 'ful', '$|\\\\', 'soll', 'assa', 'register', 'STAT', 'IMA', 'Random', '里', 'sy', 'forces', 'wave', 'forb', 'bl', 'iono', 'send', 'ién', 'kende', 'Optional', 'cil', 'agh', 'than', 'cont', 'recherche', 'holm', 'лез', 'yo', 'permission', 'округа', 'Internacional', 'Network', 'tab', 'sle', 'mayo', 'Daily']\n",
      "in Layer2 , sorted_indices_dimension2146:  ['UTC', 'cul', 'PDF', 'LAB', 'rif', 'ban', 'aban', 'cutting', 'iano', 'ession', 'aring', 'Congress', 'Folder', 'hard', 'iche', 'exe', 'excel', 'GA', 'dru', 'жан', 'igh', 'icale', 'ira', 'merged', 'OS', '身', '野', 'ria', 'べ', 'Ton', 'classes', 'pdf', 'cdn', 'occ', 'Dum', 'Roland', 'excel', 'lif', 'dem', 'în', '光', 'aw', 'icker', 'Types', 'wan', 'roph', 'setContentView', 'ص', 'thought', 'rough', 'ails', 'ги', 'hell', 'ento', 'Classes', 'fit', 'yt', 'пов', 'aven', 'NG', 'mer', 'вид', 'combined', 'fis', 'ind', 'refs', 'sn', 'arina', 'ival', 'obi', 'ℚ', 'fit', 'Вы', 'Externa', 'Canal', 'merchant', 'Os', 'malloc', 'кор', '火', 'Cand', 'explicit', 'war', 'ห', 'odu', 'vois', '리', 'ability', 'ի', '§', 'canal', 'endif', 'burn', 'pon', 'pop', '館', 'oc', 'Κ', 'rick', 'dem', 'cis', 'тив', 'atos', 'ría', 'ckets', 'hal', 'ęp', 'erdings', 'be', 'DEFAULT', 'вопро', 'retto', 'opera', 'igr', 'lac', 'Morris', 'Hard', 'hard', 'Gre', 'cardinal', 'gross', 'mer', 'css', 'Dru', 'lin', 'trif', 'gress', 'Audio', 'w', 'ienza', 'ë', 'Ruth', 'folder', '=\".', 'Capit', 'eqn', 'тре', ']=\"', 'plement', 'ville', 'Hal', 'Veg', 'las', 'iras', 'iques', 'mist', 'Mult', 'équ', 'Dur', 'bin', 'Han', 'merge', 'ical', 'apers', '±', 'IAB', 'fic', 'po', 'Mer', 'canonical', 'leaves', 'ocup', 'idel', 'anth', 'sections', 'FS', 'ich', 'Mer', 'вы', 'ří', 'flor', 'expl', 'demon', 'virtual', 'call', 'Lip', 'iencia', 'Egy', 'cz', 'há', 'apt', 'Ven', 'Auß', 'pa', 'BE', 'classes', 'ielt', 'dernière', 'ij', 'ющи', 'Kennedy', 'árs', 'zial', 'relation', 'fire', 'cor', 'ven', 'beh', 'भ', '話']\n",
      "in Layer2 , sorted_indices_dimension4711:  ['rå', 'iy', 'pad', 'Hud', 'arters', 'pri', 'olo', 'esa', 'riteria', 'eler', 'onderwerp', '址', 'eben', 'ляет', 'Felix', 'rale', 'Pad', 'Cache', 'udo', 'fer', 'chev', 'delegate', 'chr', 'ouc', 'év', 'ゃ', 'Jazz', 'fel', '�', 'rev', 'še', 'nę', 'liches', 'TAC', 'Arena', 'olare', 'GS', 'UID', 'ля', 'estamp', '소', 'ABC', 'szám', 'چ', 'ょ', 'itats', 'ἔ', 'èg', 'Fir', 'Anto', 'iai', 'üst', 'dzie', 'тая', 'VO', 'iono', '越', 'ura', 'externes', 'nen', 'atal', 'uc', 'departamento', 'wrap', '면', 'DES', 'SE', 'UR', 'ural', 'Gra', 'ck', 'ounce', 'еде', 'eller', 'zat', 'dec', 'rez', 'Rev', 'Selector', 'URI', 'Area', 'sole', 'Buffered', 'endencies', 'bootstrap', 'zem', 'ytu', 'haft', 'comer', 'Opera', '話', 'talet', 'ohen', 'iced', 'adora', 'esterni', 'ienza', '未', 'anni', '다', 'ical', 'ünd', 'chrom', 'cache', 'тур', 'fah', 'bol', 'trav', 'jahr', 'BUG', 'bine', 'osto', 'jazz', 'ству', 'walt', 'ever', 'zák', 'unc', 'dec', 'ụ', 'IMA', 'юз', 'CO', 'gra', 'Grace', 'opera', '>::', 'fn', '�', 'bug', 'ü', 'zil', 'ensa', 'ู', 'ic', 'clipse', 'ologische', 'condem', 'thread', '$_', 'Lied', 'Desp', 'Bür', 'debugger', 'younger', 'bars', 'findViewById', 'UN', 'iento', 'pad', 'ぶ', 'außer', 'styles', 'lections', 'rappres', 'ref', 'ifolia', 'ґ', 'cip', '論', 'ции', 'Stanisław', 'ixon', 'unic', 'rész', 'Pad', 'ahl', 'Thread', 'ScrollView', 'ôt', 'cko', 'UI', 'seed', 'ń', 'never', 'agna', 'Від', 'ське', 'oper', 'aval', 'ema', 'rac', 'rius', 'составе', 'iments', 'ugin', 'ührt', 'èque', 'endorf', '�', 'Sever', 'brázky', 'convert', 'Depuis', 'ye', 'esi', 'apt', 'кому', 'deel', 'Traceback']\n",
      "in Layer2 , sorted_indices_dimension2376:  ['abet', 'slash', 'Boot', 'Commons', 'spole', 'Kurz', 'kö', 'card', 'boot', 'cards', 'raph', 'thes', 'ershell', 'Blue', 'brázky', 'anne', 'Card', 'cca', 'onces', 'sword', 'Blue', 'rass', 'Wein', 'tags', 'epen', 'reason', 'gut', 'lez', 'att', 'Georges', 'Ț', 'Rein', 'ńst', 'Window', '‰', 'ards', 'groupId', 'apt', 'Card', 'tensor', 'lices', 'Harr', 'Pont', 'card', 'beh', 'گ', 'up', 'eded', 'sierp', 'upload', 'rick', '�', 'apt', 'Window', 'landa', 'known', 'sdl', 'gun', 'ряд', 'nja', 'uli', 'zeich', 'ays', 'inx', 'tags', 'conversion', 'ya', 'pont', 'cards', 'grat', 'slug', 'pen', 'tag', 'urrency', 'ously', 'ремен', 'iner', 'Navigation', 'Ble', 'agnet', 'Boot', 'cel', 'usa', 'Exchange', 'ź', 'vard', 'HR', 'lee', '史', 'concrete', 'пар', 'Mess', 'ella', 'kazy', 'CR', 'fog', 'locally', '¨', 'mathchar', 'Part', 'property', 'weise', 'ственно', 'compat', 'cab', 'Connect', 'њи', 'oma', '{%', 'arch', 'avid', 'Prop', 'Bishop', 'greater', 'answers', 'ingu', 'execution', 'verb', 'paid', 'gas', 'ên', 'amentos', 'edes', 'MAX', 'j', 'Turn', 'Operation', 'Deput', 'cx', 'gue', 'aland', 'intu', 'cloudflare', 'лё', 'plan', 'abort', 'zi', 'ometer', 'Coll', 'obt', 'Setting', 'deput', 'schließ', 'état', '书', 'arse', 'ج', 'Ist', 'propag', 'eben', 'carte', 'reboot', 'boot', 'ável', 'Plan', 'doing', 'rep', 'language', 'uns', 'great', 'Turn', 'crete', '�', 'Activity', 'isión', 'Capit', 'UITableView', 'ces', 'hus', 'cour', 'abs', 'ø', 'зи', 'sudo', 'lang', 'veg', 'ernal', 'Ori', 'adrat', 'sup', 'NU', 'nyelven', 'curves', 'clojure', 'Conne', 'Palmar', 'comput', 'lès', 'marker', 'omp', 'Property', 'networking', 'LI', '¼', 'ason', 'Тур', 'ya', 'antal', 'держа', 'emat']\n",
      "in Layer2 , sorted_indices_dimension5005:  ['atem', 'pool', 'aten', 'yst', 'letter', 'zak', 'lag', 'lings', 'sam', 'yz', 'yj', 'range', 'pool', 'ystycz', 'an', 'speed', 'speed', 'RS', 'iller', '果', 'legend', 'ön', 'egu', 'Рос', 'letter', 'gram', 'пей', 'mp', 'ги', 'це', 'lett', 'success', 'status', 'Ehr', 'ae', 'execution', 'aggi', 'VA', 'cit', 'Python', 'actory', 'vic', 'XX', 'amplitude', 'refer', 'ogne', 'Pool', 'Temple', 'Speed', 'è', 'screen', 'мах', 'amar', 'anchor', 'PI', 'ám', 'blo', 'Taylor', 'LI', 'context', '�', 'blo', 'Adam', 'gas', 'conv', 'др', 'referencing', 'SA', 'Ferd', 'legend', 'фер', 'status', 'zas', '&', 'amarin', 'floor', 'ánico', 'exer', 'range', 'Gol', 'yourself', 'endo', 'sex', 'bla', 'rew', 'fac', 'Status', 'wis', 'óp', 'correspond', 'maintain', 'leid', 'iks', 'enschapp', 'oper', 'dam', 'BU', 'nbsp', 'himself', 'energy', 'blank', 'Russell', 'action', 'rog', 'uni', 'Speed', 'whole', 'змі', 'https', 'Simon', '�', 'рами', 'ifa', 'miss', 'viz', 'ступа', 'bold', 'ub', 'ather', 'Ā', 'vol', 'etro', 'anal', 'dg', 'Uniti', 'vale', 'silent', 'agog', 'Ritter', 'assen', 'Ε', 'am', 'zig', 'АН', 'тах', 'ios', 'bow', 'ional', 'vis', 'urger', 'dah', 'Union', 'itis', 'le', 'well', 'bou', 'Review', 'sible', 'Gib', 'vict', 'press', 'Mär', 'se', 'Olimp', 'blank', 'Py', 'mit', 'Hamburg', 'йской', 'Ad', 'pass', 'soul', 'ър', 'flow', 'cko', 'ach', 'ritten', 'Victor', 'volume', 'Bla', 'mary', '面', '始', 'ili', 'Minor', 'adult', 'mouth', 'énd', 'ager', 'maintenance', '�', 'agues', 'medi', 'Sam', 'mar', 'LOAD', 'ε', 'opera', 'ag', 'python', '伝', 'ample', 'wal', 'AN', 'pass', 'voc', 'urname', '彦', 'camp', 'mai']\n",
      "in Layer2 , sorted_indices_dimension6542:  ['Datos', 'Border', 'ò', 'beskre', 'Wikispecies', 'border', 'ptic', 'дер', 'isson', 'Fragment', 'alberga', '---+', 'irse', 'virtual', 'oy', 'owo', 'achiv', '道', 'слу', 'zas', 'nr', '♣', 'swe', 'spread', 'ią', 'Fragment', 'dot', 'ota', 'NotFound', 'border', 'CD', 'uden', '-+', '>:', '動', 'otta', '弘', '²).', 'ník', 'pun', 'ROUP', 'lag', 'lia', 'ę', 'ھ', '›', 'jak', 'urk', 'TA', 'counting', 'ར', 'dagger', 'AppData', 'cant', 'duties', 'Fritz', '信', 'onders', 'itzen', 'Virtual', 'zyż', 'ivas', 'MENT', 'idense', 'fer', 'getMessage', 'ogene', 'akult', 'ply', 'Kontrola', 'Ζ', 'cd', 'lait', 'ilor', 'iak', 'нан', 'све', 'dict', 'listen', 'zor', 'вро', 'uil', 'respond', 'liqu', 'chter', 'compile', 'Tage', 'odox', 'öld', 'ど', 'iskt', 'Bd', 'oup', 'Unicode', 'algorithm', 'rx', 'inflate', '자', 'Border', 'ḏ', 'げ', 'comot', 'iges', '�', 'Props', '/%', 'tur', 'erade', 'Columns', 'Fer', 'Expression', 'Mouse', 'ritz', '=\"${', 'vr', 'xty', '%%%%%%%%', '�', 'obey', 'buntu', 'Ign', 'LECT', 'inois', 'ührt', 'Unidos', 'gun', 'kte', 'poly', 'ędzy', 'buch', 'rc', 'bru', '雲', 'Datenbank', 'apsed', 'olean', 'ąz', 'licht', 'CD', '嘉', 'cita', 'caught', 'ühr', 'tech', 'idal', 'liste', 'word', 'Autres', 'idad', 'Messages', '�', 'чен', '~~~~~~~~', 'ën', 'lag', 'Dispatch', 'vy', 'пли', 'issement', 'QUEST', 'Fernández', 'axy', 'pair', 'ńczy', 'urz', 'virtual', 'ńcz', 'dot', 'во', 'linker', 'hpp', 'ок', 'Wort', '▼', 'AA', 'ръ', 'lient', 'kir', 'DateTime', 'PASS', 'branch', 'ierno', 'виси', 'Lag', 'ots', 'Årsmed', 'resp', 'heit', 'rote', 'ospod', 'tek', 'Bog', 'ץ', 'exponential', 'бо', 'PropertyChanged', 'abase', 'екси', 'TAG', 'Denkmal']\n",
      "in Layer2 , sorted_indices_dimension10226:  ['Wikipédia', 'Dead', 'ças', '行', 'ampl', 'ces', 'erta', 'dead', 'dy', 'пас', 'Mall', 'ftrag', '구', 'origin', 'ří', '堂', 'trop', 'hit', 'прав', 'iness', '역', 'vity', 'ijo', 'atura', 'ceae', 'afen', 'ieron', '�', 'pipe', 'nis', 'INFO', '州', 'igne', 'ket', 'ark', '&=\\\\', 'nder', 'reflect', 'ën', 'π', 'coffee', 'ições', 'któ', 'kit', 'rust', '流', 'position', '�', 'West', 'iero', 'ça', 'Switch', 'нец', 'baum', 'itié', 'реа', 'posa', 'Données', 'kup', 'vić', 'oir', 'orithm', 'amt', 'erner', 'Ë', 'onn', 'tend', 'Halle', 'blog', 'kill', '起', 'ɵ', 'Исто', 'zo', 'ña', 'neut', 'utter', 'dc', 'dorf', 'ë', 'beeld', 'magn', 'puesta', 'guer', 'ppe', '/~', 'ël', 'Ь', 'instit', 'guide', 'Computer', 'Pia', 'scale', 'CES', 'olan', 'inta', 'shoot', 'dot', 'agi', 'wp', 'oire', 'guide', 'wire', 'Trop', '->_', 'tor', 'õ', 'ряд', '座', 'óm', '⅓', 'ове', 'чита', 'ienn', 'себя', 'aties', 'estore', 'ender', 'lav', 'ikel', 'actor', 'inn', 'nap', 'flex', 'oi', 'quency', 'eredetiből', 'ija', 'prayer', 'Kor', 'rile', 'llaços', 'Instit', 'Puerto', 'kon', 'range', 'ek', '物', 'enders', 'ppo', 'ing', 'ständ', 'correct', 'Ing', 'Mate', 'ANGE', 'uen', 'ample', '.@', 'riz', 'Marg', '무', 'Paz', 'aggio', 'лежа', 'мир', 'para', 'ré', 'tml', 'ler', 'bia', 'straight', 'Fam', 'auff', 'це', '̥', 'cé', 'Justice', 'ument', 'deviation', 'Guide', 'course', 'Fame', 'ighth', 'SER', 'oster', 'TRAN', '̃', 'släktet', 'Off', '�', 'asket', 'ają', 'même', 'entropy', 'tijdens', 'recon', 'cí', 'egyzetek', 'Rico', 'villa', 'стре', 'Lanc', 'quet', 'Guer', 'fect', 'ità', 'народ', 'ugel', 'tv']\n",
      "in Layer2 , sorted_indices_dimension3059:  ['望', 'erf', 'lez', 'zs', 'borg', 'ame', 'Touch', 'antal', 'amp', 'hart', 'opf', 'naz', 'fico', 'Ober', 'astern', 'anted', 'kow', 'ahu', 'ір', 'agnost', 'fri', '=\"<?', 'Mie', 'Ə', 'orf', 'ụ', 'шин', 'Dro', 'eln', 'cons', 'endo', '리', 'eme', 'jon', '/-', 'Ort', 'ajn', 'alberga', 'ison', 'kov', 'nia', 'opera', 'нем', '泉', 'haupt', 'Dir', 'beh', 'ops', 'Opera', '�', 'lé', '∙', 'Ziel', 'FE', 'voir', 'acht', 'DC', 'idget', '乡', 'uniform', 'Mira', '⁻', 'iembre', 'conscience', 'Cés', 'фе', 'largo', 'лів', 'ktion', '拳', 'Bian', 'penas', 'ermeister', 'wind', 'Deutsch', 'Script', 'зі', 'bian', 'buntu', 'jm', 'ང', '⊕', 'cons', 'weg', 'jal', 'Village', 'Touch', 'zA', 'elles', 'зен', 'ätz', '�', 'fab', 'iem', 'Rout', 'Dieu', 'ando', 'touch', 'cgi', 'posto', 'ocket', 'Limited', 'Symbol', 'iera', 'lied', 'minipage', 'Mock', 'UD', '配', 'pó', 'imi', 'atura', 'dedu', 'société', 'ве', 'divs', 'kap', 'IME', 'Norden', 'Portail', 'pie', 'html', 'externes', 'ent', 'Derby', 'adel', 'did', 'azon', 'rz', 'Ṭ', 'izzata', 'anto', 'прав', '房', 'Архівовано', 'totalité', 'És', 'ע', 'lear', 'atform', 'Lab', 'column', 'fact', 'Cord', 'Italiana', '∞', 'lí', 'лта', 'società', 'ictures', 'Feld', 'Seb', 'Lam', 'Napole', 'omena', 'Song', 'framework', 'externs', 'onte', '值', 'pobla', 'andbox', 'Son', 'Eva', 'assumes', '結', 'Picture', '∧', 'ɛ', 'CHAPTER', 'єдна', 'opsis', 'nect', 'arf', '}}%', 'äh', 'mn', 'ння', 'ometer', 'UE', 'arn', 'cloud', 'cord', 'iom', 'connexes', 'Cop', 'nja', 'signed', 'nasc', 'agem', 'Usage', 'ilon', 'mask', 'kem', 'iano', 'opin', 'limit', 'repro', 'ialog', '\\\\<']\n",
      "in Layer2 , sorted_indices_dimension697:  ['ն', 'incor', 'ECT', 'nete', 'Leip', 'xaml', 'фе', 'anze', 'atus', 'wort', 'erm', 'Pin', 'lymp', 'cademy', 'plements', 'weg', 'Lima', 'olymp', 'urz', 'yo', 'Rate', 'uras', 'urname', 'Kennedy', 'основ', 'ante', 'agyar', 'ansen', 'raint', 'Mess', 'pó', 'Eisen', '్', 'tit', 'ско', 'autorité', 'ouvern', 'Hey', 'руп', 'itaire', 'irtual', 'utter', 'gepublic', 'jamais', 'uario', 'ulf', 'ancer', 'ussen', 'heimer', 'largo', 'igger', 'igu', 'Mine', 'wiki', 'mouth', '제', 'heet', 'BeanFactory', 'ně', 'sess', 'inary', 'Ulrich', 'START', 'lement', 'тра', 'emeinde', 'ried', 'nett', 'emo', 'icus', '孝', 'Castro', 'ے', 'URE', '\\x83', 'ст', 'Session', 'External', 'Mess', 'ським', 'Colleg', 'Ђ', 'ormal', 'tocol', '›', 'antes', 'hner', 'ROUP', 'qua', 'lang', 'Bind', 'ﬁ', 'jsf', 'completion', 'ando', 'rate', 'buch', 'ytu', '̣', 'Dans', '\\x9c', 'ül', 'Olympics', '�', 'ál', 'Framework', 'Cob', 'initialization', 'virti', 'euw', 'ité', 'öl', '>\\\\<', 'osas', 'clés', 'Données', 'docs', 'ichi', 'agy', 'ὑ', 'ième', 'à', 'arde', 'еру', 'ъ', 'ゆ', 'Salt', 'voll', 'honneur', 'bylo', 'eny', 'wards', 'ero', 'amente', 'bereits', '\\x94', 'дови', 'ný', 'část', 'repres', 'liv', 'framework', 'ului', 'np', 'rong', 'infty', 'anto', 'epen', 'onato', '+=', 'ydro', 'partiellement', 'angol', 'eless', 'atri', 'entre', 'parallel', 'Marco', '传', 'Кра', 'ativo', 'côté', 'ooth', 'чёт', 'сти', 'tcp', 'Bald', 'rag', '常', 'Nas', 'ouverneur', 'jango', '君', 'okal', 'oshi', 'Augen', 'textt', 'ikus', 'Olympic', 'ktop', 'míst', 'astr', 'значи', 'sters', 'illi', 'CTYPE', 'veröff', 'iones', 'じ', 'бран', 'ità', 'ionario', 'initialize', 'percent', 'URI', 'сра', 'mines', 'ools', 'висини', '️']\n",
      "in Layer2 , sorted_indices_dimension668:  ['AXI', 'olu', 'elij', 'Ehren', 'expected', 'mismatch', 'ym', 'Nom', 'cres', 'erw', 'Krieg', 'iction', 'Hoff', 'nom', 'upd', 'heb', 'Krie', 'Fair', 'kre', 'phia', 'bian', 'ould', 'opera', 'Rena', 'getElementsBy', 'ká', 'kh', 'expected', 'Aff', 'ouri', 'Depuis', 'yk', 'Fa', 'alt', '故', 'adaptation', 'adult', 'attice', 'голо', '�', 'holes', 'BUG', 'ign', 'aring', 'FM', 'Fi', 'df', 'scores', 'Fe', '青', 'Table', 'ByVal', 'touch', 'Kop', 'igan', 'kop', 'sha', 'utf', 'Foundation', 'ider', '../../', 'rale', 'FE', 'patch', 'ände', 'umann', 'мого', 'decor', 'ring', 'fair', 'Fine', 'IndexPath', 'bez', 'har', 'iero', 'iki', 'шо', 'rica', 'станов', 'ations', 'hib', 'zott', 'fo', 'yci', 'ime', 'да', 'escaped', 'Famil', 'halt', 'escape', 'polski', 'Serializer', 'Guide', 'fine', 'threaten', 'сто', '∗', 'Fou', 'mus', '??', 'interests', 'cri', 'Tab', 'Accessor', 'tres', 'dan', 'ada', '|_{', 'ation', 'Spo', 'ề', 'moth', 'olt', '若', 'ĩ', 'gra', '好', 'kaz', 'heck', 'FD', 'mirror', 'Mutter', 'nasc', 'Vo', 'ares', 'gathered', 'score', 'Namen', '́', 'Ali', '�', 'table', 'infer', 'aff', 'nth', 'ering', 'expect', 'тор', 'au', 'eli', 'rai', 'aties', 'comm', 'olo', 'iel', 'dan', 'iche', 'Co', 'IME', 'clock', 'belonging', 'anze', 'airo', 'reconst', 'Conf', 'escape', 'patch', 'agli', 'fe', 'нь', 'Anfang', 'т', 'clock', 'ple', 'Panel', 'holm', 'rij', '장', 'Tab', 'dc', '第', 'posa', 'imes', 'Opera', 'got', 'Esc', 'abc', 'sess', 'ере', 'battery', 'Field', 'дова', 'neut', 'Ober', 'pin', 'спо', 'report', 'рак', 'panel', 'cha', 'ends', 'icket', 'ẓ', 'ée', 'cer', 'cript', 'Roc', 'Ens', 'td', 'ы']\n",
      "in Layer2 , sorted_indices_dimension889:  ['osto', 'visibility', 'csol', 'quelle', 'ży', 'icult', 'Constant', 'nę', 'beskrevs', 'zew', 'vous', 'Active', 'rif', 'ennen', 'uese', 'ходить', 'Overflow', 'erei', '料', 'emein', 'DECLARE', 'pta', 'avel', 'angu', 'zyst', 'étés', 'kań', 'scriptstyle', 'schen', 'entr', 'OST', 'ForKey', 'acks', 'MDb', 'Span', 'pton', 'zett', 'ERR', 'xes', 'endance', 'issenschaft', 'Pit', 'už', 'zeit', '้', 'keit', 'ズ', 'Filip', 'istence', 'ּ', 'phia', 'desktop', 'ards', 'onces', 'asta', 'mb', 'tématu', 'sterdam', 'vos', 'ън', 'Buffer', 'kel', 'reibung', 'uela', 'osed', 'oa', 'veis', 'ualmente', 'amerikanischer', 'sede', 'Fichier', 'RL', 'сайте', 'Binding', 'urale', 'enium', 'relax', 'VB', 'iała', 'bü', 'ads', 'heim', 'pt', 'Visibility', 'aterra', 'opus', 'ак', 'ücke', 'reverse', 'Leonard', 'Ξ', 'Erst', 'żyn', '�', 'ije', '산', 'ader', 'ltal', 'meno', '{%', 'endif', 'helm', 'cin', 'ített', 'elles', 'Eva', '해', 'FOR', 'active', 'reverse', 'ücken', 'season', 'Overflow', 'article', 'yrus', 'cles', 'ieder', 'reiche', 'Ingl', 'stell', 'baz', 'ńst', 'седа', 'sigu', 'änge', 'NA', 'aqu', 'interview', 'yter', 'Vorlage', 'atform', 'quin', 'amentos', 'lijk', 'erves', 'шин', 'chez', 'Active', 'ères', 'Sitz', 'enser', 'seasons', 'Profil', 'vuel', 'lio', 'duplicates', 'anterie', 'orientation', 'Finale', '‹', 'icamente', 'Afr', 'Estad', 'ificate', 'Ori', 'cept', 'hire', 'onnées', 'ifiz', 'moz', 'ты', 'aments', 'Aires', 'merk', 'aks', 'atin', 'été', 'emberg', 'št', 'legate', 'aci', 'oston', 'allo', 'ĩ', 'вели', 'iből', 'ichte', 'nach', 'uale', 'parallel', 'leb', 'лен', 'ҡ', \"'_\", 'Classification', 'ermeister', 'mals', 'plorer', 'ural', 'uje', 'cam', 'atives', 'голов', 'сто', 'ง', 'Binding', 'пре', 'izio', 'ż', 'kund']\n",
      "Key: model.layers.3.mlp.down_proj.weight\n",
      "in Layer3 , sorted_indices_dimension1248:  ['еру', 'feed', 'dom', 'RewriteRule', 'egos', 'ceil', 'zę', 'lef', 'ätz', 'roit', 'ří', 'indent', 'onCreate', 'DOM', 'ousin', 'dorf', 'estad', 'hner', 'instantiate', 'Wikispecies', 'aje', '洞', 'pipe', 'lej', 'perty', 'tain', 'Mex', 'Nova', 'umerate', 'ROUP', 'cape', 'Sel', 'ят', 'оби', 'ред', 'airo', '~[', 'idge', 'flu', 'lev', 'bero', 'gr', 'так', 'зя', 'porte', 'ommen', 'sz', 'Traceback', 'rict', 'cgi', 'cement', 'сте', 'скус', 'lua', 'Dat', 'nement', 'jsf', 'abord', 'ご', 'tren', 'oust', 'gress', 'jamin', 'gminy', 'INCT', 'dj', 'eff', 'cx', 'lesh', 'endl', 'ред', 'utility', 'meck', 'déput', 'ero', 'ért', 'igny', 'hall', 'дон', 'LINQ', 'collect', 'министратив', 'lay', 'ouss', 'tml', '‡', 'kin', 'forall', 'stan', 'édé', 'WIDTH', 'anha', '江', 'vole', 'ļ', 'ousel', 'ony', 'ilde', '料', 'Ton', 'emer', 'muse', 'RewriteCond', 'остан', 'mechanism', 'слен', '�', 'DM', 'Factory', 'твор', '分', 'ель', 'VICE', 'synd', 'Тур', 'Academia', 'fmt', 'LayoutInflater', 'Baseball', 'Dog', 'проф', 'skal', 'ego', 'Sz', 'sel', 'contre', 'formatt', 'Widget', 'blob', 'kol', 'vc', 'lade', 'ska', 'йской', 'ifie', 'Lin', 'lä', 'flesh', 'abl', 'datab', 'estat', 'repla', 'Date', 'lapsed', 'ague', 'cus', 'Widget', 'роль', 'powiat', 'WA', '^(', '̶', 'eff', 'Estad', 'gy', 'plane', 'inct', 'share', 'lès', 'зяй', 'lish', 'Castro', 'inación', 'inus', 'jpeg', 'stein', '`-', '^-', 'OM', '�', 'ǐ', 'TAC', 'starting', 'bráz', 'Geb', 'Deze', '<=', 'Bass', 'mos', 'Opera', 'Feed', 'sehen', 'Cape', 'Edge', 'ilda', 'hausen', 'particul', 'ald', '>;', 'Middle', 'propor', 'Leo', 'Moz', 'rup', 'dash', 'рев', 'grouping', 'sterdam', 'arga', 'hub']\n",
      "in Layer3 , sorted_indices_dimension1281:  ['ersch', '❯', 'mont', 'ześ', 'lacht', 'висини', 'lez', 'inn', '◄', 'cape', 'ebook', 'Хронологија', 'sjö', 'zahl', '球', 'Tam', '˚', '巴', '(|', '<-', 'lá', 'ClickListener', 'Einzelnach', 'sey', 'apt', '#>', 'asi', 'eren', '�', 'ilis', 'osc', 'jus', 'abad', 'ovis', 'pay', 'acting', 'átum', 'Boston', 'ове', 'kaf', 'ئ', '華', 'ThreadPool', '\\u200c', 'län', 'schemas', 'ufen', '⁰', 'bot', 'ſ', 'gemein', 'aine', 'zyma', 'stract', 'ycler', 'ethe', 'koz', 'rás', 'istory', 'ros', 'üssen', 'DataFrame', 'тури', 'bě', 'шей', 'unlikely', 'ِ', 'TC', 'ennes', 'kommen', 'arn', 'cito', 'стоя', 'ract', 'кол', 'amid', 'ionen', 'ヒ', 'ал', 'berger', 'doFilter', 'ocker', '<-', 'oped', 'osi', 'ockey', 'ú', 'égl', 'Mari', 'side', 'fall', 'Bayern', 'árt', 'ampf', 'Massachusetts', 'Historia', 'Palmar', 'äst', 'Биография', 'Bundes', 'Janu', 'schaften', 'éal', 'selenium', 'ffen', '╬', 'bild', 'encounter', 'arter', 'presa', 'demselben', 'Gef', 'Gó', 'té', '景', 'norm', '败', 'PDO', 'Wat', 'fram', 'ractor', 'keiten', \"'/\", 'anas', 'dfs', 'бира', 'Մ', 'Gen', '传', 'estaven', 'pract', 'itsch', 'Objects', 'екси', '////////', 'atre', 'Len', 'länkar', 'EGIN', 'cred', 'ahlen', ':/', '�', 'cloudflare', 'Савез', 'ʊ', 'remov', 'stag', 'skip', 'бо', 'clojure', 'dbo', '長', '利', 'Scope', 'Strings', 'appen', 'ši', 'contra', 'volution', 'º', 'rör', '\\xa0\\xa0', 'isat', 'mare', 'olimp', 'Febru', 'raste', 'revers', 'alth', 'nement', 'ﬁ', 'sdk', 'bráz', 'safe', 'atra', 'deriv', 'appreci', 'zew', 'ancer', 'ბ', 'ker', 'divid', 'джа', 'Begriffe', 'istol', 'pecies', 'aires', 'mans', 'owy', 'flex', 'Vorlage', 'formatt', 'wald', 'отри', 'aram', 'hay', 'yc', 'aga', 'XY']\n",
      "in Layer3 , sorted_indices_dimension2146:  ['ov', 'agna', 'Kas', 'contra', 'contra', 'rever', 'ria', 'mel', 'Cz', 'Przyp', 'owski', 'Gli', 'Bug', 'arct', 'ović', 'бран', 'oot', 'acs', 'Instit', 'Response', 'tain', 'сер', 'Elect', 'Mam', 'bug', 'uder', 'ri', 'Ann', 'debug', 'arto', 'ζ', 'oid', 'agn', 'eta', '反', 'ӏ', '()', 'elect', 'Ost', 'tac', 'aml', 'iams', 'chang', 'il', 'ica', 'manus', 'ium', 'or', 'uri', 'ot', 'uto', 'candidate', 'References', 'Forum', 'antin', 'iano', 'Ź', '@{', 'Fern', 'équ', 'ustom', 'raint', 'pł', 'wal', 'yo', 'arts', 'eff', 'cas', 'angles', 'ال', 'Ť', 'bra', 'serv', 'opportun', '故', '////////////////', 'unit', 'ást', 'quad', 'applicable', 'ellschaft', 'Extensions', 'consequences', 'zar', 'uola', '器', 'Kam', 'adre', 'rial', 'makeText', 'ession', 'binary', 'ots', 'prim', 'andra', 'Dez', 'uen', 'PF', 'ový', 'Prim', 'pport', 'candidates', 'ectors', 'rian', 'ensoort', 'rea', 'fab', 'reaction', 'ann', 'owo', '%%%%%%%%', 'ilis', 'horses', 'lap', 'ord', 'debugger', 'amil', 'pto', 'ita', 'ast', 'exper', 'Mo', 'pf', 'ener', 'Prime', 'Politik', 'basket', 'Jazz', 'opportunity', 'reas', 'lica', 'iod', 'dflare', 'inus', 'utton', 'Factory', 'uria', 'lij', 'iesa', 'kommen', 'információ', 'ian', 'oo', 'ellan', 'stell', 'usa', 'Lig', 'media', 'сан', 'bug', '$}}%', 'rå', 'qua', 'ewnę', 'bund', 'uga', 'id', 'modifications', 'ouverneur', 'et', 'Sans', 'bata', 'connecting', '고', 'Transfermarkt', 'ud', 'Pil', 'Gemeinsame', 'Bast', 'staw', 'fahren', 'Giov', 'ela', 'iti', 'al', 'Mutable', 'ap', 'ấ', 'Arbeits', 'LL', 'annels', 'guitar', 'avam', 'serv', 'eli', 'ark', 'ки', 'otic', '陽', 'BUG', 'sk', 'ár', 'atos', 'ias', 'cess', 'Opera', 'bern', 'cod', '�', 'Li']\n",
      "in Layer3 , sorted_indices_dimension1795:  ['жива', 'ux', 'spec', 'counting', 'ступ', 'INNER', 'ych', 'Lind', 'ittest', 'Sig', 'embly', 'oul', 'Brun', 'istic', 'ześ', 'ument', 'менталь', 'Tová', 'reib', 'manip', '⊙', 'eper', 'istics', 'icket', 'маль', 'uben', 'rund', 'inos', 'able', 'LR', 'удо', 'apper', 'dotnet', 'Anto', 'union', 'xis', 'privile', 'стри', 'privileges', 'raham', 'roph', '강', 'Données', 'Bedeut', 'techni', 'ʾ', '�', 'Ak', '�', 'seq', 'DIR', 'huvud', 'rien', 'UNION', '%%', 'jev', 'iller', 'decode', 'ifiable', 'ipart', 'ступа', 'Bibliografía', 'azu', 'pac', 'Office', 'oben', 'acent', 'Koch', 'colog', 'utos', 'createElement', 'EE', 'бо', 'ILL', 'ction', 'call', 'она', 'anu', 'alu', 'abi', 'office', 'soul', 'latter', 'bow', 'uby', 'iber', 'Spec', 'ļ', 'спе', 'spel', 'ə', 'Dé', 'EGIN', 'unction', 'polit', 'ological', 'ABC', 'odge', 'ribución', '雪', 'ட', 'atu', 'clip', 'Sang', 'Rach', 'ै', 'transform', 'présent', 'бора', 'ographic', 'GV', '김', 'plex', 'decode', 'Abr', '術', 'ca', 'lez', 'xim', 'dm', 'villa', 'poly', 'Mock', 'strap', 'character', 'horn', 'мента', 'ucht', 'poll', 'omorph', 'retto', 'Laur', 'ться', 'öm', 'կ', 'Lincoln', 'transformation', 'ingår', 'yst', 'worker', 'instal', 'atoire', 'Jos', 'cli', 'inner', 'Einzelnachweise', 'dll', 'egin', 'iak', 'ak', 'ள', 'έ', 'Géographie', 'politique', 'ino', 'duty', 'ategories', 'xf', 'dal', 'DBC', 'тель', 'nik', 'Studien', 'ô', 'Mans', 'duino', 'LES', 'ос', 'éon', 'ms', 'sem', '제', 'ños', 'required', 'Region', 'ograph', 'Franklin', 'Dabei', 'dbo', 'Character', '密', 'uka', '\\u200e', 'ña', 'NUM', 'cast', 'día', 'ImageView', 'ectors', 'виде', 'ى', 'каль', 'mal', 'ō', 'ῥ', 'Camil', 'rag', 'attle', '河', '放']\n",
      "in Layer3 , sorted_indices_dimension9388:  ['sce', 'ombres', 'Stan', 'Category', 'тара', 'demselben', '郡', 'connexes', 'category', 'EXISTS', 'iew', 'rn', 'scriptsize', 'encuent', 'Jacques', 'exchange', '********', 'ム', 'latter', 'erne', 'ilder', 'owe', 'ства', 'œuvre', 'kbd', 'ach', 'gue', 'aks', 'rollo', 'count', 'll', 'wa', 'clock', 'ば', 'persistent', 'VC', 'Christ', 'arna', 'tip', 'works', 'People', 'POST', 'Netherlands', 'umb', 'context', 'exercise', 'aban', 'demand', '****************', 'misma', 'CCE', 'category', 'appreciate', 'exchange', 'scrolling', 'pace', 'Olympics', '弘', 'gro', 'énario', 'dust', 'Renaissance', 'ips', 'lon', 'Inf', 'aire', 'zew', 'ство', 'inf', 'oga', 'Kais', 'asp', 'Paint', 'apost', 'jos', 'cur', 'Komm', 'arbeit', 'os', 'uez', 'TW', 'énd', 'Bret', 'стве', 'Gro', 'awa', 'baum', 'ifen', 'rvm', 'Mess', 'ég', 'art', 'ран', 'getName', 'exception', 'reader', 'Originals', 'aby', 'anni', 'ocument', 'Category', 'läu', 'pobla', 'banks', 'schließ', 'ľ', 'ourg', 'elde', 'onym', 'scroll', 'aga', 'fer', 'рд', 'akh', '元', 'sob', 'enn', 'Ľ', 'cket', 'Gu', 'Fen', 'anchor', 'gate', 'wei', 'swap', 'clock', 'exerc', 'March', 'Cur', 'aceae', 'cast', 'indow', 'kow', 'extract', 'zysk', 'Us', 'bahn', '方', 'aa', 'county', 'Apost', 'lections', 'ів', 'Références', 'фе', 'lés', 'spher', 'zan', 'bed', 'elsen', 'bro', 'ď', 'ade', 'aes', 'èg', 'externas', 'oper', 'ienn', 'omány', 'persistence', 'udo', 'ể', 'divers', 'senior', 'api', 'HttpRequest', 'tent', 'mess', 'ios', 'square', 'agan', 'вен', 'bau', 'itch', 'Pent', 'enburg', 'Cast', 'perhaps', 'rad', 'adata', 'perspective', 'MD', 'amb', 'Cur', 'immagini', 'persist', 'principal', 'paramet', 'bes', 'Cris', 'Ned', 'rect', 'Platz', 'ELSE', 'especie', 'Quint', 'ellan', 'categories', 'pher', 'paint']\n",
      "in Layer3 , sorted_indices_dimension5870:  ['Stra', 'Chain', 'stra', 'nap', 'stra', 'esty', 'eller', 'schrift', 'rock', 'vend', 'тин', 'Shang', 'sjö', 'ulus', 'zó', 'Rock', 'rag', 'eye', 'au', 'lyn', 'jack', 'nap', 'Hay', 'vendor', 'chain', 'iso', 'rocks', 'Zür', 'andas', 'zug', 'chain', 'play', 'ikon', 'aft', '•', 'дже', 'aro', 'atro', 'mut', 'whom', 'crowd', 'rock', 'Bian', 'rn', 'Protocol', 'level', 'subst', 'ISO', 'Schaus', 'pic', 'пло', 'inline', 'cand', 'Pero', 'atorio', 'sizes', 'str', 'ilo', 'alt', 'assemble', 'rench', 'angularjs', 'recom', 'inline', 'хода', 'priv', 'ijn', 'estra', 'assen', 'Bat', 'pped', 'ша', 'rance', 'дами', 'ově', 'absol', 'Lyn', 'estr', 'Hein', 'rok', 'Eug', 'Ζ', 'ว', 'level', 'ろ', 'Push', 'odos', 'вет', 'istiques', 'Bis', 'imes', 'дан', 'gestellt', '–', 'zz', 'mur', 'Pred', 'Vog', 'beh', 'degrees', 'mee', 'fi', 'rok', 'odd', 'ISO', 'Python', 'oso', 'gen', 'лли', 'SB', 'üst', 'Kno', 'hoof', 'gs', 'краї', 'Golden', 'HA', 'Vic', 'rode', 'нь', 'режи', 'std', 'yn', 'Castle', 'Jose', 'Graphics', 'oreign', 'hang', 'Schiff', 'inger', 'auc', 'складу', 'Thread', 'gen', '·', 'bat', 'pred', 'Sed', 'éri', 'Canad', 'ten', 'ps', 'bs', 'idents', 'Shared', 'пе', 'Error', 'engelsk', 'itants', 'cat', 'command', 'M', 'für', 'сти', 'тт', 'DAY', 'profil', 'orient', 'aster', 'кие', 'icker', 'udni', 'sink', 'acquaint', 'alt', 'until', 'ються', 'cel', 'anyway', 'Python', 'epo', 'Ped', 'cat', 'Storm', 'volution', 'Gab', 'ęp', 'desar', 'day', 'degree', '郎', 'org', 'za', 'сите', 'reactjs', 'Error', 'dio', 'icos', 'phere', 'fair', 'Zob', 'meck', 'ran', 'Abstract', 'Standard', 'postgresql', 'Pred', 'ns', 'Cat', 'fellow']\n",
      "in Layer3 , sorted_indices_dimension3765:  ['ange', 'ól', 'Reform', 'iges', 'odox', 'äng', 'uria', 'sieme', 'stan', 'vas', 'Java', 'лиза', 'Node', 'ен', 'д', 'reform', 'vie', 'Lion', '后', 'СР', 'jed', 'Sito', 'squ', 'зе', 'dut', 'zp', 'unnecess', 'som', '⁻', 'xs', 'liga', 'Landes', 'zt', 'лее', 'aines', 'лат', 'контра', 'UE', 'VICE', 'ново', 'dart', 'este', 'лази', 'Chr', 'unnecessary', 'anges', 'kin', 'ade', 'ron', 'шлен', 'VB', 'Medic', 'кови', 'Body', 'ns', 'body', 'mistaken', 'Neder', 'entferne', 'mouse', 'zahl', 'medic', 'eu', 'Système', 'ords', 'VB', 'lint', 'days', 'setTimeout', 'osc', 'lon', 'cancel', 'lav', 'gat', 'ła', 'Cult', 'pied', 'ills', 'ohl', 'сини', 'used', 'esség', 'gent', 'racy', 'fins', 'zw', 'пери', 'chain', 'zák', 'жи', 'poste', 'június', 'anel', 'schließ', 'ant', 'sob', '房', 'iß', 'Fichier', '`:', '=\"@+', 'setopt', '隆', 'VP', 'Rica', 'Mouse', 'Mouse', '----', '-+', 'pint', 'ishi', 'estic', 'ig', 'cultural', 'trans', 'individ', 'GV', 'principles', 'ké', 'mpeg', 'NS', 'desc', 'Seiten', 'eh', 'zeti', 'tz', 'Tour', 'esp', 'transm', 'Pages', 'occ', 'JVM', 'Nations', 'zoom', 'piano', 'Cultural', 'Einz', 'omen', 'uent', 'findViewById', 'Fix', '호', 'asc', 'sr', 'iras', 'xa', 'tour', 'conda', 'golf', 'Chain', 'ὀ', 'dl', 'ž', 'icación', 'ähr', 'галь', 'cancel', '人', 'individuals', '✿', 'zyż', 'urrent', 'dash', 'iore', 'pygame', 'uce', 'bing', 'compression', 'ус', 'ux', 'hoch', 'igi', 'spl', 'READ', 'ANGE', 'ők', 'chain', 'reb', 'estr', 'heim', '#####', 'ција', 'Einsatz', 'hardly', '━', 'fixes', 'Output', 'delay', 'Node', 'range', 'Napole', 'security', 'satisf', 'ird', 'stdio', 'recon', 'ční', 'vertical', 'pu', 'continuous']\n",
      "Key: model.layers.4.mlp.down_proj.weight\n",
      "in Layer4 , sorted_indices_dimension1184:  ['orno', '话', 'ahu', 'ango', 'щее', 'iske', 'iből', 'Ћ', 'ugno', 'ispecies', 'gry', 'forge', 'Zob', 'angularjs', 'Einzeln', 'spole', 'równ', 'istiques', 'bras', 'erw', 'ciu', 'станови', 'mieszkań', 'ools', 'gior', 'ufe', 'ategory', 'reactjs', 'stackexchange', 'ʒ', 'schemas', 'zeuge', 'oon', 'sets', '洲', 'ѫ', 'allo', '̩', 'qué', 'oin', 'FAULT', 'れ', 'pec', 'stack', 'iemann', 'prowad', 'ciente', 'ragma', 'eerst', 'yles', 'kwietnia', 'Binary', 'egin', 'reibung', 'steht', 'rou', 'cand', 'icamente', 'ща', 'Česk', 'argent', 'lide', 'xhtml', '�', 'vek', 'öß', 'äß', '密', ':@', 'oul', 'Category', 'icode', '调', 'gepubliceerd', 'icación', 'ट', 'interpretation', 'empt', 'ҡ', 'iche', 'ор', 'Bras', 'ico', 'ore', 'atica', 'teger', 'mouvement', 'ocker', 'teck', 'manually', \"%'\", 'irtual', 'Љ', 'рон', 'дови', 'imore', 'binnen', 'zione', 'clipse', 'virti', 'cím', 'acion', 'ultats', 'упо', 'atuur', 'zunächst', 'Boh', 'wikipedia', 'Ged', 'attro', 'herr', 'aggio', 'ohen', 'gat', 'iesz', 'cookie', 'ето', 'andis', 'нг', 'orn', 'heutigen', 'consulté', '<s>', 'eclipse', 'ampf', 'Fernández', 'ʊ', 'Mold', 'iskt', 'ALSE', 'òria', 'MI', '์', 'esper', 'desar', 'alion', 'temper', '타', 'Syst', 'пода', 'talál', 'VID', 'onneur', 'för', 'veg', 'Familien', 'igue', 'cera', 'grud', 'åk', 'ẓ', 'ɫ', 'bru', 'nehm', 'вал', 'Italiana', 'enz', 'htt', 'javafx', 'сі', 'přek', 'atti', 'Бра', 'quet', 'sq', 'Петер', 'управ', 'АН', 'ximo', 'binary', 'ban', 'elsk', 'Brainz', 'ável', 'asse', 'lease', 'webdriver', 'uw', 'gnu', '为', 'Browser', 'ouw', 'jeune', 'Мексичка', 'abgerufen', 'enza', 'iali', 'geldig', 'owi', 'shr', 'standing', 'sieme', 'населення', 'temper', 'flush', '話', 'Mitglieder', 'alin', 'rass', 'decor']\n",
      "in Layer4 , sorted_indices_dimension70:  ['lär', 'staden', 'Zak', 'ент', 'IMARY', 'path', 'rias', 'Path', 'wrap', 'dri', 'entes', 'ante', 'perty', 'lett', 'Fame', 'stadt', 'León', 'kwiet', 'usammen', 'ile', 'distrito', 'вати', 'nucle', 'rép', 'кти', 'gg', 'фициаль', 'weap', '↳', 'sierp', 'OF', 'subs', 'Path', '竹', 'Pitt', 'ente', 'ently', 'ić', 'Null', 'heb', 'abhäng', 'wr', '房', 'œuv', 'agar', 'structures', 'Rechts', 'inheritance', 'льный', 'копия', 'ční', 'sizes', 'ệ', 'nth', 'teat', 'ober', 'antes', 'UNT', 'анд', 'metros', 'UND', 'èle', 'î', 'Mundo', '✔', 'apk', 'Professional', 'vé', 'дів', 'ended', 'alias', 'opera', 'wc', 'nero', 'nederbörd', 'ocr', 'aw', 'пада', 'Stock', 'ун', 'jsf', 'ialog', 'enten', '�', 'lande', 'acity', '校', 'ores', 'pitt', 'stad', 'Berliner', 'Insel', 'ธ', 'ouvern', 'Mechan', 'ũ', 'wx', 'Linked', 'ves', 'size', 'cza', 'emplo', 'wur', '件', '�', 'èces', 'erton', 'répond', 'Données', 'erek', 'ध', 'notify', 'emen', 'wrapped', 'Knight', 'ctic', 'Opera', 'wrapping', 'Distribution', 'UMN', 'wind', 'Oper', 'dział', 'érica', 'chestra', 'ütt', 'desc', 'irc', 'ents', 'urr', 'nada', 'empor', 'bed', 'icios', 'Safari', 'déjà', 'quare', 'мина', 'Poz', 'wn', 'нд', 'size', 'illé', 'destru', 'ग', 'ゼ', 'mismatch', 'validation', 'ży', 'ش', 'Bolog', 'häng', 'ünd', 'ян', 'LENG', 'Nem', 'dfs', 'tér', 'követ', 'érez', 'inale', 'hide', 'uria', 'metro', 'öff', 'bed', 'inas', 'yan', 'emor', 'buff', 'clin', '++)', 'köz', 'UM', 'ride', 'shell', 'Buff', 'ITable', 'ancia', 'キ', 'erne', 'Rugby', '제', 'swer', 'angularjs', 'agog', 'lines', 'questions', 'oom', 'ent', 'ina', 'Domain', 'path', 'cco', 'ď', 'Bed', 'wrap', 'копи', 'йн', 'ป']\n",
      "in Layer4 , sorted_indices_dimension9928:  ['alem', 'ork', 'phia', 'í', 'мно', 'ioso', 'roller', 'ban', 'stra', 'eria', 'Mobile', '◄', 'fahren', 'Höhe', 'Bla', '右', 'argin', 'стей', 'kmal', 'ennen', 'unicí', 'lipse', 'uwe', 'straight', 'KEY', 'PN', 'Pattern', 'poque', 'ML', 'ville', 'alias', 'vous', 'ban', 'phys', 'isz', 'ennis', 'IME', 'lä', 'powiecie', 'itza', 'Stanisław', 'staat', 'dom', 'Hog', 'ky', 'path', 'imenti', 'Rang', 'uola', 'izer', 'esta', 'keys', 'agyar', 'powiat', 'Rights', 'plain', 'plane', 'fi', 'та', 'вра', 'indexing', 'Tried', 'iker', 'Fest', '�', 'fn', 'Vas', 'Bytes', 'Short', 'pn', 'mill', 'bla', 'lesia', 'bow', 'outline', 'utsch', 'Lyn', 'istra', 'DOM', 'fal', '万', 'kwiet', 'igne', 'osc', 'świ', 'Kn', 'Архив', 'ето', 'sob', 'osten', 'Stra', 'Gemeins', '�', 'platz', 'ize', 'probabil', 'NR', 'fahr', 'Crist', 'Harrison', 'terme', 'setContentView', 'ox', 'chter', 'cipe', 'Republik', 'arg', 'Cry', '�', 'ita', 'ค', 'Spark', 'ují', 'Википедии', '宗', 'iers', 'ismo', 'ieve', 'uben', 'plot', '=\".', 'imento', 'ша', 'Fine', 'gren', 'enumerate', 'Einzel', 'сла', 'izz', 'Main', '�', 'pios', 'Occ', 'ffic', 'ś', 'Ras', 'Verein', 'Fu', 'kreis', 'ocr', 'себе', 'gradient', 'isée', 'iano', 'ipped', 'iqu', 'Stad', 'fan', 'aped', 'sac', 'migr', 'fu', 'piano', '�', 'anged', 'abase', 'état', 'CC', 'issement', 'pel', 'rollers', 'pil', 'hab', 'Tour', '目', 'iała', 'âtre', 'pal', 'occident', 'laquelle', 'ellett', 'tab', 'Context', 'каль', 'adem', 'pon', 'kn', 'ă', '看', 'tero', '(&', 'edor', 'ront', 'phen', 'ész', 'fu', 'iod', 'spieler', 'town', 'зі', 'ls', 'virtue', 'ан', 'func', '�', 'dissol', 'vas', 'inci', 'mary', 'auch']\n",
      "in Layer4 , sorted_indices_dimension1802:  ['pic', 'yter', 'diff', 'raste', 'pre', 'ufe', 'sr', 'pred', 'ERE', 'ϕ', 'entry', 'ĭ', 'rien', 'ñas', 'ing', 'cabinet', 'пред', '<%', 'éral', 'LA', 'Rout', 'EventListener', 'ogne', 'sit', 'thin', 'від', 'Disney', 'golf', 'proxy', 'edi', 'fond', 'asket', 'mines', 'uff', 'ifie', 'emberg', 'tero', 'transparent', 'inction', 'jub', 'wi', 'INCT', 'Updated', 'ikal', 'aset', 'пре', 'Void', 'Din', 'Problem', 'diferen', 'стов', 'ツ', 'wall', 'peror', 'apis', 'iation', 'izo', 'plate', 'asis', 'wid', 'mine', 'mine', 'asketball', 'wall', 'inte', 'de', 'page', 'initi', 'eft', 'entry', 'пов', 'ceu', 'ensen', 'пу', 'vertical', 'sense', 'rode', 'Diff', 'diffusion', 'raf', 'zetek', 'yt', 'Ide', '나', 'Job', 'поль', 'raph', 'stru', 'ClassName', 'Opera', 'icale', 'rian', 'зова', 'clipse', 'isi', 'atel', 'Tomatoes', 'amm', 'ermo', 'ere', 'event', 'Broad', '红', 'aff', 'жений', 'sitt', 'push', 'Müller', 'pective', 'Dro', 'dry', 'Event', 'rond', 'freely', 'ernel', 'otr', 'Tom', 'arca', 'grad', 'vä', '},{', 'diffus', 'wid', 'arod', 'Politiker', 'благо', 'vim', 'effic', 'ode', 'diff', '道', 'xs', 'enter', '紀', 'opera', 'Element', 'init', 'vict', 'ms', 'andenburg', 'Dead', '라', 'ependant', 'нок', 'qui', 'agini', 'eme', '认', 'vég', 'Entry', 'osta', 'ciel', 'жен', 'thm', 'За', 'itle', 'ogn', 'лян', 'arz', 'xico', 'cod', 'Nations', '岩', 'LIN', 'Nied', '击', 'ifen', 'azu', 'relativ', 'WF', 'vc', 'dé', 'Wall', '周', 'assembly', 'ivamente', 'thur', 'europ', '�', 'yst', 'gro', 'iod', 'Off', 'ITable', ':]', 'ც', 'ándose', 'лий', 'подацима', 'abund', 'обо', 'Organ', 'Namen', 'edad', 've', 'ко', 'Effect', 'ヒ', 'vac', 'path']\n",
      "in Layer4 , sorted_indices_dimension6603:  ['ati', 'terne', 'ikai', 'Observable', 'bor', 'imi', 'ớ', 'ena', 'por', 'fr', 'sched', 'BO', 'lic', 'è', 'right', 'frames', 'Tang', 'olia', 'oss', 'Univers', 'bis', 'fa', 'Paris', 'speech', 'ok', 'reun', '://', 'ca', 'body', 'rio', 'ook', 'ily', 'orum', 'ispecies', 'rak', 'right', 'dam', 'Son', 'flesh', 'los', 'cad', 'pros', 'convers', 'лев', 'trop', 'rado', 'ud', 'forsch', 'zerw', 'дра', 'ork', 'dialog', 'S', 'Rh', '$(\".', 'öst', 'develop', 'orb', 'iden', 'Rud', 'agre', '間', 'Jo', 'dam', 'imiter', 'atrice', 'insp', 'lar', 'entic', 'govern', 'Scope', 'cos', 'ым', '号', 'ename', 'verified', 'versch', 'orbit', 'estaven', 'conditions', 'inn', 'Society', 'estre', 'unicode', 'ity', '개', 'So', 'Joe', 'dep', 'ples', 'cht', 'zin', 'Dialog', 'yll', 'Veg', 'bet', 'pez', 'ieved', 'Micro', 'Bor', 'prü', 'Edit', 'ty', 'borrow', 'ém', 'Ra', 'immediate', 'Grid', 'Or', 'proper', 'pels', 'Champ', 'ox', 'bor', 'declarations', 'trem', 'VF', 'lessly', 'ui', 'pat', 'ouver', 'nich', 'ó', 'ὑ', 'Taylor', 'Govern', 'oper', 'ще', 'Unicode', 'Ort', 'quadratic', 'sil', 'esta', 'Mason', 'aten', 'mot', 'schap', 'dialog', 'ox', 'IGHT', 'opening', 'Congo', 'ights', 'ectors', 'atmosphere', 'Van', 'whitespace', 'wants', 'ris', 'frames', 'nas', 'pected', 'ixa', 'labels', 'anos', '切', 'samples', 'ali', 'elect', 'mism', 'natur', 'dw', 'tropical', 'Den', 'und', 'dello', 'princip', 'owan', 'Kim', 'anka', 'pom', 'WH', 'iva', 'confirm', '�', 'stoff', 'U', 'Norden', 'vie', 'gru', 'unde', 'lambda', 'verify', 'jo', 'Sor', '史', 'ct', '函', 'cadem', 'univers', 'principales', 'bur', 'Parker', 'it', 'irm', 'Er', '$(\"', 'goal', 'ulsion', 'pla']\n",
      "in Layer4 , sorted_indices_dimension9194:  ['ako', '�', 'mol', 'sero', 'gar', 'Zweiten', 'ɲ', 'vik', 'éra', 'apper', 'weg', 'endar', 'Second', 'cke', 'ounter', 'anson', 'VD', 'patch', 'Second', 'jer', 'rás', 'ĉ', 'scène', 'ble', 'CD', 'esent', 'ébec', '�', 'clock', 'ça', 'slash', 'nis', 'enis', 'Kim', 'aille', 'ieu', 'patr', 'oi', 'zewnętrz', 'éal', 'veis', 'anglès', '{{', 'Mol', 'lein', 'ühl', 'げ', 'ː', 'orage', 'цо', 'ivari', 'кра', 'póź', 'obst', 'ць', 'blem', 'anse', 'рд', '&=\\\\', 'ída', 'gy', 'Root', '�', 'weig', 'hanced', 'Den', 'dal', 'fish', 'uis', 'prototype', 'ryty', 'readable', 'Beach', 'ɫ', 'Rom', 'comment', 'к', 'Weltkrieg', 'cors', 'EventArgs', 'agin', 'aciones', 'Barb', 'ruguay', 'Ы', 'ta', '�', 'ían', 'elin', 'idenote', 'imon', '%%%%', 'ras', 'eras', 'Dest', 'igkeiten', 'acker', 'tart', 'ké', 'mez', ']`.', 'pend', 'val', 'Gilbert', 'rable', 'efect', 'azi', 'stub', 'symmetric', 'uo', '�', 'sd', 'ÿ', 'yk', 'Var', 'enfer', 'writ', 'waste', 'ィ', 'ouve', '�', 'bash', 'TEST', 'Données', 'discover', 'lapsed', '�', 'Den', 'keiten', 'fond', 'DC', 'Gar', 'Anto', 'ˇ', 'Historic', 'cí', 'acid', 'erno', 'finger', 'лях', 'undle', 'Window', 'Ÿ', 'gable', 'iod', 'reasoning', 'egy', 'subjects', 'able', 'appe', 'ób', 'agi', 'ius', 'мента', 'ене', 'cyk', 'лё', 'éon', 'Dynamic', 'ván', '____', 'ationen', 'INNER', 'Anton', 'lament', 'Fish', 'галь', 'indul', 'Memory', 'Ts', 'hl', 'destin', 'fic', 'tut', 'iddle', 'rom', 'rag', 'scan', 'egu', 'pap', 'роман', 'dest', 'slider', 'ouvelle', 'ikon', 'тах', 'huvudstaden', 'Jazz', 'Water', 'тай', 'Anth', 'fish', 'García', '記', '?:', 'overrid', 'dział', 'Completion', 'schrift', 'energy']\n",
      "in Layer4 , sorted_indices_dimension734:  ['uma', 'öld', 'ERT', 'bras', 'Metropolitan', 'bullet', '久', 'arium', 'iento', 'ợ', 'äre', 'lac', 'skap', 'metropol', 'register', 'Kaiser', 'zett', 'фи', 'Picker', '治', 'pointers', 'model', 'Real', 'Recht', 'manual', 'Alter', 'legen', '면', 'inea', 'Judge', 'ilty', 'ROR', 'ello', 'aille', 'ior', 'bron', 'Controller', '�', 'Ctrl', 'bullet', 'ἰ', 'awa', 'posit', 'abeth', '�', 'DECLARE', 'Register', 'przed', 'custom', 'imon', 'Selected', 'ɨ', '﹕', 'neigh', 'inus', 'utt', 'Det', 'idé', 'bul', 'annels', 'ace', 'ügel', 'bmatrix', 'TC', 'гля', 'Mex', 'legraph', 'TV', 'beskre', 'inta', 'habit', 'berg', 'Brook', '雅', 'orm', 'ат', 'ebol', 'isten', 'Jahrhunderts', 'supre', 'wol', 'exped', 'bush', 'reactjs', 'Formula', 'akespe', 'marg', 'mise', 'blocked', 'aw', 'footer', 'Fil', 'manually', '鳥', '[,', 'gray', 'ulen', 'password', 'quasi', 'soap', 'ди', 'TX', 'auch', 'kten', 'afternoon', '洞', 'gel', 'äche', 'gray', 'button', 'gele', 'assen', 'Di', 'alloc', 'ölker', 'um', 'LS', 'ternoon', 'chmark', 'zew', 'стову', 'жен', 'cape', 'Schwe', 'model', 'jboss', 'Det', 'flux', 'determin', 'othek', '夜', 'Italia', 'spole', 'hub', 'VICE', 'channel', 'recht', 'Drawing', 'unch', 'ть', '司', 'wick', 'registered', 'invari', 'exp', 'yclerView', 'Exec', 'tring', 'Executive', 'whites', 'Fut', 'elsen', 'azionale', 'Fine', 'egründ', 'expon', 'Filter', 'ahr', 'ça', 'shell', 'cas', '진', 'jel', 'द', 'Statistics', 'batt', 'ancer', 'Channel', 'насеље', 'ouwd', 'volume', 'ług', 'channel', 'śc', 'class', 'custom', 'amb', 'значи', 'ep', 'cap', 'Süd', 'cruel', 'Bruce', 'klass', 'uro', '测', 'equilib', 'ép', 'optional', 'bres', 'hmen', '尔', 'René', 'functional', 'primit', 'ू', 'Jur', 'ブ', 'ilda', 'filtered']\n",
      "in Layer4 , sorted_indices_dimension2807:  ['onderwerp', 'enden', 'webpack', 'rak', '号', '根', 'ällor', 'sv', 'wal', 'coal', 'Dev', 'pieler', 'sí', 'div', 'transl', 'dev', 'ouss', 'lius', 'Хронологија', 'лях', 'références', 'wid', 'hostname', 'appoint', 'serial', 'witz', 'lay', '�', 'äu', 'References', 'mbH', 'pon', 'cruel', 'inek', 'ael', 'Населення', 'teles', 'rade', 'setContentView', 'complete', 'belang', 'ande', 'painting', 'зне', 'iből', 'gow', 'Dev', 'estaven', 'collection', 'eles', 'neur', 'undial', 'BL', 'umerate', 'ude', 'wissenschaft', 'anza', 'lossen', 'aum', 'etu', 'Title', 'owi', 'lés', 'syn', 'okat', 'тали', 'Assume', 'ři', 'square', 'ciente', 'babel', 'seq', 'inet', 'információ', 'carrera', 'gain', 'Martín', 'crown', 'pc', 'Days', 'PATH', 'anta', 'diss', '˚', 'Jag', '�', 'conclude', 'dev', 'kur', 'FILES', 'муніципалі', 'tod', 'blah', 'ango', 'mainten', 'affected', 'ují', 'udi', 'yyyy', '�', 'SV', 'serial', 'rance', 'synth', 'Datenbank', 'jap', 'ucha', 'bs', 'oco', 'Segunda', 'wo', 'ument', '日', 'рах', 'uur', 'sin', 'memor', 'BS', 'све', 'iks', 'ury', 'tasks', 'équip', 'gan', 'Path', 'virtuel', 'cle', 'iae', 'skal', 'anger', 'Messages', 'oll', 'Pair', 'wed', 'Annotation', 'esség', 'LAY', 'Cannot', 'ján', 'title', 'vě', 'ктив', 'ej', 'Історія', 'OB', 'slash', 'onto', 'are', 'phen', '友', 'breaks', 'car', '画', 'schemas', 'flush', 'canvas', 'Instance', 'principale', 'decre', 'arel', '�', 'ύ', 'TAC', 'oauth', '按', 'OIN', 'welt', 'Ṭ', 'Hed', 'conclusion', 'Lud', 'Foundation', 'wich', 'inequality', '\\x07', 'anton', 'oint', 'Conse', 'sn', 'хи', 'Notable', 'ℚ', 'history', 'sys', 'Список', 'пописа', 'sudo', 'ум', 'dés', 'gegenüber', 'Cmd', 'weit', 'vera', 'Tab', 'translate', 'organisation', 'Sql', 'Lomb', '│', 'ptop']\n",
      "in Layer4 , sorted_indices_dimension9661:  ['esti', 'adel', 'jure', 'ople', 'pad', 'RS', 'hn', 'pri', 'Pad', 'jel', 'risult', 'èces', 'gence', 'выступа', 'lí', 'inx', 'comp', 'ope', 'Pad', 'ode', 'ych', 'adm', 'little', 'Proc', 'multip', 'proc', 'oto', 'Ele', 'iale', 'йской', 'iano', 'word', 'rike', 'lle', '話', 'ifa', 'ște', 'Vin', 'х', 'rez', 'sharp', 'ht', 'itle', 'rès', 'adal', 'otto', 'ар', 'IO', 'ingo', 'omo', 'Hunter', 'лия', 'ele', 'arna', 'iod', 'сі', 'Sof', 'пли', 'sta', 'sister', 'Raz', 'stor', 'title', 'inton', 'jar', '测', 'kih', 'Egy', 'External', 'Terminal', 'další', 'shed', 'Сред', 'Another', 'Sozial', 'вя', 'mann', 'fraction', 'añ', '̌', 'ře', 'pad', 'Serv', 'ек', 'л', 'fields', 'work', 'ме', 'geh', 'ôle', 'Sé', 'Natural', 'sec', 'ishi', 'lio', 'berga', 'rin', 'agas', 'Jimmy', 'Haz', 'себе', 'Within', 'Shared', 'rene', 'Dun', 'tít', 'Wir', '�', 'Virtual', 'Sul', 'üg', 'ën', 'Vari', 'otted', 'op', 'sep', '意', 'oben', 'entire', 'Ned', 'cler', 'ittle', 'ashed', 'iller', 'gebra', 'roke', 'cca', 'addressed', 'leb', 'tex', 'glo', 'tin', 'dn', 'ane', 'ele', 'within', 'rp', 'ué', 'eau', 'vare', 'vin', 'Federation', 'borg', 'anno', 'IT', 'пет', 'big', 'oped', 'innen', 'ène', 'рен', 'ttemberg', 'tennis', 'Wall', 'elo', 'Rés', 'Fra', 'ich', 'opy', 'férences', 'oli', 'Оте', 'movements', 'з', 'proc', 'џ', 'ië', 'Organisation', 'externas', 'га', 'ley', 'nero', 'ґ', 'Kay', 'atti', 'Maz', 'oding', 'ör', 'innerhalb', 'functions', 'Lind', 'title', 'augusti', 'odu', 'ва', 'comp', '[@', 'terre', 'itet', 'rix', 'Jag', 'Manuel', 'ulation', 'md', 'dzie', 'dh', 'complement', 'дире', 'rane', 'Федера']\n",
      "in Layer4 , sorted_indices_dimension5246:  ['ilib', 'manifest', 'sorted', 'orp', 'flight', 'enas', 'forg', 'út', 'John', 'vere', 'markup', 'lingen', 'panel', 'uf', 'unas', 'orf', 'сле', 'infer', 'Ver', 'Aut', 'plut', 'Plot', 'Plat', 'erf', 'Kauf', 'NF', 'meck', 'Events', 'appar', 'olf', 'Ung', 'Cl', 'panel', 'Por', 'effects', 'plat', 'VF', 'Doc', 'hum', 'örd', 'Edwards', 'scr', 'sorting', 'aut', 'fur', 'oles', 'torneo', 'bank', 'iling', 'events', 'sheet', 'export', 'dry', 'ian', 'kin', 'pg', 'bra', 'forth', 'Pl', 'Dam', 'effect', 'Hospital', 'amen', 'angu', 'usa', 'ops', 'affen', 'pian', 'óp', 'chr', 'grands', 'ouverneur', 'akt', 'enschaft', 'leak', 'iten', 'nasc', 'Sh', 'Afr', 'Net', 'FI', 'hol', 'Liver', 'гру', 'commanded', 'Sh', 'weig', 'Cass', 'ensor', 'reve', 'Fir', 'Sele', 'вин', 'urst', 'nehmen', 'methods', 'Pla', 'scri', 'Net', '[:', 'auto', 'enf', '秀', 'manif', 'route', 'buried', 'Una', 'Brun', 'ommen', 'autonom', 'lub', 'azy', '@\"', 'sop', 'Dem', 'ofic', 'issen', 'cens', 'mc', 'Gall', 'Italiana', 'Nas', 'Спо', 'Fur', 'Wikipedia', '除', 'ucha', 'el', 'док', 'ên', 'ando', 'event', 'Morgan', 'households', 'oph', 'Route', 'datab', 'ici', 'ted', 'auss', 'нен', 'PR', 'U', 'fame', 'li', 'LI', 'Edu', 'manifest', 'elian', 'spre', 'Me', 'select', 'vision', 'Prima', 'Ver', 'vm', 'Roberts', 'anst', 'BB', 'ingt', 'нев', 'zan', '越', 'hole', 'egr', 'select', 'li', 'ScrollView', 'Brow', 'ública', 'Broad', 'capture', 'Brown', 'Method', 'Rights', 'blank', 'Rh', 'shed', 'sheets', 'ols', 'ą', 'Wy', '�', 'Ple', 'lying', 'flows', 'cart', 'ze', 'fe', 'excess', 'reb', 'Attributes', 'i', 'iam', 'ensa', 'Ac', 'Rotten', 'Mul', 'tables', 'ak']\n",
      "Key: model.layers.5.mlp.down_proj.weight\n",
      "in Layer5 , sorted_indices_dimension3972:  ['ono', 'nem', 'сер', 'nitz', 'utt', 'wers', 'studio', '용', 'runt', 'nab', 'ousel', 'cop', 'DA', 'ento', 'Botan', 'ops', '火', 'vess', 'dw', 'anto', 'useppe', 'ebb', 'imen', 'laus', 'CAA', 'orsz', 'bach', 'ammen', 'pres', 'estudio', '复', 'bib', 'ös', 'frat', 'ims', '�', 'Cop', 'rola', 'Sax', 'wort', '场', 'BU', 'ën', 'oper', 'dm', 'Users', 'arget', 'mos', 'networking', 'Wik', 'CG', 'cop', 'dict', 'èn', 'indent', 'ň', 'inta', 'lub', 'init', 'kende', 'owa', 'hoff', 'ettes', 'obox', 'archy', 'ername', 'DM', 'Sync', 'chamber', 'ardin', 'Hint', '政', 'swift', 'Dict', 'менталь', 'erea', 'champ', 'Coupe', 'énario', 'enf', 'nap', 'automatisch', 'diction', 'act', 'ális', 'inals', 'éma', 'alem', 'herr', 'enst', 'ilio', 'uses', 'тин', 'aglia', 'studio', 'uellement', 'ordo', 'дія', 'users', '<>', 'ondere', 'CB', 'zes', 'Sib', 'Arn', 'cope', 'ogram', 'Caval', 'mente', 'apt', 'uent', 'érer', 'agog', 'amen', 'skal', 'onders', '操', 'клуб', 'oven', 'isti', 'dz', 'cab', 'bulk', 'ért', 'geme', 'foreach', 'vez', 'ณ', '昌', 'wyd', 'imedia', 'ек', 'lieder', 'nica', 'cabinet', 'oment', 'momento', 'dr', 'essional', 'дели', 'mus', 'engl', 'ului', 'running', 'triangle', '<>', '甲', 'üng', 'desar', 'cada', 'laten', '字', 'ят', 'Studio', 'ран', 'cursor', 'copied', 'superfic', 'midt', 'ocs', 'utiliz', 'ederb', 'лово', 'Glas', 'ette', 'Lexikon', 'う', 'Mail', 'Champ', 'Grund', 'nat', 'avigation', 'wart', 'padding', 'üt', 'rsg', 'стрі', 'trunc', 'equivalence', 'Mail', 'arg', 'рій', 'Encyclopedia', 'ött', 'sigu', 'ahr', 'éré', 'cb', 'тар', 'populations', 'enant', 'СР', 'сты', 'dimen', 'Running', 'trial', 'гро', 'wed', 'alberga', 'ency']\n",
      "in Layer5 , sorted_indices_dimension6796:  ['amy', 'ze', 'isi', 'árs', 'ü', 'ым', 'diff', 'teen', 'LD', 'ella', 'tum', 'jsf', 'jem', 'ボ', 'datas', 'tu', '♯', '丁', 'respond', 'rew', 'parenthes', 'Kop', 'aven', 'Fen', 'tools', 'tu', 'ych', 'ща', 'Tools', 'piano', 'disambiguation', 'Tu', 'ure', 'republic', 'tod', 'tact', 'ren', 'ajo', 'hero', 'ement', 'lets', 'Gra', 'ishi', 'Nach', 'zek', 'eld', 'Kreis', 'aver', 'sea', 'let', 'nier', 'ixen', 'ppings', 'reven', 'todo', 'fundamental', 'ten', 'cont', 'mellan', 'yg', 'promotion', 'Tu', 'quence', '%{', 'fen', 'ello', 'efe', 'Es', 'Clar', 'Prom', '˜', 'Gib', 'ounce', 'member', 'ZE', 'emat', 'conversion', 'Nav', 'delta', 'poly', 'iteration', 'mount', 'ao', 'Bow', \"{'\", 'todos', 'opera', 'ero', 'solit', 'yl', 'boot', 'pair', 'delegate', 'Ele', 'recre', '️', 'edit', 'дор', 'Sea', 'ụ', 'thesis', 'eln', 'lés', 'gra', 'Major', 'pending', 'Names', 'ě', 'fan', 'to', 'presently', 'isy', 'freedom', 'jen', 'aja', 'fah', 'ivent', 'zig', 'вич', 'tort', 'astro', 'big', 'mo', 'machine', '\\xa0', 'tous', 'major', 'rig', 'money', 'currently', 'сле', 'Navy', '好', '都', '之', 'oshi', 'dav', 'rör', 'recip', 'esten', 'ร', 'ohen', 'ven', 'det', 'вар', 'зня', 'lauf', 'synth', 'quin', 'genomsnitt', 'isie', 'hner', 'espèce', 'слід', 'alone', 'named', 'stra', 'чу', 'NR', 'grund', 'ever', 'ner', 'áv', 'thorough', 'edu', 'family', 'dai', 'easy', '____', 'worth', '大', 'contrib', 'registry', 'Limit', 'fact', 'basic', 'IB', 'X', 'decent', 'ecycle', 'Gener', 'ensure', 'єм', 'venue', 'reven', 'y', 'ec', 'uniqu', 'illa', 'anti', 'dirty', 'Jane', 'chus', 'oly', 'rach', 'NR', 'varied', 'fen', 'ы', 'span']\n",
      "in Layer5 , sorted_indices_dimension7477:  ['closure', 'Emil', 'ober', 'scop', 'chap', 'gens', 'scope', 'Hil', '⁄', 'стров', 'Lanc', 'Liver', 'lbl', 'Karl', 'Gemeinsame', 'asta', 'lat', 'oro', '씨', 'Lou', 'ühr', 'hrer', 'esta', 'iki', 'chron', 'AtIndex', 'bekend', 'öld', 'orum', 'Princi', 'жде', 'assen', '息', 'las', 'virti', 'brothers', 'Squad', '*\"', 'bal', 'wik', 'hip', 'yi', 'icken', 'prü', 'Хро', 'algo', 'Chap', 'chk', 'uje', 'Tout', 'asi', 'Rout', 'Pit', 'mus', 'vex', 'reload', 'Wikip', 'Gay', 'Lac', 'mort', 'Overflow', 'Convert', 'ava', 'ège', 'Tennis', 'convey', 'principle', 'eless', 'Kaiser', 'глав', 'avo', 'ić', 'сі', 'morrow', '年', 'geon', 'rout', 'yed', 'Chron', 'istan', '则', 'influen', 'historian', 'GS', 'ourg', 'мир', 'diss', 'ょ', 'ensis', 'њ', 'principles', 'developer', 'vas', 'ouv', 'тик', 'éré', 'webdriver', 'chen', 'iens', 'Rost', 'AC', 'crim', '년', '失', 'лад', 'Paz', 'Schwar', 'inand', 'hon', 'clos', 'rière', 'mental', 'Napoleon', 'LIM', 'лий', 'dat', 'irement', 'otos', 'ewnętrz', 'Lit', 'mus', 'hoofd', 'ether', 'orous', 'hip', 'histor', 'pin', 'Wass', 'мена', 'va', 'Cher', 'ør', 'ifik', 'Deleg', 'Cart', '构', 'aceae', 'iwers', 'wr', 'Histor', 'lax', 'irie', 'SUM', 'хів', 'pit', 'stab', 'iske', 'closing', 'Crime', 'mense', 'avam', 'azine', 'vess', 'ility', 'unicí', 'ample', 'opf', 'chte', 'deleg', 'NO', 'cart', 'minipage', 'nel', '[\"', 'ola', 'Dort', 'Commonwealth', 'Glad', 'ђ', 'Rö', 'converts', 'constru', 'partial', '=>', 'ș', 'rios', 'prospect', 'printer', 'Nord', 'siglo', 'await', 'cope', 'Reg', 'Elle', 'äler', 'SIZE', 'Vor', 'similarly', 'š', 'Img', '�', 'CLARE', 'formerly', 'ш', 'quia', 'Lomb', 'anc', 'princi', 'pin', 'Convert']\n",
      "in Layer5 , sorted_indices_dimension216:  ['Ran', 'scri', 'ulus', 'squ', 'oper', 'Fore', 'Cant', '\\x9c', 'YPE', 'elian', 'mitt', 'fc', 'orum', 'каз', 'fl', 'Nap', 'quet', 'пописа', 'gon', 'scription', 'шта', 'hausen', 'fa', 'ilio', 'orn', 'Krieg', 'urban', '包', 'Famil', 'nan', 'urrency', 'genus', 'bec', 'Von', 'Im', 'urrence', 'iki', 'Square', 'Stein', 'ulsion', '景', 'Pack', 'mock', 'FC', 'pack', 'Савез', 'simultane', 'lio', 'év', 'opera', 'laz', 'tikz', 'њ', 'Hur', 'ikz', 'Gene', 'avigator', 'indows', '்', 'мен', 'prisoner', 'noreferrer', 'Susan', 'aments', 'square', 'HEAD', 'Paul', 'Parse', 'usion', 'CF', 'ités', 'usto', 'brázky', 'Nue', 'iments', 'ellan', 'orial', 'GridView', 'rame', '++,', 'appreci', 'ACK', 'вест', 'actors', 'nave', '�', 'xa', 'haft', 'nos', 'currency', 'bekend', 'na', 'irs', 'вико', 'Defaults', 'société', 'na', 'squ', 'square', 'Setter', 'imientos', 'vě', '書', 'Throw', 'Johannes', 'oire', 'player', 'nt', 'conten', 'Famil', 'pia', 'orient', 'iled', 'ữ', 'league', 'fp', 'pa', 'attle', 'Paulo', 'Rico', '被', 'atted', 'functional', 'players', 'Stanis', 'sust', 'adata', 'famil', 'stadt', 'mér', 'dorf', 'von', 'ум', 'Finale', 'architect', 'Orient', 'ette', 'ikon', 'ка', 'шп', 'chestra', 'ernel', 'ènes', 'ROUP', 'ུ', 'ò', 'honneur', 'ço', 'onia', 'таль', 'vessels', 'Running', 'vou', 'mex', 'observ', 'archy', '�', 'zetek', 'ters', 'Gén', 'industri', 'Execution', 'Zip', 'AS', 'SSH', 'bury', 'Kreis', 'inden', 'ahl', 'quis', 'ili', 'inen', 'improv', 'curity', 'izioni', 'flags', 'CLARE', 'Zag', 'executing', 'Paolo', 'Sender', 'Jacques', '者', 'adopt', 'ado', '원', 'ǐ', 'enf', 'ibration', 'cattle', 'ぐ', '嘉', 'со', 'CF', 'medicine', 'patron', 'кораб', 'Jess', 'Gruppe', 'Style']\n",
      "in Layer5 , sorted_indices_dimension8124:  ['Uni', 'ow', 'opera', 'wij', 'dom', 'Bug', 'Ham', 'med', 'še', 'Schul', 'iert', 'Wing', 'ti', 'май', 'Fur', 'Jord', 'Bootstrap', 'onCreate', 'streams', 'tion', 'simply', '麻', 'perp', 'Medic', 'scalar', 'och', 'CREATE', 'inas', 'ang', 'edom', 'Alf', 'adu', 'dro', 'Baden', 'elij', 'ther', 'зан', 'Wolfgang', 'ус', 'colo', 'plex', 'usk', 'ior', 'boot', 'bug', 'echo', 'ach', 'intr', 'Bol', 'лосо', 'andom', 'Gabriel', 'elligence', 'fi', 'huvudstaden', 'Erd', 'tut', 'alk', 'esti', 'von', 'Serge', 'mines', 'prüng', 'LL', 'ün', 'Rou', 'uniqu', 'unst', 'endar', 'medic', 'opt', 'Й', 'Hom', 'echo', 'èt', 'isu', 'Fland', 'eso', 'ision', 'instrument', 'med', 'ші', 'ähl', 'pian', 'PP', 'stable', 'ло', 'ALSE', 'bootstrap', 'дно', 'beeld', 'Low', '口', '·', 'possibly', 'idth', 'law', 'Victor', 'imore', 'speak', 'golf', 'opera', 'cri', 'tered', 'ництво', 'Forces', 'ored', 'coup', 'sal', 'merely', 'gior', 'website', 'Coast', 'euw', 'ATE', 'hoof', 'eria', 'pace', 'ci', 'Raum', 'nia', 'кри', 'overcome', 'untu', 'umerate', 'zung', 'éric', 'Bran', 'just', 'factor', 'Ja', 'sched', 'processed', 'reson', 'česk', 'arrow', 'ixon', 'Lé', 'ker', 'omena', 'company', 'ව', 'eeuw', 'џ', 'dél', 'Brig', 'ih', 'processor', 'blatt', 'Sito', 'scop', 'utsch', 'day', 'eli', 'ogni', 'urity', 'iqu', 'tre', 'eler', 'onk', 'owa', 'abstra', 'stabil', 'се', 'cel', 'ieder', 'Seb', 'ån', 'hash', 'Finn', 'tan', 'ucky', '-\\\\', 'iende', 'дже', 'dé', 'Jakob', 'Finland', 'low', 'pshire', 'dom', 'çais', 'wagen', 'iddle', 'Ther', 'ट', 'plot', 'trakten', '⊙', 'geg', 'bug', 'wi', 'Cel', 'mine', 'abase', 'IES', 'Lam', 'Bow', 'ostream', 'lect']\n",
      "in Layer5 , sorted_indices_dimension1118:  ['obil', 'тив', 'ishment', 'elli', 'arte', 'TB', 'mechanism', 'ival', 'ass', 'Bach', 'anh', 'inale', 'рал', 'Cong', 'orphism', 'strictly', 'issance', 'ID', 'isa', 'ови', 'fran', 'ump', 'UND', 'createElement', 'ral', 'ť', 'SV', 'Friedrich', 'UN', 'ieck', 'chain', '符', 'ERR', 'Inn', 'onto', 'ranch', 'lub', 'fish', 'onen', 'rum', 'included', 'Fichier', 'rate', 'uerto', 'Lub', 'otte', 'UD', 'mund', 'rs', 'iano', 'fetch', 'perd', 'premi', 'Kob', 'gram', 'EMA', 'recogn', 'ὀ', '아', 'cido', 'тори', 'rund', 'Mechan', 'limit', 'dr', 'lished', 'Lak', 'Brad', 'estamp', 'pid', 'Terminal', 'árt', 'cala', 'avoir', 'laps', 'ippi', 'ʌ', 'rypt', 'contract', 'inc', 'bald', 'ɾ', 'ohen', '�', '�', 'territory', 'spoken', '\\u200d', 'чь', 'Anders', 'тель', 'uba', 'fiel', 'над', '★', 'iez', 'nu', 'compress', 'Gil', 'Ok', 'gate', 'placeholder', 'induction', 'TD', 'това', '區', 'Hub', 'inhab', 'implicitly', 'cru', 'operations', 'ór', 'wire', 'IS', 'vier', 'proxy', 'plant', 'irection', 'boldmath', '书', 'dialect', 'fico', 'Gesch', 'engelsk', 'Claud', '【', 'Cort', 'pes', 'uky', 'gli', 'poque', 'racht', 'ŭ', 'adj', 'sten', 'vé', 'Martin', 'Mid', 'Amer', 'ƒ', 'intern', 'Okay', 'hundred', 'Lib', 'ɑ', 'ord', 'oko', 'ahlen', 'lop', 'Luis', 'bal', 'isch', 'lv', 'plex', 'burgh', 'bucket', 'teen', 'cable', 'opus', 'cli', 'энциклопеди', 'contre', 'neut', 'br', 'Teil', 'пу', 'flows', 'slot', 'jih', 'LD', '吉', 'TL', 'staden', 'Len', 'gray', 'pad', 'ana', 'fahren', 'Heimat', 'Hamb', 'férences', 'architecture', 'TE', 'run', 'Num', 'desert', 'Heinrich', 'ish', 'рово', 'ld', 'rant', 'bronze', 'ienn', 'hu', 'uben', 'ito', '�', 'inclu', 'NS', 'Yam']\n",
      "Key: model.layers.6.mlp.down_proj.weight\n",
      "in Layer6 , sorted_indices_dimension5121:  ['ICE', 'rör', 'erta', 'kie', 'ythm', '身', 'нат', 'External', 'ље', 'external', 'ice', 'eles', 'ono', 'TEXT', 'WR', 'lee', 'jar', 'jos', 'Text', 'box', 'lua', 'icale', 'Wieder', 'Rhein', '式', 'illy', 'qa', 'zip', 'вало', 'mal', 'bishop', 'Depuis', 'Ō', 'cent', 'uen', 'ĝ', 'incl', 'atter', 'iony', '�', 'Ἰ', 'ibt', 'imon', 'embly', 'osta', 'intercept', 'ору', '<s>', 'ielt', 'Види', 'ht', 'instit', 'heit', 'personas', 'Texture', 'engaged', 'Classic', 'unction', '�', '∇', 'Series', 'lossen', 'glory', 'шу', '⇔', 'häng', 'Names', 'ziel', 'ња', 'Orient', 'Stars', 'нен', 'пла', 'Lincoln', 'nat', 'iono', 'capac', 'STR', 'Primera', 'idi', 'ugno', 'ńst', 'itzen', 'oly', 'któ', 'ForKey', 'GL', 'overflow', '|_{', 'Portail', 'klas', 'statue', 'atte', 'ifice', '体', 'KB', 'pover', 'atmos', 'STAT', 'opro', 'exports', 'arqu', 'љ', 'nouveau', 'lint', 'nyelven', 'ied', 'card', 'rach', 'gele', 'ろ', 'мия', 'сылки', 'fony', 'тература', 'lus', 'idos', 'Selon', 'ĕ', 'upt', 'series', 'aden', '�', 'pyg', 'vre', 'Deport', 'reun', 'ederb', '院', 'lin', 'hagen', 'manifest', 'później', '≡', 'gart', 'bia', 'Ori', 'ุ', 'asympt', 'pool', 'Overflow', 'engl', 'intermediate', 'Text', 'etro', 'esség', 'bur', 'cker', 'infinity', 'pu', 'öss', '像', 'lés', '春', 'Bishop', 'White', '-+', 'Pract', 'му', 'располо', 'Entry', 'Hall', 'Institution', 'lopedia', '┌', 'információk', 'vesc', 'sink', 'овано', 'пло', 'Ice', 'vě', 'worth', 'orient', 'dioc', 'ISO', 'essel', '雪', '页', 'ethod', 'розта', 'Mil', 'lap', 'contract', 'ḏ', 'ieder', 'Также', '典', 'words', 'Bayer', 'arms', 'ento', 'bay', 'carriage', 'ּ', 'Cependant', 'makeText', 'avant', 'Top', '�']\n",
      "in Layer6 , sorted_indices_dimension10113:  ['IOS', 'vern', 'ios', 'igned', 'LENG', 'ť', 'acent', 'Nag', 'izi', 'Bedeut', 'Lng', 'áll', 'xmlns', '密', 'ivent', 'ego', 'carrière', 'Begr', 'ébec', 'esterni', 'oka', 'анд', 'argo', 'Urs', 'Alter', 'swer', 'odot', 'FOR', 'ken', 'Asp', 'intersect', 'aret', 'ouw', 'Vill', 'IZ', 'ʋ', 'Bug', '세', 'stor', 'ivi', 'sak', '\\\\<', 'Peg', 'Universal', 'nag', 'Marg', 'asp', 'Prefix', 'aching', 'onto', 'Ele', 'Ach', 'Fur', 'stup', 'œuv', '秀', 'ior', 'mont', 'VI', 'ernal', '�', 'Hil', '/$', 'információ', 'indow', 'yter', 'ek', 'ER', 'Ster', 'avia', 'ativo', 'wik', 'ius', 'andr', 'setAttribute', 'akh', 'Syl', 'ège', 'Vert', 'intersection', 'łów', 'ont', '条', 'bach', 'best', 'koz', 'iba', 'пора', 'ivo', 'Art', 'assignment', 'ta', 'asse', 'ppel', 'ambiguation', 'boldmath', 'separator', 'ABASE', 'BUG', 'vertical', 'asket', 'Sever', 'omed', 'вя', 'ом', 'реки', 'ached', 'ց', 'år', 'oused', 'owa', 'Brainz', 'uka', 'шки', 'lacht', 'iver', 'ante', 'бю', 'Opera', 'урна', 'piano', 'lg', 'egin', 'zed', 'ASP', 'hood', 'Village', 'ར', 'ford', 'нет', 'ř', 'uwe', 'VII', 'azi', 'KB', 'longue', 'ض', 'ā', 'Hub', 'réal', 'eor', 'Vier', 'ruf', 'egos', 'wij', 'umph', 'bbe', 'WM', 'ented', 'inet', '[@', 'ép', 'DP', 'blogs', 'refix', 'asi', 'boBox', '박', 'telt', 'fé', 'Historic', 'ǫ', 'fur', 'yk', 'prez', 'ił', 'rh', 'ír', 'jewe', 'ná', 'Vere', 'Украї', 'ços', 'aban', 'iment', 'ネ', 'pend', 'prefix', 'обу', '龙', 'bald', 'igi', 'endes', 'versary', 'валь', 'clock', 'operator', 'folge', 'spacing', 'ąc', '�', 'lavor', 'ณ', 'audi', 'час', 'Пре', 'frente', 'totalité', 'ز', 'ссе']\n",
      "in Layer6 , sorted_indices_dimension8744:  ['ië', 'eton', 'Kong', 'ṛ', 'ppen', 'loyd', 'Vitt', 'tek', 'retra', 'vier', 'Alt', 'contra', 'ita', 'infl', 'ync', 'infl', 'oth', 'Un', 'event', 'invert', 'bell', 'rijk', 'str', 'inst', 'VD', 'ien', 'inale', 'Matth', 'pid', '装', 'oy', 'ango', 'ș', 'ük', 'Sm', 'ivent', 'uto', 'influen', 'тия', 'rike', 'ovy', 'už', 'events', 'зо', 'wid', '式', 'hes', 'iens', 'iska', 'ask', 'listen', 'tim', 'Cooper', 'ют', 'CN', 'Hamb', 'iew', 'SER', 'Store', 'Kno', 'ensed', 'processing', 'owy', 'ags', 'veis', 'extr', 'orient', 'czy', 'arrison', 'départ', 'unos', 'checkout', 'frika', 'maximum', 'iop', 'ork', 'plate', 'Aless', 'rig', 'ef', 'Nil', 'reh', 'alt', 'utt', 'Ferd', 'Kon', 'interpre', 'istas', 'coron', 'inking', 'Call', 'elijk', '序', 'achine', 'tomb', 'adesh', 'Ori', 'prim', '制', 'utors', 'tracking', 'Santo', 'Emb', 'bottom', 'Bras', 'influenced', 'sens', 'event', 'rend', 'call', 'inea', 'MyClass', 'бой', 'arg', 'infer', 'expert', 'WorldCat', 'rän', 'UTF', 'vere', 'tod', 'appen', 'âtre', 'mini', 'wild', 'odel', 'ifen', 'odon', 'vu', 'ton', 'я', 'vertical', 'fitting', 'kele', 'то', 'perl', 'Ung', 'bapt', 'inks', 'aft', 'tons', 'стро', 'лий', 'maison', 'during', 'și', '机', 'гли', 'ensa', 'throughout', 'Bug', 'bir', 'Pit', 'cri', 'rome', 'rik', 'burgh', 'beneath', 'eria', 'opera', 'imm', 'gan', 'Kloster', 'HP', 'strike', 'Uns', 'tk', 'ICE', 'vey', 'Baden', 'ält', 'enso', 'merged', 'Service', 'instit', 'Ori', 'пі', 'ней', 'pian', 'urban', 'Orientation', 'AB', 'ме', 'enska', 'hum', 'monot', 'expl', 'bug', 'ancia', 'Bez', 'elm', 'pull', 'Ser', 'ittle', 'ots', 'Rak', 'FM', 'Raf', 'olit', '만']\n",
      "in Layer6 , sorted_indices_dimension3660:  ['igin', 'rok', 'ae', 'Baker', 'ivas', 'Els', 'commer', 'дена', 'Russ', 'oty', 'egen', 'uce', 'rame', 'psum', '˜', 'óż', 'ограф', 'agne', 'режи', 'водо', 'quot', 'ilde', 'usement', 'asc', 'pla', 'igi', 'ва', 'atan', 'false', 'Cla', 'слу', 'efe', 'hours', 'icon', 'atore', 'zák', 'aris', 'Sé', 'onden', 'atem', 'seg', 'ongodb', 'ǒ', 'mine', 'False', 'oj', 'serv', 'образ', 'ént', 'patron', 'Jenkins', 'ató', 'eles', 'agas', 'uszt', 'adu', 'preced', 'kte', 'bě', 'gru', 'EL', 'rita', 'agnet', 'CLI', 'gebracht', 'лежа', 'hide', 'aki', 'card', 'false', 'ouvelles', 'ános', 'Francesco', 'debug', 'Muse', 'тре', 'льной', '再', 'perl', 'icons', 'Lam', 'společ', 'correspond', 'бу', 'ouc', 'ugin', '�', 'schemas', 'oi', 'Pat', 'STATUS', 'dz', 'Parliament', 'lah', 'abet', '์', 'divid', 'VIAF', 'monument', 'comercial', 'článku', 'esso', 'Jim', 'äck', 'ânt', 'fortune', 'pped', 'ních', 'Capital', 'dire', 'дав', 'lessly', '⁷', 'antal', 'canvas', 'emet', 'José', 'quot', 'ép', 'ropol', 'ède', 'osc', 'oshi', 'riter', 'bounded', 'rott', 'nem', 'detail', 'бен', 'jem', 'ież', 'анта', 'Monument', 'Dialog', 'Pia', 'ì', 'Stone', 'ined', 'Jose', 'igned', 'angu', 'comedy', 'entes', 'bek', 'ares', 'older', 'hel', 'ан', 'rov', 'yw', 'icken', 'Cla', 'cribe', 'optera', '別', 'ös', 'cement', 'жно', 'asion', 'wikipedia', 'makeText', 'Olympics', 'othek', 'anni', 'hausen', 'Gel', 'ktion', 'ństw', '⍵', 'orum', 'fug', 'Helen', 'enced', 'British', 'horror', 'ení', 'Claud', 'ර', 'repla', 'Giov', 'auff', 'franc', 'há', \"+'\", 'contre', 'inea', 'reun', 'Great', 'ieder', 'Bek', 'ël', 'servlet', 'Rotten', 'methods', 'phas', 'Icon', 'institutions', 'beg', 'ibrary', 'orio']\n",
      "in Layer6 , sorted_indices_dimension7730:  ['uffle', 'attro', 'ѫ', 'lia', 'bid', 'ivent', 'iwers', 'ӏ', 'gebras', 'atica', 'stre', 'rès', 'lag', 'rit', 'kreich', 'ilt', 'uff', 'enser', 'jsf', 'geordnet', 'onato', 'ҡ', '߬', '&=\\\\', 'respond', 'uzz', 'bě', 'ículo', 'jd', 'éral', 'whe', 'zess', '能', 'Geography', 'unicí', 'FP', 'št', 'ша', 'ostęp', 'stellung', 'чник', 'ège', 'orr', 'encias', 'ѐ', 'ritz', 'Session', 'allas', 'Rotten', 'noreferrer', 'nad', 'ologe', 'lesia', 'œuvres', 'zös', '☉', 'pity', 'ven', 'cep', 'chez', 'läu', 'Rot', 'dich', '�', '중', 'Ven', 'жет', 'idenote', 'стов', 'corso', 'ők', 'turno', 'cid', 'uet', 'Lit', 'shape', 'ourse', 'uche', 'slow', 'virtuel', 'пись', 'Cloud', 'reven', 'заво', 'ruct', 'Rot', 'voir', 'Delegate', 'rend', 'Navigation', 'gestellt', 'ivot', 'био', 'orio', 'iciones', 'olit', 'usalem', 'uy', 'trail', 'sampling', 'Kong', 'adv', 'cru', 'už', 'ссе', 'ům', 'endencia', '◄', 'Off', 'üh', '⚭', 'сты', 'textt', 'льта', 'catt', 'lengths', 'Contempor', 'hon', 'alion', 'hal', '\"^', 'ivers', 'dí', 'ictwo', '~[', 'gest', 'ˇ', 'fact', 'Begriffe', 'nero', 'Off', 'noble', 'útbol', 'offs', 'nection', 'izi', 'ività', 'stor', 'iai', 'adj', 'cite', 'heiten', 'parenthes', 'ué', 'Nem', 'mid', 'ongo', 'präsident', 'Bou', 'вания', 'dátum', 'órico', 'Navigation', 'Cultural', 'pmod', 'inde', 'omial', 'onsieur', 'onn', 'juni', 'icas', 'cyc', 'Corpor', 'stor', 'Martínez', '⊙', 'vd', 'лё', 'ador', 'lat', 'Ram', 'çais', 'obi', 'миче', 'functions', '÷', 'CCESS', 'ť', 'Flora', 'contrib', 'ями', 'Mand', 'ování', 'idden', 'angers', 'anja', 'opera', 'Wa', 'esk', 'session', 'rift', 'gest', 'cza', '话', 'indexPath', 'reven', 'já', 'Whe', '�', 'izzazione']\n",
      "in Layer6 , sorted_indices_dimension2419:  ['utsch', 'Хронологија', 'jú', 'atform', '玉', 'реди', '↵', 'Herz', 'rix', 'мого', 'brázky', 'rès', 'kaf', 'ɕ', 'inferior', ':`', '效', 'iada', 'CTYPE', 'vil', 'sier', 'их', 'inha', 'lach', 'тература', 'мия', 'rack', 'Einzeln', 'retain', 'Ț', 'igung', 'asp', 'руд', 'SBN', 'üsseld', 'eredetiből', '書', 'ugno', 'mathchar', 'ker', 'rip', 'ichter', '老', 'ActivityThread', 'jon', 'adem', 'янва', 'SError', 'Grande', 'LOAD', 'февра', 'ią', 'Попис', 'цов', 'ehemal', 'arin', 'count', 'ribu', 'kende', 'мей', 'temper', 'hoff', 'noreferrer', 'Seb', '�', '[])', 'empre', 'CLARE', 'sq', '\"`', 'им', 'ContentView', 'COUNT', 'SERT', 'сом', 'ɔ', 'Gra', 'trust', 'legate', 'Schles', 'пописа', 'unicí', 'Pier', 'AtIndex', 'itzer', 'neh', 'Count', '$}}%', 'Stack', 'сона', 'ث', 'Nur', 'umann', 'wrong', 'країн', 'Є', 'arp', 'віт', 'ť', 'ך', 'ack', 'narr', 'мах', 'Sar', 'orsz', 'ǔ', 'Bundle', 'хва', 'sup', 'ubre', 'außer', 'riction', 'Gran', 'Grant', 'TEXT', 'slash', 'md', 'iterator', 'streams', 'ispecies', 'wechsel', 'Verein', 'Frei', 'fault', 'Ernest', 'coll', 'Deleg', 'Harvard', 'Lor', 'rabb', 'Theorem', 'iedenis', 'onymes', 'ientí', 'yci', 'flash', 'em', 'édé', 'unde', 'MD', 'Coll', 'ulus', 'ництво', 'па', 'Jet', 'ube', 'pack', 'iske', 'pier', 'thr', 'Justice', 'setContentView', ';;;;', 'bin', 'essel', 'Eq', 'ору', 'Laur', 'ску', 'ńst', 'вере', 'anter', 'Neue', 'strip', 'zetek', 'Sidenote', 'opsis', 'ordo', 'ächt', 'spole', 'Deux', 'Contract', 'Trust', 'tub', 'ayer', 'ју', 'Bedeutung', 'ves', 'Fen', 'redirect', 'wr', 'Coll', 'arsi', 'textt', 'eras', 'obar', 'Dennis', 'idé', 'Window', 'ред', 'ppel', 'eline', 'powiat', 'wod', 'MD', '↳', 'Ні', 'Ern', 'windows', '県']\n",
      "in Layer6 , sorted_indices_dimension3961:  ['rgba', 'heit', 'Board', 'schen', 'Archivlink', '++', 'kor', 'escol', '~[', 'ecz', 'åk', 'board', 'ogo', 'ouch', 'invånare', 'orten', 'Љ', 'Board', 'stag', 'jekt', 'fiddle', '+(', 'nem', 'Squad', 'QL', 'ento', 'lm', 'Wien', 'autorité', 'Mie', 'Einzeln', 'ách', 'żyn', 'ás', 'heits', 'carrera', 'Sir', 'attr', 'enci', 'muerte', 'ugno', 'raph', 'fasst', 'entferne', 'ich', 'тики', 'ск', 'Short', 'bars', 'Stre', 'aso', 'orgen', 'wi', 'Џ', 'stoff', 'hnen', 'kyr', 'sch', 'stad', 'ERT', 'emas', 'pue', 'ogy', 'dash', 'katol', '<>', 'kil', 'PASS', '\\x9d', 'ász', '\\u2003', 'zym', 'teck', 'ici', 'eten', 'pad', 'бка', 'rot', 'oro', 'stato', 'ually', 'ɫ', 'ے', 'обла', 'euw', 'obox', 'ා', 'Campe', 'ʔ', 'Fiche', 'ő', 'sn', 'ect', 'ligt', 'indows', 'став', 'отри', 'ryption', 'fahrt', 'ого', '回', 'elsk', 'frique', 'ett', 'lbl', 'eus', 'emat', 'acle', 'ˠ', 'Brandenburg', 'ئ', 'wik', 'Cris', 'SEE', 'ˌ', 'imat', 'entropy', 'ami', 'adratkilometer', '�', '════', 'specie', 'PRI', 'ków', '►', 'kommun', 'konn', 'gers', 'OP', 'см', 'flash', 'assen', 'aucoup', 'zien', 'sir', '秀', 'asis', 'emor', 'entation', 'ipt', 'ils', 'kor', 'ktet', 'olph', 'туа', 'Email', 'lyn', 'repre', 'nant', 'Oh', 'municip', 'Sand', 'Augen', 'ASCII', 'append', 'Мор', 'RL', 'Wein', 'bject', 'ila', 'ому', 'urus', 'Unit', 'ppi', 'abord', 'Ét', 'стор', '分', 'stycz', 'pygame', 'lack', 'appy', 'liste', 'Short', 'Kan', 'istiche', 'iore', 'лаго', 'gemeinde', 'schrift', 'lingen', 'Partei', 'dirett', 'ockey', 'erte', 'ius', 'Genomsnittlig', 'angu', 'orsz', 'bow', 'askell', 'ʲ', 'mac', 'reichen', 'Submit', 'JavaScript', 'SUB', 'tact', 'talet', 'statunit']\n",
      "in Layer6 , sorted_indices_dimension9563:  ['ocker', 'lei', 'jna', '└', 'una', 'iante', 'paździer', 'wieku', 'xter', 'uh', 'enn', 'gg', 'Hav', 'nex', 'Adel', 'asi', 'ого', 'դ', 'homonymes', 'eden', 'rin', 'inate', '否', 'mask', 'osto', 'Unterscheidung', 'Interceptor', 'ivo', 'och', 'Sitz', 'camb', 'গ', 'weit', 'ifa', 'ungs', 'пописа', '门', 'vik', 'intern', 'storing', 'halt', 'phia', 'Bast', 'varchar', 'succeeded', 'ife', 'ços', 'augusti', 'rai', 'adora', 'fel', '<>', 'ése', 'ográfica', 'Hub', 'ifier', 'Ě', 'otto', 'ział', 'Ó', 'iels', 'delen', 'Store', 'techni', 'сти', 'direction', 'eds', '\\u2060', 'internet', 'oktober', 'ว', 'verein', 'criptor', 'lej', '角', 'nan', 'ях', 'extend', 'int', 'sud', 'aña', 'Nied', 'dx', 'ệ', 'meck', 'ど', 'oh', 'esa', '该', 'cdn', 'arters', 'êque', 'ų', 'jal', 'Bat', 'ступ', 'Wil', '泰', 'ivas', ':\\u2009', 'aire', 'ści', 'États', 'polity', 'damit', 'wi', 'enschapp', 'джа', 'asa', 'mismatch', 'mask', 'vek', 'edu', 'KB', 'amd', 'тся', 'assen', 'ww', 'tera', 'ění', 'wrześ', 'ześ', 'ker', 'bild', 'mathchar', 'ོ', 'дна', 'ң', 'Wayne', 'гле', 'cych', 'geordnet', 'nero', 'atti', 'uman', 'ulk', 'irection', '雄', 'INTER', 'lyn', 'éricaine', 'чин', 'Tele', 'ِ', 'вана', 'acle', 'fel', 'remote', 'bat', 'nahme', 'ott', 'ikan', 'Keith', 'держа', 'iddle', 'sierp', 'Mask', 'ggreg', 'Formula', 'isch', 'alle', 'shift', 'siège', 'Stati', 'meter', '\\u200d', 'expect', 'кня', 'eles', 'asis', 'bereich', 'xtart', 'States', 'cade', 'verk', 'ollar', 'eper', 'ља', 'Lin', 'án', 'fen', 'Organisation', 'že', '\\u2009', 'moi', '지', 'fe', 'лим', 'Jahrhundert', 'medi', 'sci', 'ต', 'medi', 'plom', 'aper', 'mitt', 'anza', 'bank', 'ɡ', 'ník']\n",
      "Key: model.layers.7.mlp.down_proj.weight\n",
      "in Layer7 , sorted_indices_dimension7172:  ['żyn', 'RelativeLayout', 'istra', 'imer', 'Begriffsklär', '�', 'ز', 'datab', 'äft', 'ello', 'ере', 'dział', 'attan', 'blatt', 'ferrer', 'za', 'SESSION', 'Este', 'ités', 'guez', 'ța', 'zewnętrz', 'urr', '<s>', '画', 'зма', 'gaben', 'babel', 'isches', 'Ses', 'VICE', 'halten', 'agnet', 'noreferrer', 'odkazy', 'łow', 'abase', 'ighth', 'их', 'Records', 'iro', 'ulas', 'utlich', 'rea', 'boBox', 'Angeles', 'Ź', 'umption', 'ош', 'lette', '<>();', 'Stutt', 'opera', 'Przyp', 'hline', 'Burg', 'stwo', 'са', 'oka', 'ALSE', 'és', 'ctrine', 'dam', 'Ő', 'getElement', '衛', 'bury', 'Session', 'Frederick', 'Dal', 'Session', 'бург', 'Mate', 'dotnet', 'ellt', 'jes', 'ت', 'spre', '速', 'apsed', 'printStackTrace', '甲', 'venir', 'meno', 'Formatter', 'zález', 'Gui', 'ー', 'ят', 'oł', 'χ', 'AppData', 'мат', 'INCT', 'irse', 'ович', 'fahren', 'ês', 'ék', 'лка', 'установ', 'рела', 'giv', 'kotlin', 'virt', 'sey', 'Hung', 'owych', 'wiąz', 'rl', 'вого', 'groupId', 'blah', 'trans', 'Fichier', 'ще', 'Fir', 'uma', 'dostęp', 'otr', 'destination', 'ñ', 'èrent', 'sdl', 'nad', 'urrence', 'erde', 'exterior', '➜', 'Bien', 'mij', 'ña', 'ugel', 'ometric', 'Ta', 'SA', 'session', 'onas', 'ätter', 'raz', 'nad', 'ħ', 'png', 'bazie', 'рем', 'yt', 'burg', 'dot', 'ahr', 'labels', 'inwon', 'eszt', 'OnClickListener', 'переда', 'secolo', 'ERE', 'ité', 'uen', 'ode', 'altro', 'mate', 'mense', 'org', 'mac', 'footnote', 'Ern', 'Datos', '座', 'INIT', 'юз', '+$', 'stract', 'osh', 'como', 'ých', 'consin', 'Års', 'зо', 'quel', '‹', '番', 'лові', '*$', 'л', 'kmal', 'сі', 'дела', 'Lig', 'urbed', 'ąd', 'ulos', 'zw', 'ettings', 'rance', 'raj', 'bor', 'uve', '>=', 'eres', 'manner']\n",
      "in Layer7 , sorted_indices_dimension197:  ['aqu', 'heimer', 'ilian', 'dri', 'resse', 'acker', 'libs', 'parad', 'asa', 'ât', '`:', 'вя', 'Zug', 'кра', 'arium', 'Preferences', 'okal', 'ituto', 'Dou', 'ices', 'orp', '`[', 'unicí', 'Campbell', 'angle', 'ächs', 'ҡ', 'agrant', 'ecc', '研', 'elsk', '้', 'comm', 'ced', 'mozilla', 'взя', 'iben', 'initi', 'ship', 'trab', 'Miss', 'exchange', 'Angel', 'quant', 'чё', 'eden', 'imir', 'Bayer', 'ski', 'Query', 'Hub', 'ште', 'FLAG', 'usto', 'distance', 'unks', 'pie', 'alin', 'Autow', 'ship', 'meteor', 'indre', 'zyż', 'cod', 'кур', '话', 'asser', 'ғ', 'ozzá', 'stories', 'habitat', 'Lex', 'tu', 'resource', 'reci', 'TAC', 'yp', 'öt', 'benchmark', 'сть', 'exped', 'ья', 'webdriver', 'Cris', 'Ressources', 'Ά', 'layers', 'Mais', 'Meteor', 'cian', 'inea', 'ía', 'Film', 'хозяй', 'rom', 'commut', 'ķ', 'excel', 'enemy', 'kil', 'bernate', 'icons', 'oz', 'ación', 'FF', 'HL', 'ске', 'hod', '∙', 'inne', 'emph', 'emu', 'xim', 'Ə', 'öv', 'zó', 'welt', 'scient', 'olare', 'qu', 'edit', 'schau', 'сві', 'ttp', 'XV', 'rant', 'ès', 'stoff', 'isie', 'ą', '話', 'tom', 'observ', 'dou', 'adas', 'Christmas', 'utils', 'тали', 'otrop', 'Pennsylvan', 'defaults', '�', 'Bug', 'capital', 'rien', '(:', 'Bl', 'hub', 'iqu', 'gez', 'unwrap', 'ped', 'Dialog', 'toolbar', 'BS', 'чке', 'ptions', 'DECLARE', 'Gab', 'Ξ', 'transmission', 'Liv', 'acceler', 'rowser', 'ali', 'bug', 'bibliothek', 'Ky', 'tagon', 'че', 'agent', 'Belgique', '拳', 'exchange', 'inspect', 'uffer', 'воз', 'FC', 'suc', 'Plot', 'aken', 'ouss', 'Mai', 'hints', 'emi', 'ítás', 'omorphism', 'Big', 'reib', 'quia', 'obox', 'spec', 'jal', 'везе', 'query', 'mel', 'specification', 'nett', 'iento', 'ﬁ']\n",
      "in Layer7 , sorted_indices_dimension10415:  ['previous', 'previously', 'esters', 'previous', 'sterd', 'already', 'ieren', 'din', 'sel', 'alia', 'лия', 'WT', 'Jud', 'Opera', 'fern', 'nic', 'Newton', 'organized', 'itas', 'erve', 'kord', 'Pon', 'arlo', 'Се', 'erv', 'ira', 'spe', 'Din', 'cier', 'ра', 'Chal', 'horn', 'Tun', 'ős', 'odon', 'imes', 'dia', 'ws', 'Alb', 'revel', 'browser', 'vern', 'pi', 'rup', 'ális', 'est', '[@', 'estro', 'topics', '—', 'Clo', 'Spart', 'Reich', 'ls', 'Abs', 'mutable', 'vious', 'earlier', 'Scala', 'нах', 'Dist', '@@', 'pon', 'Tor', 'conf', 'gre', 'opera', 'scala', 'нами', 'alen', 'will', 'privileges', 'SSION', '�', 'olia', 'assets', 'ubs', 'stro', 'ti', 'gab', 'dispon', 'estion', 'nica', 'Perry', 'bereits', 'gnu', 'reserved', 'sr', 'GN', 'Golden', 'files', 'oster', 'Santo', '-', 'Reserve', 'Ry', 'Gran', 'Riv', 'ář', 'estimation', 'Wit', 'jud', 'logger', 'topic', 'mag', 'DAT', 'geh', 'pro', 'до', '@\",', 'ева', 'uries', 'adem', 'differently', '만', 'abs', 'Lig', 'aden', 'eries', 'aglia', 'ç', 'alem', 'tre', 'manifest', '—', 'già', 'Kob', 'Django', 'cc', 'erd', 'çais', 'Alan', 'attend', 'BU', 'engu', 'sensitive', 'Gre', 'UPDATE', 'piano', 'abs', 'climate', 'spe', 'hi', 'Bernard', 'Zero', 'West', 'ies', 'mag', 'anse', 'Um', 'Barbara', 'Copy', 'sel', 'recht', 'inspir', 'reserve', 'alert', 'dispers', '@', 'Sem', 'dic', 'Bay', 'Accessor', 'mat', 'Fle', 'Резу', 'web', 'decor', 'organ', 'Julia', '©', 'Wy', 'aren', 'icol', 'Trad', '已', 'pat', 'schon', 'dic', 'rub', 'azar', 'ссе', 'Rub', 'uben', 'tradicional', 'bal', 'Internet', 'Balt', 'VC', 'віці', 'Sov', 'Main', 'déjà', 'imum', 'estim', 'pecies', 'Cl', 'WS', 'brow', 'ancer']\n",
      "in Layer7 , sorted_indices_dimension337:  ['ori', 'bat', 'pta', 'Jas', 'bat', 'Gay', 'Else', 'rapp', 'anas', 'estra', 'ensus', 'ewnętrz', 'Jordan', 'libert', 'Bat', 'Else', 'dice', 'ограф', 'зво', '究', 'Насеље', 'Ell', 'ethod', 'odi', 'dic', 'Cooper', 'ض', 'haupt', 'spo', 'Identity', 'ilon', 'ativ', 'ър', 'rails', 'mark', 'berts', 'ultats', 'tan', 'kiej', 'ante', '幸', 'Christmas', 'ked', 'ish', 'DEBUG', 'argent', 'Datos', 'wedge', 'Stim', 'eu', 'eca', '断', 'ango', 'hnen', 'ུ', 'rä', 'isol', 'bahn', 'stack', 'Scal', 'anga', 'Hitler', 'Libert', 'idente', 'erta', 'VAR', 'веро', 'gay', 'Њ', 'forth', 'Branch', 'etra', 'blica', 'omin', 'ield', 'archivi', 'kat', 'FAULT', 'eli', 'xsl', 'erk', 'infant', 'rails', '状', 'ardon', 'rank', 'sir', 'decimal', 'Mark', 'ained', 'agnet', 'layer', 'Kim', 'RELEASE', 'eder', 'Dok', 'Are', 'Zob', 'branch', 'alle', 'vere', 'sau', 'train', 'Pager', 'trains', '�', 'bah', 'equilib', 'Kat', '街', 'роках', 'kbd', 'ientes', 'icator', '학', 'Stack', 'ax', 'luck', 'uber', 'ucker', 'ever', 'jna', 'oi', 'ки', 'ież', 'oded', 'ante', 'дека', 'fur', 'Voor', 'markup', 'indow', 'pour', 'ų', 'ingen', 'asto', 'Desktop', 'ident', 'istra', 'ell', '✿', 'swift', 'ThreadPool', 'Railway', 'Vik', 'Yu', 'k', 'jest', 'отде', 'Ot', 'kord', 'Train', 'ples', 'isolated', 'anya', 'poll', 'висини', '연', 'Preferences', 'Execution', 'ènes', 'lung', 'vill', 'jug', 'Ő', 'XT', 'voy', 'Роди', '──', 'Broadway', 'Decimal', 'formula', 'Vo', 'Tib', 'Rail', 'archiviato', 'overflow', 'Communic', 'TA', 'gy', 'coal', 'LAY', 'required', 'raph', 'identity', 'EventArgs', 'bell', 'pole', 'Documents', 'Weiter', 'Chart', '座', 'ark', 'ienza', 'сте', 'une', 'pitch', 'ана', 'ABASE', 'ará']\n",
      "in Layer7 , sorted_indices_dimension7155:  ['❯', 'ree', 'ере', 'erei', 'рес', 'reb', 'fiddle', 'ummy', 'loor', 'ẓ', 'insc', 'triangle', 'amour', '包', 'igan', 'kim', '�', 'decor', 'kernel', 'Commons', 'onnen', 'ímp', 'ND', 'waste', 'ordo', 'ipart', 'zę', 'illo', 'conservation', 'ono', 'stub', 'thm', 'angen', '(\\\\<', 'тра', 'pus', 'ivas', 'vos', 'oot', 'NULL', 'menor', 'Gren', 'curv', 'che', 'iesz', 'DER', 'CAA', 'kten', 'ре', 'azz', 'Augen', 'skim', 'devil', 'яз', 'HMS', 'CURL', 'ńcz', 'Gia', 'ке', 'irtschaft', 'Operation', 'olimp', 'partiellement', 'cil', 'Conserv', 'Ṣ', 'tis', 'bare', 'REE', 'fica', 'Grid', 'itat', 'door', 'zug', 'tort', 'uka', 'ActivityThread', 'decla', 'partici', 'abc', 'chen', '∂', 'CESS', '题', 'bef', 'bold', 'ttp', 'grid', 'operation', 'ociación', 'WR', 'ʾ', 'uder', 'implicit', 'bü', 'rav', 'Chine', 'tha', 'sten', 'par', 'ering', 'ниш', 'mar', 'ḏ', 'teck', 'ска', 'shell', 'prayer', '्', 'Tsch', 'compart', 'Naval', '{-', 'ņ', 'Datenbank', 'вро', 'par', 'SK', 'Recognizer', '̣', 'externs', 'Madame', 'eren', 'keit', 'pray', 'испо', 'Harris', '✅', 'Musical', 'timer', 'Properties', 'basket', 'cou', '{%', 'archiv', 'iddle', 'defn', 'благо', 'simplest', 'Vincent', 'fon', 'gev', 'Besch', 'ależ', 'hoof', 'kee', 'Regierung', 'ката', 'kö', 'Imperial', 'Handle', 'говор', '庄', 'raf', 'lär', 'cler', 'declarations', 'fish', 'Tun', 'Hab', 'oven', 'ма', 'Rect', 'Begriffsklär', 'сер', 'лов', 'ERT', 'artific', 'рем', 'ec', 'mid', 'docs', '}](', 'Vie', 'abama', 'der', 'Milit', 'reproduce', 'apan', 'participation', 'anza', 'oon', 'Grid', 'Grund', 'amplitude', 'ham', 'Extern', 'hall', 'bund', 'thes', 'skiego', 'title', 'ʿ', 'ган', 'к', 'Ps', 'SK', 'ष', 'ust', 'olymp']\n",
      "in Layer7 , sorted_indices_dimension3351:  ['di', 'coin', 'archiviato', 'ifer', 'Ord', 'dell', 'ede', 'verte', 'Caval', 'onato', 'Dob', '君', 'fel', 'équipe', 'ownik', 'della', '¦', 'тва', 'mess', 'elif', 'Encyclopedia', 'Tul', 'dei', 'Princi', 'ello', 'rok', 'Camera', 'archivi', 'fé', 'ELSE', '目', 'ias', 'ública', 'rias', 'Barb', 'Camera', 'ube', 'Memorial', 'autorité', 'És', 'Архівовано', 'heure', 'Қ', 'Jefferson', 'equip', 'нец', 'sb', 'ensoort', 'mont', 'sel', 'koz', 'determin', 'uzz', 'ebol', 'кет', 'pend', 'Kennedy', 'jna', 'fu', '~[', 'formatt', 'anh', 'häng', 'BeanFactory', 'konn', 'alberga', 'norm', 'erk', 'discuss', 'Gang', 'YS', 'нок', 'рук', 'omb', 'Nazionale', 'nou', 'भ', 'rif', 'ulty', 'lès', 'publique', 'uz', '洞', 'iből', 'Хронологија', 'ู', 'skog', 'gen', 'oca', 'Comm', '장', 'asts', 'équipes', 'bě', '良', 'AX', 'Resol', 'дар', '﹕', 'kazy', 'ordin', 'ibile', 'До', 'kmal', 'Bbb', 'borough', 'nam', 'ver', 'dag', 'èg', 'Ric', 'gouvern', 'camera', 'Beruf', 'IX', 'Brainz', 'omp', 'rinn', 'mathbb', 'úblic', 'ruby', 'Timestamp', 'Arg', 'alone', 'Camp', 'xe', 'Lexikon', 'dob', 'etto', 'визи', 'arp', 'gang', 'reload', 'MB', 'cert', 'dictionary', 'preserved', 'confront', 'delle', 'hina', 'bres', 'тори', 'ków', 'mí', 'defn', 'graf', 'etti', 'yed', 'ws', 'Batt', 'elem', 'вед', 'arina', 'тных', 'Bell', 'eredetiből', 'cuss', 'rencontre', 'isch', 'spe', 'Engel', 'VERSION', 'ió', 'ivent', '$?', 'článku', 'bell', '甲', '\\x83', 'Ross', 'жду', 'tto', 'cze', 'sf', 'endra', 'onel', 'associate', 'völker', 'ogn', 'caval', 'ど', 'cube', 'cards', 'ツ', 'mals', 'anglès', 'esch', 'dst', 'groupId', 'ferro', 'mess', 'дела', '郎', 'érer', 'zec', 'Britannica', 'MB', 'Non', 'Johan', 'ież']\n",
      "in Layer7 , sorted_indices_dimension9370:  ['tn', 'ahl', 'labels', 'Oficina', 'acon', 'ods', 'áss', 'cold', 'Pir', 'night', 'gouvern', 'BA', 'RewriteCond', 'Discogs', 'compat', 'rup', 'fare', 'ech', 'лей', 'tu', 'compatibility', 'trad', 'Tro', 'label', 'compat', 'bone', 'Month', 'Cold', 'contained', 'antin', 'ouch', 'вар', 'Compat', 'repr', 'ought', '#', 'Invocation', 'assoc', 'bound', '(„', 'ált', 'Ing', '\\u200f', 'atten', 'operating', 'at', '나', 'Walker', 'conse', 'iji', 'DM', 'лер', 'Sta', 'AMP', 'bage', 'íz', 'ót', 'Opera', '影', 'compatible', 'subfigure', 'ango', 'BY', 'utch', '∞', 'сти', 'hbar', 'bitr', 'cler', 'prot', 'ger', 'Ressource', 'label', 'itut', 'lius', 'fragments', '收', 'oce', 'вид', 'FM', 'ika', 'ivot', 'erw', 'planta', 'opera', '__', 'dam', 'ֹ', 'себя', 'inge', 'ski', '�', 'ERR', 'lett', 'És', 'kir', 'ikus', 'compatible', 'oken', 'sync', 'ye', 'occ', 'amps', 'icia', 'utor', 'ether', 'FM', 'isf', 'Sver', 'internal', 'Ost', 'npm', 'dos', 'pret', 'iger', 'ט', 'Appar', 'ami', 'proper', 'Matt', 'uvud', 'listener', 'infinite', 'Grid', 'тро', 'pir', 'äufig', 'DM', 'ordin', 'rang', 'pmod', 'Mvc', 'nit', 'done', '도', 'aszt', 'enti', 'бли', 'Ehr', 'agr', 'oder', '?](', 'labels', '兵', 'err', 'grid', 'amp', 'bootstrap', 'tro', '之', 'ave', 'Ґ', 'Stad', 'Gó', 'bru', 'рь', 'domains', 'month', 'CO', 'よ', 'Nathan', 'servant', 'ческий', 'станови', 'imped', 'annt', 'CF', 'extra', 'implies', '常', 'thou', 'inet', 'nod', 'iot', 'Holder', '라', 'tl', 'implicit', 'toss', 'listener', 'alia', 'aix', 'eks', 'asto', 'же', 'instru', 'aya', 'Content', 'Color', 'Arm', 'Label', 'izer', 'organ', 'größ', 'ret', 'local', 'firewall', '=\".', 'physical', 'ус']\n",
      "Key: model.layers.8.mlp.down_proj.weight\n",
      "in Layer8 , sorted_indices_dimension1920:  ['jar', 'lm', 'skie', 'tan', 'iano', 'Shared', 'apis', '自', 'shared', 'ki', 'experiment', 'emberg', 'shared', 'chor', 'ao', 'Shared', 'FLA', 'Story', 'Story', 'pixels', 'ър', 'tan', 'distributed', 'jas', 'side', 'pun', 'zent', 'kim', '�', 'uld', 'ux', 'itel', 'udent', 'rough', 'ugh', 'Bast', 'cyc', 'Cho', 'test', 'stelling', 'enth', 'ån', 'ford', 'Directory', 'Bapt', 'Stra', 'seite', 'stories', 'tutorials', 'ǎ', 'cken', 'bapt', 'eline', 'gia', 'dex', 'otal', 'being', 'ót', 'Lit', 'permanent', 'ren', 'md', 'sud', 'test', 'states', 'FI', 'Yu', 'gla', 'perfect', 'UE', 'inand', 'uet', 'periment', 'zös', 'dependencies', 'fla', 'lein', 'lan', 'currency', 'Long', 'Gla', 'CURL', 'self', 'aju', 'hidden', 'othe', 'fl', 'ool', 'happening', 'fig', 'endor', 'UST', 'stellen', 'fig', 'Opt', 'Fran', 'ela', '\\x7f', 'otr', 'hidden', 'uel', 'тро', 'Sche', 'bytes', 'stelle', 'folge', 'amd', 'ordinates', 'tober', 'tap', 'tel', 'их', 'Ret', 'eln', 'Han', 'ote', 'zi', 'Resource', 'Gu', 'uz', 'Tan', 'iei', 'sche', 'agh', 'Pra', 'berta', 'iek', 'FI', 'currency', 'quence', 'Hidden', 'atel', 'gr', 'Feder', 'utat', 'rect', 'jours', 'sert', 'округа', 'side', 'lauf', 'Provider', 'org', 'ANGE', 'ina', '密', 'lit', 'pixel', 'idor', 'ória', 'сер', 'oul', 'enen', 'lop', 'Ret', 'Arm', 'Long', 'SY', 'слі', 'trial', 'Bruce', 'orno', 'ms', 'House', 'lait', 'Pointer', 'fl', 'Neben', 'Select', 'ret', 'ách', 'imper', 'OPT', 'Magn', 'irt', 'story', 'nx', 'ų', 'Directory', 'sin', 'ellett', 'ग', 'aim', 'Clar', 'lassen', 'messages', 'филь', 'pra', 'Å', 'ɯ', 'rör', 'open', 'pr', 'ense', 'oko', 'льный', 'FIG', 'rough', 'VAR', 'cust']\n",
      "in Layer8 , sorted_indices_dimension3109:  ['VARCHAR', 'FIFA', 'omena', 'ängen', 'œuv', 'tha', 'thes', 'onia', 'chia', 'unicí', 'Ready', 'rough', 'že', 'gior', 'las', 'ensch', 'uden', 'javase', 'Beng', 'ikz', '�', 'thesis', 'metros', 'din', 'rror', 'sert', 'ächst', 'giv', 'ierung', 'Nobel', 'bru', 'sens', 'ientes', 'soft', 'etta', 'arel', 'arrival', 'rar', 'enç', 'blica', 'chio', 'ango', 'istes', 'UTC', 'еде', 'Ess', 'ʒ', 'Revolution', 'rå', 'ifa', 'geom', 'Mapp', '玉', 'WorldCat', 'usalem', 'agua', '死', 'angu', 'avier', 'smallest', 'óg', 'шко', 'ص', 'nico', 'proven', 'Operation', 'oret', 'थ', 'televis', 'dag', 'bor', 'infin', 'lap', 'Formatter', 'uta', 'alla', 'zett', '完', 'ya', 'ämp', 'iente', '⇔', 'ℚ', 'Ţ', 'rough', 'Oper', 'externs', 'acceleration', 'bah', 'ess', 'uchte', 'arrived', 'premier', 'arrive', 'ted', 'Dam', '𝓝', '়', 'babel', 'ہ', 'programming', 'рож', 'fi', 'pg', 'slide', 'Dest', '‰', 'ührt', 'arriv', 'broadcast', 'unk', 'uther', 'çais', 'extend', 'données', 'thern', 'usch', 'MDb', '处', 'Unknown', 'тия', 'acon', 'fah', 'ى', 'ieben', '移', 'wand', 'onda', 'ᾶ', 'ът', 'nete', 'ovis', 'dense', 'igan', 'terior', 'üng', 'cors', 'ouvelle', 'мель', 'Comput', 'Maz', '仁', 'ů', 'damage', 'ng', 'lö', '�', 'teck', '-+', 'nord', 'avascript', 'essen', 'версите', 'ugno', 'Norte', 'Fot', 'entin', 'роме', 'operation', 'рабо', 'Best', 'Leop', 'MAC', 'exped', 'neut', 'sted', 'ľ', 'plat', 'uje', 'eto', 'elia', 'Tre', 'onders', 'opsis', 'länkar', 'geometry', 'oper', 'üssen', 'riz', 'idle', 'onces', 'dest', 'rf', '功', 'Category', 'kat', 'zam', 'acceler', 'Ti', 'ROP', 'ště', 'rop', 'cellation', 'vers', 'britann', 'fem', 'LP', 'ISBN', 'ientos', 'р']\n",
      "in Layer8 , sorted_indices_dimension5702:  ['pron', 'ogo', 'aca', 'Medi', 'ката', 'ac', 'Kat', 'ack', 'meas', 'pine', 'jo', 'acu', 'CD', 'itel', 'zak', 'Whit', 'cat', 'bear', 'mac', 'Testament', 'kat', 'jel', 'assistance', 'managed', 'callback', 'acs', 'Ac', 'manage', 'Cat', 'agy', 'pecies', 'mi', 'igos', 'Lomb', 'ongo', 'igo', 'continu', 'in', 'es', 'cat', 'rein', 'живо', 'dot', 'acz', 'atch', 'isse', 'stood', 'cells', 'figures', 'le', 'Fig', 'Callback', 'его', 'jar', 'com', 'catch', 'aku', 'medi', 'continu', 'gi', 'figure', 'or', 'Deport', 'engen', 'orph', 'ací', 'cell', 'unter', 'art', 'm', 'Figure', '生', 'ATCH', '\\x13', 'UILD', 'variables', 'building', 'Õ', 'aps', 'ga', 'ac', 'adj', 'ison', 'Soph', 'leaf', '洋', 'magnitude', 'fires', 'kehr', 'ро', '伝', 'cue', 'alco', 'ittel', 'data', 'es', 'presiden', 'wishes', 'Свя', 'CB', 'memb', 'home', 'rim', 'org', 'cd', 'east', 'invest', 'somehow', 'direkt', 'AE', 'surv', 'patch', 'fficiale', 'arth', 'atique', 'Националь', 'gi', 'we', 'usa', 'help', 'anc', 'oy', 'ч', 'strateg', 'perhaps', 'catalog', 'rons', 'pository', 'terminal', 'tears', 'coat', 'altern', 'owe', 'um', 'year', 'Thanks', 'pover', 'zen', 'dust', 'ui', 'Fig', 'deport', 'стоян', 'databases', 'clud', 'TS', 'bef', 'algebra', 'nuc', 'teles', 'medi', 'obliged', 'angularjs', 'ios', 'micro', 'liqu', 'Ol', 'requ', 'ango', 'ot', 'onic', 'header', 'ná', 'вся', 'fire', 'atalog', 'through', 'clusters', 'Hamb', 'roots', 'ho', 'ower', 'prec', 'Ю', 'Service', 'dev', 'lift', 'atel', 'complement', 'cluster', 'dér', 'Thank', 'bes', 'Normal', 'itos', 'pride', 'Bundes', 'UI', 'require', 'lo', 'rios', 'ine', 'cra', 'callback', 'built', 'resid', 'fig', 'torn', 'nx', 'Service']\n",
      "in Layer8 , sorted_indices_dimension4426:  ['君', 'future', 'dispar', 'aders', 'ittest', '�', 'after', 'iero', 'equal', 'until', 'lef', 'änger', '打', 'orem', 'Cés', 'atabase', 'ools', 'grud', 'rique', 'uture', 'eeuw', 'after', 'apers', 'після', 'adin', 'vim', 'habit', '后', 'legacy', 'přek', 'oning', 'ą', 'rid', 'Random', 'ilog', 'writ', 'uster', 'Ї', 'pués', 'geber', 'spole', 'Vorlage', 'ång', 'permanent', 'iffer', 'allenge', 'iges', 'pc', 'soort', '後', 'uncia', 'cra', 'поло', 'caching', 'Leip', 'kten', '谷', 'manual', 'ał', 'dopo', 'until', 'olis', 'гне', 'slo', 'vide', 'portal', 'adesh', 'после', '房', 'anha', 'burst', 'nehm', 'princes', 'subs', 'idenote', 'cache', 'ira', 'ª', 'accum', 'сло', 'rees', 'icha', 'unix', 'ThreadPool', 'schließ', 'után', 'icans', 'Credentials', 'adu', 'plain', 'till', 'március', 'рез', 'Ż', 'dialog', 'ixel', 'hab', 'cached', 'tte', 'стра', 'prés', 'resolve', 'hab', 'Ptr', 'perman', 'puis', 'ragma', '„', 'prüng', 'Rol', 'ubuntu', '算', 'tta', 'rolle', 'ieri', 'мет', 'manual', 'ably', 'sers', '府', 'vement', '紀', 'urt', 'balance', 'got', 'scher', 'après', 'trad', 'Resol', 'iende', 'február', 'iedz', 'centuries', 'skal', 'Multiple', 'blica', 'ABLE', 'дер', 'сен', 'pid', '<-', 'Č', 'urope', 'сло', 'tegr', '%{', 'ží', 'arith', 'orge', 'ció', '序', '康', 'imb', 'canon', 'eurs', 'blic', 'calc', 'ńcz', 'efter', 'dotnet', 'oting', 'ycz', 'jusqu', 'Edit', 'args', 'Й', 'após', 'exists', 'apis', 'atoire', 'dialog', 'ikus', '番', 'amt', 'rons', 'lim', 'Dance', 'ase', 'Perform', 'ampion', 'SEE', 'beste', 'auff', 'enburg', 'itza', 'xf', 'mutable', 'naio', 'Mem', 'Camer', 'ону', 'Zyg', 'liest', 'preced', 'remainder', 'ographique', 'rend', 'uber', 'ideos', 'ling']\n",
      "in Layer8 , sorted_indices_dimension10129:  ['uvud', '校', 'сторія', 'math', 'ava', 'fil', 'броја', 'rist', 'Mut', 'eria', 'íd', 'oten', 'Alg', 'Hon', 'ables', 'Str', '置', '位', 'unw', 'achiv', 'Math', 'cord', 'GR', 'pocket', 'pit', 'athan', 'converts', 'jt', 'anze', 'lea', 'ties', 'cerem', 'duplicate', 'jna', 'ilar', 'IDE', 'Ban', 'стори', 'rate', 'ifs', 'stag', 'proof', 'ITable', 'wo', 'ech', 'unde', 'Constant', 'deg', 'ça', 'ï', 'Walker', 'convert', 'Proof', 'stem', 'fp', 'proof', 'Arag', 'mut', 'olate', 'REATE', 'xt', 'Muse', 'stadt', 'testing', 'Algorithm', 'ég', 'amil', 'ives', 'iskt', 'Ana', 'Le', 'egr', 'duplicates', '∆', '้', 'дели', 'дой', 'erna', 'ath', 'Sil', 'ugins', 'FLA', 'jer', 'ნ', 'cow', 'anglès', 'ests', 'gat', 'wieku', 'ATH', 'ugin', 'printStackTrace', 'prime', 'ban', 'ël', 'Cord', 'рт', 'ків', 'Andre', 'numerical', 'esper', 'comb', 'mut', 'Alg', 'Pitt', 'olit', 'Turner', 'usb', 'öt', 'hon', 'Av', 'formulas', 'groups', 'титу', 'Mit', 'Cheers', 'EN', 'sil', 'groups', 'atura', 'ämp', 'Fed', 'DOCTYPE', 'fficiale', 'Hil', 'Model', 'Zum', 'surface', 'ulp', 'vi', 'prez', '除', 'Mechan', 'Ej', 'hu', 'animal', 'Laur', 'icki', 'Ung', 'ј', 'GT', 'lex', 'resse', 'avi', 'мате', 'ktet', 'comp', 'utf', 'mt', 'uca', 'blocks', 'basketball', 'Ill', 'Navigation', 'ף', 'IONS', 'ком', 'GR', 'ities', 'adic', 'ut', 'ん', 'Raw', 'ol', 'fram', 'ová', 'ele', 'wei', 'Conseil', 'animate', 'stad', 'ной', 'overwrite', 'fen', 'proced', '\\\\<', 'bisher', 'az', 'род', 'dam', 'fg', 'sil', 'dup', 'Convert', 'tears', 'ignor', 'Projects', 'hero', 'tests', 'º', 'XXX', 'Az', 'Zh', 'Ja', 'alle', 'Mathemat', 'нах', 'lire', 'ió', 'findViewById']\n",
      "in Layer8 , sorted_indices_dimension5302:  ['Touch', 'icola', 'Sim', 'azz', 'touch', 'ilis', 'or', 'endor', 'Career', 'ris', 'ậ', 'ène', 'Som', 'Fed', 'wis', 'ym', 'eness', 'loss', 'oracle', 'agi', 'ymi', 'career', 'Cris', 'Apost', 'кто', 'Names', 'оло', 'Wieder', 'Ī', 'Na', 'na', 'aga', 'Na', 'Coast', 'ędzy', 'eno', 'hom', 'fish', 'Dat', 'ряд', 'her', 'clip', 'cons', 'Wis', 'ограф', 'Los', 'над', 'yk', 'Clara', 'ode', 'pmod', 'CLI', 'alis', 'agy', 'Carol', 'cess', 'ollar', 'central', 'IDE', 'uis', 'earance', 'orno', 'eclipse', 'sir', 'ard', 'Phi', 'ific', 'solid', 'Lew', 'ante', 'ք', 'Los', 'hoff', 'WF', 'ene', 'abi', 'Rose', 'beskre', 'Forms', 'touch', 'lyph', 'aro', 'elev', 'hin', 'кри', 'ioned', 'cil', 'Weg', 'Touch', 'tag', 'figur', 'ifiers', 'hom', 'Stream', 'plus', 'Jenkins', 'labels', '🌍', 'ross', 'gov', 'adjust', 'ím', 'Label', 'MyClass', 'omo', 'мене', 'holm', 'cules', 'excess', 'ctl', 'orgen', 'Sommer', 'horn', 'olo', 'besondere', 'utors', 'ky', 'tag', 'jsp', 'között', 'guns', 'tank', 'า', '区', 'Scot', 'Wikiped', 'change', 'Fore', 'о', 'GC', 'Mine', 'paths', 'Tag', 'gr', 'diss', 'amazon', 'Description', 'VID', 'ansk', 'fed', 'zm', 'ake', 'stream', 'clus', 'рит', 'POST', 'los', 'aff', 'Ṭ', 'eclipse', 'gia', 'possib', 'Wol', 'ilda', 'LAB', '[@', 'lo', 'Hop', 'tags', 'tog', 'ら', 'джи', 'chter', '?(', 'ISO', 'account', 'feed', 'ције', 'вод', 'modes', 'drum', 'INNER', 'gre', 'Von', 'руп', 'labels', 'rose', 'Gene', 'una', '路', 'Lem', 'гом', 'Using', 'lice', 'цент', 'jus', 'eca', 'そ', 'oret', 'caller', 'isk', 'Walk', '确', 'estr', 'goals', 'Robinson', 'na', '氏', 'Simon', 'Broad']\n",
      "in Layer8 , sorted_indices_dimension2998:  ['uz', 'fields', 'English', 'Hur', 'fields', 'domains', 'uri', 'issues', 'core', 'Transport', 'uru', 'iver', 'basic', 'English', 'areas', 'hous', 'transport', 'bild', 'core', 'verf', 'uer', 'ori', 'idal', 'ardo', 'org', 'programming', 'opera', 'ﬁ', 'matters', 'дон', 'nah', 'Chor', 'sight', 'Opera', 'ahu', 'ница', 'cat', 'vity', 'riz', 'ri', 'bez', 'nar', 'ט', 'Transport', 'viol', 'Lee', 'lak', 'services', 'aty', 'gu', 'hl', 'tera', 'Mad', 'pressing', 'End', 'Sund', 'iti', 'Stutt', 'ouv', 'ctr', 'span', 'oph', 'テ', 'жен', 'ite', 'rá', 'everything', 'Pred', 'pert', 'transport', 'wind', 'ception', 'ен', 'Ren', 'ctors', 'lar', 'aga', 'RL', 'ct', 'na', 'URI', 'ită', 'dre', 'idor', 'drums', 'Basic', 'clou', 'music', 'sop', 'Uri', 'end', 'Span', 'Ë', 'icio', 'contro', 'delegate', 'Admin', 'oh', 'ề', 'Fel', 'original', 'leak', 'Inner', 'uel', 'slider', 'Select', 'issues', 'orn', 'Toul', 'cand', 'Chan', 'Kreis', 'юз', 'iet', 'framework', 'unicí', 'health', '夢', 'vě', 'oux', 'ital', 'cont', 'charges', 'order', 'HS', 'urance', 'years', 'Salt', 'kop', 'Dorf', 'verband', 'Freder', 'Health', 'ру', 'Depart', 'energy', 'terms', 'Cont', 'amma', 'quet', 'r', 'oust', 'dorf', 'pint', 'standard', '安', 'occupied', 'ur', 'marque', '!(\"', '管', 'ช', 'xe', 'ln', 'hu', 'ouri', 'invån', 'cam', 'Original', 'mee', 'éma', 'aug', 'demol', 'simplicity', 'cel', 'stone', 'engineering', 'ren', 'Psych', '~/', 'subs', 'embar', 'ith', 'numero', 'osed', 'Dup', 'fam', 'gex', 'dimin', 'fundamental', 'zos', 'Harrison', 'hina', 'ledge', 'Middle', 'ів', 'Uri', 'hur', 'pu', 'SL', 'Einz', 'ren', 'hydro', 'х', 'gift', 'кли', 'Preis', 'Standard', 'schemes', 'iv']\n",
      "in Layer8 , sorted_indices_dimension7896:  ['кови', 'Barcel', 'mathchar', 'makeText', 'Хронологија', 'ство', 'istiques', 'iből', 'édé', '%%%%', 'piel', 'ege', 'wohl', 'aben', 'ROP', 'łoż', 'Victor', 'ispecies', 'yen', 'örd', 'ѫ', 'asso', 'ょ', 'mouth', 'ield', 'olt', 'ationen', 'кипеди', 'ién', 'dbc', 'пет', 'issement', 'kotlin', 'Ḩ', 'Tun', '̯', 'Ung', 'idth', 'orten', '{%', 'utos', '�', '良', 'nico', 'ettings', 'Bug', 'пара', 'homonymes', 'れ', 'punkt', 'Tony', 'Begriffsklär', '⊕', 'xaml', 'izione', 'infty', 'Buc', '️', '˚', 'asser', 'Audiodateien', 'wiki', 'Wis', 'ὰ', 'ку', 'urname', 'ensoort', 'grad', 'roph', 'premiers', 'Sito', 'ués', 'Grad', 'istiche', 'multicol', 'reten', 'mysq', 'archar', 'Википедии', '件', 'militar', 'estaven', '‒', 'zewnętrzne', 'równ', 'igkeiten', 'perl', 'cdn', 'ѐ', 'cn', 'Bapt', 'dział', 'ץ', 'kund', 'ielt', 'wald', 'onnen', 'atti', 'ermeister', 'LENGTH', 'liches', 'webpack', 'consultato', 'icole', 'zien', 'SERT', 'ány', 'Unidos', 'ɫ', 'Wo', 'ály', 'jest', 'mouth', 'ту', 'pian', 'anos', 'ุ', '符', 'ächst', 'Gy', 'Einzelnach', 'Guerre', 'wik', 'iencia', 'Commons', 'kommen', 'ionen', 'oru', 'Jahren', 'Wies', 'Sdk', 'rijk', 'Us', 'vat', 'ĝ', 'deport', 'ägt', 'istique', '葉', 'clojure', 'педи', 'Terminal', 'heb', 'bug', 'gestellt', '崎', 'ampio', 'isé', 'prec', '*{', 'ണ', 'stvo', 'Grad', 'ө', 'visibility', 'step', 'topic', 'вания', 'ToList', 'geo', 'ej', 'deploy', 'CG', 'archivi', 'Щ', 'php', '@@', 'ismiss', 'difference', 'ʎ', 'VALUE', 'yaume', 'debug', 'спе', 'gow', 'atos', 'hardware', 'sott', 'gende', 'jes', 'ู', 'INCT', 'отде', 'stwo', '<%', 'kow', 'ność', \"'):\", 'worth', 'premi', 'facil', 'specie', 'силання', 'altung', 'bibli', 'Mario', 'dé', 'rero', 'Gemeinsame', 'geführt']\n",
      "Key: model.layers.9.mlp.down_proj.weight\n",
      "in Layer9 , sorted_indices_dimension10852:  ['partiellement', '典', 'Jahrh', 'antal', 'Ź', 'CLARE', 'agna', 'bernate', 'Gal', 'gh', '{-', 'Bath', 'rror', 'bat', 'Glo', 'DOCTYPE', '塔', 'фев', 'orgen', '########', 'Zone', 'тал', 'emer', 'omm', 'тара', 'bat', 'erade', 'gouvern', 'publicada', 'kbd', 'клад', 'Zent', 'ỹ', 'emberg', 'Pia', 'сту', 'ActivityThread', 'Overflow', 'ral', 'landet', 'Fal', 'onderwerp', 'gal', 'iesen', 'statunit', 'lave', 'Sul', 'komm', 'isol', 'Ґ', 'Sto', '先', 'раб', 'ölker', 'gal', 'Dal', 'ън', 'ugust', 'undo', 'states', 'ńcz', '�', 'ält', 'пар', 'footer', 'iros', 'princi', 'pin', 'werb', 'Single', 'ERR', 'zone', 'externos', 'Stefan', 'Zone', 'zas', 'љу', 'antics', 'autory', 'apa', 'Brainz', 'Pour', '*)', 'wont', 'suivante', 'abord', 'ص', '<s>', 'ikan', 'mér', 'aute', 'beskre', 'erschien', 'emann', 'тер', 'preventDefault', '상', 'ин', 'Lap', 'вана', 'лез', 'vere', 'ン', 'zyż', 'Coun', 'pin', 'ź', 'eeuw', 'öst', 'Hist', 'wechsel', 'ena', 'untime', 'Fiche', 'otto', 'Dict', 'RelativeLayout', 'Nom', 'fal', 'zd', 'exports', 'zone', 'ze', 'fficient', 'lapse', 'soort', 'ween', 'refresh', 'ulp', 'zon', 'overflow', 'fav', 'FB', 'hab', 'Roger', 'imper', 'reactjs', 'Unterscheidung', 'Fuß', 'anh', 'рів', 'ekonom', '[^', 'stackoverflow', 'stringify', 'ingly', 'favour', 'cler', 'LCCN', ':\\u2009', 'footer', 'ített', 'ôt', 'сто', 'invalid', 'eno', 'wrapper', 'dal', 'ancora', 'нем', 'desar', 'ajn', 'bath', 'champ', 'Oriental', 'рь', 'banks', 'opere', 'ök', 'zer', 'tér', 'Tal', 'FALSE', 'ardo', 'çaise', 'konn', 'coun', 'erta', 'plate', 'ormal', 'zal', 'Gegen', 'пла', 'ße', 'Picker', '̥', 'DB', 'ố', 'arga', 'raum', 'ñas', 'slave', 'Mouse', 'szerint', 'vois', 'wik', 'opposite', 'rowser', '越', 'akte']\n",
      "in Layer9 , sorted_indices_dimension4613:  ['osh', 'Options', 'ellan', 'zar', 'Bar', 'bar', 'hrte', 'fixes', 'Fel', 'ued', 'improv', 'epen', 'TAC', 'ockey', 'zung', 'living', 'repair', 'ano', 'ώ', 'ต', 'ště', 'catal', 'rocks', 'Ros', 'cape', 'options', 'core', 'Pok', '育', 'ąż', 'races', 'meno', 'tracks', 'fix', 'outside', 'annel', 'scar', 'fell', 'ista', 'XVII', 'śc', 'azar', 'WS', 'Living', 'options', 'gior', 'fixing', 'Jos', 'Options', 'access', 'Barbara', 'Barb', 'pac', '太', 'annotation', 'kmal', 'auer', 'рей', 'iada', 'ws', 'Bar', 'ал', 'fixed', 'Sh', 'ктиче', 'analog', '编', 'лении', '\\u200a', 'itive', 'meisterschaft', 'schw', 'ctr', 'sharp', 'gabe', 'bow', 'cil', 'lop', 'onn', 'Cla', 'Cin', 'UI', 'üt', 'fixed', 'pok', 'wal', 'ienie', 'chod', 'Kultur', 'Navigation', 'forces', '編', 'eper', 'ights', 'iftung', 'jud', 'важа', 'decimal', 'Hockey', 'anonymous', 'core', 'bars', 'CP', 'Bij', 'eredet', 'Anne', 'xp', 'inton', 'дра', 'Gü', 'Fix', 'Rosen', 'ixa', 'comment', 'ço', 'Forces', 'Cos', 'orio', 'Cat', 'кре', 'kup', 'pun', 'cod', 'Archive', '้', 'cret', 'access', 'ège', 'Days', 'von', 'repres', '%,', 'cosm', 'Dit', 'REE', 'CRE', 'scar', 'reshold', 'anon', 'bazie', 'ühr', 'ao', 'Przyp', 'floor', 'Mau', 'ution', 'sert', 'üsseld', 'subfigure', 'Core', 'Wayne', 'van', 'Rails', 'merce', 'ign', 'bara', 'Moh', 'umen', 'Cache', 'externs', 'estaven', 'Append', 'rewrite', 'adel', 'Rights', 'Occ', 'Kos', 'REST', 'playing', 'Ana', 'Mass', 'анта', 'ystem', 'Pla', '사', 'Margaret', 'blocks', 'дів', 'orer', 'weights', 'istema', 'nę', 'Forest', '�', 'Archives', 'рі', 'presso', 'ht', 'open', 'long', 'arante', 'omet', 'xis', 'diretto', 'ohen', 'onom', '-+', 'fix', 'anni', 'markt']\n",
      "in Layer9 , sorted_indices_dimension7301:  ['вме', 'Desp', 'ARNING', '里', 'ival', 'nehmen', 'Century', 'Ć', 'advise', 'alive', 'nim', 'improv', 'desp', 'avoided', 'DP', 'imenti', 'alis', 'ɲ', 'Mouse', 'folk', 'wiki', 'Pascal', 'archivi', 'canvas', 'кло', 'totalité', 'ouvelles', 'ั', 'Вер', 'homonymes', 'forward', 'ivi', 'Aus', 'detected', 'nem', 'Rena', 'seguito', 'externos', 'wik', 'docs', 'Hij', 'sensitive', 'scribe', 'ivel', 'nim', 'plots', 'modific', 'festival', 'ване', 'Festival', '代', 'agn', 'alle', '机', 'ivot', 'proyect', 'fica', 'ieri', 'восто', 'ذ', 'зо', 'кто', 'чан', 'FILE', 'externas', 'Њ', 'ím', 'advis', 'fit', 'чко', '合', 'akh', 'mod', 'dod', 'instead', 'immagini', 'zych', 'mol', 'iele', 'Hat', 'Box', '̍', 'frag', 'aller', 'ered', 'incoming', 'tak', 'dorf', 'Ritter', '変', 'ways', 'profile', 'FILE', 'marry', 'ワ', 'ctor', 'ʊ', 'redirects', 'gestion', 'dat', 'actor', 'cluster', 'soap', 'arning', 'lande', 'fol', 'vić', 'enem', 'дії', 'zach', 'leid', 'пр', '�', 'maxim', 'disease', 'À', 'avoid', 'Constra', 'cancer', 'box', '✔', 'cito', 'bef', 'cop', 'arn', 'erer', 'Stu', 'зай', 'Django', 'detection', 'Originals', 'raz', 'sla', 'RIPT', '대', 'esség', 'cow', 'ivo', 'opp', 'центра', 'ö', 'pian', 'stolet', 'iframe', 'ixa', 'astern', 'Références', 'Mach', 'Ol', '어', 'essen', 'onderwerp', 'Gegen', 'census', '击', 'gre', '木', 'pivot', 'Framework', 'あ', 'iframe', 'conjunto', 'ivil', 'лові', 'ahu', '式', 'sick', 'sele', 'rä', 'Fl', 'EventListener', 'clean', 'lookup', 'дере', 'ción', 'び', 'oct', 'iv', '郎', 'uby', 'ichtung', 'anie', 'Hed', 'Projects', 'oso', 'хозяй', \"='\", 'ienst', 'gele', 'Mitt', 'cki', 'né', 'bow', 'alement', 'rx', 'SELECT', 'Portail', 'Suisse', 'elegant', 'actor']\n",
      "in Layer9 , sorted_indices_dimension7661:  ['Gest', 'Void', 'cht', 'Wikip', 'unas', 'null', 'adm', 'Års', 'Einsatz', 'мен', 'œuv', 'inner', 'Chine', 'oku', 'initialized', 'grid', 'kmal', 'altern', 'icina', 'grid', 'Inner', 'Campe', 'native', 'mo', 'zie', 'Generic', 'alternative', 'Warning', 'rab', 'prez', 'null', 'Stre', 'Према', 'nah', 'chten', 'CTYPE', 'раб', 'ϵ', 'kor', 'tort', 'ęp', 'Review', 'quelle', 'warning', 'nico', 'Buen', 'проф', 'Camera', 'ampf', 'Native', 'mathchar', 'unos', 'elen', 'MC', 'chor', 'usto', 'Kennedy', 'Einz', 'accompl', 'Unidos', 'den', 'esta', 'heb', 'TD', 'Sad', 'oll', 'cal', 'xp', 'native', '__(', '⁻', 'idd', 'iformes', 'ellan', 'DATE', 'lemagne', 'erw', 'DIR', 'pract', 'una', 'Campbell', 'einges', 'Token', 'hum', 'Ster', 'solem', 'ysz', 'fol', 'admit', 'hum', 'City', 'enes', 'hall', 'piel', 'Opera', 'og', 'elin', 'ister', '希', 'Ď', 'Germ', 'ög', 'rog', 'zung', 'пере', 'alem', 'ung', 'suggestion', '----+', 'ɯ', 'alternatives', 'uje', 'sympathy', 'Rad', 'ennen', '效', 'fe', 'mine', '⊆', 'itud', 'Bab', 'city', 'gest', 'Control', 'akov', 'Salv', '$(\\\\', 'DM', 'нут', 'Trib', 'Cam', 'men', 'Fame', 'iglia', 'amen', 'bonus', 'Inner', 'mine', 'prob', 'Kore', 'Bere', ')^', 'Gest', 'inner', 'Grad', 'ณ', 'Cés', 'kwiet', 'akespe', 'latex', 'bold', 'ych', '上', 'Sym', 'genomsnitt', 'singleton', 'ุ', 'illon', 'iah', 'boldmath', 'ieu', 'Lane', 'лок', '今', 'met', 'Alo', 'Camera', 'лог', 'tab', 'expectation', '関', '=\"\"', 'virt', 'altern', 'Tot', 'ね', 'kunft', 'accompan', '店', 'dz', 'accomp', 'ѐ', 'мах', 'ufen', 'ßer', 'alternate', 'async', 'skim', 'да', 'odi', '史', 'SI', 'Single', 'Ferd', 'tac', 'лей', 'proc', 'SError', 'Scala', '色']\n",
      "in Layer9 , sorted_indices_dimension8175:  ['eft', 'vid', 'ipage', 'combin', 'endorf', 'Cés', '𝓝', 'ikor', 'jon', 'forall', 'sono', 'Ḩ', 'rare', 'subfigure', 'ange', 'Voci', 'Oficina', 'abase', 'cji', 'Mock', 'olia', 'ething', 'információ', 'mock', 'Primary', 'nię', 'nitt', 'гар', 'Primary', 'rag', '=\"@+', '员', 'erei', 'avia', 'ande', 'solute', 'caus', '素', 'änd', 'rikt', 'Compiler', 'osób', 'rinn', 'données', 'Paz', 'argv', 'Pattern', 'chmark', 'load', 'mock', 'azzo', 'oires', 'aru', 'supre', 'ña', 'mund', 'ungen', 'бі', 'trat', 'ġ', 'сто', 'PRIMARY', 'Found', 'yter', '়', 'Pérez', 'chts', 'вос', 'printStackTrace', '万', 'ʐ', 'iler', 'ège', 'gresql', 'cen', 'archivi', '技', 'THEN', 'jub', 'wojew', 'cio', '용', 'fé', 'Х', 'äd', 'ollary', 'ispecies', 'documentclass', 'ulté', 'Pow', 'сподар', 'AtIndex', 'hagen', 'wen', 'рован', 'Zie', 'aal', 'ณ', 'rack', 'вич', 'önig', 'információk', 'ază', 'ц', 'сту', 'embargo', '视', 'gravity', 'andis', 'retto', 'ViewController', 'Japon', 'zeug', 'ês', 'lesia', 'CollectionView', 'ocker', 'Ő', 'bezeichneter', 'па', 'riere', 'ído', 'markup', 'Esta', 'iała', 'rus', 'Volk', 'emu', 'sugg', 'depos', 'Lav', 'transfer', 'WORD', 'ej', 'oit', 'deg', 'intellij', 'Einzelnach', 'FLA', 'чения', 'Si', 'jav', 'heav', 'üs', 'dic', 'quipe', 'mary', 'lès', 'Diam', 'chten', 'bucket', 'sert', 'ható', 'ᵉ', '/~', 'сто', 'Doug', 'incor', '>\"', 'vid', 'istrzost', 'cker', 'diag', 'нат', 'advoc', 'primary', 'Nazionale', 'surrender', 'ocket', 'ock', 'pu', 'vent', 'Validation', 'чер', 'зер', 'dag', 'INCT', 'mur', 'inton', '장', 'lasse', 'ega', 'ças', 'minor', 'оло', 'Grab', 'oven', 'Universität', 'Logger', 'ilon', 'ֶ', 'hely', 'epo', 'hou', 'ovo', 'Quart', 'łów', 'ListView', 'consultato', 'Pacific']\n",
      "in Layer9 , sorted_indices_dimension1939:  ['Jew', 'blind', 'LED', 'ote', 'operator', 'uta', 'arm', '藏', 'te', 'sch', 'dur', 'Liberal', 'fort', 'est', 'abi', 'fug', 'operators', 'agn', 'Arm', 'depend', 'ụ', '衛', 'Arm', 'orb', 'ffe', 'Jones', 'Sug', 'stab', 'Fland', 'kar', 'key', 'piano', 'ter', 'upt', 'obs', 'рем', 'ä', 'pers', '++', 'otta', 'hy', 'Key', 'surv', 'iva', 'yna', 'ioni', 'geom', 'ù', 'Pres', 'Te', 'pend', 'Gest', 'brit', 'lieder', 'kap', 'vex', 'шо', 'neu', 'defense', 'Leopold', 'Begriffe', 'pian', 'aps', 'ffic', 'lib', 'Glas', 'vers', 'Stream', 'virtual', 'Shakespe', 'ta', 'hard', 'aja', 'est', 'Sen', 'sen', 'AF', 'док', 'nature', 'basic', 'handlers', 'Gent', 'pres', 'refer', 'Ос', 'luck', 'quot', 'wind', 'pres', 'ensch', 'p', 'iw', 'noise', 'Berliner', 'stream', 'eny', 'af', 'べ', 'Grey', 'chap', 'JAX', 'beat', 'Mitg', 'Joh', 'current', 'mee', 'jam', 'lement', 'andas', 'hoff', 'GL', 'Executor', 'Beat', 'susp', 'ons', '気', 'IAB', 'Резу', 'க', 'supp', 'setopt', 'bearing', 'Grande', '요', 'packages', 'exist', 'ro', 'Gli', 'timing', 'cos', 'calculus', 'bru', 'ấ', 'leid', 'resp', 'atmos', 'convention', 'Lewis', 'ico', 'ighed', 'Conse', 'caps', 'tom', 'Williams', 'bear', 'Ont', 'icamente', 'amet', 'Glasgow', 'fit', 'doctor', 'nect', 'MS', 'salv', 'quantum', 'not', 'dep', '�', 'nerv', 'ply', 'QL', 'lt', 'den', 'not', 'az', 'odge', 'Harr', '了', 'Reserve', 'zones', 'traffic', 'amb', 'ijn', 'lit', 'Java', 'apr', 'ag', 'Chor', 'ot', 'aby', 'Virtual', 'uario', 'ührt', 'hidden', 'y', 'Ingl', 'Basic', 'node', 'icity', '風', 'Krist', 'lies', '⊙', 'Word', 'dep', 'AF', 'igi', 'eter', 'ots', 'chos']\n",
      "in Layer9 , sorted_indices_dimension4248:  ['committed', 'atum', 'duty', 'wor', '~[', 'orum', 'sein', 'тре', 'bay', '¶', 'orn', 'ski', '********', 'achment', 'ienie', 'geber', 'PD', 'Dun', 'URE', 'Nick', 'ди', 'дей', 'ferro', 'illet', 'odon', 'cile', 'ій', 'tart', 'snow', 'bound', 'art', 'показа', 'uth', 'ivi', 'agg', 'Wor', 'Mé', 'uset', '�', 'бург', 'ptop', 'Rails', 'tar', 'Nur', 'achim', 'looping', 'дор', 'Uri', '♦', '�', 'cluster', '溪', 'tele', 'worse', 'Napole', 'cki', 'ь', 'према', 'ilen', 'haus', 'ос', 'rav', 'Barcel', 'isse', 'ivel', 'ński', 'ingår', 'idel', 'ksam', 'bus', 'спо', 'тор', 'zn', 'Ball', 'boundary', 'commit', 'cus', 'dale', 'Hud', 'del', 'Dienst', '`--', 'WOR', 'auf', '`&', 'slant', 'Uk', 'iones', 'изда', 'guess', 'orno', 'transformations', '意', 'keit', 'Snow', 'Kaiser', '多', 'canton', 'му', 'ök', 'Dor', 'mud', 'Rena', 'orders', 'Creek', 'ordered', 'ḫ', 'aser', 'Coll', 'ám', 'acc', 'bank', '命', 'ith', 'affection', 'untime', 'urable', 'ded', 'iter', 'external', 'passe', 'Gh', 'iai', 'ectors', 'fixed', '↔', 'tax', '码', 'BR', '�', 'сов', 'Inform', 'stuck', '清', 'дин', 'Nad', 'iella', 'oren', 'ор', 'Wikip', 'exempl', 'cir', 'urger', 'boy', 'őd', 'Cape', 'та', 'oblig', 'Alc', 'utors', '**', 'spare', 'phas', 'Paris', 'successor', 'Felix', 'ceptor', 'ük', 'bara', 'Dur', 'oy', 'сон', 'Autres', 'stract', 'Refresh', 'commit', 'Show', 'ată', 'merk', 'avant', '梅', 'orld', 'Cant', 'oł', 'inos', 'CS', 'adv', 'лося', '章', 'evident', 'setopt', 'mean', 'ый', 'Fetch', 'letter', 'Sou', 'Corn', 'wur', 'zig', 'fine', 'Miss', 'ват', 'registr', 'cycle', 'ње', 'partitions', 'ług', 'boundaries', 'showed', 'zen']\n",
      "in Layer9 , sorted_indices_dimension1981:  ['Mine', 'Call', 'synd', 'iale', 'gan', 'libraries', 'rap', 'duplicates', 'waste', 'bis', 'andas', 'sv', 'erd', 'blank', 'wind', 'og', 'Finn', 'wind', 'etro', 'andal', 'GE', 'duplicate', 'pdf', 'oty', 'Sym', 'Call', 'pdf', 'itas', 'Weit', 'age', 'sw', 'cej', '路', 'KE', 'ھ', 'lua', 'ius', 'Stad', 'Wind', 'jes', 'min', '�', 'ív', 'syn', 'ogn', '近', 'leg', '目', 'son', 'jen', 'phases', '山', 'like', 'GP', 'adal', 'supp', 'lam', 'appar', 'hen', 've', 'camp', 'amin', 'Hall', 'certain', 'ray', 'тек', 'mitt', 'пов', 'Fine', 'cord', 'GER', 'paper', 'iety', 'sacr', 'MC', 'lug', '6', 'образ', 'ร', 'Unis', 'ger', 'Pool', 'WP', 'avano', 'vain', 'yk', 'प', 'sight', 'Cord', 'sym', 'Tamb', '∞', 'termin', 'RIPT', '{#', 'Syn', 'fik', 'AI', 'pm', 'mine', 'bean', 'orial', '橋', 'adin', 'сі', 'Match', 'delegate', 'сви', 'Sax', 'mines', 'ew', 'kn', 'iver', 'token', 'tó', 'êm', 'Sank', 'termin', 'tennis', 'sister', 'iano', 'swing', 'pressure', 'deprec', 'Jacob', 'Begriffsklär', 'loss', 'Bull', 'Poly', 'battery', 'protest', 'esta', 'ben', 'Bridge', 'polygon', 'rest', '�', 'han', 'card', 'wrap', 'anto', 'uwe', 'arf', 'Syn', 'legend', 'Image', 'phase', 'ρ', 'Sym', 'assured', 'propag', 'baum', 'wand', 'deploy', 'ella', 'ke', 'Sint', 'branches', 'WR', 'tri', 'hon', 'yw', 'tamb', 'ď', 'sake', 'redundant', 'android', 'Ke', 'supp', 'Android', 'grad', 'lu', 'negative', 'GP', 'Camb', 'Beach', 'oko', 'Ern', 'staff', 'opera', 'éri', 'Gam', 'SBN', 'Cop', 'uniform', 'Bean', 'sacrific', 'Reyn', 'Met', 'min', 'campaign', 'Slo', 'IMAGE', 'provision', 'E', 'ull', 'worker', 'чик', '5', 'Dres']\n",
      "Key: model.layers.10.mlp.down_proj.weight\n",
      "in Layer10 , sorted_indices_dimension3042:  ['uropa', 'Ξ', 'coal', 'erme', 'äl', 'bose', 'ّ', '津', 'reten', 'agnost', 'ersch', 'erst', '象', 'ANGE', 'embre', 'emb', 'ὀ', 'jsf', 'automat', 'bolds', 'presiden', 'NU', 'detect', 'MyClass', 'ící', 'Din', 'bol', 'ALSE', 'bos', 'ἔ', 'cri', 'тельство', 'ус', 'chter', 'earance', 'ällor', 'бю', 'kis', 'andenburg', 'izen', 'Einzeln', '消', 'invert', 'rikt', 'Hart', 'delegate', '̣', 'vare', '♣', 'are', 'iden', 'рина', '@\",', 'Thom', 'istrzost', 'ribución', '銀', 'cza', 'estre', 'Airlines', 'Adams', 'silver', 'satellite', '@\"', '雲', 'kov', 'cribe', 'ests', 'wor', 'Eisen', 'atomic', 'zor', 'gable', '寺', 'compens', 'pian', 'saf', 'cons', 'threads', 'chain', 'anter', 'Chap', 'enfor', 'Georges', 'rend', '雪', 'краї', 'trace', 'outer', '≃', 'Trace', 'ynomial', 'ichten', 'eltemperaturen', 'gran', 'prü', 'Ṭ', 'schw', 'sil', '客', 'ус', 'jan', 'Dol', 'Zob', 'LayoutInflater', 'rome', 'atu', 'bal', 'Bos', 'opp', 'psum', 'bir', '씨', 'Mih', 'istiche', 'wach', 'äter', 'EAR', 'хар', '보', 'har', 'Gran', 'ſ', 'employ', 'divid', 'jší', 'Wor', 'ὲ', 'enst', 'ested', 'verk', '态', 'Television', 'заво', 'chin', 'superior', 'maste', 'estab', 'Ζ', 'imientos', 'dann', 'unos', 'icky', 'Employee', 'Mort', 'zerw', 'xcode', '្', 'Thompson', 'cod', 'seh', 'ActivityThread', 'mpeg', 'bir', '体', 'фі', 'Delegate', 'establishment', 'AtIndex', 'ikt', 'lesia', 'uby', 'ód', 'rollo', 'ץ', 'яз', 'nel', 'dbo', 'coded', 'stre', 'europ', 'ниче', 'garant', 'Ī', 'fir', 'Silver', 'ritt', 'ческих', 'icode', 'pie', '🌍', 'Kos', 'Theatre', 'atro', '形', 'automatisch', 'arlo', 'ups', 'extern', 'зня', 'цер', 'Lady', '♀', 'себя', 'mist', 'ho', 'Boh', 'вати', 'Deutschland', 'SError']\n",
      "in Layer10 , sorted_indices_dimension2498:  ['Kloster', 'daugh', 'xa', 'ultur', 'uma', 'ras', 'una', 'ek', 'autorité', 'frak', 'athol', 'taire', 'рус', 'jure', 'icale', 'urm', 'ulp', 'ardin', 'ῦ', 'рё', 'catal', 'chart', 'contra', 'obj', 'Object', 'kaf', 'вар', 'colo', 'SEE', 'zos', '♂', 'dzie', '�', 'Bou', 'gior', '̌', 'wor', 'object', 'jna', '----', 'etta', 'VIAF', 'rita', 'Zar', 'Хронологија', '塔', 'anyway', 'ー', 'Ú', 'Object', 'ect', 'itare', 'Down', 'agnost', 'vek', 'Neu', 'fel', 'bibli', 'tta', '�', 'textt', 'delay', 'äft', 'Bibliothèque', 'arto', 'facts', 'Boh', 'ук', 'Musée', 'recensement', 'Plugin', 'puis', 'Teatro', 'раль', '↓', 'ycz', 'kot', 'intrag', 'Filip', 'віці', 'Down', '丸', 'ў', 'quer', 'erta', 'iesz', 'ulpt', 'сей', 'prez', 'ornal', '取', '⠀', 'ają', '堂', 'jed', 'pol', 'gg', 'mos', 'repeat', 'URN', 'wart', 'cause', 'altra', 'Pologne', 'лий', 'Петер', 'Ė', 'bron', 'cedes', 'organ', 'ців', 'pret', 'icano', 'VICE', 'riel', '߬', 'ът', 'ied', '\\u2002', '¤', '周', 'cop', 'reserved', 'anas', 'WE', 'bomb', 'ད', 'дей', '川', 'spec', 'igneur', 'dou', 'aal', 'raz', '令', 'ста', 'ím', 'yt', 'rę', 'zdob', 'chart', 'Scottish', 'Site', 'veg', 'Pool', 'perl', 'inaire', 'factor', '默', 'Austral', 'una', 'Қ', 'bject', 'Cop', 'rière', 'polic', 'Pi', 'Pierre', 'Kirch', 'cem', 'ти', 'iot', 'zeich', 'թ', '♠', 'devil', 'Irish', '},', 'úl', 'Californ', 'ém', '库', 'zak', 'Luft', 'siehe', 'marker', '개', 'download', 'réal', 'acz', 'boot', '创', 'alt', 'ainer', 'Sm', 'Workbook', 'Meister', 'Entity', 'alus', 'себя', 'oder', 'bou', '码', 'dostęp', 'icana', 'gg', 'erca', 'einmal', 'contre', 'agr']\n",
      "in Layer10 , sorted_indices_dimension8299:  ['ested', 'pity', 'rop', 'plot', 'pobla', 'prise', 'past', 'pgf', 'fare', 'ping', 'spring', 'companion', 'ney', 'plots', 'ogy', 'wol', 'Preis', 'shire', 'icane', 'ippi', 'ami', 'pring', 'Processor', 'compan', 'pri', 'プ', 'Notre', 'stdio', 'preg', 'uben', 'possibilities', 'proper', 'frequ', 'ías', 'Peter', 'possib', 'perturb', 'precip', '程', 'profile', 'PH', 'ể', 'stan', 'Peters', 'Cab', 'protein', 'Ph', 'propos', 'zar', 'prem', 'probable', 'PD', 'iste', 'program', 'process', ';</', 'COM', 'patterns', 'Pap', 'sets', 'ph', 'Provider', 'Praha', 'пута', 'ub', 'princes', 'perm', 'dimen', 'pattern', 'ardi', 'progress', 'ble', 'prost', 'spring', 'probability', 'ria', 'rea', 'pro', 'proven', 'pray', 'paste', 'improv', 'profiles', 'possibility', 'punkt', 'processor', 'pat', 'proposal', 'ican', 'PC', 'daten', 'potential', 'reme', 'lein', 'iku', 'esome', 'parl', 'ias', 'WM', 'iri', 'igent', 'par', 'pass', 'CLA', 'progress', 'nehm', 'приз', 'Para', 'ropy', 'stand', 'пове', 'by', 'aper', 'enum', 'processing', 'pmatrix', 'ZE', 'Gal', 'pp', 'prototype', 'fred', 'proc', 'ishi', 'pre', 'ider', 'multiply', 'CV', 'pres', 'priest', 'Tier', 'pressing', 'processor', 'beauty', '≡', 'Plot', 'p', 'proces', 'pred', 'pol', 'currently', 'publi', 'ory', 'prime', 'rance', 'CL', 'prop', 'scop', '်', 'Past', 'profile', 'othy', 'Cop', '◦', 'proved', 'ahl', 'paste', 'Pacific', 'programa', 'пас', 'Mount', 'Ban', 'Bot', 'att', 'cop', 'Austral', 'პ', '品', 'proceed', 'Meister', 'pron', 'plane', 'inder', 'ответ', 'proxy', 'ord', 'set', 'kwiet', 'ář', 'programma', 'Prix', 'fel', 'ats', 'as', 'pap', 'publique', 'ership', 'à', 'pattern', 'ORY', 'pent', 'ouble', 'Ph', 'Process', 'ennes', 'Coast', 'COMP', 'drawable', 'pain', 'pressure', 'predicted']\n",
      "in Layer10 , sorted_indices_dimension3251:  ['Fichier', 'aged', '介', '�', 'ogram', 'susp', 'lat', '院', 'Gemeinsame', 'ular', 'vid', 'cile', 'nom', 'oem', 'baar', 'iemann', 'ella', 'orb', '➖', 'elles', 'ἱ', 'strij', '�', 'onc', 'tml', 'ked', 'ann', 'führt', 'rias', 'kh', 'beeld', 'ksam', 'Sever', 'yml', 'egen', 'bert', 'unicí', 'parish', 'itar', '操', 'led', 'ब', 'ат', 'Sus', 'fluss', 'kret', 'esta', 'живело', 'agt', 'aging', 'dal', 'лю', 'tion', 'oemd', 'guez', 'indre', 'bibli', 'nitt', 'ków', 'Holz', 'ôme', 'ipsum', 'ząd', 'ugg', 'geon', 'сто', 'alias', 'ély', 'Driver', 'ève', 'stru', 'tér', 'lag', 'Lexikon', 'emann', 'ِ', '서', 'buch', 'issen', 'Denkmal', 'Ald', 'dém', 'texte', 'neh', 'ategor', '�', 'aplic', 'beskrevs', 'eree', 'ELD', 'thes', 'pag', 'maste', 'rib', 'Lat', 'chrom', 'mock', 'тех', 'wal', 'othy', 'anel', 'ď', '默', 'snap', 'ske', 'tend', 'veg', 'Player', 'ágina', 'ḳ', 'Españ', 'lu', 'heten', 'arith', 'emit', 'kap', 'YS', '处', 'reen', 'Britann', 'update', 'Fou', '弘', 'PA', 'ел', 'ometry', 'HC', 'oltre', 'recover', 'irl', 'ucker', 'notin', 'scriptstyle', 'ako', 'ulos', 'mart', 'amm', 'för', 'lee', '�', 'ugel', 'pret', 'reader', 'ńska', 'sigu', 'ethe', 'HO', 'ama', 'Berl', 'nom', 'circular', 'edes', 'pic', 'acs', 'álva', 'него', 'Einwohner', 'нологи', 'osed', 'zyma', 'scheidung', 'likely', 'raw', 'rowser', '丁', 'imon', 'poor', 'uen', 'Ă', 'nombre', 'ulo', 'ąc', 'itud', 'Parlament', 'ǎ', 'łą', 'ieu', 'erg', 'para', 'ometric', 'ided', 'hal', 'este', 'oph', '명', 'keiten', ':\\u2009', 'ks', 'Nom', 'ễ', 'deutsch', 'ḥ', 'Glo', 'ooth', 'schließend', 'ke', 'Driver', 'uve', 'lat', 'flat']\n",
      "in Layer10 , sorted_indices_dimension2490:  ['ixed', 'ops', 'seau', 'Kirk', 'opera', '�', 'oup', 'dorf', 'ęd', 'fp', 'abase', 'FP', 'noc', 'lak', 'arms', 'каче', 'Host', 'iego', 'ént', 'Types', 'odon', 'limit', 'uur', 'chus', 'indent', 'Studio', 'ɵ', 'compr', 'Gam', 'cio', 'onc', 'bat', 'utf', ':#', 'Weiter', 'emi', 'fox', 'Drive', 'alle', 'ivamente', 'servlet', 'kem', 'ipage', 'CES', 'override', 'arbe', 'Hit', 'iety', 'duino', 'ombres', 'Ignore', 'Studio', 'lej', 'ientí', 'ligne', 'чо', 'reshold', '�', 'aturen', 'edo', 'outline', 'ulen', 'dort', 'tuple', 'keit', 'acle', 'Bonn', 'ClassName', 'filter', 'categor', 'CAA', 'му', 'міні', 'ích', 'Ò', 'ме', 'Gran', 'bundle', 'зи', 'acia', 'intu', 'Ē', 'ox', 'bat', 'äm', 'cock', 'entitled', 'ident', 'filter', 'cció', 'Ва', 'ige', '料', 'kee', 'ху', 'rive', 'alle', 'arth', 'aqu', '于', 'penas', 'Heidel', 'TeX', 'ită', 'htt', 'èt', 'rees', 'oport', 'tv', 'pent', 'Widget', '�', 'acu', 'aku', 'Email', 'ө', 'IR', 'slice', 'стов', 'Архи', 'ར', 'inheritance', 'arriv', '�', 'arrival', 'Stream', 'quet', 'зі', 'еру', 'backend', 'rite', 'ej', 'kele', '@{', 'insert', 'ître', 'cier', 'carte', 'oster', 'irks', 'зидент', 'Class', 'ega', 'rx', 'рез', 'alement', 'etes', 'achen', '🌍', 'emas', 'berg', 'ків', 'buch', 'schutz', 'Republik', 'CS', 'opro', 'android', 'ppers', 'arrest', 'Classification', 'дий', 'fab', 'FO', 'awt', 'VF', 'Henri', 'kord', 'Archive', '列', 'Classes', 'arrive', 'кур', 'nake', 'ăt', 'ях', 'sop', 'ḍ', 'eared', 'xyz', 'ptic', 'pent', 'tuple', 'включа', '收', 'edu', 'fix', 'werke', 'Bé', 'Springer', 'optera', 'eta', 'ayer', 'aggreg', 'ʌ', 'inth', 'Hä', 'Staaten', 'Це', 'FO']\n",
      "Key: model.layers.11.mlp.down_proj.weight\n",
      "in Layer11 , sorted_indices_dimension2635:  ['background', 'Dur', 'iero', 'ċ', 'мати', 'ske', '密', 'iclopedia', 'impl', 'dur', 'sols', '意', 'cych', 'buff', 'mc', 'tabs', 'familiar', '✿', 'Background', 'Durant', 'orig', 'atti', '界', 'Sic', 'sus', 'resse', 'itu', 'urst', 'roots', 'Californ', 'ava', 'Beg', 'native', 'zo', 'beg', 'tabs', 'background', 'orm', 'Ġ', 'AVA', 'utt', 'loops', 'resp', 'icher', 'cko', 'LC', 'beg', 'horn', 'bomb', 'Eng', 'absor', 'Shah', 'uman', 'cycl', 'scri', 'layout', 'inser', 'lide', 'um', 'uet', 'atch', 'hab', 'Corn', 'extract', 'amateur', 'Bek', 'ich', 'amazon', 'feas', 'ender', 'Dat', 'atform', 'abs', '本', 'acje', 'imos', 'pec', '---------+', 'Punk', 'pc', 'Ped', 'logic', 'kommen', 'Statist', 'runner', 'unwrap', 'FE', 'User', 'beh', 'ACT', 'unn', 'usto', 'mit', 'else', 'Mes', 'aper', 'äch', 'CE', 'urrent', 'onne', 'LENG', 'Eng', 'żyn', 'punk', 'Sü', 'ASC', 'тек', '++)', 'ément', 'Vil', 'ĉ', 'xt', 'нут', 'inks', 'reform', 'чер', 'Ung', 'ung', 'tober', 'RL', 'corners', 'datab', 'eso', 'қ', 'ALSE', 'Ang', 'origin', '̶', 'WP', 'Naz', 'viss', 'Um', 'user', 'User', 'keit', 'McG', 'hin', 'old', 'hal', 'ун', 'opera', '̀', 'conced', 'undial', 'incor', 'ershell', 'icken', 'Гор', 'Mit', 'ende', 'attice', 'keys', 'extract', 'wner', 'subscri', 'ubuntu', 'perties', 'li', 'xc', 'READ', 'odon', 'sum', 'atal', 'keley', 'icker', 'ped', '事', 'ijk', 'abs', 'imar', 'Ny', 'Engel', 'buff', 'bben', 'consp', 'con', 'carte', 'astro', 'mande', 'ços', 'read', '义', 'equival', 'час', 'xp', 'avo', 'anci', 'usta', 'ancien', '={{', 'lyr', 'itt', 'ga', 'EE', 'inn', 'ន', 'osition', 'cor', 'necess', 'lder']\n",
      "in Layer11 , sorted_indices_dimension334:  ['itung', 'ymbol', 'част', 'requ', 'prep', 'imas', 'ragment', 'Ъ', 'lesh', 'excel', 'penas', 'entication', 'desen', 'essen', 'mouth', 'ican', 'appe', 'Wien', 'hand', 'textt', 'fut', 'cura', 'åk', 'мирова', 'Wies', '葉', 'symbol', '�', 'reste', 'ambda', 'neighbor', 'nitz', 'acional', 'RewriteCond', 'irit', 'arqu', 'Airlines', 'erst', 'ako', 'igung', 'osof', 'ével', 'Chain', 'obil', 'onomie', 'runtime', 'beg', '⊙', 'NR', 'repos', 'resta', 'sparse', 'Austria', '比', 'ulf', 'linux', 'Hof', '#>', 'ered', 'œuv', 'ésie', 'copying', 'ственно', 'odu', 'рем', 'которы', 'Petersburg', 'строй', 'switching', 'align', 'és', 'ést', 'ím', 'ář', 'neh', 'symbols', 'Mie', 'sup', 'forsch', 'feld', 'ˇ', 'ɨ', 'remaining', 'voce', 'ès', 'iation', 'Vien', 'icane', 'psum', 'ysis', 'ником', 'տ', 'erca', 'pios', 'пад', 'œuvre', 'ent', 'ZE', 'še', 'wojew', 'hart', 'cido', 'generic', 'ponents', 'Generic', 'align', 'distance', 'Begriffe', 'regia', 'glo', 'Љ', '∀', 'ى', 'Serv', 'OCLC', 'Beg', 'amo', 'indre', 'minimal', 'luss', 'cowo', 'omorphism', 'Session', 'download', 'Hub', 'Symbol', 'avigation', 'гар', '�', 'oso', 'ování', '量', 'Vienna', 'рии', 'applicable', 'tał', 'rör', 'elem', 'yp', 'pie', 'Kurz', 'unnecessary', 'REG', 'esis', 'Übers', 'Zygote', 'oci', 'бря', 'ографи', 'bo', '然', 'osition', 'Required', '∗', 'intu', 'Background', 'выпол', 'Bitmap', 'cô', 'édia', 'aucoup', 'чо', 'Ћ', 'Calendar', 'шње', 'ozzá', 'Ent', 'ด', 'ibil', 'enger', 'Års', 'palace', 'kir', 'Begr', 'remainder', 'rest', 'Niem', 'dinast', '街', 'telep', '�', 'figura', 'operator', 'Client', '⁰', 'Inside', 'Wald', 'interfaces', 'Jah', '符', 'wię', 'тельно', 'ikan', 'rence', 'Akt', 'gminie', 'чин', 'squ', 'części', 'ọ']\n",
      "in Layer11 , sorted_indices_dimension4207:  ['achiv', 'servable', 'angen', 'hina', 'Burg', '知', 'umerate', 'autorité', 'ongodb', 'ordered', 'CCN', 'bach', 'nan', 'trab', 'bourg', 'invariant', 'relief', 'automat', 'engen', 'elter', 'рт', 'urls', 'baum', 'ienst', 'agraph', 'burg', 'pton', 'defaults', 'ptop', 'tid', 'angu', 'сть', 'üng', '达', 'inaug', 'ign', 'minipage', 'Math', 'burger', 'ytu', 'antin', 'Ehren', 'Kontrola', 'kmal', 'tourn', 'bid', 'ocs', 'tart', 'ć', 'че', 'ült', 'arp', 'itter', 'гру', 'ängen', 'SBN', 'ores', 'ATH', 'onto', 'citiz', 'eau', 'xtart', 'NN', 'sun', 'Audio', 'eken', 'idad', '登', 'domains', 'unicí', 'Dok', 'printStackTrace', 'horn', 'ikh', 'aal', 'determin', 'bekannt', 'groupId', 'ieu', 'ig', 'witz', 'domain', 'arrest', 'ät', 'umn', 'ད', 'gat', 'Gru', 'ało', 'ugno', 'Municip', 'tocol', 'sum', 'nap', 'nect', 'зя', 'uminate', 'IGN', 'лн', 'slant', 'warnings', 'worth', '程', 'hagen', 'cht', 'epen', 'patr', 'ур', 'лет', 'ош', 'mn', 'berts', 'тро', 'utzt', '園', 'Commons', '학', '➖', 'af', 'ikon', 'omorphism', 'uga', 'Len', '�', 'ribución', 'ftrag', 'seau', '�', 'ced', 'ermo', 'ame', 'burg', 'arbitrary', 'SDK', 'त', 'ré', '学', 'against', 'ommun', 'avia', 'ucht', 'age', 'ณ', 'mieszkańców', 'Lamb', 'ším', 'asynchronous', 'otte', 'ciendo', 'colonial', 'вро', 'laps', 'Airl', 'Math', 'ueil', 'virti', 'demás', 'operator', '港', 'йн', 'ätze', 'Theorem', 'cyk', 'част', 'unicip', 'Audiod', 'regex', 'Grad', 'fug', 'otti', 'default', 'aws', 'Child', 'annels', 'delegate', 'imin', 'weap', 'époque', 'FilterChain', 'Baker', 'ет', 'rado', 'saf', 'ktor', 'Амери', 'ggplot', \"']['\", 'Erd', 'partial', 'Nam', '-+', 'archive', 'Pattern', 'чё', 'Jakob', '�', 'Story', 'férences', 'Values', 'ald']\n",
      "in Layer11 , sorted_indices_dimension5297:  ['det', 'CCN', 'leak', '종', 'resid', 'Research', 'bibliothek', 'Wik', 'research', 'orem', 'Halle', 'library', 'odor', 'aft', 'ongs', 'artifact', 'issen', 'Wikipedia', 'ITE', 'SON', 'Хронологија', 'mines', 'Савезне', 'Library', 'ką', 'PG', 'YES', 'azon', 'коно', '�', 'cost', 'Ingl', 'iona', 'Det', 'som', 'olas', 'ason', 'жовт', 'Nikol', 'KS', 'songs', '⟶', 'state', 'agg', 'arf', 'proportional', 'ris', 'tf', 'fug', 'mas', 'cera', 'Ya', 'пописа', 'рт', 'gan', 'Wik', 'asons', 'NO', 'apat', 'anga', 'yan', 'bit', 'osis', 'гар', 'icana', 'mozilla', 'Nob', 'introduced', 'прода', 'aret', 'Betty', 'Honor', 'Cost', 'hang', 'Master', 'arring', 'ft', 'Songs', '研', 'liber', 'IMDb', 'empre', 'Berl', 'physics', 'Sing', 'bs', 'arten', 'BS', '歌', 'IM', 'Physics', 'Compat', 'scales', 'YES', 'programmer', 'rust', 'ш', 'mas', 'rust', 'wont', 'Horn', 'flug', 'Гу', 'piano', 'troubles', 'zon', 'controls', 'ὀ', 'Library', 'assoc', 'Википеди', 'Conference', 'ere', 'Cost', 'background', 'bast', 'Hermann', 'сор', 'bitr', 'general', 'physics', 'dan', 'Pas', 'Попис', 'annten', 'pas', 'Platz', 'Stan', 'oris', 'son', 'โ', 'innoc', 'OCLC', 'uola', 'engo', 'Background', 'но', 'po', '¯', 'cod', 'ains', 'scher', 'pont', 'orge', 'cogn', '⊙', 'dent', 'Fe', 'Stre', 'fid', 'apost', 'allen', 'Apol', 'сона', 'onders', 'argin', 'Roll', 'pose', 'visor', 'зько', 'cost', 'song', 'му', 'oust', 'upt', 'iglia', 'ara', 'laus', 'ety', 'ling', 'quot', 'achter', 'Clara', 'artifact', 'lev', 'categories', 'roll', '消', 'LOB', 'Но', 'Гер', 'ciel', 'Initialize', 'hoff', 'Exec', 'Jahrhunderts', '保', 'Select', '🌍', 'unknown', 'omm', 'gar', 'ilor', 'wik', 'Details', 'stuck', 'rh', 'cc', 'dar', 'gew']\n",
      "in Layer11 , sorted_indices_dimension659:  ['empre', 'Nikol', 'Tol', 'asso', 'auc', 'Comics', 'asc', 'bij', '化', 'при', 'ief', 'ज', 'apa', 'farm', 'gems', 'mount', 'owanie', 'Fernández', 'ouc', 'gz', 'oug', 'amarin', 'ymbol', 'cz', 'minipage', 'doll', 'fic', 'lem', 'olas', 'oba', 'сти', 'Train', 'Mitt', 'uk', 'García', 'lez', 'Tamb', 'ück', 'encing', 'gia', 'ร', 'при', 'örd', 'automat', 'zem', 'lef', 'zos', 'oms', 'asc', 'psum', 'слу', 'жно', 'Gó', 'ignes', 'tol', 'Об', 'got', 'ppings', 'baar', 'б', 'railway', 'IDE', 'olit', 'sou', 'iese', 'stycznia', 'jan', 'dash', '按', 'slide', 'zan', 'haus', 'IDE', 'lemagne', 'Rail', 'ktet', 'agy', 'aso', 'opera', 'esser', 'oma', 'EG', 'illery', 'Trust', 'olin', 'bei', 'imos', 'lán', 'agog', 'Handle', 'य', 'Gand', 'rund', 'prise', 'diplom', 'ogram', 'спо', 'press', '�', 'slaves', '林', 'Bek', 'ç', 'eign', 'rm', 'Racing', 'édé', 'Ear', 'India', 'IMARY', 'plug', 'lyph', 'ذ', 'Nicol', 'Cot', 'Integer', 'Eg', 'bia', 'lyn', 'ugg', 'org', '目', 'IE', 'lias', 'дно', 'soul', 'PP', 'поли', 'lord', 'ifications', 'ASC', 'Нор', 'nom', 'ourg', 'ocz', 'Zug', 'IONS', 'rail', 'поя', 'endance', 'mass', 'Ке', 'Engel', 'ollar', '만', 'лем', 'Stim', 'annel', 'rei', 'superfic', 'alen', '정', 'Append', 'tes', 'ienst', 'Kunst', 'Doug', 'handled', 'су', 'alion', 'intervals', 'ield', 'sue', 'mely', 'erna', 'rg', 'przy', 'enf', 'BI', 'quar', 'optim', 'agt', 'ktur', 'Railway', 'bourg', 'penas', 'iji', 'kle', 'Über', 'туры', 'init', 'acje', 'mog', 'compt', 'Gent', 'union', 'fin', 'verse', 'Diplom', 'nitz', 'ado', 'ši', 'ounding', 'indo', 'unci', '商', 'mals', 'ünd', 'assign', 'ensions']\n",
      "in Layer11 , sorted_indices_dimension9398:  ['aru', 'ummy', 'asi', 'tring', 'folge', 'ho', 'лав', 'CCE', 'tam', 'erer', 'dr', 'tol', 'kr', 'far', 'alt', 'äufig', 'atori', 'yll', 'gle', 'ival', 'подо', 'IA', 'ius', 'ystycz', 'osto', 'vey', 'jp', 'дар', 'âge', 'Media', 'contra', 'au', 'ství', 'lear', 'ading', 'ythm', 'ken', 'imore', 'kil', 'lav', 'Vent', 'hat', 'Plat', 'DO', '変', 'к', 'gat', 'einges', 'toda', 'hoff', 'har', 'que', 'ネ', 'FirstName', 'Walker', 'hor', 'vent', 'lar', 'mas', 'Tokyo', 'geprüft', 'hr', 'Хронологија', 'Media', 'wr', 'ios', 'zös', 'legate', 'arde', 'hora', 'Geg', 'Tol', 'ῖ', 'Far', 'ieß', 'Lil', 'Orth', '\\u200d', 'logo', 'kol', 'National', 'wo', 'media', 'hren', 'jem', 'Pot', 'ɕ', 'gat', 'essa', 'allel', 'ме', 'Tam', 'Monument', 'FE', 'European', 'International', 'widet', 'ště', '写', 'Invoke', 'gable', 'ader', 'toler', 'oz', 'cken', 'fir', 'label', '将', 'qa', 'voke', 'angen', 'appreci', 'walt', 'Delay', 'ars', 'yz', 'ば', 'wouldn', 'gegen', 'pels', 'Britann', 'Bedeutung', 'Harold', 'Попис', 'Pre', 'кате', 'rating', 'longest', 'HR', 'minipage', 'Ext', 'Robin', 'ier', 'Tony', 'heits', 'asz', 'war', '////////', 'wr', 'racy', 'cloudflare', 'ait', 'far', 'тал', 'igo', 'herit', 'equ', 'ян', 'appreciate', '国', 'ula', 'her', 'Imp', 'eps', 'aligned', 'bourne', 'oun', 'sod', 'tod', 'Age', 'Sach', 'cza', 'imp', 'Fred', 'кор', 'yan', 'Toggle', 'лее', 'VP', 'athol', 'служ', 'ogram', 'skip', 'Gir', 'inho', 'ß', '《', 'льта', 'чий', 'ított', 'categ', 'igua', 'aran', 'oming', 'pta', 'zat', 'zess', 'Pero', 'DEFAULT', 'ณ', 'Binary', 'ogn', 'media', 'поя', 'ört', 'ivo', 'Fir', 'putting', 'Ged', 'arith']\n",
      "Key: model.layers.12.mlp.down_proj.weight\n",
      "in Layer12 , sorted_indices_dimension8961:  ['herit', 'woord', 'ähl', 'lev', 'zett', 'ierno', 'sert', 'Forces', 'virti', 'omp', 'cape', 'vee', 'ĝ', '�', 'frak', 'ответ', 'atio', 'inherit', 'bran', 'ätze', 'hall', 'lei', 'Schaus', 'chten', 'prüng', 'cip', 'erten', 'Municipal', 'ordnung', 'cloudflare', 'elev', 'ристи', 'tip', 'esehen', 'firm', 'hall', 'œ', 'bis', 'emann', 'ël', 'inheritance', 'olk', '<s>', 'jekte', 'Thompson', 'ules', 'слав', 'wort', 'ieder', 'ế', '越', 'esti', 'cache', 'aman', 'jel', 'тил', 'EMA', 'ツ', 'cache', 'ichten', 'ossen', 'ende', 'sweise', 'Қ', 'cat', 'sd', 'berga', '호', 'слі', 'сті', 'ername', 'AtIndexPath', 'iteit', 'iwers', 'metric', 'cons', 'enso', 'ktur', 'republic', 'Mant', 'rugby', 'versch', 'tegr', 'nats', 'forces', 'cust', 'auté', 'испо', 'ғ', 'ois', 'éric', 'cres', 'franc', 'још', 'Star', 'Hall', 'municipal', 'baz', 'fen', 'eries', 'onnées', 'flu', 'hrte', 'branch', 'he', 'alto', 'fou', 'нва', 'HOST', 'tennis', 'nete', 'носи', 'reg', 'CCE', 'gior', 'Kost', 'людя', 'istiques', 'zu', 'Layout', 'ViewHolder', 'rano', 'ower', 'sin', 'abad', 'controllers', 'pok', 'Vin', 'tip', 'subt', 'ume', 'Material', 'Squad', '点', 'arden', 'cloth', 'Orts', 'sim', 'edit', 'SI', 'oemd', 'Region', 'ugby', 'жовт', '京', 'adt', 'racht', 'rę', 'He', 'controller', 'kende', 'wij', 'sj', 'Sim', '=\"{', 'ългар', 'Method', 'optera', 'onato', 'auff', 'helm', 'lés', 'Fest', 'erte', 'vard', 'Mot', 'symmet', 'emia', 'ńst', 'ić', '令', 'mai', 'Pav', 'ituto', 'données', 'џ', 'Leop', 'команди', ':\\u2009', 'SW', 'Christ', 'jets', 'entr', 'Laur', 'Edit', 'Es', 'corte', 'at', 'syn', 'otimes', 'intensity', 'atalog', '},{', 'iano', 'stwa', 'count', 'eton', 'von', 'Mik', 'lee']\n",
      "in Layer12 , sorted_indices_dimension7428:  ['nik', 'oid', 'lei', 'Wayback', 'nis', 'nes', 'NI', 'округу', 'isf', 'stuff', 'enough', 'cc', 'Pays', 'зо', 'WCF', 'rias', 'dar', 'CC', '心', 'Friend', 'cis', 'ħ', '[\"', 'wa', 'sf', '☺', 'sson', '✿', 'ór', 'ⁿ', 'suf', 'eland', 'Censo', 'UNION', 'apple', 'Kab', 'ov', 'Akademie', 'abase', 'ник', 'osa', 'mé', 'nisse', 'Settings', 'Hav', 'nika', 'ciones', 'Sep', 'Settings', 'philosoph', 'ären', 'Definition', '否', 'meno', 'macht', 'DECLARE', 'Overflow', 'cro', 'Gal', 'inson', 'imir', 'lish', 'shoot', 'friend', '](/', 'roku', 'termin', 'assen', 'Selected', 'vál', 'Cultural', 'Frame', 'indep', 'Données', 'SF', 'ggi', 'cid', 'Valent', 'ipage', 'INNER', 'Owner', '支', 'Observable', 'lay', '想', 'ham', 'zaj', 'Schul', 'rame', 'Leon', 'than', 'Argument', 'umph', 'ǒ', 'igner', 'xsl', '�', 'endor', 'mont', 'wid', 'Fil', 'Spo', 'wär', 'otted', 'лаго', 'sef', 'лад', '[\\\\', '克', 'aret', 'zek', 'strik', 'ġ', 'GND', 'Janeiro', '<=', 'innen', 'DataSet', 'helm', 'ellite', 'uchar', 'cen', 'particular', 'izont', 'englisch', 'англ', 'estaven', 'дія', 'sted', 'gior', 'acht', 'Fr', '密', 'fahr', 'achine', 'holder', 'scattered', 'schließ', 'heten', 'strike', 'avan', 'unicí', 'alm', 'patr', 'Sept', 'operation', 'homonymes', 'esterni', 'udio', 'eig', 'ши', \"['\", 'tober', 'ços', 'select', '----+', 'Author', 'enson', 'Pale', 'advice', 'Mundo', 'ника', 'lished', '///', 'лен', 'zas', 'ington', '\\x0b', 'tcp', 'Hyp', 'sab', 'unto', 'ciente', 'obar', 'uclide', 'współ', 'Impl', 'otherwise', '符', 'besondere', 'Singles', 'Pse', 'textbox', 'čen', 'même', 'train', 'giv', 'Fame', 'ér', 'ǎ', 'than', 'Fig', 'illeurs', 'friendship', 'égl', 'napshot', 'terra', 'capac', 'Inner', 'Draw']\n",
      "in Layer12 , sorted_indices_dimension1992:  ['administr', 'situ', 'anst', 'пописа', 'omorphic', 'ownik', 'Tová', 'INCT', 'Ari', 'wicklung', 'äler', 'iš', 'tip', 'sg', 'щее', 'Mann', 'añ', 'efined', 'tir', 'Administr', 'esto', 'connexes', 'ventory', 'onymes', 'administrator', '�', 'broad', '↔', 'zych', 'ionario', 'externos', 'annels', 'auteurs', 'znik', 'carrière', 'ッ', 'reno', 'MQ', 'ribu', 'нен', 'Хронологија', 'Square', 'Loop', 'administrative', 'associ', 'patch', 'itle', 'Bran', 'equival', 'Cur', 'коли', 'Rég', 'Gén', 'Ul', 'feld', 'ewnę', 'field', 'Gé', 'iot', 'itories', 'Tu', 'nię', 'érique', 'triangle', 'éch', 'ত', 'Fitz', 'achi', 'не', '์', 'zett', 'viron', 'pez', 'tip', 'urname', 'enix', 'ormal', 'äu', 'ribute', 'Situ', 'од', 'curve', 'Tu', 'ispecies', 'tu', 'ulk', 'ziale', 'gresql', 'чество', 'tritt', 'nitz', '�', '়', 'outer', 'unicí', 'plut', 'Registry', 'vek', 'lez', 'ingen', 'ospod', 'game', 'ederb', 'сей', 'пу', 'agens', '月', 'boot', '(*', 'ษ', 'patch', 'Jahrh', 'Schutz', 'ependant', 'vd', 'ître', '/>', 'NUM', 'Jord', 'inct', 'establish', 'држави', 'infty', 'RY', 'nelle', 'ultado', 'Pal', 'Ged', 'sorted', 'Weight', 'ѣ', 'Xcode', 'counted', 'vs', '完', 'RAM', 'тря', 'Gan', 'loop', '定', 'rugu', 'Prefix', 'Cic', 'acs', 'Inga', 'grouped', 'ti', 'tips', '们', 'td', 'plorer', 'Esc', 'oti', 'square', 'onden', 'Broad', 'zec', 'iare', 'Ψ', 'imum', 'rik', 'hibernate', 'Bath', 'LENG', 'teilung', 'horizon', 'Государ', 'бург', 'imo', 'filesystem', 'scheid', 'Ζ', 'ListItem', 'ulaire', 'simplest', 'ณ', 'iley', 'totype', 'ąż', 'kiem', 'éricaine', 'ин', 'rend', 'UI', 'IndexPath', 'волю', 'RED', 'Bij', 'ouverneur', 'ША', 'Pal', 'ionali', '�', 'taire', 'Lng', 'istre', 'ór', 'sq', 'inners', 'Õ']\n",
      "in Layer12 , sorted_indices_dimension9258:  ['хом', 'бен', 'avel', 'vd', 'мет', 'Finale', 'arta', 'aties', 'ROR', 'account', 'ytu', 'обще', 'Hash', 'рин', 'eas', 'Input', 'share', 'ím', 'fault', 'tamb', 'skiego', 'ieu', 'Њ', 'longest', 'Visual', 'üst', 'execution', 'тури', 'ius', 'ydro', 'нів', 'egen', '子', 'GR', 'hash', 'uter', 'suffer', 'atalog', 'ън', 'sam', 'accounts', 'account', 'orp', 'ultado', 'hid', 'anas', 'Grad', 'rän', '민', 'shook', 'ragen', 'ClickListener', 'bet', 'bos', 'ли', 'ast', 'Subject', 'Visual', 'зав', 'prefix', '直', 'зни', 'VD', 'shares', 'Rico', 'astero', 'ե', 'cope', 'ті', 'sky', 'э', 'ksam', 'ぐ', 'betre', 'ictionary', 'ail', 'Mall', 'Н', 'runtime', '̌', 'Sen', '帝', 'esti', 'angularjs', 'Frame', 'NG', '�', 'constitu', 'Exec', 'tail', 'agu', 'orial', 'ég', 'ständ', 'wär', 'works', 'Heidel', 'emein', 'чий', 'execution', 'ection', 'ges', '동', 'Становништво', 'daily', 'commons', 'vos', 'yd', 'rela', 'ias', 'subjects', 'Ü', 'native', 'alf', 'Nachdem', 'actual', 'Май', 'orter', 'бов', 'anos', 'ograph', 'lo', 'classes', 'жде', 'visual', 'gehör', 'idi', 'apes', 'ugby', 'ege', 'граф', 'Framework', 'els', 'affected', 'Welt', 'ild', 'introdu', 'łu', 'cpp', 'setAttribute', 'child', 'Grad', 'beho', 'ichi', 'völker', 'ག', 'Uni', 'ло', 'bil', 'juris', 'ängen', 'berry', '地', 'fasst', 'Bé', 'chim', '过', 'MTV', 'witz', 'тро', 'matrices', 'тики', 'Васи', 'Input', 'ril', 'anos', 'й', 'ність', 'longitude', 'log', 'ț', 'jar', 'launch', 'Account', 'йт', 'lives', 'eus', 'aki', 'ür', 'corre', 'canton', '�', 'ility', 'projection', 'anzen', 'рен', 'mét', 'swers', 'Während', 'schließlich', 'orem', 'слу', 'dra', 'sum', 'icted', 'frames', 'deprec', 'duration', 'agues', 'aqu']\n",
      "in Layer12 , sorted_indices_dimension9164:  ['atol', 'dek', 'г', 'berg', 'sequ', 'orgen', 'sel', '$}}%', 'elif', 'gin', 'zia', 'Barcel', 'repla', 'issu', 'isen', 'нь', 'ensa', 'beskre', 'ambiguation', 'į', 'bg', 'werp', 'Ль', 'olymp', 'gerufen', 'Ps', 'Olympic', 'terre', 'ibn', 'seau', 'lop', 'eny', 'gs', 'ή', 'ifica', 'eingesetzt', 'sentence', 'unc', 'astro', 'stoff', 'vel', 'burg', 'ѫ', 'mense', 'uben', 'nal', 'Freund', 'widet', 'Prima', 'тя', 'лин', '米', 'слав', 'onces', 'ơ', 'бай', 'Fiche', 'Vien', 'chanson', 'runtime', 'neigh', 'inqu', 'джа', 'xture', 'gmin', 'Ath', 'ondissement', 'observer', 'ý', 'Aqu', 'icity', 'мир', 'swer', 'EGIN', 'Observer', 'République', 'Hook', 'tera', 'illaume', 'ství', 'musica', 'xter', 'iformes', 'ń', 'arter', 'rough', 'neur', 'équ', 'verf', 'ន', 'aso', 'quia', 'borg', 'spos', 'ms', 'els', 'isser', 'äler', 'Olympics', 'iny', '�', 'üll', 'ski', 'Государ', 'lg', 'nl', 'uns', 'iod', 'ө', 'organ', 'urname', 'ltre', 'carri', 'LIC', 'inea', 'zig', 'sols', 'jus', 'unicí', 'ąd', 'Pop', '어', 'orage', 'loading', 'ề', 'Schön', 'ynie', 'altra', 'ką', 'MS', 'ã', 'Berl', 'лий', '⁄', 'alth', 'wort', 'syntax', 'Stati', 'textcolor', 'äs', 'Stanisław', 'kele', 'enschaft', 'Mall', 'comer', 'ný', 'тера', 'ссе', 'Ком', 'Lang', 'projekt', '⁰', 'ə', '{`', '⁹', 'CCE', 'ttemberg', '화', 'etro', 'рю', 'лов', 'iada', 'CCN', '�', 'loads', 'kiem', 'RIPT', 'commercial', 'ώ', 'ird', 'bor', 'čen', 'TextBox', 'burgh', 'Bird', 'slov', 'lopedia', 'richt', 'ytics', 'auf', 'cls', 'hood', 'uv', 'duc', 'lan', 'vel', 'tv', 'зик', 'EventArgs', '客', 'слі', 'ività', 'laps', 'atal', 'Ű', 'quot', 'ˠ', 'fasst', 'qui', 'Warsza']\n",
      "in Layer12 , sorted_indices_dimension10575:  ['kup', 'aval', 'asto', 'endif', 'ini', 'vid', 'поло', 'arguments', 'idi', 'dynam', 'Gu', 'rec', 'кет', 'ouv', 'opens', 'auss', 'umann', 'äter', 'tout', 'prima', '華', 'became', 'wall', 'ountry', 'RED', 'ци', 'куль', 'amo', 'extract', 'gu', 'Lic', 'condition', 'osob', 'starb', 'Magn', 'couldn', 'extracted', 'Hotel', 'обра', 'Fre', 'ido', 'ardi', 'Political', 'cui', 'polygon', 'appa', 'Гу', 'Parse', 'arius', '州', 'zk', 'using', 'gr', 'affairs', '太', 'Seconds', 'first', 'uni', 'icha', 'bru', 'vba', 'perfect', 'political', 'imp', 'валь', 'liquid', 'льно', 'uls', 'mut', 'ino', '条', 'fre', 'Processor', 'RU', 'ipo', 'vc', 'Partido', 'бай', 'sod', 'arguments', 'els', 'ably', 'red', '.-', 'VAL', 'alf', 'IN', 'ycle', 'vorm', 'vehicle', 'oul', 'First', 'Camp', 'condition', 'jör', 'od', 'cope', 'reten', '华', 'auch', 'manip', 'Lob', 'pocket', 'cri', 'gr', '@@', 'ово', '音', 'soul', 'ateur', 'gresql', 'undial', 'guest', 'alles', 'guitar', 'esi', 'grammar', 'ette', 'ocket', 'ivari', 'poly', 'œ', 'hab', 'ziale', 'autor', 'ouc', 'obar', 'wild', 'grado', 'abbre', 'anterie', 'fran', '�', 'ново', 'esa', 'character', 'license', 'Observable', 'IF', 'пол', 'Pod', 'govern', 'ст', 'Award', 'finger', 'extract', 'ocia', 'hell', 'guarantee', 'retrieved', ':#', 'ind', 'dor', 'Einz', 'endo', 'forma', 'adj', 'ushing', 'property', 'sold', '★', 'ioni', 'rument', 'ław', 'mut', 'Bernard', 'même', 'erk', 'guarante', 'kraj', 'ples', 'нал', 'pred', 'válto', 'fah', 'rec', 'Chinese', 'Guer', 'sat', 'extr', 'wehr', 'François', 'habit', 'ards', 'proofs', 'Pos', 'ень', 'retired', 'oro', 'kra', 'cent', 'IP', 'Fran', 'ruit', 'consulté', 'ове', 'ip', 'ensch', 'Georges', 'ден']\n",
      "in Layer12 , sorted_indices_dimension8051:  ['ped', 'scale', 'scale', 'uerte', 'scales', 'ampio', 'jsf', 'chor', 'Ped', 'atori', 'со', 'vos', 'clic', 'mbH', 'wür', 'uvo', 'footer', 'itori', 'ligen', '전', 'мене', 'cases', '⇔', 'ódigo', 'scaling', 'isecond', 'iec', 'toire', 'Rule', 'asta', 'organ', 'Burg', 'privileges', 'huvudstaden', 'ped', 'бри', 'iddle', 'pint', 'сан', 'alette', 'lla', 'particular', 'clo', 'transparent', 'asa', 'strij', 'pair', 'нец', 'agog', 'окру', 'necess', 'aro', 'Villa', 'spr', 'halt', 'mer', 'ھ', 'height', 'aft', 'mot', 'Ont', 'Stefan', 'cke', 'Sold', 'carri', 'Bast', 'округа', 'alty', 'шлен', 'TP', 'keyword', 'JB', 'bridge', 'Ď', 'jours', 'MD', 'merchant', 'Przyp', 'Ott', 'éch', 'necessary', 'lin', 'invari', 'passage', 'ере', 'acity', 'rius', 'spread', 'rule', 'Hmm', 'слов', 'produ', 'ieu', 'ness', 'chapter', 'icro', 'betre', 'Coast', 'ichi', '法', 'пас', 'Msg', 'omorphism', 'Bio', 'reno', '景', 'Model', 'legal', 'traffic', 'Bild', 'predicate', 'onto', 'aily', 'argin', 'arten', 'organ', 'raj', 'ont', 'rera', '士', 'prom', 'ض', 'jel', 'uchte', 'ants', 'Thom', 'reb', '拳', 'irl', 'тал', 'Edu', 'space', 'clause', 'bio', 'pply', 'baut', 'nécessaire', 'base', 'iewer', 'ظ', 'Wright', 'antics', 'situ', 'pair', 'Fu', 'aur', 'сылки', 'Ford', 'Db', 'abet', 'NE', 'lia', 'ro', 'unnel', 'DB', '\\x16', 'tk', 'justice', 'ready', 'щен', 'porte', 'culo', 'Bibliografia', 'periodic', 'arbeit', 'ret', '∥', 'elij', 'że', 'мати', 'HT', 'therm', 'neh', 'мерикан', 'egeben', 'ecycle', 'clip', 'май', 'ços', 'ras', 'kten', 'öst', 'scala', 'ccion', 'Encyclop', 'случа', 'lichkeit', 'mayo', 'imeter', 'previous', 'érer', 'majority', 'jud', 'Pair', 'ganz', 'rror', 'riere', 'Pa', 'refer', 'Peace']\n",
      "in Layer12 , sorted_indices_dimension3381:  ['nero', 'lips', 'extr', 'vee', 'fin', 'naio', 'Inner', 'Hello', '房', 'lea', 'Operator', 'Inner', 'Kin', 'operators', 'syn', 'engen', 'stabil', 'Syn', 'hmen', 'momento', 'insc', 'ilor', 'Oper', 'enumer', 'Operation', 'operator', 'hello', 'adin', 'earance', 'stability', 'nik', 'LayoutParams', 'ride', 'waves', 'achine', 'rola', 'hina', 'arden', 'ITH', 'Syn', 'released', 'тро', 'ificación', 'іль', 'tit', 'ued', 'udent', 'мец', 'hyper', 'eken', 'Scott', 'html', 'Serie', 'ados', '`__', 'mas', 'Przyp', 'сла', 'Hed', 'endant', 'relative', 'antry', 'CK', 'lez', 'arian', 'igan', 'BeanFactory', 'gia', 'Hom', 'arde', 'дор', 'stag', 'wald', 'ousin', 'hom', 'opera', 'Chron', 'ogne', 'rob', 'ski', 'aran', 'hausen', 'пра', 'ла', 'chten', 'Ша', 'woord', 'Cas', 'Hamm', 'Moh', 'Ti', 'enumerate', 'apache', 'emen', 'Hin', 'cki', 'Jordan', 'син', 'роб', 'compatible', 'itte', 'apache', 'hens', 'laten', ']=\"', 'Jazz', 'etro', 'Oper', 'Slo', '�', 'chron', 'backend', 'adjacent', 'ès', 'encoded', 'uss', 'operation', 'homonymes', 'arga', 'nginx', 'Fill', 'dictionary', 'évrier', 'Lip', 'Leb', 'añ', 'ugel', 'hen', 'Guide', 'lau', 'ushed', 'Args', 'board', 'tunnel', '×', 'yo', 'embro', 'profiles', '上', 'libre', 'lin', 'ubuntu', 'agr', 'agne', 'mn', 'fish', 'Se', 'missing', 'Behavior', 'synth', 'mez', 'uerdo', 'alement', 'Apache', 'squares', 'Mountains', 'inate', 'igner', 'bars', 'ître', 'FOR', 'tok', 'boats', 'codes', 'Release', 'Hass', 'startup', 'départ', 'operation', 'fico', 'спе', '紀', 'toss', 'Entry', 'Britannica', 'Gazette', 'uen', 'opere', 'цин', 'idenote', 'verte', 'заня', 'ち', 'Bau', 'hous', 'Release', 'Minister', 'ati', 'release', 'cio', 'Feuer', 'ву', 'oci', 'movie', 'lip', 'Mount', 'ordon', 'ivement', 'ño', 'SK']\n",
      "in Layer12 , sorted_indices_dimension3670:  ['useppe', 'ząt', 'auss', 'ható', 'Setter', 'людях', 'vod', 'ActivityThread', 'emeinde', '﹕', 'leans', 'туре', '&=\\\\', 'Aires', '연', 'dimen', 'ragma', 'miesz', 'ouvelle', 'przew', 'typen', 'alin', 'рит', 'iges', 'Gegen', 'stelle', 'Pages', 'angers', 'rivial', 'usalem', 'aceae', 'ieg', 'macht', 'session', 'ipage', 'ղ', 'geslacht', 'ɹ', 'rangle', 'bezeichneter', 'ango', 'techni', '♠', '故', 'SION', 'istra', 'thur', '号', 'лан', 'EventListener', 'Wass', 'ührung', 'automatisch', 'Pager', 'demás', 'Ї', 'baum', 'igung', 'ição', 'threads', 'Overflow', '希', '┐', 'Rahmen', 'ethod', '\"];', 'će', 'LETE', 'HL', 'dictionary', '씨', 'osh', 'ว', '于', 'Bitte', 'arium', 'ὸ', 'osten', 'кур', 'javafx', 'vole', 'kele', 'Са', 'rinn', 'тие', 'bir', '除', 'LinearLayout', 'ények', 'mathchar', 'stwo', 'powiat', 'gerufen', 'ächen', 'Oficina', 'թ', 'Berl', 'ceae', 'gesellschaft', 'нут', 'коли', 'yrus', 'beskrevs', 'ępu', 'cies', 'лл', '夜', 'osoph', 'тре', 'ір', 'ляр', '[$', 'risult', 'gaben', 'imir', 'unicí', 'ologe', 'leur', 'unnable', 'multicol', 'riage', 'rule', 'Regiment', 'äude', 'mongodb', 'eground', '象', 'obec', 'staden', 'separ', 'rero', 'ieux', '久', 'вод', 'Christoph', 'Dra', 'squadra', 'cej', 'bru', '量', 'äler', 'Pal', 'ängen', 'urname', 'Observable', 'eton', '�', 'ryty', 'зах', 'ט', 'ències', 'cím', 'Áng', 'iterator', 'mere', '가', 'педи', 'äng', 'บ', '乡', 'atus', 'HER', 'pués', 'ribu', 'тей', '�', 'бо', 'ält', 'nú', 'ح', 'zyst', 'amar', 'Dispatcher', 'sono', 'phia', 'wad', 'angle', 'irtual', 'estig', 'cida', 'regiment', 'maste', 'baut', 'ène', 'kim', 'Pse', 'Seq', '孝', 'mysq', 'istik', 'еди', 'мах', 'hmen', 'Brandenburg', 'cych', 'xtart', 'ɒ', '♣', 'legt', 'numer']\n",
      "in Layer12 , sorted_indices_dimension183:  ['rim', 'aru', 'schließ', 'izi', 'illaume', 'TagName', 'Piet', 'hai', 'puis', 'pace', 'raum', 'тик', 'circumst', 'ador', 'ctl', 'ran', 'costa', 'Raum', 'zych', '洋', 'íd', 'мом', 'hid', 'slant', 'bben', 'âr', 'connexes', 'einges', 'running', 'ifer', 'jú', 'prü', 'verf', 'red', 'pois', 'wrześ', 'ensional', 'od', 'running', 'ム', 'id', 'Architecture', 'Events', 'わ', 'іс', '№', 'olimp', 'Olímp', 'Bild', 'kiem', 'tuple', 'рес', 'czy', 'hagen', 'Input', 'äß', 'пописа', 'äft', 'rip', 'ol', '�', 'bounds', 'Ḫ', 'Nederland', 'Roma', 'essa', '�', 'eggi', 'ucci', 'руг', 'bro', 'Portug', 'żyn', 'Struct', 'anka', 'Shape', 'Squad', 'дій', 'ֵ', 'ogs', 'ację', 'sen', 'scriptstyle', 'iony', 'ゼ', 'ædia', 'separ', 'consultato', 'nahe', 'dar', 'essor', 'externos', 'нцикло', 'ній', 'гом', 'ímp', 'Running', 'Rh', 'Feed', 'msdn', 'rou', 'míst', 'array', 'struct', 'ader', 'ạ', 'facility', 'ı', 'пня', 'Ung', 'extrem', 'Struct', 'Austin', 'Forces', '关', 'Madonna', 'fter', 'akult', 'ә', 'pace', 'range', 'stract', 'addr', 'Ű', 'ív', 'tem', 'reste', 'Brandenburg', 'isen', 'ʐ', 'temps', 'hath', 'ruby', 'спе', 'designed', 'poster', 'öm', '空', 'findet', 'Img', 'hod', 'onio', 'Port', 'ves', 'rei', 'alla', 'они', 'angles', 'źdz', 'orr', 'бре', 'eerd', 'troubles', 'pris', 'shell', 'uder', 'angular', 'orum', 'ғ', 'pus', 'Array', 'Fi', 'rea', 'Mosk', '皇', 'AJAX', 'chance', 'Athletics', '�', 'imes', 'isi', 'férences', 'zA', 'спе', 'ном', 'citet', 'Vere', 'oca', 'рд', '还', 'тика', 'esta', 'rey', 'AC', 'temporal', 'Cultura', 'Icon', 'Human', 'Spirit', 'ж', '千', '收', 'ရ', 'agrant', 'Br', 'wert', 'approaches', 'ө', 'pecially', 'Events']\n",
      "in Layer12 , sorted_indices_dimension406:  ['ousel', 'iei', 'ache', 'Mas', 'enas', 'eau', 'ee', 'aca', 'indent', 'omas', 'Arthur', 'ow', 'respond', 'Serial', 'Sus', 'enu', 'runt', '�', 'laten', 'Ъ', 'appe', 'Нов', 'Kel', 'Glad', 'Hy', 'addle', 'iva', 'lave', 'allas', 'collapse', 'catal', 'няя', 'aylor', 'ben', 'сы', 'Ce', '/\\\\', '์', 'mas', 'Ál', 'catal', 'lav', 'Master', 'ion', 'slow', 'hy', 'atal', 'ius', 'fly', 'Joy', 'imientos', 'nement', 'ensional', 'ere', 'ches', 'Julius', 'bres', 'eng', 'ior', 'iformes', 'Sac', 'fast', 'нь', 'Dy', 'omo', 'Fast', 'Albert', 'Ele', 'wa', 'dl', 'fast', 'ゼ', 'ump', 'erving', 'premi', 'Fra', 'beck', 'RY', 'гла', 'aret', 'arten', 'Camp', 'Statist', 'Eng', 'ymn', 'WT', 'omic', 'bury', 'olo', 'cep', 'ough', 'court', 'Vel', 'гля', 'Қ', 'lav', 'tó', 'lär', 'authentic', 'env', 'ctor', 'ark', 'ación', 'aki', 'ح', 'antic', 'fmt', 'Wieder', 'Reform', 'Hyper', 'US', 'ouse', 'Prem', 'stream', '\"\\\\', 'distances', 'criv', 'Serial', 'apps', 'fraction', 'съ', 'по', 'bru', 'authentic', 'Donald', 'использу', 'Gott', 'ános', 'Dez', 'isce', '康', 'conne', 'having', 'ocker', 'Catal', 'că', 'ulas', 'ulsion', 'wisdom', 'Desc', 'маль', 'onato', 'Bis', 'Nav', 'Acc', 'mans', 'istrz', 'privileges', 'oll', 'ionales', 'esse', 'obey', 'ɲ', 'пей', 'ycz', 'override', 'Bot', 'anning', 'schaften', '间', 'vba', 'Primary', 'schap', 'ugly', 'dil', 'secure', 'enc', 'minim', 'usa', 'prem', 'ци', 'аль', 'au', 'Ein', 'emet', 'cra', 'ově', 'bootstrap', 'ienne', 'abol', 'ectors', 'овой', 'extended', 'eh', 'mas', 'Glas', 'trees', 'swift', '话', 'Form', 'че', 'uve', 'aju', 'jer', 'rav', 'eyes', 'unya', 'Ble', 'mid', 'matrices']\n",
      "in Layer12 , sorted_indices_dimension10047:  ['gener', 'ulp', 'Desc', 'awa', 'desc', 'descend', 'comot', 'pond', 'ста', 'untu', 'urbed', 'ulpt', 'Barcel', 'oko', 'ICE', 'respond', 'desc', 'ève', 'gram', 'Fe', 'Promise', 'ậ', 'inand', 'Abstract', 'yclerView', 'reten', 'lacht', 'źdz', '�', 'ufe', 'Observable', 'memory', 'vous', 'Ē', 'essel', 'upd', 'prec', 'responses', 'LayoutInflater', 'wal', 'arde', 'hav', 'descent', 'ahl', 'rt', 'Observable', 'iből', 'нала', 'esser', 'ев', 'pent', 'arsi', 'grad', 'ження', 'odor', '兴', 'gener', 'Попис', '容', 'bara', 'grud', 'Rang', 'Fe', 'ugno', '&=\\\\', 'VO', ';\">', 'lagen', 'enti', '化', 'бю', 'response', 'ears', '∅', 'Extern', 'Wikispecies', 'ç', 'ührt', 'yz', 'BeanFactory', 'ições', 'ettings', 'statunit', 'hov', 'imir', 'iente', 'вання', 'aine', '들', 'izin', 'rod', 'textt', 'ATCH', 'rained', 'akte', 'engo', 'raction', 'respond', 'ßer', 'cep', 'ulté', 'анг', 'ciones', 'լ', 'ряд', 'Canal', 'Gener', 'ixa', 'Perry', 'Barbara', 'ôt', 'їв', 'ühl', 'шта', 'Union', 'broken', 'pian', 'willing', 'olia', 'soap', 'obox', 'signific', 'よ', 'uminate', 'eca', 'Voor', 'widet', 'ingu', 'ThreadPool', 'ifecycle', 'irre', 'ichtet', 'Raum', 'ziale', 'FE', 'Shaw', 'Sheet', 'SEE', 'ouri', 'obi', 'zyk', 'ynast', 'memory', 'Oracle', 'sob', 'atch', 'nius', 'Municip', '华', 'us', 'ус', '崎', 'Visible', 'itel', 'susp', 'Checked', 'ponse', 'isl', 'Pennsylvan', 'Autow', 'bour', 'ódigo', 'fic', 'unsafe', 'lär', 'MODE', 'Edu', 'plex', 'odes', 'hos', 'cycle', 'станов', 'RewriteCond', 'terior', '➖', 'illas', '(?', 'ональ', 'lyph', 'гии', 'neu', 'ordnung', 'ів', 'mate', 'тра', '車', 'ret', '報', 'mind', 'Eg', 'яз', 'rale', 'ède', 'lige', 'ushed', 'exposed', 'sweise', 'rok', 'entlich', 'mig']\n",
      "Key: model.layers.13.mlp.down_proj.weight\n",
      "in Layer13 , sorted_indices_dimension6919:  ['Ta', 'kin', 'iei', 'sigu', 'distributed', 'ery', 'dav', 'alt', 'ides', 'Management', 'hers', 'Compiler', 'ks', '\\u202d', 'рев', 'LT', 'pun', 'MAIN', 'ateg', 'Philosoph', 'philosophy', 'obi', 'acon', 'management', 'Sher', '物', 'ln', 'äg', 'sc', 'nu', 'dc', 'riminal', 'њи', 'contents', 'usta', 'geschichte', 'cer', 'PE', 'UE', 'ru', 'Main', 'живо', 'lt', 'argo', 'Dist', 'rano', 'Eng', 'ERY', 'ker', 'orth', 'desar', 'Zo', 'Main', 'RE', 'abi', 'Engel', 'compiler', 'collections', 'ош', 'ser', 'static', 'pu', 'стом', 'Mode', 'tm', 'runner', 'tr', 'esse', 'alling', 'ány', 'vac', 'da', 'Metro', '朱', 'erei', 'ain', 'flex', 'pe', 'ischof', 'хи', 'trom', 'Ana', 'Richmond', 'ategories', 'ë', 'Mu', 'iro', 'option', 'Alt', 'sc', 'ruf', '장', 'Batch', 'distrib', 'каз', 'уда', 'pb', 'aya', 'tax', 'weis', 'neu', 'GET', 'batch', 'phon', 'ives', 'Cer', 'Dev', 'flex', 'rypto', 'Young', 'anta', 'Bien', '\\u2002', 'isto', '“', 'remote', 'ox', 'nel', 'grounds', 'ieben', 'equival', 'So', 'App', 'ate', 'oc', '►', 'History', '[]{', 'tale', '戸', 'љи', 'tax', 'sni', 'cou', 'convenient', 'Boh', 'communic', 'glo', 'Medicine', 'eind', 'Amount', 'Am', 'Pom', 'ivamente', 'opera', 'Stat', 'oca', 'PI', 'invoke', 'inve', 'glass', 'Dum', 'dist', 'Dav', 'VM', 'tales', 'пе', 'рона', 'cler', 'null', 'ほ', 'UE', 'volume', 'ups', 'pu', 'former', 'distribu', 'manager', 'offs', 'nich', 'pier', 'def', 'bir', 'alt', 'ég', 'option', 'cou', 'idense', 'arts', 'eux', 'ue', 'ary', 'Pu', 'omorph', 'ael', 'ォ', 'bi', 'Oper', 'ass', 'aux', 'card', 'Tax', 'pped', 'findViewById', 'pi', 'erk', 'integer', 'afka', 'tres', 'debugger']\n",
      "in Layer13 , sorted_indices_dimension3249:  ['Orth', 'éb', 'iani', 'uen', 'arga', 'Parad', 'religios', 'Santa', 'пра', 'Dres', 'slä', 'recht', 'homes', 'bes', 'recens', 'parlament', 'izard', 'irat', 'STATUS', 'iare', 'homonymes', 'boot', 'jam', 'off', 'CBS', 'Commun', 'boot', 'anzen', 'Naz', 'arte', '園', 'antics', 'draw', 'Axis', 'Intern', 'orthogonal', 'ort', 'gun', 'Mih', 'Ann', 'Vere', 'Gun', 'реди', 'полу', 'ệ', 'unto', 'offs', 'raph', 'intern', 'Ξ', 'ша', 'argo', 'gun', 'erhalten', 'Bian', 'rev', 'ote', 'Cec', 'stack', 'ateful', 'externe', 'lade', 'externos', 'rece', 'off', 'aju', 'enfor', 'ら', 'Rud', 'мати', 'couple', 'WRITE', 'ju', 'ред', 'Свя', 'ведения', 'Sv', 'escape', 'orge', 'Seb', 'ones', 'iven', 'fur', 'vu', 'steps', 'ugby', 'apparent', 'rep', 'cano', 'chio', 'urd', 'anta', 'hi', 'ес', 'бро', 'rep', 'though', 'script', 'frances', 'ferro', 'las', 'ligne', 'ceae', 'calls', 'eness', 'Roc', 'gres', 'оте', 'lah', 'songs', 'Row', 'AUT', 'Religion', 'стве', 'unas', 'setting', 'Ener', 'phere', 'vulner', 'sam', 'terre', 'programming', 'Stack', 'Unis', 'zv', 'got', 'gior', 'erade', 'kor', 'writing', 'jsf', 'writes', 'Star', 'пор', 'island', 'Ke', 'Osten', 'Studios', 'ju', 'wrote', 'song', 'hai', 'lie', 'verw', 'ati', 'rah', 'чёт', 'NN', 'Parliament', 'Tra', 'spe', 'Allen', 'ras', '�', 'iz', 'oy', 'rote', 'wedge', 'surv', 'vs', 'IONS', 'bot', 'lac', 'hers', 'writing', 'String', 'ohn', 'ці', 'Lob', 'raf', 'nost', 'tra', 'iano', 'ago', 'reven', 'bis', 'з', 'dro', 'mit', 'LM', 'Quint', 'Rece', 'ensus', 'Context', 'programming', 'sql', 'act', 'icator', 'Managed', 'eken', 'âce', 'Ju', 'ším', 'step', 'ности', 'actu', 'Cinema', 'Parlament', 'Вели', 'Thor']\n",
      "in Layer13 , sorted_indices_dimension5526:  ['Final', 'peat', 'elim', 'inal', 'CP', 'final', 'Kas', 'hold', 'Final', 'бка', 'arten', '止', 'umen', 'elimin', 'ola', 'ша', 'Qual', 'weis', 'apers', 'final', 'ent', 'semif', 'brackets', 'bau', 'atio', 'proceed', 'Pas', 'zi', 'ép', 'iet', 'ppet', 'proceeded', 'SD', 'Référence', 'Є', 'Minn', 'adre', 'FE', 'ini', 'endi', 'geprüft', 'carry', 'xi', 'FB', 'adv', 'стоя', 'erme', 'mer', 'ape', 'aru', 'lay', 'Dat', 'ended', 'districts', 'gan', 'imon', 'ді', 'rees', 'Gil', 'Eng', 'dispos', 'cmp', 'ani', 'commer', 'luc', 'duty', 'Si', 'books', 'terminal', 'hold', 'PA', 'retained', 'xx', 'Terminal', 'quarters', 'root', 'olas', 'prowad', 'ppa', 'Ћ', 'root', 'anten', 'aby', 'mont', 'Medal', 'roots', 'ề', 'Palmar', 'oca', 'erst', 'lap', 'municip', 'rai', 'ra', 'qual', 'cze', 'carried', 'onden', 'ssl', 'vil', '수', 'FB', 'ufe', 'Tree', 'Lund', 'datas', 'mér', 'ante', 'enden', 'Luc', 'stages', 'iewer', 'medi', 'Bac', 'infin', 'onto', 'Hou', 'vod', 'atica', 'orem', 'pis', 'Tree', 'utz', 'Selection', 'Tat', 'ấ', 'ending', 'од', 'mont', 'exha', 'Див', '้', 'ocket', 'Qual', 'cket', 'Thom', 'ipp', 'CP', 'ninger', 'buch', 'blast', 'Town', 'vice', 'RS', 'ɪ', 'avas', 'buttons', 'cho', 'inae', 'шее', 'ede', 'trees', 'pé', 'Books', 'iemann', '一', 'ano', 'perp', 'является', 'voke', 'locked', 'ounds', 'device', 'olin', 'Guide', 'seed', 'oppon', 'isher', 'Lil', 'Tele', 'ga', 'morph', 'au', 'aste', 'Bot', 'adratkilometer', 'gebru', 'facebook', 'ande', 'USE', 'Ё', 'tcp', 'ref', 'selection', 'porte', 'efficient', 'esterday', 'nacional', 'background', 'odi', 'sede', 'świ', '根', 'Background', 'carrying', 'ski', 'nil', 'dom', 'conf', 'iska']\n",
      "in Layer13 , sorted_indices_dimension4631:  ['Sar', 'iger', 'вро', 'lyn', 'ains', 'np', 'an', 'luck', 'Wilson', 'wil', 'ie', 'Wil', 'virtual', 'ธ', '置', 'virtual', 'iens', 'Rein', 'AML', 'ISO', 'lig', 'Schrift', 'rez', 'complement', 'dx', 'ought', 'Kaiser', 'ITE', 'rive', 'rey', 'suc', 'ieving', 'Sab', 'Scope', 'rod', 'imper', 'essel', 'ija', 'royale', 'CLA', 'desp', 'pare', 'sar', 'ゼ', 'anja', 'vig', '[\"', 'Хронологија', 'dub', 'Version', 'riv', 'Unterscheidung', 'Го', 'Virtual', 'Parameters', 'remainder', 'юза', 'Lauf', 'ĩ', 'lor', 'Version', 'numpy', 'ivan', 'zel', 'erk', 'deploy', '�', 'Ви', 'ança', 'ey', 'rait', 'kar', 'role', 'redu', 'сов', 'opera', 'line', 'lag', 'rick', 'ro', 'ously', 'culture', 'lands', 'expedition', 'konst', 'öst', 'Prop', 'Sus', 'ends', 'EM', 'ст', 'рож', 'lic', 'пове', 'pas', 'factory', 'ite', 'Zygote', 'step', 'dav', 'deployment', 'reboot', 'etzung', 'рови', 'rolling', 'roe', 'dispatch', 'vek', 'vre', 'CLI', 'Bowl', 'rei', 'end', 'Villa', 'reas', 'rat', 'olas', '葉', 'Olymp', 'answered', 'male', 'fug', 'Ley', 'fou', 'Ђ', 'rag', 'ius', 'iesz', 'House', 'rich', 'пе', 'passage', 'isme', 'cheval', 'tong', 'doors', 'kop', 'deport', 'lb', 'овин', 'ree', 'ately', 'schools', '/:', 'dx', 'emptyset', 'odb', 'num', 'Begriffe', 'anje', '/_', 'conqu', 'rifice', 'Culture', 'ív', 'rec', 'őd', 'istische', 'ney', 'mouse', 'rike', 'Ay', 'ąc', 'Album', 'excellent', 'Sint', 'kar', '�', 'Fort', 'review', 'fortune', 'ding', 'liga', 'произ', 'fort', 'believe', 'roll', 'ован', 'ste', 'ISO', 'surg', 'cube', 'eszt', '�', 'ln', 'aju', 'checked', 'DC', 'Ě', 'schaft', 'ListView', 'Legisl', 'bro', 'sugar', 'iers', 'eclipse', 'EY', 'kunst', 'itory', 'date']\n",
      "in Layer13 , sorted_indices_dimension6712:  ['jev', 'pas', 'adel', 'ر', 'Zw', 'yl', 'enem', 'ieu', 'enkins', 'Secretary', 'amet', 'graf', 'puis', 'Focus', 'lobal', 'iore', 'izers', 'ev', 'unicí', 'lé', 'roz', '�', 'accompl', 'ikan', 'hoff', 'ivos', '�', 'extrem', 'nar', 'ev', 'ง', '⋅', 'rangle', 'zaw', 'ovie', 'Township', '崎', 'vet', 'Bonn', 'る', 'Hamilton', 'fah', '成', 'beskre', '道', 'erno', 'mu', 'Fitz', '番', 'commit', 'рт', 'zes', 'VF', 'rew', 'inet', 'abit', 'Ez', 'verter', 'cock', 'ituto', 'Nar', 'pov', 'berg', 'gz', 'aucoup', 'бур', 'zw', 'ei', 'conversion', 'addr', 'landet', 'enten', 'useppe', 'viss', 'opposite', 'óp', 'enti', 'рак', 'DC', 'commit', 'Ost', '←', 'quer', 'plain', 'plorer', 'Oficina', 'accomp', 'projet', 'взя', 'Gott', 'iot', 'alone', 'uki', 'act', '銀', 'Lake', 'gly', 'Route', 'contrary', 'en', 'aci', 'тен', 'kc', 'Raz', 'secretary', 'abile', 'util', 'Wikip', 'cias', 'sight', 'ardo', 'UTE', '编', 'Kan', 'telep', 'éric', 'horn', 'tur', 'Ι', 'kie', 'semb', 'tir', 'itter', 'burn', 'Sig', 'conten', '�', 'macro', 'nem', 'suffer', 'も', 'Numbers', 'пун', 'vid', 'Az', 'Record', 'Rel', 'versch', 'etwork', 'ff', 'тур', '編', '\\\\)', 'Curt', 'tz', 'card', 'rencontre', 'focus', 'select', 'Wissenschaft', 'Running', 'Connection', 'trem', 'Pass', 'Sie', 'ere', 'inae', 'Ferdinand', 'itate', 'ènes', 'зь', 'Vict', '↑', 'nement', 'benchmark', 'Arc', 'structures', 'ville', 'VID', 'Pf', 'бе', 'ё', 'Wikipedia', '�', 'ὀ', 'Territ', 'xico', 'ISO', 'selector', 'zz', 'ючи', 'Tw', 'ochastic', 'WR', 'Thread', 'xp', 'wer', 'Federation', 'Dal', 'Wo', 'elet', 'pool', 'inand', 'enst', 'adó', 'gew', 'ages', 'Mount', '泉', 'QU']\n",
      "Key: model.layers.14.mlp.down_proj.weight\n",
      "in Layer14 , sorted_indices_dimension67:  ['ulu', 'Fel', 'ROR', 'ho', 'hop', 'Hop', 'amer', 'arp', 'Ign', 'istro', 'kens', 'bind', 'embargo', 'Bud', 'aha', 'Proc', 'opera', 'osof', 'nich', 'Cir', 'le', 'Herz', 'Musik', 'po', 'nten', 'zten', 'scope', 'trig', 'open', 'Pav', 'sc', 'budget', 'rera', 'ampion', 'contract', 'icio', 'genre', 'lea', 'pit', 'acs', '↑', 'Wer', 'doors', 'Formula', 'eds', 'inde', 'Morgan', 'ocket', 'parad', 'pio', 'oor', 'yman', 'agne', 'ану', 'predicate', 'anson', 'rance', '�', 'Pit', 'ulus', 'Opera', 'Parse', 'лях', 'ful', 'ulative', 'atti', 'igner', 'aben', 'ikt', 'auc', 'nung', 'pk', 'argo', 'ert', '溪', 'rinn', 'mob', 'ka', 'ября', 'izon', '\\u2003', 'ag', 'erton', 'cel', 'agr', 'away', 'ответ', 'ouw', 'izi', 'Stuart', 'missing', 'cook', 'reso', 'CV', 'ante', 'zza', 'harm', 'incomplete', 'ViewHolder', 'Env', 'args', 'spr', 'Bry', 'compose', 'mé', 'Ig', 'uche', 'assign', 'Dark', 'bin', 'eld', 'avor', 'ade', 'kop', 'purchase', 'Agr', 'ig', 'CONFIG', 'refix', 'Ful', 'popular', 'нан', 'ris', 'burn', 'ге', 'diction', 'Harm', 'agr', 'få', 'pok', 'racle', 'ati', 'criptor', 'anus', '�', 'Cel', 'ступил', 'Parse', 'fl', 'aby', 'bei', 'RewriteCond', 'avel', 'ала', 'approach', 'bud', 'ca', 'Kop', 'leaf', 'yz', 'сель', 'ania', 'mieszkań', 'íst', 'UL', 'folders', 'rame', 'Central', 'oom', 'Rich', 'нос', 'piano', 'icios', 'reign', 'addy', 'cz', 'CODE', 'Processor', 'merchant', 'тки', 'aven', 'napshot', 'sono', 'Jim', 'спо', 'oul', 'льный', 'azon', 'wohl', 'accessible', 'river', 'oll', 'CP', 'jar', 'DIR', 'erner', 'Av', 'ʎ', 'itzerland', 'поль', 'CCN', 'pool', 'az', 'ThreadPool', 'repr', 'oo', 'igt', 'Kl', 'atta', 'historiques']\n",
      "in Layer14 , sorted_indices_dimension2563:  ['dates', 'date', 'tom', 'Date', 'Date', 'DATE', 'date', 'apis', 'DATE', 'fecha', 'tom', 'emos', 'scheduled', 'partiellement', 'Engel', 'native', 'roph', 'dates', 'stwo', '于', 'ilio', '�', 'WHERE', 'sap', 'expos', 'argo', 'tomcat', '曲', 'Düsseld', 'DateTime', 'жен', 'native', 'aligned', 'oli', 'kbd', 'uni', 'days', 'come', 'omet', 'dalle', 'April', 'Совет', 'Zyg', 'dll', 'dated', '�', 'times', 'ogene', 'WH', 'omi', 'Neu', 'aqu', 'ден', 'rov', 'cattle', 'clock', 'idenote', 'asse', 'vent', 'ikus', 'doors', 'eduled', 'owe', 'Arc', 'irche', 'sv', 'historiques', 'Rolle', 'powiecie', 'uli', 'taire', 'совет', 'sem', 'Arg', 'broadcast', 'heim', 'DateTime', 'trop', 'asset', 'partecip', 'desar', 'Times', 'xls', 'au', 'mals', 'eness', 'perty', 'emble', 'cui', 'gior', 'liv', 'haft', 'étr', 'énd', 'retr', 'clock', 'dess', 'plut', 'col', 'ἡ', 'BC', 'weis', 'ByVal', 'odel', 'kh', 'Tomatoes', 'coming', 'arias', 'iformes', 'mant', 'infatti', 'ixon', 'żyn', 'nginx', 'mysq', 'liv', 'October', 'uent', 'Mouse', 'ános', 'WHERE', 'WHEN', 'tał', 'leur', '日', 'kaf', 'wen', 'hur', 'login', 'pů', 'jú', 'listade', 'particolare', 'aligned', 'registr', 'dex', 'empre', 'шти', 'kter', 'nez', 'û', 'нцикло', 'Broadcast', 'opera', 'docker', 'ieux', 'april', 'Argent', 'runtime', '弘', 'rze', 'hö', '�', 'DB', 'ре', 'sector', 'week', 'Хро', 'Public', 'Ю', 'wis', 'dic', 'Mouse', 'Castro', '�', 'sprach', '회', 'oscill', 'región', 'Smith', 'pril', 'Warner', 'dinner', 'iert', 'visibility', 'Sup', 'log', 'uet', 'mitt', 'ün', '比', 'Come', 'models', 'Urs', '식', 'rist', 'opsis', 'dated', 'IF', 'Datos', 'férences', 'aucoup', 'opp', 'iale', 'continu', 'Syn', 'datetime', 'public', 'држа', '造']\n",
      "in Layer14 , sorted_indices_dimension4345:  ['GA', '수', 'ад', 'propri', 'mil', 'porte', 'ivel', 'adal', 'zz', 'tel', 'ES', 'asant', 'osen', 'osed', 'рез', 'nde', 'тра', 'ieck', 'icol', 'vis', 'Prize', '트', 'guard', 'Hal', 'cks', 'лки', 'rou', 'wor', 'غ', 'Mil', 'Jakob', 'vent', 'vex', 'rep', 'CS', 'pf', 'guard', 'Promise', 'mil', 'uen', 'Dra', 'Mil', 'Españ', 'perce', 'reducible', 'ga', 'wick', 'selected', 'ardin', 'visual', 'seg', 'modal', 'Matth', 'чь', 'iven', 'orf', 'Aires', 'bek', 'reaction', 'rou', 'xp', 'Visual', 'decor', 'ail', 'lifetime', 'te', 'Antoine', 'Response', 'halt', 'Emil', 'Colors', '松', 'zess', 'agh', 'rip', 'selected', 'Mock', 'random', 'iedz', 'ной', 'Cs', 'gh', 'comp', 'sero', 'curs', 'embed', 'visual', 'ے', 'plan', 'URI', 'criter', 'Ez', 'contre', '服', 'ciel', 'allas', '府', '∗', 'math', 'embedded', 'Term', 'ével', 'BD', 'gravity', 'zw', 'mina', 'Math', 'Meta', 'vity', 'ovan', 'opro', 'Reform', 'Kas', 'Giov', 'colors', '�', 'gebras', 'Visual', '光', 'čka', 'Select', 'params', 'math', 'Ehren', 'emot', 'ople', 'Ga', 'kre', 'parties', 'по', 'household', 'forces', 'repe', 'vin', 'orm', 'Zum', 'Jed', 'Erd', 'bei', 'modal', 'zam', 'éal', 'iments', 'ghan', 'omány', 'Rep', 'beskre', 'guid', 'tot', 'Seg', 'manifest', 'select', 'Vertrag', 'нин', 'ガ', 'Esp', 'random', 'Seg', 'ouvel', 'una', 'amma', 'easiest', 'urch', 'oem', 'Forum', '池', 'ails', 'Wir', 'wrap', 'party', 'wheel', 'лка', 'inner', 'igan', 'Heil', 'Selected', 'Rosa', 'forum', 'СССР', 'react', 'Random', 'pat', 'auch', 'га', 'stract', 'фев', 'mana', 'idge', 'aum', 'anos', 'rep', 'platforms', 'gram', 'Prom', '管', 'ieder', 'ỳ', 'plans', 'пли', 'anz']\n",
      "in Layer14 , sorted_indices_dimension5957:  ['Institution', 'ateg', 'Longrightarrow', 'sop', 'Ros', 'iki', 'gros', 'če', 'кт', 'clos', 'closure', 'MDb', 'arbeit', 'defect', 'ymi', 'SA', 'keiten', 'clos', 'rijk', 'ńst', 'ita', 'Garc', 'ium', 'alse', 'olar', 'increment', 'sel', 'DL', 'Lady', 'NT', 'HE', 'compose', 'urop', 'arius', 'сла', 'wicklung', 'lady', 'osi', 'ře', 'DC', 'ivel', 'othek', 'Orchestra', 'criv', 'anto', 'orem', 'HE', 'aller', 'Martínez', 'Schne', 'ê', 'Tax', 'CNN', 'olare', 'saf', 'Crime', 'VP', 'örd', 'istro', 'acyj', 'plugins', 'elo', 'Village', '交', 'eli', 'lop', 'Riv', 'decla', 'Category', 'Count', 'ewrite', 'clock', 'written', 'Cec', 'Ce', 'efficient', '界', 'closure', 'escrit', 'Bes', '유', 'pyg', 'riers', 'Cle', '商', 'łu', 'Bez', 'Archiv', 'rv', 'Museum', 'bat', 'Writ', 'crit', 'architect', 'Bras', 'ros', 'uset', 'okrę', 'ǔ', '∗', 'ikan', 'wordpress', 'merk', 'alberga', 'oct', 'ocument', 'lus', 'letter', 'Kno', 'фамилией', 'catalina', 'EP', 'ší', 'Eliz', 'jen', 'Een', 'clock', 'disambiguation', 'ós', 'casting', 'пись', 'lbl', 'wife', 'Hel', 'Career', 'zą', 'шње', '│', 'Hel', 'Prof', '/#', 'batch', 'át', 'cry', 'faire', 'bog', 'mittel', 'consulté', 'ɾ', 'країн', 'ael', 'фами', 'Trad', 'зня', 'udni', 'nica', 'ják', '➖', 'uf', 'ons', 'ség', 'Harm', 'rinn', 'steller', 'GM', 'zess', 'lade', 'Villa', 'Braun', 'blica', 'category', 'mig', 'Salv', 'dov', 'нова', 'mart', 'iller', 'lei', 'článku', 'ago', 'vik', 'bez', 'nav', 'ppa', 'agnostics', 'бора', 'burning', 'dove', 'kle', 'institution', 'Oper', 'buffer', 'ui', 'anton', 'interval', 'zug', 'bes', 'belle', 'ких', 'bird', 'Rosen', '守', 'fait', 'Resource', 'tart', 'ši', 'Cast', 'asia', 'externas', 'ці']\n",
      "in Layer14 , sorted_indices_dimension6059:  ['LENG', 'Lomb', 'Temp', 'örd', 'fox', 'Express', '명', 'dex', 'ixen', 'letin', 'clud', '▼', 'ína', 'ensk', 'itled', 'olean', 'azione', 'тник', 'Lok', 'úblic', 'Mix', 'unic', 'othèque', 'Wikip', 'Connect', 'vä', 'abl', 'Express', 'eso', 'çais', 'ąż', 'Fox', 'onic', 'regon', 'MDb', 'fir', 'uet', 'éal', 'Muhammad', 'lius', 'Temp', 'utto', 'rias', 'nown', 'ächst', 'info', 'uis', 'Bildern', 'Explorer', 'annel', 'jin', '情', 'Zach', 'metros', 'Thread', 'пов', '开', 'sson', 'imon', 'менталь', 'atalog', 'tres', 'Moz', 'situ', 'ках', 'boa', 'olare', 'Düsseld', 'Rec', 'Thread', 'információk', 'ippi', '果', 'Chr', 'Unidos', 'Affairs', 'leased', 'pau', 'anel', 'EQ', 'bew', 'Imp', 'ikel', 'native', 'су', 'gener', 'lease', 'Leop', 'agar', 'itel', 'LOB', 'lé', 'share', 'lassen', 'compan', 'awa', 'Utils', 'ließ', 'kwiet', 'vál', 'ų', 'Fischer', 'Move', 'idia', 'ttemberg', 'nerv', 'asons', 'Deleg', 'ytu', 'Lage', 'sust', 'uliar', 'stuff', 'Sic', 'icher', 'Daw', 'INFO', 'lichkeit', 'gew', 'ése', 'SError', 'iera', 'express', 'fty', 'sierp', 'oure', 'iftung', 'Fichier', 'pid', 'ší', 'zett', 'agraph', 'agua', 'avam', 'pela', 'Przyp', 'pe', 'uria', 'connect', 'maps', 'mez', 'ilt', 'єю', 'che', 'ódigo', 'циональ', 'tto', 'cyc', 'lift', 'mix', 'affair', 'ras', 'ähr', 'Imp', 'Lock', 'Akadem', 'ads', 'Dort', 'chmark', 'Sele', 'Scope', 'ütt', 'camb', '�', 'eria', 'Wort', 'execut', '़', 'ą', 'zz', 'ored', 'factors', 'Specific', 'African', 'побе', 'atore', 'ienia', 'hrte', 'anch', 'urity', 'affection', 'factor', 'ksam', 'ktr', 'ouri', 'vic', 'rek', 'phas', 'Nobel', 'vin', 'find', 'athon', 'bad', '=`', 'adr', 'Creek', 'ców', 'ся', 'unos', 'aucoup']\n",
      "in Layer14 , sorted_indices_dimension7791:  ['zug', 'Wit', 'replaced', 'rache', 'Airl', 'artific', 'unden', 'aye', 'osto', 'Cav', 'ек', 'pto', 'Pri', 'atus', 'erton', 'Scan', 'incie', 'ulas', 'alet', 'fur', 'Content', 'engelsk', 'cab', 'lieu', '☺', 'Load', 'TAC', 'pri', 'adel', 'ECT', 'ependant', '津', 'secret', 'voj', 'reverse', 'тник', 'Durant', 'reverse', 'spre', 'ifique', 'tact', 'itter', 'mouv', 'ogene', 'artificial', 'lassen', 'lie', 'priest', 'Trib', 'ego', 'kow', 'ect', 'ть', 'pal', 'Replace', '🌍', 'irc', 'vre', 'Sam', 'fir', 'eben', 'replace', 'ado', 'pon', 'ein', 'opera', 'urr', 'ierto', 'replacing', 'ród', 'dan', 'ugins', 'fang', 'ither', 'Pic', 'Sc', 'adora', 'Mag', 'ounds', 'surve', 'bek', 'eton', 'äischen', 'везе', 'удо', 'ados', 'Sever', 'ades', 'een', 'circumstances', 'zast', 'iech', 'elenium', 'retro', 'кры', 'preis', 'partidos', 'hre', 'argo', 'äger', 'DD', 'ellan', 'рин', 'ebb', 'dynamics', 'wan', '\\xa0\\xa0\\xa0\\xa0', 'ого', 'Content', 'gene', 'attached', 'Prize', 'electric', 'lect', 'texte', 'newline', 'öh', 'angol', 'ERT', '\\x82', '�', 'oo', 'fault', 'ieben', 'agna', 'вме', 'miejsce', 'Howard', 'Begr', 'RT', 'unic', 'forg', 'élé', 'ools', 'ugin', 'replace', 'ity', 'DA', 'Dit', '载', 'Vé', 'secret', 'aute', 'Від', 'horse', 'Selected', 'секре', 'reen', 'ския', 'lan', 'Bret', 'scan', 'orry', 'г', 'Cost', 'Boh', 'entin', 'Ve', 'cipl', 'стра', 'reply', 'classic', 'zych', 'lá', 'oning', 'Zyg', 'ContentView', 'yar', 'uka', 'cav', 'míst', '☉', 'ox', 'aglia', 'asures', 'osos', 'jan', 'possibil', 'Alignment', 'eredet', 'say', 'lecture', 'Cab', 'Yan', 'atr', 'desar', 'vert', '包', 'Sebastian', 'ongodb', 'binom', 'TextView', 'Contents', 'fér', 'isolated', 'язы', 'apo', 'effort', 'ox', 'савез']\n",
      "in Layer14 , sorted_indices_dimension10777:  ['asto', 'рела', 'Pok', 'Chamber', 'amento', 'zyż', 'pił', 'esia', 'sug', 'ordnet', 'ké', 'pec', 'decla', 'perty', 'ington', 'uns', 'сте', 'uder', 'zen', 'hos', 'oles', 'gam', 'metro', 'hd', 'chev', 'Saf', 'ね', 'til', '⁻', 'Gam', 'RAM', 'communauté', 'objects', 'esc', 'Lexikon', 'hein', 'тил', 'ós', '对', 'références', 'Permission', 'зо', 'HD', 'São', 'anda', 'mathchar', 'là', 'ftp', 'upd', 'сп', 'Bürger', 'andas', 'ʒ', 'ъл', 'еди', 'binding', 'Gemeins', 'étant', 'IO', 'magn', 'undial', 'ística', 'itten', 'uchs', 'cpy', 'ългар', 'reci', 'chant', 'обо', 'Lors', 'бом', 'reci', 'cross', 'scene', 'Cob', 'oid', 'LOG', 'пло', 'sla', 'versión', 'Version', '頭', 'amentos', 'données', 'visibility', 'ipeline', 'vard', 'nyelven', 'readsheet', 'Zum', 'gest', 'száz', 'Martín', 'alla', 'wind', 'microsoft', 'IO', 'unk', 'Gest', 'zan', 'zz', 'Domain', 'бо', 'iem', 'ort', 'Category', '⁄', 'Pero', 'rug', 'mist', 'ц', 'ram', 'мії', 'metros', 'omorphic', 'asta', '久', 'zu', '�', 'вал', 'ді', 'Wort', 'Sug', 'ogonal', 'projekt', 'safety', 'mier', 'alle', 'már', 'relac', 'profile', 'beaut', 'inf', 'Microsoft', 'improv', 'cloudflare', 'abase', 'Rem', 'Log', '산', 'Jó', 'Palmarès', 'ft', 'Hash', 'versione', 'fün', '🌍', 'castle', 'ча', 'лага', 'orch', 'context', 'Vin', 'lez', 'upp', 'vendor', 'parameters', 'jähr', 'Projects', 'lambda', 'Cinema', 'ermo', 'válto', 'eredet', 'Aless', 'ettbe', 'Opera', 'texte', 'ズ', 'Polen', 'deep', 'inte', 'mongo', 'rola', 'Rem', 'nement', ')$-', 'stor', '÷', 'Eth', '$-', 'bent', 'ram', 'レ', 'nelle', 'Jed', 'erne', '...)', 'Ru', 'ℓ', 'rita', 'ugo', 'unch', '�', 'older', 'comun', 'Syl', 'Bridge', 'сти', 'Context']\n",
      "in Layer14 , sorted_indices_dimension10459:  ['repeat', 'history', 'repeating', 'repeat', 'repet', 'experience', 'history', 'mistakes', 'History', 'History', 'mistake', 'avoid', 'prevent', 'pattern', 'déjà', 'similarity', 'repe', 'past', 'parallel', 'pattern', 'paste', 'warn', 'ca', 'echo', 'historia', 'warning', 'previous', 'истории', 'Pattern', 'oi', 'рт', 'similar', 'identical', 'avoided', 'repeated', 'Past', 'patterns', 'duplicate', 'Ï', 'echo', 'Hy', 'same', 'iso', 'outcome', 'prevents', 'experiences', 'uben', 'again', 'warnings', 'Pattern', 'cycle', 'drawn', 'apest', 'Pit', 'memory', 'clone', 'draw', 'Thread', 'Sug', 'Thread', 'rép', 'ituto', 'дон', 'umerate', 'Geschichte', 'ience', 'rep', 'Lad', 'paste', 'peat', 'warn', 'sugar', 'refresh', 'hash', 'ellers', 'spir', 'iteration', 'similar', 'Hog', '未', 'pain', 'zych', 'previous', 'archar', 'comparison', 'prevent', 'retto', 'Similar', 'dil', 'lear', 'pit', 'hash', 'igare', 'тва', 'liquid', 'liberty', 'hist', 'same', 'Hill', 'Warning', 'aran', '宗', 'eer', 'musical', 'payment', 'reprodu', 'ban', 'span', 'osed', 'Sm', 'bean', 'orf', 'learned', 'run', 'Same', 'benefit', 'Hy', 'Hyper', 'Ali', 'threads', 'ö', 'ů', 'Kaiser', 'Whe', 'oux', 'fast', 'Msg', 'drew', 'oline', 'История', 'familiar', 'unto', 'fast', 'draw', 'Warning', 'libre', 'округа', 'allo', 'uela', 'ależ', 'alet', 'sterreich', 'svě', 'txt', 'less', 'error', 'уні', 'ested', 'thread', 'recom', 'setAttribute', 'lane', 'Hash', 'Sim', 'histoire', 'hren', 'atting', 'iwers', 'ově', '支', 'równ', 'tw', 'eria', 'HT', 'lava', 'eur', 'getText', 'oil', 'hyper', 'órico', 'prohib', 'oslov', 'propriet', 'Draw', '�', 'Hash', 'concurrent', 'ooth', 'ân', 'vä', 'caption', 'HT', 'Ξ', 'years', 'ових', 'PHP', 'central', 'Λ', 'learn', 'prede', 'Musical', 'pro', 'dé', 'profit', ']).', 'lear', 'historical', 'yc', 'zewnętrz', 'event']\n",
      "in Layer14 , sorted_indices_dimension1182:  ['uld', 'dessen', 'electric', 'spole', 'zes', 'WID', 'recens', 'ôt', 'omy', 'zas', 'Lob', 'át', 'tx', 'desar', 'ype', '_{-', 'TX', 'комп', 'ander', 'rm', 'adrat', 'Palmar', '�', 'zw', 'inte', 'xaml', 'embedded', 'Ru', 'infatti', 'ror', 'mill', 'iki', 'spot', 'тури', 'UTE', 'պ', 'nam', 'rar', 'ież', 'trick', 'sp', '由', 'spaces', 'uration', 'джи', 'rito', 'ว', 'ucion', 'HI', 'ute', 'perty', 'geme', 'attice', 'izard', 'cura', 'blogs', 'зан', 'zam', 'ione', 'ROUP', 'isch', 'CI', 'vict', '�', 'Got', 'lder', 'struct', 'zen', 'à', 'mn', '현', 'var', 'zv', 'ld', 'nim', 'Insel', 'Selected', 'borg', 'ru', 'height', 'fres', 'ph', 'Runtime', 'пута', 'Sax', 'СР', 'Janeiro', 'spr', 'Bath', 'ERE', 'Hint', 'mill', 'urity', 'lade', '⁻', 'bridge', 'Services', 'uta', 'посе', 'spre', 'itung', 'вест', 'ź', 'UC', 'дат', 'マ', 'lag', 'Zyg', 'embedding', 'Senate', 'Manchester', 'Planet', 'ם', 'Binary', 'loader', 'ppen', 'pod', 'reno', 'ientí', 'до', 'owane', 'Electric', 'ша', '역', 'planet', 'ю', 'remote', 'Lage', 'Congrès', 'imin', 'ло', 'Id', 'undle', 'Ids', 'loading', 'utor', 'ider', 'uten', 'ursive', 'då', 'eny', 'cija', 'î', 'inclusion', 'tips', 'pł', 'oty', 'gap', 'pool', 'chain', '橋', 'itats', 'Krie', 'Burg', 'contest', 'illet', 'Bowl', 'Error', 'stad', 'Mur', 'chrome', 'services', 'añ', '무', 'Mercur', 'oti', 'Services', 'buntu', 'DAT', 'imenti', 'bf', 'ichi', 'mana', 'rons', 'üg', 'piano', 'iai', 'unci', 'Mau', 'ampa', 'spot', '@@', 'Plus', 'enda', 'pue', 'mai', 'ako', 'orn', 'écrit', 'мат', 'Series', 'Pologne', 'Mal', 'num', 'Mas', 'PHP', '♭', 'arto', '电', 'LIM']\n",
      "Key: model.layers.15.mlp.down_proj.weight\n",
      "in Layer15 , sorted_indices_dimension7079:  ['ímp', '◄', 'oreign', 'ʌ', 'gresql', 'vens', 'Bass', 'jú', 'пет', 'ета', 'Ṭ', 'nten', 'archivi', 'sers', 'DB', 'Denkmal', 'elter', 'ser', 'imes', 'rugu', 'vice', 'czas', 'itmap', 'лаго', 'gior', 'kwiet', 'sierp', 'Vitt', 'ńska', 'vo', 'uen', 'vez', 'Ћ', 'nac', 'vos', 'fico', 'textt', 'Städ', 'ext', 'Anleitung', 'Hinweis', 'aszt', 'ua', 'ʋ', 'oem', 'Leopold', '⊕', 'CCE', 'NU', 'alu', 'xim', 'quez', 'Bürger', 'veg', 'ächst', 'èque', 'sert', 'ǧ', 'гово', 'ountry', 'пун', 'Primera', 'Xcode', 'Staaten', 'esian', 'ší', 'ennes', 'ゼ', 'BIT', '---+', 'otr', '拳', 'vess', 'Przyp', 'NB', 'Frau', 'prüfe', 'iba', 'ális', 'races', 'ingsområ', 'Љ', 'imb', 'ipeline', 'сона', 'ît', 'Pub', 'lack', 'Mit', '²).', 'urm', '⊂', '드', 'Vertrag', 'vest', 'нию', 'Dob', '衛', 'pse', 'Martínez', 'ὺ', 'ủ', 'pau', 'staw', 'iels', 'прия', 'ína', 'шње', 'урна', 'Airport', 'Async', 'Exit', 'fest', 'ictwo', 'Kob', 'spole', 'Unterscheidung', 'Shell', 'makeText', 'Net', 'ĩ', 'Хронологија', 'таль', 'parator', 'ẓ', 'ữ', 'Ἀ', 'ówn', 'zna', 'WID', 'NS', 'ὶ', 'gepubliceerd', 'età', 'Bedeut', 'iry', 'regnigaste', 'Џ', 'beans', ']_', 'torraste', 'iből', 'dział', 'conse', 'iker', 'ibil', 'Ziel', 'maste', 'xcode', 'superfic', 'bass', 'werk', 'Norweg', 'Begriffe', 'arth', 'ouest', 'Tras', 'oun', 'ępu', 'Einzeln', 'ckså', 'istrzost', 'Jeux', 'ศ', 'Έ', 'orch', 'exit', 'сп', 'zb', 'Ale', 'pub', 'bos', 'temperaturen', 'Référence', '▸', 'Gemeins', '⇔', 'ℓ', 'pit', 'key', 'atem', 'nica', 'andbox', 'dou', 'Lawrence', 'bo', 'sef', 'Weltkrieg', 'perf', 'cije', '⟩', 'pmatrix', 'ícula', '⊗', 'Ő', 'жить', 'ientos', 'ViewById', 'ísticas', 'Ext']\n",
      "in Layer15 , sorted_indices_dimension10825:  ['ite', 'ie', '�', '�', '�', 'se', 'uce', 'ife', 'USA', 'เ', 'ia', '지', 'USA', 'ITE', 'ka', 'се', 'azine', 'ние', 'oe', 'IME', 'ione', 'ies', 'che', 'ye', 'cipe', 'ma', 'Lake', 'usa', 'le', 'ne', 'me', 'Maurice', 'mes', 'e', 'IO', 'ya', 'ko', 'nake', 'ue', 'te', 'ura', 'lace', 'aceae', 'GA', 'ba', 'рое', 'ühl', 'TA', 'рук', 'зо', 'ono', 'ceae', 'bra', 'ua', 'uate', 'še', 'efined', 'ge', 'na', 'ites', 'pse', 'бе', 'ce', 'né', 'ö', 'anda', '�', 'Mine', '�', 'u', 'scriptstyle', 'á', 'nie', 'IE', 'Sue', 'гани', 'brace', 'de', '⊆', 'ace', 'face', 'faces', '=~', 'кой', 'ae', 'uis', 'II', 'dece', 'bra', 'ime', '--+', 'mine', 'scribe', 'o', 'ouses', 'autory', 'iba', 'media', 'pace', 'ote', 'abe', 'ico', 'Wayne', 'mine', 'una', 'ure', 'ipes', 'CO', 'ato', 'ba', 'tree', 'po', 'пла', 'amar', 'io', '�', 'Medicine', 'ío', '️', 'ätze', 'xe', 'ablo', 'yo', 'Bet', 'UIImage', 'hou', 'une', 'aine', 've', 'ła', '有', 'moyenne', 'here', 'uous', 'phe', 'ene', 'ía', 'ば', 'ovi', 'je', 'iből', '�', 'фа', 'Ole', 'чество', 'те', 'javax', 'Tree', 'ra', 'ena', 'место', 'Ге', 'house', 'ße', 'ine', '题', 'Haz', 'rea', 'ike', 'Palace', 'pla', 'aware', 'Institute', 'lacement', 'auer', 'Sierra', 'ito', '示', 'ouse', '여', 'ourse', 'ble', 'da', 'blue', 'anta', 'bo', 'heimer', 'oser', 'é', 'enson', 'inae', 'cave', 'medicine', '�', 'bla', 'race', 'arma', 'geo', 'oem', 'ische', 'BU', 'sr', 'Liber', 'мой', 'zę', 'кие', 'Laura', 'ta', 'equation', 'SE']\n",
      "in Layer15 , sorted_indices_dimension7978:  ['vague', 'ambigu', 'guessing', 'incomplete', 'clar', 'unclear', 'obox', 'crypt', 'guess', 'Clar', 'Without', 'lack', 'vec', 'rov', 'missing', 'specify', 'prompt', 'char', 'without', 'cow', 'susp', 'prob', 'lack', 'sufficiently', 'ambigu', 'extract', 'Grey', 'reactjs', 'alse', 'Cow', 'cue', 'crete', 'пра', 'ery', 'char', 'clarify', 'enough', 'цю', 'plays', 'dr', 'mond', 'uc', 'narrow', 'cho', 'rio', 'nero', 'etti', 'clue', 'sufficient', 'general', 'contain', 'atra', 'limited', '요', 'antal', 'without', 'ALSE', 'card', 'UC', 'pshire', 'information', 'clar', '省', 'Specific', 'dimensional', 'icha', 'generic', 'Star', 'cow', 'рист', 'RT', 'bey', 'Orient', 'udo', 'undefined', '書', 'emp', 'Spec', 'Question', 'RY', 'wald', 'ev', 'ql', 'extract', 'hina', 'extracted', '†', 'ué', 'ḷ', 'externes', '**', 'живело', 'Historic', 'abstract', 'rame', 'ря', 'лено', 'Wor', '➜', 'varchar', 'gram', 'hus', '信', 'iast', 'ographique', 'info', 'Void', 'ade', 'Root', 'arel', 'asked', 'Express', 'CL', 'explicit', 'wal', 'dr', 'orno', 'specific', 'prov', 'acu', 'withdraw', 'ror', 'Shape', 'mv', 'canvas', 'shape', 'PS', 'efined', 'lär', 'uba', 'odon', 'incor', 'conj', 'minimal', 'shapes', 'äu', 'klär', 'PS', 'activ', 'ague', 'lish', '↓', 'ientos', 'isch', 'router', 'sympt', 'questions', 'dry', 'undefined', 'shape', 'amen', 'detail', 'unda', 'tant', 'chant', 'rome', 'ifa', 'hören', 'pio', 'Action', 'Ti', 'hez', 'ail', 'ім', 'supplies', 'craft', 'iri', 'angularjs', 'é', 'sketch', 'oken', 'risk', 'rys', 'capital', 'agy', 'encourag', 'ty', 'stract', 'Star', 'rypted', 'Ï', 'encrypted', 'sedan', 'pi', 'rir', 'English', 'canvas', 'ymbol', 'void', 'bau', 'Ä', 'MY', 'maps', 'ig', 'aco', 'psi', '\\x9d', 'äch', 'generic', 'prime']\n",
      "in Layer15 , sorted_indices_dimension7086:  ['ʒ', 'brázky', 'Republik', 'Republic', 'ption', 'presente', 'azz', 'republic', 'familjen', 'ży', 'Leopold', 'ugust', 'vice', '風', '親', 'vé', 'Grund', 'ect', 'parenthes', 'Ď', '还', 'kter', 'zett', 'stream', 'пун', 'ames', 'zt', 'Storia', 'antics', '◄', 'ml', 'Serv', 'člán', '{\"', 'cabin', 'havet', 'зом', 'sky', 'giv', 'Japon', 'TR', 'cro', 'SELECT', 'ü', 'Cinema', 'ifier', 'SELECT', 'lax', 'oken', 'aki', 'ari', 'fik', 'NU', 'tbl', '明', 'ˆ', 'vista', 'зик', 'Ferd', 'inct', 'orden', 'області', 'anka', 'LINQ', 'zm', 'Opera', 'interview', 'hold', 'dici', 'vy', 'reich', 'Ni', 'stadt', 'Frankreich', 'änger', 'istrzost', 'dek', 'Deutschland', '<!', 'gepubliceerd', 'cub', '�', 'län', 'é', 'öh', 'Dir', 'spole', 'ա', 'éc', 'trick', 'må', 'lung', 'Germania', 'top', 'ün', 'Серг', 'Repub', 'ью', 'wit', 'height', 'ublic', 'icional', 'Britannica', 'Nations', 'vés', 'oda', 'нен', 'forte', 'maven', 'NaN', 'substring', 'བ', 'vu', 'ins', 'poque', 'poz', 'rör', 'êm', 'ichter', 'consid', 'nx', 'ни', 'рё', 'dém', 'öll', 'authorization', 'NI', 'UEFA', 'cro', 'ol', 'oso', 'ion', 'opera', 'ט', 'Begriffsklär', 'пада', 'Serv', 'Fut', 'lease', 'pił', 'ess', 'Ћ', 'itel', 'Alexandre', 'Desp', 'aucoup', 'provin', '╔', 'Ṣ', 'сылки', 'chi', 'należ', 'powie', 'fé', 'Vice', 'ÿ', 'soort', 'strutt', 'or', 'bran', 'ther', 'ação', 'сор', 'Stream', 'zvuky', 'alia', 'mozilla', 'ografia', 'wz', 'long', 'Castro', 'ί', 'prés', '안', 'Garc', 'Premio', 'ifiers', 'спе', 'skim', 'Reserve', 'Fields', 'Raymond', 'ario', 'ɯ', 'Syntax', 'ura', 'sympathy', '<\\\\', 'Span', 'Schauspieler', '̥', 'Guillaume', 'xi', '{|', 'zak', 'листо', 'serv', 'set', 'dependence', 'aterra']\n",
      "in Layer15 , sorted_indices_dimension6771:  ['spin', 'success', 'tout', 'claim', 'positive', 'statistics', 'report', 'Operation', 'numbers', 'дости', 'magn', 'counts', 'narr', 'report', 'credit', 'tout', 'pra', 'stat', 'tot', 'reporting', 'pitch', 'counted', 'ude', 'bo', 'fe', 'victory', 'claimed', 'counting', 'boost', 'ово', 'proc', 'absolv', 'stat', 'tid', 'stories', 'vol', 'Lomb', 'ณ', 'announ', 'mis', 'achiev', 'è', 'record', 'tro', 'Tout', 'ros', 'numbers', 'Report', 'boost', 'jective', 'onaut', 'Ek', 'failure', 'Fe', 'plat', 'quant', 'pus', 'maj', 'cheer', 'tr', 'metric', 'aggreg', 'Stat', 'claims', 'Pra', 'ira', '算', 'Activity', 'bil', 'FE', 'rör', 'scal', 'impress', 'valor', 'stats', 'bil', 'numer', 'xt', 'true', 'mas', 'reports', 'Success', 'iene', 'Vol', 'declare', 'sugar', 'ante', 'Statistics', 'excited', 'total', 'lab', 'Opt', 'result', 'Progress', 'show', 'ante', 'triumph', 'outcome', 'looking', 'cattle', 'metrics', 'beskre', 'ege', 'optim', 'anne', 'ycz', 'w', 'loss', 'win', 'Bil', 'ws', 'var', 'OF', 'ror', 'PR', 'во', 'figures', 'optim', 'orde', 'ima', 'metric', 'Magn', 'opera', 'progress', 'proud', 'aggregate', 'osz', 'loss', 'success', 'lab', 'iev', 'reported', 'otal', 'rag', 'met', 'S', 'reading', 'ovo', 'ann', 'thr', 'bene', 'Lab', 'orph', 'impression', 'declaring', 'Fe', 'oting', 'man', 'Ac', 'true', 'count', 'grande', 'meg', 'gl', 'Operation', 'pret', 'tam', 'magnitude', 'vie', 'reading', 'Core', 'ols', 'Mars', 'stats', 'lesia', 'mart', 'Process', 'Head', 'circ', 'number', 'ilon', 'Ende', 'raw', 'otherwise', 'count', 'override', 'statement', 'br', 'num', 'pad', 'asing', 'rug', 'Story', 'eg', 'ured', 'win', 'PR', 'false', 'statement', 'neur', 'story', 'legacy', 'cred', 'ros', 'Number', 'accomplish', 'logs', 'Activity', 'Wir', 'glo']\n",
      "in Layer15 , sorted_indices_dimension4127:  ['anta', 'hos', '◄', 'Gemeins', 'Screen', 'Außer', 'Pere', 'ญ', 'wach', 'iek', 'hner', 'usammen', 'epen', 'talet', 'Przyp', 'Screen', 'desar', 'łów', 'город', 'ower', 'ому', 'hover', 'noreferrer', 'wert', 'acions', 'anth', '�', '명', 'ril', 'Mär', 'ти', 'Unterscheidung', 'future', 'ран', 'Total', 'фер', 'priority', 'ühl', 'eti', 'enberg', 'ɨ', '국', 'isol', 'economy', 'Rest', 'postgresql', 'Jahrh', 'jsp', 'esterni', 'lapse', 'ồ', 'WID', 'gar', 'Actions', 'Future', 'ambiguation', 'ué', '起', 'leich', '(/', 'net', 'fried', 'ikal', 'rup', 'кому', 'голо', 'چ', 'мет', 'ław', 'bere', 'halt', 'тии', 'cin', 'Airl', 'minipage', 'embros', 'yours', 'oa', 'burg', 'itted', 'fb', 'oi', 'hui', 'Sus', 'ousel', 'await', 'iento', 'yond', 'orie', 'зни', 'Narod', 'lá', 'ori', 'iből', 'connexes', 'oris', 'Virtual', 'Total', 'тие', 'poj', 'akte', 'cour', 'fare', 'май', 'isEmpty', 'ható', 'vet', '̃', 'ų', 'mouv', 'бка', 'ři', 'stra', 'лав', 'Wikipédia', 'unft', 'tick', 'чни', 'äg', 'ți', 'haupt', 'Future', 'чество', '̥', 'mark', '.:\\u200a', 'ędz', 'Sender', 'weit', 'von', 'рё', 'ников', 'ply', 'nav', 'confirm', 'Jac', 'яз', 'autorité', 'flag', 'latter', 'final', 'dabei', 'Straßen', 'umerate', 'tabular', 'transition', 'arring', 'Forces', 'zös', 'łącz', 'дами', 'arie', 'forces', 'Net', 'вое', 'étique', 'mq', 'lei', 'mesh', 'Fuß', 'commun', 'anos', 'composition', 'differential', 'selves', '†', 'halten', 'een', 'Dabei', 'onom', '^(', 'lipca', 'óż', 'gende', 'hof', 'vote', 'ры', 'dialect', 'className', 'into', 'anti', 'Ко', 'Spe', 'secure', 'osen', 'жил', 'steller', 'ńskiego', '�', 'ês', 'century', 'total', 'Parent', 'uest', 'baum', 'East', 'gele', 'མ', 'ਿ', 'ө']\n",
      "Key: model.layers.16.mlp.down_proj.weight\n",
      "in Layer16 , sorted_indices_dimension1600:  ['lete', 'agr', 'al', 'town', 'yle', 'rod', 'aris', 'spring', '持', 'diffusion', 'Kre', 'spr', 'iu', 'kre', 'Spr', 'stad', 'ute', 'udni', 'Du', 'reate', 'vale', 'esk', 'ade', 'nucle', 'vil', 'Oficina', 'ijk', 'town', 'ari', 'circum', 'Mach', 'Spring', 'alm', 'ioso', 'Julian', 'aszt', 'center', 'ilen', 'Hen', '.__', 'withdraw', 'ymnas', 'alph', 'yes', 'iante', 'ingo', 'listing', 'ellett', 'ion', 'rikt', 'acts', 'verz', 'Mars', 'enum', 'ване', 'Opera', 'kom', 'etzt', 'izers', 'rade', 'kem', 'тся', 'Train', 'Tras', 'Tang', 'Thompson', 'czy', 'bat', 'PU', 'incie', 'cze', 'iser', 'thou', 'Jeux', 'audi', 'enu', 'elia', 'ame', 'phen', 'ствовал', 'spring', 'Mask', 'stadt', 'kwargs', 'umn', 'Lew', 'isson', 'mos', 'legraph', 'le', 'isons', '╔', 'sg', 'cas', 'contents', 'Spring', 'Mitte', 'flows', 'capit', 'constant', 'apt', 'manus', 'aders', 'вод', 'aff', 'Rod', 'aly', 'puzz', 'Dist', 'LETE', 'lä', 'caps', 'rund', 'orde', 'right', 'leid', 'Stadium', 'erde', 'Mart', 'pez', 'atalog', 'bol', 'Lors', 'r', 'izio', 'ingu', 'chr', 'тур', 'art', 'haut', 'rame', 'bg', 'ей', 'ége', 'nú', 'Rein', 'atus', 'od', 'fla', '[:', 'ücke', 'nes', 'kein', 'arts', 'flav', 'san', 'San', 'face', 'ien', '면', 'app', 'бан', 'flo', '方', 'shr', 'chain', 'cida', 'Jup', 'itie', '朝', 'verk', 'contents', 'Hook', 'Yan', 'lais', 'azzo', 'jak', 'rze', 'SG', 'reverse', 'erst', 'puesta', 'зі', '引', 'focus', 'spl', 'üg', 'ucci', 'heart', 'rest', 'Mont', 'Nue', 'hook', 'iate', 'рой', 'Bapt', 'contemporary', 'zur', 'тори', 'atte', 'iss', 'volte', 'Wit', 'seed', 'Multimedia', 'silence', 'Monte', 'ro', 'oming', 'Wass']\n",
      "in Layer16 , sorted_indices_dimension6585:  ['дри', 'СР', 'Википеди', 'ССР', 'staden', 'edad', 'Raum', 'ír', 'Становништво', 'Cap', 'ceed', 'hos', 'dostęp', 'zwe', 'мати', 'isz', 'zat', 'Autres', 'ega', 'Попис', 'ospod', 'цов', 'ars', 'stycz', 'uez', 'ientí', 'ès', 'ForKey', 'footer', 'zek', 'Domain', 'ἰ', 'жу', 'Eisen', 'zt', 'icrosoft', 'zor', 'èg', 'dflare', 'sierp', 'estaur', 'cope', 'энциклопеди', 'èn', 'onia', 'UNION', 'ος', 'osz', 'chmark', 'anth', 'XV', 'lon', 'èrent', 'elia', 'elli', 'ibe', 'cv', 'ipt', 'Sommer', 'Beit', 'ħ', 'Scal', 'ház', 'uario', 'iare', 'akult', 'Flor', 'нию', 'Domain', 'browser', 'нет', '通', 'CO', '종', 'igny', 'der', 'ael', 'irse', 'Ż', 'rice', 'undle', 'wort', '연', 'Spe', 'partiellement', '區', 'atore', '(()', 'ья', 'Kirch', 'ignore', 'ços', 'navig', 'Barcel', 'iből', 'ذ', 'zess', 'zeitig', 'enn', 'KB', 'Voll', 'Govern', 'DataSource', 'ih', 'Zur', ':\\u2009', 'plotlib', 'zawod', 'ól', 'sigu', 'ccc', 'alk', 'imet', 'zh', 'Capit', 'Website', 'ově', 'onen', 'ivil', 'urre', 'aceae', 'auf', 'ovis', 'dru', 'ář', 'Ptr', 'Zw', 'ո', 'Cop', 'irus', 'aggio', '천', 'plex', 'Cap', 'Mey', 'Overflow', 'plit', '�', 'hab', 'odel', '호', 'DAY', 'Ri', 'ppi', 'utat', 'вз', 'cco', 'leid', 'invån', '业', 'antom', 'Gebäude', 'тай', 'flat', 'pace', 'eigen', 'мат', 'Ки', 'Bart', 'comer', 'ensch', 'Entry', 'YS', 'тва', 'сов', 'kommun', 'кови', 'gestion', 'bronze', 'dt', 'tomcat', 'nię', 'Offset', 'dbo', '孝', 'тература', '佐', '�', 'Schne', 'за', 'árt', 'Der', 'leb', 'kwiet', '昌', 'sce', '<s>', 'czerw', 'edia', 'space', 'dom', 'ivamente', 'чник', 'overflow', 'хо', 'eur', 'IX', 'Миха', 'cpp', 'arel']\n",
      "in Layer16 , sorted_indices_dimension1554:  ['several', 'following', 'siguientes', 'certain', 'следу', 'folgender', 'few', 'ollow', 'einige', 'Following', '以', 'ertain', 'follow', 'siguiente', 'follow', 'follows', 'Here', 'segu', 'certain', 'Several', 'below', 'quelques', 'Here', 'some', 'Pacific', 'INCT', 'Follow', 'мет', 'ляр', 'ně', 'Points', 'folgenden', 'за', 'неско', 'icode', '�', 'here', 'követ', 'ępu', '些', 'factors', 'characteristics', 'eca', 'Below', 'некоторы', 'points', 'ряд', 'plusieurs', 'несколько', 'esti', 'odot', 'owy', 'amen', 'Pac', 'pił', 'oped', ':--', 'illas', 'rad', 'ệ', 'fs', 'chia', 'conditions', 'amil', 'criteria', 'varios', 'esta', 'AA', 'rado', 'rails', 'widet', 'some', 'Rein', 'uff', 'lär', 'couple', 'Stern', 'key', \"'):\", 'suiv', 'Made', 'ši', 'features', 'qq', 'ewnę', 'Kas', 'havet', 'steps', 'endorf', 'bib', 'aantal', 'Lad', 'föl', 'érature', 'lob', 'ufen', 'antes', 'facts', 'uni', 'oned', 'RENT', 'Format', '件', 'Guer', 'ithmet', 'nederbörd', 'Zone', 'chas', 'grat', 'esto', 'め', 'charts', 'riers', 'сла', '县', 'fingers', 'changes', 'otes', 'ialog', 'convergence', 'olg', 'nitt', 'versione', 'ieder', 'fla', 'trif', 'minipage', 'things', 'attributes', 'enschapp', 'ع', 'Ned', 'Fo', 'anguage', 'varias', 'abe', 'lika', 'alcune', 'loped', 'estaven', 'slant', 'い', 'pointers', 'Format', 'odn', 'points', 'сад', 'igner', 'ston', 'lö', 'scri', 'frames', 'ätt', 'stolet', 'слу', 'las', 'rame', 'indow', 'Renderer', 'observations', 'riteria', 'emann', 'istiche', 'вла', 'pac', 'pit', 'yar', 'owe', 'Ì', 'quit', 'CTYPE', 'spring', 'adesh', 'formatt', 'dynast', 'reasons', 'aused', 'notes', 'gow', 'here', 'jango', 'ynast', 'haft', 'Bed', 'amilton', 'öv', 'endencies', 'kwiet', 'фа', 'myth', 'viron', 'hov', 'gui', 'rent', 'particular', 'xelles', 'sierp', 'í', 'руг', 'ipage']\n",
      "in Layer16 , sorted_indices_dimension4451:  ['ɔ', 'bu', 'ango', 'iro', 'augh', 'ulf', 'xt', '法', 'acy', 'ptr', 'tap', 'ifi', 'ulos', 'ree', 'rew', 'ye', 'simp', 'res', 'vre', 'irement', 'работы', 'isi', 'diam', 'чь', 'omp', 'aug', 'sul', 'Cham', 'materials', 'loop', 'colors', 'iam', 'symbol', '才', 'Wayback', 'juris', 'om', 'corner', 'wid', 'bil', 'reverse', 'factory', 'ora', 'texte', 'Buck', 'hy', 'ön', 'Clay', 'inkel', 'Show', 'reverse', '类', 'ins', 'uss', 'nung', '←', 'dri', 'Academy', 'Stre', 'ég', 'pun', 'enda', 'attached', 'height', 'itaire', 'firm', 'wsp', 'act', 'Content', 'creature', 'refuge', 'independ', 'ogram', 'ize', 'ież', 'Las', 'fir', 'logging', 'aff', 'isse', 'ва', 'ire', 'LENG', 'justice', 'blue', 'iel', 'ju', 'comb', 'Law', 'aran', 'Line', 'ɲ', 'disp', 'ieu', 'ход', 'lu', 'Double', 'designs', 'extr', 'установ', 'File', 'diameter', 'sing', 'steam', 'orf', 'pb', 'answers', 'oto', 'din', 'cademy', 'ometry', 'angles', 'едера', 'стре', 'inned', 'lop', 'inking', 'Act', 'ager', 'é', 'work', 'exempl', 'дом', 'zaj', 'ängen', 'gr', 'grass', 'ai', 'gold', 'Imper', 'gros', 'thermal', 'tres', 'aben', 'ered', 'combinations', 'éri', 'material', '帝', 'career', 'anguages', '̀', 'ich', 'steel', 'urre', 'St', 'repos', 'divis', 'arden', 'stoff', 'ires', 'snap', 'Colors', 'SSL', 'vorg', 'Bear', 'corners', 'eston', 'Gall', 'Alg', 'si', 'height', 'sizes', 'her', '�', 'liv', 'hy', 'ang', 'irm', 'avel', 'azi', 'ride', '貴', 'color', 'lé', 'ём', 'istas', 'eng', 'emph', 'Foreign', 'lip', 'markup', 'nord', 'Front', 'jud', 'blue', 'stein', 'idos', 'imet', 'Career', 'pray', 'File', 'comp', 'Chain', 'ext', 'rike', 'à', 'Height', 'Phone', '<?']\n",
      "Key: model.layers.17.mlp.down_proj.weight\n",
      "in Layer17 , sorted_indices_dimension7682:  ['ade', 'lack', 'arin', 'pen', 'iti', 'keyword', 'scale', 'ibm', 'fal', '\\u200e', 'channels', 'team', 'rott', 'owan', 'ian', 'urt', 'ians', 'l', 'island', 'iante', 'enta', 'annel', 'lim', 'GP', '[', 'pén', 'Verm', '⅓', 'чен', 'iana', 'es', 'Nathan', 'EY', 'rian', 'teams', 'lich', 'sky', 'ahn', 'parenthes', 'warn', 'эн', 'aban', 'enza', 'loor', 'rout', 'lt', 'ibility', 'sample', 'dal', 'Mey', 'auth', 'pl', 'dow', 'creen', 'limat', 'unst', 'ban', 'davon', 'investig', 'osten', 'bey', 'IT', 'URE', 'Esp', 'Investig', 'Opt', 'ITH', '明', 'Syntax', 'aer', 'odd', 'VC', 'meck', 'chan', 'coh', 'lifetime', 'Tra', 'Oscar', 'anh', 'команди', 'mee', 'skip', 'ibrary', 'dia', 'Españ', 'bel', 'uset', 'Island', 'Rock', 'ăt', 'dark', 'pu', 'Intent', 'opo', 'andom', 'subm', 'iba', 'ending', 'key', 'subsequ', 'Fil', 'ler', 'rimonio', 'tom', 'army', '아', 'agini', 'поль', 'dy', 'loster', '立', 'conda', 'essel', 'ouv', 'kin', 'vs', 'oli', 'rame', 'som', 'Louis', 'Sure', 'sain', 'kens', 'kl', 'enn', 'keyboard', 'rien', 'ría', 'め', 'iente', 'Fol', 'Polit', 'CO', 'Jimmy', 'fl', 'Howard', 'end', 'pian', 'ff', 'ream', 'Kin', '云', 'aget', 'Según', 'ською', 'gay', 'jon', 'vern', 'esh', 'Sommer', 'age', 'вро', 'ienne', 'áb', 'inals', 'sen', 'phr', 'alleg', 'riel', 'Phili', 'olis', 'conv', '機', 'rich', 'piano', 'samples', 'rock', 'itt', 'ername', 'aussian', 'uis', 'кра', 'hre', 'Team', 'tabs', 'attack', 'reno', 'obser', 'rule', 'dbc', 'rial', 'nab', 'ulos', 'DBC', 'CO', 'мель', 'nl', 'orf', 'eed', 'ure', 'Scale', 'Pen', 'pus', 's', 'Thanks', 'omorph', 'arm', 'antes', 'Opera', 'филь']\n",
      "in Layer17 , sorted_indices_dimension6307:  ['railway', 'cig', 'tele', 'Ernest', '電', 'Jules', 'pian', 'piano', 'télé', 'Albert', 'Anto', 'radio', 'Victor', 'motor', 'machine', 'industrial', 'typed', 'newspaper', 'Federation', 'Pacific', 'ferro', 'Camil', 'Nelson', 'telep', 'Mate', 'Alfred', 'machine', 'terminal', 'president', 'intern', 'Gust', 'fus', 'dynam', 'preview', 'million', 'serial', 'Adolf', 'newsp', 'Force', 'Hitler', 'President', 'Eug', 'Љ', 'suff', 'режи', 'polar', 'Wagner', 'bullet', '昭', 'eto', 'Nobel', 'rail', 'Reserve', 'satisf', 'Kaiser', 'international', 'Петер', 'pione', 'journalist', 'Станов', 'Electric', 'magazine', 'coordinates', 'Budapest', 'tele', 'esto', 'Fue', 'Alice', 'Napole', 'Railway', 'psych', 'kaz', 'Wilson', 'diam', 'Colonel', 'bom', 'International', 'Rail', 'Präsident', '洋', 'clone', 'Liber', 'bahn', '联', '∙', 'typing', 'photograph', 'electric', 'locomot', 'Napoleon', 'циона', 'Atlantic', 'din', 'Alo', 'facilities', 'USS', 'bomb', 'Soviet', 'inder', 'United', 'onia', 'Apost', 'Salvador', 'sovi', 'javax', 'Preferences', 'tren', 'cinema', 'SError', 'billion', 'zas', 'pandas', 'Pablo', 'Territ', 'alias', 'hel', 'jections', 'gresql', 'Stanis', 'broadcast', '면', 'Cuba', '\\u2002', 'review', 'radio', 'concrete', 'Carl', 'Machine', 'pilot', 'Isra', 'velope', 'stelling', 'Glad', 'Rab', 'Invalid', 'mate', 'Af', 'inaugur', 'lak', 'ctl', 'pseud', 'Motor', 'Eugen', 'Oscar', 'decid', 'mem', 'sak', 'Radio', 'champ', 'factory', 'galax', 'inject', 'CG', 'Serial', 'Girls', 'Gand', 'Excel', 'Central', 'debut', 'baseball', 'tex', 'clone', 'Social', 'онов', 'tropical', '区', 'Leb', 'Intern', 'журна', 'Fried', 'Santos', 'Trust', 'propag', 'Herz', 'éon', 'weig', 'budget', 'cycl', 'Pr', 'äsident', 'Belgique', 'Factory', 'u', 'tram', 'Gustav', 'chn', 'Bureau', 'Jr', 'universe', 'keiten', 'vorg', 'tagon', 'amo', 'Charlie', 'DJ', 'ATP', 'train', 'odia', 'rif', 'Lehr']\n",
      "in Layer17 , sorted_indices_dimension203:  ['univers', 'wid', 'sop', 'rest', 'aw', 'wid', 'cond', '理', 'reg', 'element', 'circ', 'Hub', 'het', 'cra', 'arn', 'scope', 'hub', 'impact', 'ch', 'cond', 'Hub', 'eda', 'Beaut', 'ynt', 'ark', 'рей', 'estate', 'ré', 'temper', 'ca', 'ello', 'Univers', 'ral', 'вор', 'oke', 'rin', 'ives', 'iva', 'part', 'side', 'lin', 'Aw', 'Radio', 'tor', 'anne', 'shield', 'Cond', 'äs', 'Side', 'сан', 'ç', 'dia', 'spole', 'Мос', 'parte', 'port', '�', 'truth', 'elta', 'aza', 'Shared', 'Executive', 'istor', 'Behavior', 'container', 'ks', 'onne', 'tag', 'imer', 'ix', 'iner', 'HI', 'vice', 'nia', 'enta', 'Fran', 'ford', 'ysis', 'vin', 'coordin', 'band', 'çon', 'wig', 'ittest', 'Geography', '�', 'how', 'ider', 'tran', 'Asp', 'муниципа', 'vš', 'side', '付', 'avel', 'Cond', 'Navigation', 'Choice', 'pian', '容', 'Ca', 'iki', 'ao', 'kunft', 'коли', 'qu', 'larg', 'Según', 'Converter', 'External', 'CR', 'flat', 'assignment', 'revers', 'ivi', 'priv', 'emb', 'behaviour', 'crew', 'íz', 'ley', 'ki', 'radio', 'Union', 'uther', 'yclerView', 'container', 'American', 'rano', 'ð', 'worry', 'care', 'Mercur', 'chanson', 'elev', 'ify', 'viol', 'Ca', 'raj', 'Element', 'le', 'ти', 'Http', 'behavior', 'Aust', 'ree', 'ater', 'Hi', 'depart', 'ega', 'com', 'box', 'widely', 'ed', 'Els', 'anga', 'Vi', 'Vice', 'deb', 'status', 'visor', 'Robin', 'gar', 'heid', 'imper', 'van', 'Vers', 'diff', 'shot', 'Wik', 'części', 'dispos', 'Raz', 'caption', 'optimization', 'Bio', 'alls', 'ulla', 'width', 'piano', 'meg', 'poster', 'Conseil', 'IM', 'czę', 'changes', 'ゆ', 'Profile', 'clouds', 'bald', 'DO', '(%', 'imi', 'tack', 'ilation', 'Cr', 'emot', \"$('\", 'band', 'mellan']\n",
      "in Layer17 , sorted_indices_dimension9868:  ['View', 'jsp', 'Fol', 'U', 'lake', 'fol', 'Scope', 'eli', 'album', 'ELD', 'column', 'Mich', 'journal', 'Sync', 'zt', 'package', 'ener', 'View', 'Gray', 'view', 'dom', 'merge', 'avy', 'Lake', 'retch', 'lord', 'views', 'walt', 'tank', 'Herz', 'vie', 'Navy', 'Fried', 'Mik', 'inherited', 'ecc', 'land', 'ult', 'osa', 'ведения', 'calcio', 'зя', 'bomb', 'account', 'ccc', 'types', 'центра', 'mines', 'atoes', '湖', 'bag', 'Bean', 'nas', 'ocean', 'льно', 'drum', 'deployment', 'ather', 'hus', 'тро', 'imer', 'Fine', 'Column', 'produ', 'sail', 'ose', 'products', 'Bom', 'clock', 'views', 'Dest', 'Production', 'ähr', 'columns', 'editor', 'ye', 'erea', 'Dow', 'respect', 'type', 'éli', 'round', 'moon', 'Sa', 'sync', 'ina', 'arden', 'галь', 'ria', 'lee', 'aten', 'Dest', 'container', 'Young', 'cond', 'collections', '�', 'pher', 'urs', 'CV', 'album', 'Urs', 'ingen', 'phere', '景', 'ад', 'ovie', 'vie', 'intelligence', 'Brit', 'Gem', 'olds', 'Schwar', 'sah', 'ync', 'edited', 'collections', 'FC', 'packages', 'edit', 'Wis', 'diam', 'agi', 'controls', 'peculiar', 'Session', 'unfold', 'reader', 'perty', 'sleep', 'review', 'Dak', 'Bag', 'Bomb', 'prod', 'ур', 'lang', 'Cal', 'cala', 'curv', 'ქ', 'kee', '�', 'New', 'view', 'eggs', 'dép', 'herr', 'sync', 'каз', 'container', 'Sea', 'factor', 'erd', 'irls', 'cal', 'column', 'izer', 'fmt', 'balls', 'Michael', 'pressing', 'LM', 'ante', 'rés', 'parse', 'higher', '反', 'fis', 'Free', 'Gregory', 'Ult', 'ț', 'iful', 'ship', 'рож', 'ingo', 'Entertainment', 'integr', 'integration', 'Phili', 'obar', 'Views', 'пов', 'Usage', 'fried', 'incomplete', 'monitor', 'дома', 'sky', 'Pos', 'wounded', 'Sa', 'itz', '{\"', 'са', 'bert', 'У', 'exchange', 'nic']\n",
      "in Layer17 , sorted_indices_dimension10637:  ['achiv', 'mes', 'tempo', 'öv', 'exclus', 'dat', 'emi', 'гор', 'spo', 'git', 'agem', 'ker', '°', 'wid', 'eno', 'prost', 'ped', '康', 'Fam', 'infl', 'reme', 'enas', 'alo', 'Monte', '�', 'asp', 'джи', 'poly', 'population', 'XX', 'EDIT', 'Infl', 'BY', '세', 'спо', 'wid', 'infl', 'artific', 'зя', 'unden', 'grab', 'gren', 'omed', 'ethod', 'azar', 'ças', 'Dat', 'obtain', 'pół', 'гра', 'lemagne', 'imas', 'Jules', 'demic', 'eso', 'ellen', 'damit', 'sn', 'ica', 'Liber', 'status', 'CUR', '화', 'ixen', 'heid', 'avo', 'enario', 'asy', 'ho', 'chron', 'opera', 'ículo', 'println', 'kn', 'asz', 'фон', 'inherit', 'microsoft', 'herit', 'alm', 'Mes', 'tn', 'Franz', 'agini', 'com', 'aga', 'nic', 'parenthes', 'group', 'себе', 'temperature', 'ош', 'mez', 'Pal', 'chor', 'Freder', 'iras', 'olu', 'ror', 'commands', 'kur', 'dress', 'к', 'La', 'none', 'zo', 'Tem', 'root', 'bitter', 'chus', 'press', 'empor', 'velocity', 'Tree', 'reform', 'Inst', 'lect', 'мно', 'id', 'спе', 'kwargs', 'doc', 'olg', 'relief', '$}}%', 'horn', 'asa', 'Bret', 'rå', 'Reform', 'CN', 'Men', 'кан', 'fill', 'tree', 'Nicol', 'owy', '̂', 'unas', 'syntax', 'sculpt', 'ivi', 'Publishing', 'bog', 'Sn', 'взя', 'fur', 'solic', 'datab', 'rol', 'forest', 'dat', 'тик', 'stability', 'constraint', 'äl', 'Cr', 'group', 'FM', 'men', 'arbe', 'ゆ', 'ч', 'formation', 'chrom', 'SN', 'apro', 'antics', 'irm', 'Status', 'influen', 'inheritance', 'none', 'SS', 'рем', '__(', 'spé', 'game', 'teat', 'ш', 'ì', 'proxim', 'ebol', 'Cur', 'dal', 'Barb', 'unos', 'Long', 'rollo', 'Costa', 'Prozent', 'cedes', 'graph', 'hyper', 'gor', 'pa', 'href', 'adas', 'status', 'eness']\n",
      "in Layer17 , sorted_indices_dimension7664:  ['Museum', 'museum', 'examples', 'avas', 'ism', 'arian', 'џ', 'contra', 'glob', 'museum', 'mes', 'музе', '博', 'ieu', 'exhib', 'Cur', 'rare', 'atra', 'kaf', 'acab', 'Cab', 'gal', 'samples', 'examples', 'Wilson', 'Type', 'Switch', 'curiosity', 'arius', 'oper', 'Au', 'ées', 'presente', 'amples', 'XV', 'lau', 'au', 'uellement', 'inale', 'Turk', 'movements', 'ního', 'archive', 'fix', 'Sir', 'ßer', 'kem', 'oty', 'ainer', 'spin', '球', 'arrow', 'anka', 'ʰ', 'unix', 'Murray', 'au', 'gericht', 'cius', 'fare', 'che', 'Бу', 'consult', 'Scala', 'archive', 'Hunter', 'års', 'Father', 'hagen', 'sche', 'unix', 'walls', '((', 'Harrison', 'Anth', 'Außer', 'options', 'counter', 'ante', 'bahn', 'drums', 'округу', 'cks', 'osten', 'kyr', 'fen', 'Austin', 'кур', 'Market', 'ingår', 'vin', 'consent', 'TX', 'illon', 'hmen', 'irs', 'cem', 'chmark', 'absolv', 'lod', 'heart', 'quickly', 'display', ')-', 'xs', 'cza', 'À', 'circul', 'justice', 'library', 'equivalent', 'ús', 'WorldCat', 'ID', 'vity', 'dess', 'Krak', 'sle', 'tex', 'rium', 'bout', 'orders', 'Policy', 'Hist', 'ps', 'baum', 'gro', 'contra', 'wirtschaft', 'oses', 'repository', 'ต', 'Ṣ', 'override', 'Lou', 'erman', 'vin', 'Nil', 'Bour', 'igration', 'plements', 'wine', 'useum', 'anth', 'Global', 'levant', 'iken', 'ṯ', 'ismo', 'nitt', 'Dr', 'SO', 'singles', 'Sak', 'curs', 'te', 'Gal', 'cell', 'options', 'ynie', 'arrow', 'mania', 'movement', 'вые', 'eto', 'dess', 'ษ', 'configured', 'rinn', 'Beau', 'Atlas', 'aga', 'Werner', 'Super', 'Person', 'contrad', 'ismus', 'RED', 'cat', 'Rhein', 'cab', 'Books', 'Priv', 'nov', 'pel', 'display', 'Class', 'вин', 'Ps', 'chim', 'texte', 'cur', 'Herzog', 'Nil', 'courses', 'ряд', 'og', 'history', '心', 'example']\n",
      "in Layer17 , sorted_indices_dimension3158:  ['tis', 'ugno', 'abase', 'untime', 'nect', 'invert', 'blic', 'ongo', '̣', 'Begriffsklär', 'atform', 'Aires', 'ilder', 'arten', 'ancia', 'rov', 'ilde', 'nett', '拳', 'maja', 'ibles', 'Pala', 'oom', 'blica', 'Ξ', 'Joy', 'flag', '&=\\\\', 'riv', 'ugo', 'yle', 'ictionary', 'ROP', 'Parlament', 'eters', 'ibe', 'dor', 'bern', 'unnel', 'seau', 'tags', 'bezeichneter', 'зу', 'owan', 'ied', 'ћа', 'scales', 'ович', 'lab', 'desar', 'oir', 'fficiale', 'irectory', 'pec', 'Մ', 'uola', 'yntax', 'vern', 'Wa', 'Cat', 'Sym', 'ứ', 'uca', 'Encyclop', 'Tsch', 'psum', 'streams', 'hagen', 'uy', 'encuentra', 'pet', 'себя', 'akers', 'Cec', 'VICE', 'ünstler', 'še', 'imation', 'inho', 'amounts', 'ography', 'ptr', 'net', 'pull', 'arte', 'ieck', 'uvud', 'hög', 'frica', 'undial', 'ġ', 'SERVER', 'quip', 'emat', 'relax', 'pmod', 'Cic', '┌', 'üd', 'nem', 'tagon', 'opsis', 'useum', 'stra', 'rivate', 'arda', 'kwiet', 'pha', 'Rah', 'phr', 'Wei', 'nom', 'leans', 'flag', 'wa', 'antage', 'usion', 'Vé', 'utto', 'bas', '박', 'dens', 'oppon', 'Hier', 'acht', 'conde', 'anten', 'aceae', 'beck', 'bone', 'charts', 'CAA', 'ئ', '̀', 'net', 'iesa', 'equal', 'lon', 'arta', 'pus', '́', 'igne', 'sierp', 'UID', 'gr', 'Robin', '�', 'ellig', 'ART', 'País', 'obox', 'etti', 'ards', 'agar', 'Cris', 'ierten', 'VERSION', 'до', '==\"', 'hart', 'bits', 'ost', 'iei', 'ides', '火', 'Inga', 'Cés', 'Cho', 'Bibliothèque', 'ії', 'essen', 'wire', 'ymen', 'wild', 'bach', 'roe', 'ppen', 'vin', 'atto', 'ciente', 'едера', 'sty', 'жи', 'rän', 'носи', 'Nom', 'TM', 'ffic', 'sel', 'Sebastian', 'OW', 'illas', 'alc', 'éch', 'ii', 'ference', 'Harm', 'isa', 'ała', 'Una']\n",
      "in Layer17 , sorted_indices_dimension4055:  ['glass', 'glass', 'window', 'windows', 'Window', 'Window', 'window', 'transparent', 'gla', 'Glas', 'windows', 'lass', 'Gla', 'Windows', 'crist', 'Gor', 'mirror', 'Mir', 'Windows', 'screen', 'screens', 'mir', 'polar', 'tears', 'Beg', 'рово', 'cry', 'Cry', 'screen', 'memb', 'mir', 'tras', 'cri', 'reflection', '户', 'pressed', 'adre', 'emeinde', 'grund', 'fen', 'groupId', 'Screen', 'display', 'panel', 'Lex', 'rier', 'thick', 'sted', 'ati', 'nä', 'Ret', 'scratch', 'agar', 'surface', 'lein', 'Clar', 'clam', 'pan', '面', 'katol', 'fen', 'lam', 'indows', 'clear', 'lex', 'pan', '反', 'WIN', 'pol', 'Dispatcher', 'კ', 'Clear', 'riz', 'приз', 'aturen', 'indow', 'touch', 'paper', 'layer', 'touch', 'Ga', 'ritt', 'panel', 'touched', 'TRAN', 'films', 'interface', 'rade', 'amin', '界', 'reflect', 'lg', 'oved', 'Alc', '⇒', 'clar', 'Film', 'film', 'Ret', 'succession', 'Touch', 'Trans', 'adin', 'brit', 'cu', 'Ref', '합', 'Tras', 'AML', 'DOC', 'clearer', 'Bundle', 'Panel', 'lej', 'oltre', 'oil', 'interfaces', 'zel', 'ced', 'ogle', '陽', 'Touch', 'лян', 'Wikispecies', 'ós', 'athers', 'solid', 'Clear', 'ɾ', 'лог', 'withdraw', 'layers', 'etro', 'fram', 'IP', 'lassen', 'Kunst', 'transaction', 'displays', 'nem', 'reflect', 'Device', 'vit', 'CD', 'Ole', 'dist', 'aching', 'CD', 'surfaces', 'WD', 'bject', 'fat', 'beck', 'fare', 'ká', 'enant', 'án', 'ће', 'ains', 'ai', 'Ref', 'crack', 'gon', 'ст', 'Гу', '➖', '密', 'adi', 'Cris', 'filme', 'interface', 'sm', 'iw', 'gaz', 'refs', 'bahn', 'ain', 'bben', 'ga', 'display', 'clear', 'окон', 'treated', 'Bob', 'blank', 'ELD', 'guer', 'ächen', '阳', 'transactions', 'carri', 'Trans', 'ardin', 'Science', 'lain', 'LayoutParams', 'profiles', 'iv', 'thick', 'ipp']\n",
      "in Layer17 , sorted_indices_dimension2716:  ['://', 'ungsseite', 'Bowl', 'pta', 'amento', 'fx', 'unn', 'externas', 'рай', 'elian', 'Ast', 'esterni', 'овано', 'HER', 'Bruno', 'str', 'elia', 'го', 'annel', 'Prima', 'anni', 'tit', 'ectors', 'ostream', 'Vien', 'сылки', 'Picker', 'Nobel', 'CLA', 'stream', 'classical', 'chin', 'externos', 'ait', 'йской', 'auer', 'Pager', '站', 'prede', 'тура', 'Adel', 'NG', '日', 'unicí', 'website', '▲', 'capital', 'astro', 'pag', 'aca', 'quet', 'кова', 'incor', 'ivent', 'interpreter', 'ton', 'span', 'suivante', 'gg', 'glass', 'Provider', 'itan', 'ielt', '泰', 'egos', 'Stream', 'unt', 'Greg', 'Operation', 'Oriental', 'bin', 'handled', 'handles', '#(', 'STRING', 'іс', 'govern', 'ování', 'rag', 'Nice', 'rose', 'nr', 'unque', 'unnel', 'ela', 'кро', 'inación', 'cla', 'homonymes', 'ebb', 'esen', 'capitale', 'xt', 'Runtime', 'erne', 'ados', 'successor', 'ienza', 'aug', 'citiz', 'ora', 'ambigu', 'blah', 'ächst', 'adora', 'uning', 'angular', 'UI', 'adt', 'Warner', 'digit', 'picker', 'alle', '¨', 'et', 'зе', 'burg', 'Sever', 'appropriate', 'site', 'handle', 'igr', 'anson', 'Angel', 'affect', 'BUG', 'wn', 'Andy', 'eng', 'ilde', 'Cés', 'Pic', 'roc', '宇', '古', 'Heil', 'his', 'stream', 'Ric', 'app', 'Harry', 'ambient', 'alem', 'ulté', 'бора', '═', 'lak', 'engl', 'Gram', 'streaming', 'testing', '！', 'eng', 'ala', 'AL', '向', 'Ori', 'lass', 'ithmetic', 'aque', 'испол', 'Charles', 'altra', 'omy', 'û', 'bishop', 'itu', 'rug', 'iet', 'XT', 'Bang', 'ئ', 'jango', 'Website', 'compiler', 'ernal', 'Soph', 'ença', 'rí', 'eries', 'compact', 'gouvern', 'Nick', 'geme', 'although', 'zil', 'vat', 'ución', 'FAULT', 'replacing', 'reu', 'ibrary', 'gram', 'ipes', 'Stream', 'induction', 'Ty', 'speaking', 'aug', 'Rock']\n",
      "Key: model.layers.18.mlp.down_proj.weight\n",
      "in Layer18 , sorted_indices_dimension10240:  ['restaurant', 'dent', 'retired', 'merchant', 'assistant', 'Пе', 'manufact', 'da', 'substitute', '�', 'engineer', 'TM', 'inha', 'marine', 'auto', 'festival', 'amt', 'eren', 'že', 'лова', 'tail', 'adin', 'software', 'store', 'subscribe', 'painter', 'hotel', 'вра', 'radi', 'iae', 'gar', 'asp', 'professional', 'estival', 'agricult', 'laravel', 'oil', 'em', 'boot', 'coordin', 'nja', 'gel', '教', 'ador', 'nur', 'cel', 'fortune', 'Venez', 'заво', 'factory', 'Sub', 'gro', 'Kauf', 'endl', 'iante', 'subst', 'ign', 'sel', 'sell', 'aze', '商', 'ubern', 'нь', 'iglia', 'cono', 'сле', '\\x1a', 'ž', 'ieren', 'obre', 'iter', 'kamen', 'business', 'Software', 'profes', 'utter', 'shop', 'da', '*`', 'eper', 'engine', 'umber', 'kl', 'subscription', 'wp', 'zent', 'Engine', 'inae', 'hab', 'ut', 'auto', '包', 'store', 'bing', 'hardware', 'ані', 'chain', 'anh', 'redirects', 'ront', 'ret', 'Para', 'пер', 'sold', 'ells', 'Wein', 'ouverneur', 'Schwe', 'rad', 'cite', 'н', 'adores', 'Lyon', 'subtract', 'Ret', 'vc', 'Engine', 'FAULT', 'ignment', 'занима', 'utter', 'reserved', 'ّ', ')];', 'Ṣ', 'ems', 'ierten', 'engineering', 'ад', 'Sel', 'consult', 'correct', 'rad', 'teacher', 'asp', 'Hotel', 'radio', 'сто', 'же', 'trom', 'wp', 'interpreter', 'gaz', 'estaur', 'Salvador', 'Ж', 'щ', 'onomy', 'gar', 'ping', '\\u200a', 'WP', 'pract', 'bb', 'legate', 'bank', 'анд', '海', 'Hann', 'sg', 'Reserve', 'Beaut', 'fram', 'successful', 'reso', 'marine', 'ine', 'Durant', '}`', 'indow', 'ufact', 'inspect', 'wait', 'jer', '司', 'ends', 'GP', 'industrial', 'ando', 'ош', 'anth', 'interior', 'secretary', 'wealth', 'components', 'lax', 'mystery', 'ße', 'сре', 'Kennedy', 'tensor', 'lin', 'zeg', 'Ка', 'Nur', 'designer', 'mys', 'Ze', 'wine', 'пов']\n",
      "in Layer18 , sorted_indices_dimension7361:  ['Lev', 'kov', 'jor', 'Lion', 'Las', '�', 'Stone', 'Veg', 'tid', 'beeld', 'lobal', 'stre', 'rå', 'aden', 'uration', 'vil', 'computation', 'Verkehr', 'ovan', 'azi', 'icket', 'computing', 'chor', 'ista', 'stone', 'Li', 'Comput', 'compute', 'Vor', 'пор', 'сно', 'жен', 'Ole', 'oven', 'swe', 'ност', 'stone', 'computational', 'gex', 'comput', 'prove', 'urop', 'threads', 'Portugal', 'подо', 'infty', 'Bounds', 'aze', 'ме', 'лем', 'thread', 'oggle', 'мель', 'amen', 'cyk', 'phere', 'ople', 'iom', 'married', 'tid', 'Dios', 'лё', 'Gy', 'gran', 'ignes', 'oltre', 'arg', 'orld', 'ao', 'же', 'mut', 'native', 'AI', 'дения', 'uw', 'propri', 'upt', 'Camil', 'мена', 'ën', 'пад', 'Fu', 'Window', 'overflow', 'ruguay', 'ạ', 'uerte', 'sett', 'ША', 'vole', 'imientos', 'т', 'Festival', 'сни', 'ped', 'finit', 'ض', 'ские', 'anta', 'definit', 'ʂ', 'sert', 'cod', 'III', 'sue', 'сан', 'compute', 'ticket', 'Vater', 'URI', 'Lis', '清', 'roit', 'lev', 'бор', 'Савезне', 'Alex', 'stones', '`.`', 'ки', 'overflow', 'cope', 'Dic', '展', 'object', 'itted', 'proved', 'rut', 'bere', 'Argent', 'atz', 'sted', 'cite', 'pił', 'orn', 'fra', 'маль', 'ую', 'PATH', 'poss', 'suff', 'гор', 'auff', 'Lee', 'stra', 'scope', 'ört', 'clus', 'superfic', '전', 'cko', 'fert', 'emark', 'Directory', 'aille', 'sett', 'cin', 'ℚ', 'rapport', 'юза', '⟶', 'iembre', 'fah', 'щи', 'plaats', 'omething', 'льта', 'лев', 'рой', 'donner', 'ლ', 'perties', 'LETE', '%%%%', 'ajes', 'Len', 'ه', 'IP', 'bol', '&=\\\\', '容', 'proves', 'comput', 'settled', 'Profil', 'сви', 'ǧ', 'дами', 'ated', 'Stutt', 'мін', 'gy', 'mut', 'Lit', 'theorem', 'tick', 'ihe', 'Bres', 'Studio', 'idades']\n",
      "in Layer18 , sorted_indices_dimension5552:  ['̲', 'tagon', 'kraj', 'esen', 'rado', 'lament', 'holm', 'kins', 'products', 'wn', 'amo', 'attle', ',%', 'aum', 'arde', 'abroad', 'goods', 'imento', 'imes', 'InstanceState', 'pov', 'cadem', '�', 'sost', 'pher', 'begun', 'roku', 'apat', 'cade', 'duino', 'Auflage', 'González', 'localidad', '等', 'actér', 'кам', 'zač', 'Gard', '符', 'kin', 'ling', 'дри', 'konst', 'rror', '면', 'opher', 'Framework', 'Flo', 'adas', 'сия', 'elen', 'onderwerp', 'enem', 'sigu', 'progress', 'inture', '̩', 'quip', 'ClickListener', 'engu', 'hem', 'zat', 'songs', 'exterior', 'Opera', 'weet', 'sug', 'vict', 'enne', 'elo', 'brázky', 'revers', 'ologe', 'poison', 'Lund', '意', 'Хронологи', 'transferred', 'owym', 'oreign', 'azz', 'amen', 'образ', 'adel', 'mús', 'Ě', 'principe', 'ogle', 'ろ', 'subst', 'itar', 'esc', 'Flora', 'ĕ', 'Holz', 'quia', 'ắ', 'arios', 'roke', 'conscious', 'Gegen', 'arius', 'acia', 'nested', 'onio', 'gression', 'reserved', 'iske', 'szág', 'Mitg', 'zam', 'thing', '年', '沙', 'лемен', 'proceeded', 'alen', 'Guerra', 'payload', 'esper', 'iment', 'typeof', 'chts', 'esz', 'snow', 'clicked', 'progress', 'CAA', 'voy', 'gol', 'ént', 'lings', 'rah', 'ố', 'alberga', 'seria', 'IK', 'Transfer', 'onk', 'raham', 'Ol', 'գ', 'VARCHAR', '№', 'começ', 'amarin', 'Constra', 'ennes', 'ír', 'iterations', 'äh', 'opere', 'heit', 'RENT', 'дела', 'napshot', 'gradle', 'binnen', 'Север', 'ierno', 'ftware', 'Sein', '流', 'fers', 'Snow', 'дня', 'OutputStream', '物', 'cosa', 'ennis', 'deprecated', 'geben', '云', 'haft', '****************', 'folge', 'zes', 'began', '松', 'Fn', 'enç', 'atte', 'akult', 'attice', 'ając', 'iteration', 'ke', 'aglia', 'Germania', 'Hinweis', 'ahn', 'bernate', 'hace', '指', 'ély', 'scholar', 'ṯ', 'north', 'products', '有']\n",
      "in Layer18 , sorted_indices_dimension10609:  ['haus', 'ynomial', 'colors', 'aupt', 'color', 'zna', 'unas', 'Chor', 'Color', '�', 'iveau', '色', 'lap', 'zvuky', 'nou', '♂', 'Bun', 'sono', 'ạ', 'dor', 'folk', 'colours', 'sime', 'neh', 'colors', 'ují', 'anton', 'gior', 'itmap', 'ym', 'Tamb', 'meck', 'Color', 'anguage', 'omorph', 'Wolfgang', 'zo', 'ymbol', 'species', 'googleapis', 'мен', 'даго', 'zien', 'Einzelnach', 'hmen', 'sym', 'Proc', 'idense', 'kund', 'naio', 'оте', 'nofollow', 'apk', 'iano', 'tz', 'Poz', 'éta', 'alb', 'iers', 'Wol', 'usa', 'obar', 'generic', 'eur', 'ále', 'ksam', 'cej', 'ichten', 'wol', '₀', 'oct', 'ango', 'UB', '=\"{', 'ajo', 'équ', 'Inflater', 'ITable', 'Савезне', 'versary', 'essage', 'Standard', 'frak', 'eclipse', 'tamb', 'nitz', 'нд', 'cip', 'мом', 'whites', 'zoom', 'oup', 'дон', 'uis', 'raid', 'ategory', 'species', 'vit', 'ICATION', 'Standard', 'hä', 'Leip', 'cube', 'colored', 'дар', 'jed', 'lv', 'dru', 'perty', 'wings', 'faz', 'ichte', 'Paint', 'ués', 'kazy', 'blica', 'приз', 'Colors', 'colour', 'racc', '♀', 'Species', 'кви', 'Promise', '백', 'ubs', 'ffen', 'rimonio', 'caval', 'III', 'cente', 'yles', 'ßen', 'pent', '̥', 'EXISTS', 'рак', 'egov', 'тем', 'cep', 'rgba', 'wohl', 'omsnitt', 'ye', 'quad', 'pher', 'Sierra', 'Blan', 'ís', 'passwords', 'ལ', 'zysk', '性', 'þ', 'szág', 'Zygote', 'epen', 'Ḩ', 'wol', 'lapse', 'signs', 'confer', 'alto', 'color', 'ّ', 'ķ', 'Loren', 'meg', 'stab', 'ião', 'Rout', 'gems', 'Sieg', 'omorphic', 'скус', 'AMP', 'illed', 'Images', 'տ', 'orus', 'Hibernate', 'tub', 'ším', 'кол', 'Jazz', 'xpath', 'ńcz', 'Vor', 'Admin', '清', 'ube', 'lung', 'opacity', 'dom', 'zeros', 'ARCHAR', 'ång', 'bar', 'ал', '字']\n",
      "in Layer18 , sorted_indices_dimension6557:  ['Tennis', 'tennis', 'reactjs', 'qu', 'Epis', 'angularjs', 'wine', 'jazz', 'Nord', 'aff', 'Weg', 'alth', 'Jazz', 'вор', 'subscri', '朝', 'ski', 'ally', 'Mont', 'zenia', 'chk', 'Tib', 'lieutenant', 'astro', 'ków', 'elli', 'env', 'schw', 'pol', 'ánt', 'porter', 'eas', 'wealth', 'audi', 'ommen', 'por', 'ath', 'Por', 'nih', 'ił', 'bien', 'magazine', 'improv', 'rument', 'Lib', 'Muse', 'ensemble', 'y', 'subscription', 'él', 'rost', 'hand', 'ücken', 'arth', 'perimental', 'incie', 'dw', 'mode', 'Pil', 'schau', 'числе', 'organ', 'osoph', 'zm', 'Zw', 'readsheet', 'Mau', 'ête', 'atorio', 'terra', 'że', '/#', 'Nap', 'udi', 'esp', 'rugby', 'ép', 'bout', 'optional', 'LT', 'country', 'fra', 'Æ', '�', 'Mode', 'ket', 'aware', 'Lib', 'geg', 'ttp', 'Santa', 'Ag', 'sympath', 'minipage', 'द', 'Organ', 'country', 'Sohn', 'deli', 'neu', '़', 'stell', 'spin', 'experimental', 'monaster', 'USE', 'station', 'icum', 'Magazine', 'travers', 'ops', 'цу', 'aft', 'ktr', 'intro', 'Society', 'tort', 'zusammen', 'trim', 'вое', 'privile', 'Jap', 'Buddh', 'Runner', 'łącz', 'odes', 'summar', '请', 'ponse', 'synth', 'всего', 'fine', 'ель', 'ppet', 'Lie', 'łoż', 'sum', 'assa', '서', 'scr', 'Kü', '̩', 'Rugby', '参', 'eles', 'threads', 'lac', 'ş', 'Toast', 'über', 'la', 'zus', 'zem', 'propag', 'Syn', 'pret', 'Mont', 'Notices', 'elegant', 'psych', 'zien', 'ura', 'ště', 'syn', '区', 'ан', 'Ges', 'Harvard', 'syn', 'дела', 'osof', 'av', 'absor', 'él', 'веде', '坂', 'plays', 'lapsed', 'Ü', '道', 'vote', 'adó', 'inc', 'ath', 'golf', 'avy', 'audi', 'strings', 'brary', 'bird', 'う', 'тами', 'erc', 'Japon', 'cura', 'мп', 'eff', 'Tell', 'gift', 'Kle']\n",
      "in Layer18 , sorted_indices_dimension3995:  ['swers', 'grade', 'partiellement', 'grade', 'lez', 'ню', 'ogli', 'urale', 'kar', 'immer', 'ARN', 'archar', 'silence', 'lip', 'uela', 'DEX', 'éral', 'гли', 'enne', 'Serv', 'rai', 'zeichnungen', 'зни', 'Orig', 'eps', 'Serv', 'answers', 'antin', 'nyel', 'igten', 'vba', 'Category', 'gel', 'hyp', 'iums', 'ibt', 'Bere', 'Lyn', 'wort', 'interfaces', 'проф', 'pal', 'isti', '�', 'istique', 'кар', '戸', 'consulté', 'WI', 'oku', 'Rak', '福', 'зан', 'Lev', 'iano', '-------', 'scale', 'estre', 'kar', '็', '++)', 'aks', 'ium', '序', 'response', 'readsheet', 'interval', 'Scale', 'gresql', 'лян', 'eless', 'кої', 'lace', 'phe', 'jective', 'Response', 'vim', 'cerem', 'grace', 'orsz', 'стову', 'gel', \")'\", 'sterreich', 'Category', 'augusti', 'августа', '鳥', 'igr', 'answer', 'fields', 'ベ', 'responses', 'answering', 'сты', 'zerw', 'ORM', 'igo', 'icher', 'Media', 'Mitt', 'existence', 'cala', 'usta', 'дена', 'ép', 'cheval', 'зу', 'LENG', 'Response', 'esian', 'pio', '\"?>', 'haft', 'ennen', 'anten', 'erset', 'interface', 'Longrightarrow', 'koz', 'язы', 'карь', 'careful', 'хва', 'ilty', 'uset', 'рем', 'SQL', 'Bom', 'город', 'ǧ', 'schap', \"`'\", '�', 'iből', 'Richtung', 'jest', 'unicí', 'ء', 'Interface', 'ear', 'fir', 'opera', '%;\\r', 'hours', 'permission', 'TM', 'няя', 'sam', 'chmark', 'verg', 'соб', 'према', 'grâce', 'гра', 'рови', 'ort', 'Fields', 'seau', 'edeut', 'fu', 'impression', 'Между', 'ilib', 'zaw', 'Sue', 'эта', 'esses', 'fass', 'arsi', '野', 'meister', 'bed', 'Forest', 'aggi', 'WID', 'aine', 'interface', 'Testament', 'opera', 'ׁ', '取', 'мости', 'oor', 'werk', 'ché', 'Giov', 'inta', 'eggi', 'uten', 'энциклопеди', 'нен', 'tm', 'eus', '$(', 'response', 'рен', 'hos', 'Mey', 'lips']\n",
      "in Layer18 , sorted_indices_dimension6524:  ['äl', 'hagen', 'yar', 'umerate', 'Ritter', 'los', '̯', 'laus', 'loss', 'poque', 'ável', 'idenote', 'lost', '崎', 'Fragment', 'fas', 'blogs', 'uvud', 'ّ', 'FR', 'bed', 'ześ', 'atre', 'Bool', 'Err', 'enfer', 'fr', 'illo', 'tun', 'стоя', 'Live', '\\x0c', 'cycles', 'osing', 'jící', 'ędz', 'Sever', ')`,', 'omen', 'harder', 'Mand', 'uce', 'cz', 'tm', 'vig', 'Dat', 'Mens', 'INNER', 'ĩ', 'uden', 'fragment', 'anos', 'alone', 'physics', 'hard', 'feld', 'Contact', 'HP', 'Augen', 'inwon', 'Tun', 'LAB', 'Spark', 'bien', 'svě', '%%%%', '☆', 'Forces', 'Становништво', 'Scale', 'Orleans', 'Touch', 'eben', 'davon', 'Meter', 'gros', 'solo', 'Classic', 'werk', 'infin', 'Deleg', 'oblig', 'kilomet', 'otte', 'lob', 'сон', 'blog', 'iew', 'allo', 'specie', 'tm', 'бер', 'Live', '遠', 'tutorial', 'Comment', 'ód', 'losing', '夢', '保', '伝', '光', 'pply', 'offset', 'Date', 'íp', 'realiz', 'ossen', 'ultimo', 'cycle', 'forces', 'обра', 'iki', 'Bool', '회', 'enemy', 'ativo', 'iverse', 'onderwerp', 'esz', 'жда', 'geprüft', 'ährend', 'allow', 'alf', 'Global', 'ôt', 'дж', 'Long', '波', 'schaften', 'ель', 'Bildern', 'mand', '图', 'suivante', 'mai', 'chk', 'Deb', '`{', 'Sud', 'cho', 'Kultur', 'derivatives', 'MC', 'ideal', 'DIS', 'chestra', 'dostęp', '│', 'Gros', 'Refer', '甲', 'schaft', 'prem', 'bernate', 'InstanceState', 'POST', 'Fle', 'hem', 'World', \"('.\", 'able', 'ismus', 'istische', 'ци', 'world', 'liga', 'instances', 'fle', '会', '-$', 'blog', 'phantom', 'läng', 'USA', 'scale', 'jb', 'åk', 'ael', 'lv', 'dek', 'Zweiten', 'Boot', 'telt', 'Hard', 'trim', 'iennent', 'ieben', 'Long', 'Commons', 'de', 'CES', 'world', 'Article', 'advers', 'jev', 'atum', 'keep', 'стя']\n",
      "in Layer18 , sorted_indices_dimension3837:  ['Italian', 'Italy', 'Ital', 'ital', 'italien', 'archivi', 'ità', 'Italie', 'Aless', 'Italien', 'Итали', 'таль', 'Gian', 'Giovanni', 'Luigi', 'Milan', 'Lomb', 'Batt', 'Ric', 'Giul', 'azione', 'Ital', 'Gi', 'Gi', 'Giuseppe', 'Andrea', 'Venez', 'Serie', 'azioni', 'Sic', 'ital', 'italiano', 'ione', 'Italia', 'scala', 'azz', 'della', 'ù', 'dell', 'Caval', 'Gia', 'Giov', 'Giorg', 'Chi', 'ò', 'iano', 'Paolo', '意', 'ella', 'zza', 'rollo', 'Ђ', 'Sci', 'amma', 'berg', 'Florence', 'Rome', 'di', 'agh', 'Francesco', 'alla', 'Milano', 'ello', 'lär', 'gia', 'ieri', 'Bres', 'ì', 'Mario', 'bbi', 'Sito', '義', 'Ferr', 'uclide', 'Italia', 'fatt', 'buf', 'annel', 'Antonio', 'atti', 'italiana', 'izza', 'gi', 'sci', 'allo', 'wł', 'opera', 'zione', 'espèce', 'ederb', 'Chiesa', 'atore', 'Carlo', 'spole', 'Stef', 'anel', 'Bolog', 'ano', 'Ris', 'anz', 'Scala', 'Como', 'oteca', 'acco', 'aria', 'Elis', 'igli', 'Repub', 'izione', 'Museo', 'ѐ', 'AtIndexPath', 'références', 'ġ', 'Cin', 'scal', 'arto', 'Cav', 'uzz', 'usto', 'ství', 'Salv', 'è', 'agi', 'Roberto', 'nero', 'Ist', 'javase', 'chio', 'Madonna', 'ato', 'chi', 'onio', 'à', 'passe', 'dei', 'À', 'Ћ', 'lire', 'etti', 'IMARY', 'agini', 'rès', 'asto', 'ino', 'sjö', 'ric', 'izioni', 'chia', 'ogne', 'là', '朱', 'Ces', 'como', 'gh', 'tir', 'èg', 'Marco', 'Pia', 'rea', 'etter', 'acqu', 'Camp', 'scop', 'Bian', 'Il', 'empio', 'dall', 'usc', 'Хронологија', 'obb', 'onnées', 'Feder', 'increment', 'consultato', 'Vec', 'ċ', 'bia', 'erten', 'amo', 'Oper', 'uzione', 'tembre', 'parlament', 'ibile', 'Verl', 'Ez', 'gior', '\\x99', 'abile', 'fu', 'Pad', 'Bruno', 'atorio', 'delle', 'avano', 'Bert', 'DL', 'iclopedia', 'scientific']\n",
      "in Layer18 , sorted_indices_dimension62:  ['�', 'oci', 'mes', 'ule', 'Punk', '�', 'tons', 'uler', 'itul', 'gravity', 'encia', 'onder', 'ton', 'yme', 'cide', 'office', 'schen', 'lah', 'ELSE', 'oku', 'isser', 'agas', 'висини', 'arto', 'Office', 'sock', 'ribu', 'Hamb', 'hd', 'odos', 'dispos', 'pak', 'ichi', 'urity', 'lag', 'noise', '昌', 'Clar', 'げ', 'Ed', 'office', 'же', 'aget', 'cribed', 'оте', 'желез', 'rá', 'squares', 'ali', 'ppy', 'ons', 'unk', 'punk', 'streets', 'verk', '机', '∩', 'universe', 'aters', 'jos', 'ERT', 'ɔ', 'règ', 'тара', 'ashi', 'von', 'icode', 'Pak', 'chen', 'Paulo', 'sers', 'vot', 'Pakistan', 'ród', 'avi', 'orgen', 'vider', '被', 'вана', 'implicit', 'audi', 'enders', 'ovie', 'cribe', 'endre', 'pk', 'cem', 'Fried', 'ért', 'пута', 'native', 'upp', 'uvo', 'angu', 'ioni', 'atu', 'empio', 'Intent', 'uma', 'Paz', 'itors', 'ktor', 'SS', 'icut', 'emed', 'native', 'rag', 'pog', 'mers', 'utility', 'errors', 'Serial', 'porta', 'itle', 'wad', 'Verl', 'Hash', 'urb', 'Sender', 'Harm', 'Feld', 'ktet', 'ñ', 'odia', 'eni', 'Rudolf', 'ponder', 'gravity', 'riere', 'ook', 'enci', 'aml', 'Nich', 'Sank', 'политиче', 'czy', 'berger', 'rise', 'PN', 'Compos', 'iele', 'лено', '夢', 'ctor', 'ун', 'прав', 'cita', 'arters', 'ká', 'ali', 'sense', 'icon', 'ários', 'Frei', 'Sug', 'ப', 'шин', 'Analysis', 'пон', '($(', 'burger', 'Fred', 'Maler', 'edges', '今', 'clock', 'resp', 'irs', 'useful', 'памя', 'namespace', 'Serial', 'alles', 'uen', 'HD', 'ANG', 'unique', 'Gib', 'Political', 'cza', 'рого', '대', 'marg', 'Éd', 'otos', 'прави', 'metros', 'udi', 'erv', 'inside', 'Else', 'irc', 'answer', 'Buffered', 'printStackTrace', 'kolej', 'lait', 'lette', 'lar', 'ivos']\n",
      "Key: model.layers.19.mlp.down_proj.weight\n",
      "in Layer19 , sorted_indices_dimension9590:  ['target', 'attacks', 'targets', 'attack', 'attacked', 'efforts', 'attention', 'FK', 'arget', 'directions', 'ấ', 'ん', 'Target', 'archar', 'operations', 'target', 'directed', 'Target', 'shift', 'direction', 'শ', 'rappres', 'etr', 'lär', 'focus', 'beskre', 'area', 'explo', 'choosing', 'Focus', 'вер', 'purs', 'wär', 'ря', 'activities', 'EXISTS', 'focused', 'effort', 'Richtung', 'shift', 'arus', 'Javascript', 'sott', 'área', 'ielt', 'stagione', 'ḷ', 'uvud', 'egov', 'deutsch', 'atac', 'områ', 'iros', '__(', 'areas', 'concent', 'att', 'áll', 'Ziel', 'зик', 'amenti', 'baum', 'activity', 'opera', 'energ', 'Hij', 'externs', 'area', 'recensement', 'conde', 'einges', 'dirig', 'iała', 'redirect', 'assault', 'atta', '集', 'fluss', 'directeur', 'operation', 'ders', 'дна', 'gminy', 'IMARY', 'musicale', 'concentration', 'Bahnhof', 'ɯ', 'Ley', 'cí', 'områ', 'վ', 'direction', 'totalité', 'rite', 'CURLOPT', 'Хронологија', 'Invalid', 'choose', 'шин', 'броја', 'ciu', '目', 'concentr', '&=\\\\', '�', 'ugno', '运', 'iana', 'rí', 'sav', 'Mitte', 'opera', 'choose', 'selecting', 'cji', 'zott', 'attr', 'redirects', 'ン', 'osci', 'wechselte', '$}}%', 'enburg', 'resources', 'headers', '活', 'ierno', 'општи', 'itaire', 'ध', 'Pour', 'là', 'направ', 'tedes', 'iec', 'писко', 'uda', 'Nikol', 'Sammlung', 'activity', 'esser', ']`.', 'ulpt', 'Formatter', 'sers', 'eil', 'eben', 'Düsseld', 'archiviato', '▸', 'Factory', 'dorf', 'zs', 'ност', 'branch', 'kehr', 'zeug', 'Pier', 'mehrerer', 'oteca', '~[', '奇', 'ayout', 'ран', '伝', 'untu', 'gebras', 'ubern', 'Архи', 'JavaScript', 'dor', 'stabil', 'enumer', 'lage', 'scr', 'Zak', '丸', 'focus', 'ryty', 'ว', 'else', 'omsnitt', 'nuova', 'седа', 'rivial', 'Archite', '니', 'campagne', 'BY', '選', 'Opera', 'plotlib', 'mouv', 'foc', 'ilities', 'bildung', 'diretto', 'iency', '재']\n",
      "in Layer19 , sorted_indices_dimension3076:  ['sound', 'music', 'sounds', '音', 'Sound', 'Music', 'Sound', 'sound', 'Music', 'heard', 'music', 'musical', 'зву', 'harm', '음', 'recorded', 'voice', 'vocal', 'recording', 'instrument', 'música', 'record', 'song', 'songs', 'voices', 'музы', 'vocals', 'musique', 'guitar', 'mel', 'harm', 'audio', 'radio', 'bass', 'record', 'Audiod', '歌', 'played', 'instruments', 'piano', 'listen', 'Musical', 'listen', 'musica', 'aud', 'ac', 'voice', 'mús', 'Record', 'Radio', 'son', '曲', 'listened', 'mus', 'vo', 'frequencies', '♭', 'Musik', 'музи', 'ears', 'tone', 'tracks', 'Vo', 'hearing', 'hear', 'concert', 'Record', 'noise', 'listener', 'muz', 'playing', 'phony', 'голо', 'rument', '乐', 'voix', 'phon', 'oph', 'album', 'chestra', 'aud', 'solo', 'pian', 'sop', 'accompan', 'ound', 'track', 'echo', 'singing', 'composer', 'Audio', 'Audio', 'gro', 'loud', 'пес', '楽', 'notes', 'CD', 'alto', 'singer', 'Ac', 'musicale', 'echo', 'List', 'tempo', 'spiel', 'play', 'vo', 'samples', 'audio', 'pip', 'cho', 'Radio', 'ear', 'note', 'Gro', 'mus', 'horn', 'sheet', 'fon', 'cussion', 'Mus', 'Bach', 'synth', 'rever', 'Ac', 'ring', 'records', '录', 'radio', 'Son', 'listening', 'sym', 'Aud', 'ounding', 'compos', 'arrang', 'Records', 'zvuky', 'arr', 'string', 'pitch', 'samples', 'Billboard', 'Notes', 'SON', 'canción', 'sample', 'frequency', 'conduct', 'sing', 'retto', 'strings', 'chor', 'composition', 'inton', 'ph', 'dynamics', 'cantante', 'oper', 'icas', 'oust', 'Harm', 'string', 'viol', 'uetooth', 'tym', 'volume', 'song', 'ears', 'Mus', 'غ', 'orch', '专', 'Db', 'track', 'List', 'accomp', 'listener', 'mp', 'poly', 'accord', 'компози', 'Sheet', 'ural', 'albums', 'player', 'keyboard', 'voce', 'lär', 'engineer', 'performed', 'itar', 'dir', 'Discogs', 'Audiodateien', 'notes', 'Volume', 'aria', 'Voci']\n",
      "in Layer19 , sorted_indices_dimension1574:  ['javascript', 'ince', 'ász', 'onderwerp', 'IMA', 'oti', 'ugen', 'invån', 'ienie', 'mé', 'cies', 'rör', '省', 'ân', 'cian', 'itzer', 'studio', 'Zyg', 'edit', 'rappres', 'cdn', 'Studio', 'iente', 'ibm', 'lij', 'izi', 'mob', '龙', 'UMN', 'desar', 'kill', 'inflate', 'ésie', 'зен', 'izio', 'ockey', '{#', 'supply', 'CTYPE', 'refresh', 'angen', 'ftrag', '=\"@+', 'cir', 'kund', 'icia', 'ariat', 'ébec', 'beskre', 'LOB', 'jboss', 'ician', 'nn', 'ício', 'кан', 'foot', 'anno', 'ख', 'ण', 'anha', '↔', 'ês', 'tembre', 'imento', 'Cub', 'ends', 'cloudflare', 'Anleitung', 'antin', 'etes', 'сини', 'ம', 'nung', 'Regie', 'üb', '久', 'sci', 'дами', '�', 'rane', 'isi', 'lyn', 'disp', '{.', 'repeat', 'péri', 'hu', 'onel', 'diffus', 'audi', 'manifold', 'placeholder', 'Murray', 'ники', 'Gest', 'undefined', 'berga', 'Architecture', 'nil', 'ises', '़', 'ici', 'Orig', 'pes', 'omorph', 'roke', 'ança', 'kotlin', 'bon', 'geber', 'ď', 'preview', 'нин', 'Bien', 'UE', 'accord', 'mur', 'кро', 'inci', 'Visual', 'ardi', 'crow', 'esent', 'hög', 'стем', 'ír', 'óm', 'cks', 'Gemeins', 'lá', 'uten', 'clos', 'ako', 'architect', 'architecture', 'auff', 'kill', 'uba', 'UIView', 'hadoop', 'CAA', 'elles', 'inwon', 'plom', 'Serial', 'ℓ', 'irk', 'ści', 'beginner', 'Пе', 'дов', 'blob', 'cis', 'raph', 'idenote', 'ние', 'ē', 'esta', 'prü', 'supp', 'print', 'rick', 'bon', 'ез', 'сте', 'setContentView', 'iko', 'nouvelles', 'sculpt', 'ends', 'Amts', 'anza', 'beg', 'ály', 'hes', 'äst', 'cod', 'cite', 'autorité', 'тет', 'Select', 'lek', 'ន', '/\\\\', 'prise', 'Selection', 'icher', '�', 'ings', 'webdriver', 'uri', 'Meister', 'meno', 'REQUEST', 'slä', 'Meyer', 'catalina', '尾', '\\x81', 'Λ']\n",
      "in Layer19 , sorted_indices_dimension335:  ['hotel', 'drug', 'ghan', 'adal', 'DP', 'church', 'movie', 'unal', 'ylvan', 'erade', 'itud', 'protein', 'oten', 'edom', 'forge', 'zin', 'ɐ', 'Kais', 'ança', 'fern', 'game', 'Wort', 'rug', 'ɨ', 'restaurant', 'ECK', 'koz', 'ʃ', 'isu', 'ace', 'ь', 'squ', 'marriage', '🌍', 'рав', 'elsk', 'ähl', 'prü', 'че', 'itan', 'Oscar', 'Mand', 'movie', '片', 'б', 'aca', 'phone', 'ocean', 'bour', 'paces', 'oni', 'แ', 'ield', 'ROP', 'rez', 'VP', 'imes', 'job', 'твор', 'piłkar', 'isten', 'tb', 'ami', 'studio', 'За', 'usz', 'Seine', 'anna', 'lej', 'political', 'erea', 'Ses', 'burg', 'pok', 'ije', 'ugel', 'veh', 'numer', 'ike', 'ogonal', 'liga', 'concat', 'oven', 'її', 'router', 'Seconds', 'alom', 'kins', 'quin', 'Pas', 'ille', 'hai', 'studio', 'soort', 'tis', 'TV', 'оте', 'зова', 'nehm', 'arca', 'Replace', 'usammen', 'mieszkań', 'ulle', 'decimal', 'ixa', 'vec', 'ɔ', 'heits', 'fal', 'haus', 'śc', 'bourg', 'сті', 'Cha', 'SHA', 'scheid', 'Lista', 'disease', 'ountry', 'IX', 'itzen', 'iera', 'uls', 'Ocean', 'replace', 'ense', 'Masters', 'agas', 'school', 'las', 'nej', 'product', 'consulté', 'IT', 'esters', 'rab', 'asons', 'phere', 'ствии', 'era', 'ius', 'uela', 'iore', 'dienst', 'III', 'industry', '渡', 'iges', 'tha', 'river', 'Replace', 'fficiale', 'uvo', 'utive', 'OD', 'lista', 'owie', 'Ek', 'olation', 'Wei', 'grasp', 'zwar', 'izza', 'bol', 'election', 'Cup', 'âte', 'tournament', 'ila', 'ellett', 'organiz', 'aille', 'Prize', '->_', 'церков', 'buch', 'alf', 'manera', 'prison', 'dp', 'Bod', 'й', 'owan', 'ma', 'utch', 'Hold', 'economic', 'oma', 'iała', 'erve', 'kirche', 'ष', 'ffen', 'festival', 'ellers', 'borg', 'olt', 'role', 'scription']\n",
      "Key: model.layers.20.mlp.down_proj.weight\n",
      "in Layer20 , sorted_indices_dimension7624:  ['ango', 'owie', 'Fu', 'usz', 'rode', 'дина', 'gat', 'annon', 'braio', 'enska', 'ру', 'tum', 'ок', 'papers', 'fuel', 'crist', 'struct', 'fu', 'ennen', 'tat', 'ща', 'Rou', 'perty', 'Eu', 'Свя', 'Ritter', 'oro', 'kre', 'especial', '▼', 'uf', 'Fall', 'pap', 'ocal', '¤', 'Anna', 'disco', 'ride', 'вен', 'лла', 'Rein', 'aer', 'Sank', 'ride', 'grid', 'asket', 'fare', 'quia', 'fallen', 'fall', 'grid', 'tero', 'ram', 'Lim', 'urale', 'ру', 'sf', 'ocs', 'espe', 'Night', 'ufen', 'rob', 'ufe', '경', 'Vog', 'igner', 'wer', 'ween', 'ella', 'plat', 'ms', 'orio', '마', 'estruct', 'unk', 'iter', 'isc', 'át', 'anno', 'UM', 'crash', 'eing', 'ф', '菜', 'öll', 'animate', 'CL', 'м', 'ort', 'Ven', 'rapper', 'discover', 'internacional', 'eu', 'financi', 'yield', 'bla', 'guide', 'alf', 'ți', 'quer', 'ker', 'ce', 'dom', 'commer', 'struct', 'ด', 'Ham', 'Grid', 'industrial', 'ange', 'discovered', 'це', 'generator', 'kier', 'Akt', 'ộ', 'dur', 'omena', 'collection', 'ссе', 'vär', 'ter', 'papel', 'overlap', 'fram', 'cm', 'unker', 'Britannica', 'Berg', 'stal', 'anska', 'rund', 'ο', 'structure', 'Ak', '`', 'otal', 'не', 'Guide', 'duration', 'invest', 'apers', 'red', 'ody', 'Arena', 'Mock', 'piano', 'ite', 'lder', 'гар', 'stadt', 'ermeister', 'EX', 'lesia', 'landet', 'Bla', 'ver', 'у', 'wat', '区', 'Parker', 'athon', 'enders', 'Belgique', 'anga', 'dann', 'сторія', 'documentation', 'strik', 'collection', 'kaf', 'sculpt', 'anim', 'udes', '\"\"\"', 'bru', 'Miguel', 'redis', 'falls', 'trat', 'ode', 'unn', 'pid', 'Fir', 'ECK', 'enter', 'савезној', 'Nach', 'ба', 'gold', 'PDO', 'ḏ', 'mas', 'Cic', 'ห', 'RAM', 'Limit', 'ühle', 'cri']\n",
      "in Layer20 , sorted_indices_dimension3659:  ['opening', 'ski', 'jà', 'iende', 'vt', 'pam', 'ql', 'opened', 'lv', 'icol', 'prolong', 'Lic', 'assen', 'iert', 'aupt', 'lit', 'rass', 'naam', 'ást', 'azzo', 'Finale', 'cond', 'fetch', 'ski', 'utive', 'ふ', 'lic', 'ennen', 'Æ', 'ёр', 'ry', 'beg', 'ців', 'hlen', 'gep', 'finale', 'Lit', 'тельно', 'xtart', 'ёл', 'iba', '(__', 'coll', 'Ah', 'MC', 'Akadem', 'istr', 'asta', 'lengths', 'DER', 'bourg', '博', 'rze', 'izin', 'óż', 'ellen', 'closing', 'Theme', 'capit', 'spre', 'ussen', 'idor', 'Response', 'las', 'schied', 'лли', 'opens', 'Cop', 'обра', 'vin', 'öff', 'Fetch', 'PK', 'iformes', 'ooth', '__.', 'imo', 'fetch', 'entation', 'museum', 'minipage', 'length', 'typen', 'ách', 'assign', 'begg', 'oin', 'LENGTH', 'ktet', 'assign', 'iese', 'Pam', 'meno', 'iva', 'euw', 'unfold', 'assim', 'phas', 'ському', 'ль', 'бу', 'rière', 'Situ', 'Phoenix', 'verkehr', 'Beginn', 'hö', 'iments', 'æ', 'erca', '�', 'offices', 'aste', 'iali', 'öff', 'borg', '論', '流', 'пута', 'zem', 'Las', 'insic', 'theme', 'heits', 'ít', 'Java', 'anges', 'TRAN', 'wp', 'bucket', '/_', 'MainActivity', 'ampa', 'familiar', '±', 'icos', 'opera', 'uras', 'inder', 'ahlen', 'xa', 'ims', 'ย', 'Edition', 'oint', '호', 'lbl', 'isions', 'HD', 'лю', 'šč', 'title', 'pag', 'relev', 'œuv', 'enta', '�', 'ousin', 'spole', 'terug', 'hör', '┤', 'egin', 'lower', 'beg', 'Duration', 'toString', 'бро', 'aster', 'owski', '内', 'Beg', 'Arten', 'amplitude', 'zeum', 'xelles', 'presentation', 'dart', 'bum', 'ниче', 'rap', 'amy', '展', 'longest', 'pair', 'NER', 'ależ', '/\\\\', 'credentials', 'reven', 'Rum', 'слі', 'implements', 'invert', 'achi', 'preced', 'ah', 'iony', 'wik', 'colours']\n",
      "in Layer20 , sorted_indices_dimension2540:  ['feature', 'feature', 'features', 'property', 'Feature', 'features', 'function', 'property', 'attribute', 'Property', 'functionality', 'command', 'function', '功', 'Property', 'properties', 'fonction', 'characteristic', 'option', 'functions', 'attribute', 'Properties', 'module', 'свой', 'command', 'parameter', 'функ', 'featured', 'trait', 'cmd', 'setting', 'bug', 'setting', 'власти', 'parameter', 'ability', 'Function', '属', 'built', 'caracter', 'commands', 'optional', 'option', 'comand', 'Option', 'Fe', 'Attribute', 'Module', 'attributes', 'functions', 'properties', 'plug', 'Attribute', 'modules', 'built', 'ugin', 'funcion', 'cap', 'button', 'plugin', 'module', 'extension', 'Function', 'caratter', 'featuring', 'clause', 'mier', 'Command', 'Properties', 'adj', 'wach', 'func', 'Ṭ', 'facility', 'perty', 'commanded', 'functional', 'муніципалі', 'provision', 'funkc', 'сан', 'capabilities', 'Option', 'ropy', '能', '♂', 'Setting', 'bug', 'actéristiques', 'wert', 'optional', 'yci', 'INCT', 'plugin', 'talent', 'options', 'MT', 'ientes', 'library', 'istiques', 'characteristics', 'plugins', '特', '機', 'directive', 'vulner', 'mechan', 'rule', 'cmd', 'add', 'Parameter', 'param', 'Ing', ':\\u2009', 'menu', 'ongodb', 'Gene', 'Bug', 'чер', 'ّ', 'setopt', 'Mechan', 'atures', 'flag', 'ѫ', 'Module', 'jets', 'reserved', 'icana', 'Setting', 'endet', '望', 'ण', 'bero', 'modules', 'preis', '기', 'ility', 'imenti', 'jahr', 'лом', 'ucha', 'unicí', 'commands', 'pois', 'facilities', '命', 'Bom', 'лл', 'imer', 'Command', 'library', 'behaviour', 'actér', 'ito', 'enschaft', 'attributes', 'ilities', 'repla', 'Menu', 'lung', 'field', 'щі', 'commander', 'BUG', 'instruction', 'bugs', 'Button', 'ós', 'Parameter', 'macro', 'łą', 'documentclass', 'dru', 'inde', '♀', 'acs', 'athol', 'ruguay', 'Views', 'unal', 'чник', 'native', '()', 'Pa', 'licht', 'реди', 'ecz', 'amen', 'modifier', 'Commander', 'бро', 'Roberto', 'rop', 'x', 'attachment', 'propri', 'ienst', 'iente', 'spell']\n",
      "in Layer20 , sorted_indices_dimension4398:  ['song', 'singing', 'dance', 'songs', 'music', 'dan', '歌', 'musical', 'song', 'Dance', 'sing', 'sang', 'Music', 'Song', 'пес', 'Sing', 'Music', 'Songs', 'music', 'Sing', 'dan', 'singer', 'Musical', 'sing', 'rh', 'canción', 'chanson', 'chant', 'музы', 'тан', 'chante', 'música', 'Dan', '曲', 'Musik', 'musicale', 'guitar', 'musica', 'rh', 'piano', 'hum', 'musique', 'Dan', 'ymn', 'lieder', 'Singh', 'mel', '舞', 'mus', 'ongs', 'музи', 'cantante', 'verse', 'poem', 'mús', 'hum', 'Dans', 'lyr', 'drums', 'Lied', 'singleton', 'Sang', 'harm', 'drum', 'fiddle', 'chant', '乐', 'nur', 'dans', 'march', 'rend', 'cla', 'Singapore', 'rap', 'ong', 'disco', 'Singap', 'unes', 'mus', '音', 'Hum', 'ski', 'zp', 'rend', 'pian', 'mel', 'poetry', 'ismus', 'cant', 'Ps', 'jazz', 'chestra', 'prayer', 'ps', 'rec', 'pray', 'playing', 'opera', 'Harm', 'Anto', 'harm', 'ski', 'phony', 'games', 'party', 'Blues', 'walt', '楽', 'sjö', 'ythm', 'Rh', 'etto', 'pipe', 'oper', 'folk', 'muz', 'vers', 'skip', 'synchron', 'ode', 'rock', 'vocals', 'anth', 'plays', 'SG', 'Opera', 'cad', 'тан', 'Mus', 'yr', 'ser', 'DJ', 'рит', 'iano', 'sync', 'SON', 'Orchestra', 'Daniel', 'ul', '음', 'ś', 'ONG', 'jam', 'мар', 'jump', 'sync', 'composer', 'Party', 'fest', 'inn', 'mer', 'tempo', 'ugust', 'ango', 'ody', 'tro', 'pace', 'Play', 'ountry', 'itaire', 'tap', 'anz', 'син', 'auc', 'rit', 'rez', 'Ski', 'пе', 'play', 'Cant', 'gan', 'accomp', 'lip', 'ball', 'ieder', 'ums', 'sug', 'gan', 'jeu', 'worship', 'ances', 'wh', 'accompan', 'wig', 'imenti', 'Longrightarrow', 'osz', 'дан', 'furn', 'party', 'play', 'дан', 'Mel', 'ader', 'timing', 'laugh', 'circle', 'tamb', 'aden', 'Cla']\n",
      "in Layer20 , sorted_indices_dimension8567:  ['atu', 'rr', 'ingers', 'ster', 'kne', 'alle', 'рд', 'ettes', 'urz', 'Theme', 'iante', 'Wood', 'Mission', 'pat', 'finger', 'Pub', 'Datos', 'orld', 'üd', 'detailed', 'rowser', 'painted', 'fashion', 'icos', 'ả', 'Список', 'лья', 'Strings', 'oul', 'net', 'uns', 'edo', 'hez', 'ashion', 'Tow', 'mission', 'Net', 'osto', 'Zür', 'ą', 'alla', 'uby', 'pat', 'knock', 'lasse', 'zat', 'Patri', 'rsg', 'Tennis', 'window', 'ikus', 'Χ', 'Pra', 'agn', 'greatly', 'Battle', 'Net', 'tradu', 'Paint', 'Blues', 'run', 'Illustration', 'roid', 'Wo', 'statue', 'abb', 'Й', 'lek', 'aba', 'hex', 'SER', 'missed', 'inform', 'opera', 'Bitmap', 'Toy', 'Masters', 'Ny', 'цем', 'ono', 'zó', 'Schl', 'estore', 'nur', 'ropol', 'sudo', 'ós', 'Beth', 'runtime', 'ован', 'rikt', 'opera', 'substitution', 'native', 'Komm', 'figure', 'Runtime', 'Sv', 'Pat', 'mirror', 'dess', 'screen', 'ville', 'oster', 'door', 'Bath', 'amet', 'estone', 'Pub', 'fiddle', 'Extern', 'swap', 'Wort', 'screens', 'anse', 'Pictures', 'isto', 'monitoring', 'Hozzáférés', 'pub', 'Batt', 'Syl', 'Window', 'iku', '호', 'Wrestling', 'nomin', '石', 'zos', 'ilis', 'repla', 'os', 'nav', 'battle', 'ifica', 'stat', 'informed', '�', 'mission', 'isset', 'uninstall', 'Screen', 'disco', 'colon', 'stretch', 'Rail', 'kunst', 'gau', 'Spo', 'Kn', 'цу', 'при', 'figures', 'ymn', 'bois', 'Thé', 'etailed', 'rep', 'basket', 'sys', 'gar', '∞', 'terra', 'sant', 'gar', 'encias', 'native', 'estellt', 'Jazz', 'EQ', 'кате', 'figure', 'ingsområ', 'bud', 'wood', 'Stre', 'ště', 'contrib', 'Mack', 'fig', 'Kid', 'Bitmap', 'painting', 'ools', 'inc', 'Games', 'energ', 'ца', 'ichen', 'istra', 'zin', 'bath', 'Medal', 'hover', 'dri', 'Stone', 'Till', 'дні', 'Tu', '操']\n",
      "Key: model.layers.21.mlp.down_proj.weight\n",
      "in Layer21 , sorted_indices_dimension6560:  ['reve', 'revealed', 'disc', 'spo', 'narrow', 'revel', 'tell', 'div', 'ár', 'telling', 'act', 'announ', 'hy', 'una', 'tells', 'ver', 'its', 'LM', 'hint', 'broadcast', 'uen', '師', 'che', 'confirm', 'kn', 'chen', 'ivi', 'рован', 'nose', 'giv', 'voir', 'iku', 'Wes', 'án', 'pu', 'ign', 'pie', 'nam', 'prep', 'important', 'stating', 'lan', 'ancest', 'iger', 'пло', 'Given', 'prepare', 'giv', 'né', 'ru', 'cov', 'Meyer', 'enden', 'immagini', 'oci', 'eeuw', 'released', 'asp', 'リ', 'swing', 'release', 'Bened', 'lock', 'phe', 'kö', 'ries', 'Parser', 'mouth', 'пові', 'Hint', 'Éd', 'RL', 'Spo', 'да', 'currency', 'accomp', 'meister', 'хі', 'eras', 'Give', 'мо', 'ist', 'olar', 'clarify', 'Bres', 'mer', 'card', 'ieder', 'atter', 'kis', 'дія', 'mo', 'announced', 'ън', 'arrow', 'AC', 'confirm', 'ön', 'rote', 'verify', '�', 'Way', 'specified', 'inform', 'given', 'Publish', 'VID', 'ger', 'vor', 'Tell', 'ubre', 'rieben', 'ahlen', 'hö', 'AC', 'IES', 'ське', 'Spec', 'destac', 'Ed', 'рия', 'enk', 'snow', 'competition', 'cript', 'amil', '知', 'cup', 'publication', 'Wagner', 'persone', 'rias', 'aver', 'uis', 'տ', 'Garden', 'inds', 'pł', 'nos', 'teger', 'aci', 'imin', 'rott', 'ikan', 'olare', 'bias', 'données', 'ovo', 'mn', 'encuent', 'en', 'Dres', 'краї', 'хра', 'Ward', '�', 'vy', 'grote', 'pace', 'our', 'prepared', 'omorphic', 'riz', 'apor', 'Eisen', 'ár', 'told', 'tip', 'információ', 'Lü', 'koji', 'EQ', 'skip', 'mat', 'ori', 'Поль', '⚭', 'key', 'heb', 'ere', 'bekannt', 'publishing', 'information', 'bě', 'hover', 'da', 'render', 'sib', 'кін', 'Basketball', 'Show', 'Know', 'ski', 'atto', 'engu', 'oro', 'oud', 'Jac', '面', 'decir']\n",
      "in Layer21 , sorted_indices_dimension6998:  ['music', 'orr', 'music', 'Music', 'kem', 'cook', 'musica', 'stabil', 'музи', 'Music', 'dent', 'arts', 'print', 'ename', 'Account', 'aliment', 'sang', 'Portail', 'paint', 'sted', 'sleep', 'medic', '看', 'account', 'painting', 'album', '食', 'architect', 'chem', 'musical', 'Paint', 'chante', 'музы', 'gresql', 'transport', 'Account', 'arel', 'account', 'зы', 'books', 'Print', 'Bayer', 'wine', 'zahl', 'Riemann', 'atre', 'footnote', 'algebraic', 'Discogs', 'arithmetic', 'muz', 'fit', 'Tennis', 'рой', 'Musical', 'blood', 'printer', 'circul', 'Spiel', 'Print', 'games', 'Stern', 'LED', 'fit', 'furn', 'hydro', 'breath', 'erv', 'hbar', 'Medical', 'trees', 'stoff', 'fresh', 'film', 'ächst', 'Teatro', 'aircraft', 'flex', 'licht', 'film', 'ing', 'sport', 'tree', 'liqu', 'uns', 'Orth', 'enberg', 'apa', 'fashion', 'unicí', 'book', 'mez', 'Musik', 'oris', 'svo', 'aho', 'roof', 'phi', 'Gram', '□', 'fins', 'dl', '│', '✓', 'Spieler', 'orio', 'Heidel', 'Torre', '�', 'UTF', 'mos', 'Cond', 'LD', 'méd', 'AS', 'etra', 'reen', 'Sport', 'plant', 'Schrift', 'tématu', 'mai', 'ugen', 'interno', '≫', 'annot', 'estion', 'щ', 'drawable', 'collection', 'ieder', 'peint', 'tei', 'oda', 'CD', 'Gla', 'bi', 'éroï', 'iform', 'clean', 'orch', 'speech', 'mus', 'transmission', 'för', 'ASP', 'food', 'nuclear', '音', 'све', 'Hist', 'ihe', '{-', 'imm', 'Orchestra', 'returns', '選', 'Linux', 'ov', 'collection', '↔', 'chemical', '^^', 'blah', 'fotograf', 'mús', 'match', 'book', 'Astronom', 'pler', 'stable', 'game', 'lub', 'spel', 'calcul', 'Phys', 'Sports', 'AS', '<-', 'et', 'Koh', 'Tree', 'VF', 'prost', 'MDb', 'astro', 'piano', 'opera', 'numbers', '⇒', 'Athlet', 'phot', 'alco', 'stronom', 'Garc', 'es', 'música', 'Gün', 'storage', 'math']\n",
      "in Layer21 , sorted_indices_dimension8541:  ['cza', 'arget', 'fb', 'appart', 'wards', 'рем', 'wehr', 'ży', 'alus', '(„', 'Nom', 'visibility', 'VI', 'ění', 'icina', 'Kontrola', 'weights', 'olimp', 'tensorflow', 'մ', 'inition', 'zyst', 'ement', 'pent', 'Period', 'Bac', 'arsi', 'ój', 'leben', 'shire', 'éric', 'ISBN', 'nom', 'Middle', 'moyenne', 'Cold', 'Earth', 'мен', 'ภ', 'resource', 'ieri', 'ℚ', 'plorer', 'Target', 'idden', 'bazie', 'targets', '所', 'irm', 'zna', 'javafx', 'ppo', 'kreis', 'atrice', 'პ', 'Pho', 'ischof', 'Lng', 'fos', 'Airl', 'yntax', 'Mig', 'śc', 'Données', 'isons', 'ase', 'usammen', 'licz', 'Asp', 'Jur', 'fried', 'ination', 'vac', 'Duration', 'ру', 'hrab', 'consulté', 'Syd', 'SBN', 'atori', 'fle', 'zet', 'ggreg', 'atura', 'Års', 'kiss', 'SError', '²,', 'refix', 'syntax', 'deployment', 'вания', 'dbo', 'ebook', 'vb', ']=\"', 'efe', 'isms', 'emente', 'Runner', 'oning', 'sugg', 'superfic', 'ческая', '⊥', 'бро', 'less', 'bing', 'daugh', 'atorio', 'Gy', 'bev', 'isis', 'volume', 'VIS', 'Ingl', 'Target', 'Oficina', 'éon', 'FB', 'icz', 'REF', 'agit', 'DEF', 'execution', 'iss', 'fold', 'ick', 'mol', ')--(', 'gerufen', 'fog', 'nom', 'RENT', 'кол', 'ßen', 'okres', 'bases', 'Zygote', 'ymnas', 'talent', 'olu', 'ogs', '{`', 'кафе', 'Fich', 'sBy', 'duration', 'cation', 'Zyg', 'BUG', '記', 'cube', 'television', 'Оте', 'ruf', 'xx', 'atre', 'жива', 'verf', 'beh', 'ettings', 'VALUES', 'comprend', 'PY', 'Orig', 'webkit', 'матери', 'Référence', 'ierz', 'пла', 'igner', 'agog', 'unda', 'kre', 'Static', 'ureau', 'ční', 'irst', 'naz', 'пов', 'Py', 'pb', 'Egy', 'echo', 'quis', '置', 'ASE', 'Volks', 'castle', 'Sent', 'etra', 'rewrite', 'egy', 'pton', '沙', 'aines', 'ouwen', 'atio', 'eros']\n",
      "in Layer21 , sorted_indices_dimension9974:  ['arr', 'Bevölker', 'Gemeins', 'ice', 'ymi', 'ung', 'als', 'ep', 'ere', 'ý', 'oni', 'джи', 'burg', 'heimer', 'iddle', 'ova', 'ial', 'ты', '符', 'ICE', 'iti', 'ice', 'uest', '�', 'Ь', 'ius', 'Sat', 'ɹ', 'imb', 'zia', 'eren', 'centre', 'ponent', '�', 'ossa', 'ient', 'apt', 'cide', 'tone', 'deb', 'ood', 'jor', 'Кур', 'false', 'живело', 'ump', 'Чи', 'concent', 'pointer', 'oria', 'pointer', 'Ice', '建', 'Û', 'loy', '%{', 'ron', 'ois', 'profile', 'hör', '出', 'Centre', 'ince', 'central', 'mij', 'MDb', 'estr', 'aris', 'von', 'ity', 'eks', 'PDF', 'према', 'apt', 'Fernández', 'profiles', '�', 'rh', 'aires', 'iod', 'esti', 'цент', 'spo', 'cono', 'umi', 'соста', '\\u200e', 'txt', 'lev', '居', 'scratch', 'bet', 'terne', 'indexPath', 'oca', 'nic', 'confident', 'jem', 'mk', 'rec', 'ica', 'üng', 'Bedeut', 'gain', 'ill', 'rece', 'rab', 'centro', 'MenuItem', 'ere', 'rup', 'schaft', '提', 'Agricult', 'unal', 'askell', 'center', 'べ', 'ho', 'ART', 'affili', 'fine', 'ju', 'yt', 'uropa', 'я', 'onCreate', 'suggestions', 'agricult', 'entre', 'мана', 'iom', 'aur', 'FF', 'ną', 'Nau', 'igh', 'atable', 'external', 'ím', 'owi', 'write', 'зя', 'rable', 'uo', 'Einzeln', 'Compos', 'Ill', 'owo', 'ering', 'aya', 'ford', 'Vas', 'hire', 'ea', 'satisf', 'ren', 'central', 'ér', 'ване', 'ries', 'Traceback', 'ong', 'IM', 'aggreg', 'genomsnitt', 'ices', 'ch', 'hope', 'position', 'ym', 'dart', '್', 'points', 'lauf', 'meter', 'ys', 'IB', 'ho', 'center', 'pdf', 'orial', 'inden', 'nice', 'Ě', 'Bere', 'dere', 'tar', 'arial', '心', 'orem', 'oot', '#>', 'iga', 'upload', 'ivi', '่', 'leben', 'Beit', 'bugs']\n",
      "Key: model.layers.22.mlp.down_proj.weight\n",
      "in Layer22 , sorted_indices_dimension2658:  ['band', 'bands', 'instrument', 'instruments', 'band', 'Band', 'cho', 'guitar', 'rock', 'piano', 'jazz', 'pian', 'banda', 'viol', 'classical', 'mus', 'concert', 'sym', 'compos', 'music', 'Orchestra', 'rument', 'orch', 'folk', 'composer', '曲', 'ac', '乐', 'harm', 'oper', 'keyboard', 'compos', 'rock', 'singer', 'musical', 'accompan', 'Jazz', 'composition', 'chestra', 'harm', 'string', 'компози', 'song', 'Sym', 'mus', 'mel', 'orch', 'pop', 'Rock', 'Compos', 'sheet', 'Moz', 'fiddle', 'String', 'solo', 'accord', 'chamber', 'musique', 'sing', 'songs', '楽', 'iano', 'strings', 'Music', 'música', 'ensemble', 'punk', 'opera', 'музы', 'quart', 'Ens', 'compose', 'music', 'Sym', 'Mus', 'Fol', 'olk', 'itar', 'rap', 'chanson', 'synth', '管', 'cho', 'Gram', 'ги', 'ospel', 'ens', 'sym', 'bass', 'String', 'worship', 'ор', 'chor', 'Kompon', 'mús', 'kle', 'Billboard', 'pipe', 'compose', 'musicale', 'composed', 'string', 'uk', 'cussion', 'sop', 'acts', 'metal', 'musica', 'electronic', 'Sheet', 'Ac', 'Music', 'organ', 'album', 'trom', 'пес', 'Strings', 'hip', 'electro', 'drums', 'cant', 'Blues', 'singing', 'compon', 'folk', 'Sing', 'har', 'march', 'Solo', 'opera', 'Mus', 'Musik', 'музи', 'muz', 'performance', 'fiddle', 'pop', 'alto', 'disco', 'ensemble', 'beat', 'vi', 'tun', 'sa', 'Harm', 'Opera', 'Chamber', 'albums', 'rocks', 'Chor', 'scales', '歌', 'bande', 'Cho', 'olin', 'syn', 'zespo', 'Wagner', 'Quart', 'Musical', 'cantante', 'perform', 'Oper', 'inst', 'rend', 'Inst', 'electric', 'performances', 'STRING', 'chante', 'Cant', 'ambient', 'Vi', 'Fiddle', 'kap', 'fol', 'live', 'Pop', 'trou', 'ball', 'pip', 'Class', 'Ac', 'tamb', 'tabs', 'Bach', '打', '交', 'tracks', 'sacred', 'tab', 'conduct', 'Uk', 'act', 'score', 'sing', 'accomp', 'reg', 'mez', 'lieder']\n",
      "in Layer22 , sorted_indices_dimension3846:  ['$}}%', 'aye', 'Fo', 'ahu', 'lem', 'opera', 'ostęp', 'lax', '\"?>', 'сор', 'nen', 'Palmar', '➖', 'FLA', 'afka', 'gens', 'Hollywood', '내', 'sect', 'Sil', 'vn', 'игра', 'LED', 'brázky', '�', 'arters', 'строй', '=\"@+', 'svn', 'Dres', 'мах', 'dflare', 'instantiate', 'makeText', 'ĩ', 'Campion', 'STRING', 'dash', 'Ď', 'ę', 'nig', 'cil', '器', 'structor', 'iot', 'DF', 'сіль', 'Buff', 'Konst', 'kunft', 'TA', 'da', 'Ζ', 'Ada', 'led', 'operating', '�', 'ktet', 'erten', 'paragraph', 'ļ', 'dział', 'inate', 'dash', 'processor', 'inture', 'Mär', 'тво', 'eben', 'RES', 'ʂ', 'Class', 'zon', 'doFilter', 'лек', 'Bres', '☉', 'kou', 'iből', 'ɵ', 'zt', 'Sank', 'Ξ', 'assign', 'istol', 'Nether', 'ox', 'Panel', 'Tage', 'Zob', 'merk', 'еру', 'cla', 'deg', 'prüfe', 'uszt', 'BUG', 'zug', 'теа', 'cache', '連', 'Soc', 'това', 'brid', 'чив', 'CURLOPT', 'ficos', 'дах', 'Campe', 'nika', 'mathchar', 'sup', 'ме', '////////', 'вед', 'AccessorImpl', 'կ', 'Ya', 'míst', 'rails', 'Hor', 'geg', 'cyk', 'elsen', 'éd', 'министра', 'iras', 'fel', 'atives', 'nest', 'ará', 'raw', 'retr', 'Sov', 'fo', 'Sil', '郎', '`.', 'abestanden', 'vent', 'Retrie', 'iada', 'ingers', 'tren', 'Kontrola', 'Phili', 'zone', '일', 'norm', 'imeter', 'rypt', 'ран', 'illo', 'clause', 'processing', 'stolet', 'ART', 'äst', 'Provinz', 'annot', 'Parad', 'Kais', 'édé', 'nx', 'мб', 'NaN', 'zig', 'job', 'chamber', '진', 'angel', 'accessing', 'intersection', 'Play', '津', 'хів', 'irtschaft', 'érieure', 'racle', '\")`', 'furt', 'ט', 'illaume', 'фе', 'catalina', 'мом', 'roph', 'steller', 'Fel', 'Meter', 'edge', 'fach', 'Exit', 'Tag', 'idenote', 'маль', 'eros', 'imer', 'рин', 'ege']\n",
      "in Layer22 , sorted_indices_dimension7247:  ['document', 'detect', 'Document', 'document', 'piano', 'erman', 'Dokument', 'thr', 'dent', 'Document', 'ymn', 'physics', 'physics', 'Forsch', 'hardware', 'detection', 'concert', 'solo', 'composer', 'театра', 'music', '舞', 'guitar', 'invent', 'jon', 'poet', 'dance', 'Music', 'Dance', 'ocument', 'sculpt', 'anth', 'mystery', 'jazz', 'Cop', 'PR', 'Physics', 'Doc', 'Solo', 'Jazz', 'ovan', 'olan', 'akespe', 'journalist', 'research', 'TV', 'ego', 'scient', 'EDIT', 'doctor', 'cop', 'film', 'ikel', 'strip', 'elev', 'improv', 'experiment', 'football', 'estamp', 'izon', 'Art', 'Far', 'athed', 'math', 'aggi', 'нет', 'rep', 'pp', 'movie', 'aka', 'ison', 'れ', 'opera', 'Fa', 'Short', 'ędzy', 'lette', 'lla', 'Sor', 'urz', 'Kurz', 'Kom', 'Fa', 'mathematics', 'poetry', 'egu', '((', 'museum', 'artist', '官', 'dokument', 'egründ', 'Newton', 'Asset', 'nder', 'Esp', 'nig', 'docs', 'ipage', 'iz', 'advert', 'consult', 'college', 'Begriffsklär', 'Punk', 'detected', 'zyk', 'sor', 'pian', 'useum', 'Pri', 'музы', 'documents', 'asse', 'theatre', 'comedy', 'journal', '相', 'Theatre', 'dot', 'obst', 'corpor', 'Palmar', 'skal', 'Opera', 'Pod', 'icle', 'lawyer', 'author', 'Pu', 'Фа', 'era', 'investig', 'musical', 'cussion', '家', 'Edit', 'phas', 'ritt', 'LAY', 'Research', 'iano', 'ao', 'spel', 'Vier', 'punk', 'ney', 'cko', 'football', 'zat', 'documented', 'historian', 'stri', 'manus', 'Com', 'singer', 'jev', 'stronom', 'tennis', 'folk', 'mathematical', 'Psych', 'wine', 'Orchestra', 'museum', 'asset', 'components', 'LENG', 'ando', 'host', 'Journal', 'onn', 'Kompon', 'Ca', 'Shakespeare', 'short', 'Cow', 'yz', 'icana', 'bare', 'Comics', 'priest', 'omp', 'pu', 'izza', 'pson', 'Originals', 'doc', 'com', 'ilo', 'Anti', 'лог', 'Author', 'con', 'pitch', 'доку', 'play', 'Olympic', 'wrest', 'olog']\n",
      "in Layer22 , sorted_indices_dimension2033:  ['Victor', 'Vict', 'Edward', 'vict', 'Georg', 'Victoria', 'Reg', 'victim', 'Aust', 'Empire', 'Belle', 'Vienna', 'period', 'London', 'vitt', 'suff', 'Lond', 'Dick', 'reg', 'society', 'Reg', 'British', 'Jane', 'Society', 'drawing', 'belle', 'England', 'formal', 'VI', 'eleg', 'Grand', 'Российской', 'imperial', 'gas', 'grand', 'arist', 'gentleman', 'Bath', 'Геор', 'Period', 'Oscar', 'elegant', 'ict', 'period', 'English', 'vic', 'wick', 'Imperial', 'tea', 'Wiener', 'Period', 'proper', 'emp', 'Emp', 'ington', 'Vien', 'Gründ', 'sal', 'кто', 'Vitt', 'Ed', 'Vic', 'ust', 'Gas', 'stat', 'Austria', 'stuff', 'gentlemen', 'nick', 'Gilbert', 'obar', 'Лон', 'registry', 'Queen', 'balls', 'VS', 'Goth', 'gent', 'reg', 'fashion', 'Lad', 'mann', 'steam', 'victory', 'gas', 'Louis', 'nin', 'sal', 'grand', 'Raj', 'ladies', 'Wilhelm', 'STAT', 'ел', 'Regin', 'zen', 'lady', 'Georgia', 'віт', 'ton', 'vt', 'Melbourne', 'Alfred', 'clock', 'servants', '̂', 'ons', 'ball', 'indre', 'Charles', 'parl', 'ViewController', 'Dar', 'VB', 'Herbert', 'пен', 'Lond', '£', 'Britain', 'gent', 'URL', 'Dum', 'Well', 'Regex', 'VC', 'opera', 'ví', 'Londres', 'prü', 'Edwards', '明', 'vill', 'bow', 'terra', 'Ві', 'Gesellschaft', 'uki', 'awa', 'ві', 'Olymp', 'Emp', 'ча', 'grandes', 'Opera', 'brit', 'ste', 'prom', 'pse', 'colonial', 'George', 'Федерации', 'ви', 'Napoleon', 'grande', 'Ste', 'Sher', '`.`', 'wik', 'iskt', '貴', 'Ge', 'grace', 'respect', 'el', 'coal', 'LOC', 'Gent', 'engag', 'Napole', 'ี', '统', 'Federation', 'üsseld', 'grands', 'Kaiser', 'órico', 'oker', 'bast', 'oper', 'fo', 'champ', 'English', 'società', 'Brun', 'cleaner', 'HTML', 'nc', 'ikt', 'импе', 'Fo', 'Art', 'pian', 'kur', 'convers', 'Grace', 'draw', 'Entertainment', 'ashion', 'Vill', 'card']\n",
      "in Layer22 , sorted_indices_dimension4056:  ['conde', 'šč', 'Ő', 'TC', 'itos', 'iß', 'ء', 'tac', 'consulté', 'LS', 'nach', 'retra', 'rust', 'match', 'rå', 'wij', 'ká', 'ști', 'poč', 'száz', 'icity', 'match', 'Genomsnittlig', 'weig', 'ionario', 'fla', 'śc', 'Ÿ', 'czas', 'wr', 'pick', 'ović', 'asc', 'jen', 'poque', 'ätter', 'ppa', 'scr', 'inho', 'irm', 'atta', '１', 'скус', 'RewriteRule', 'gresql', 'ichtet', 'supply', 'patch', 'styles', 'hausen', 'ima', 'unkt', 'illes', 'üh', 'maste', '算', 'ờ', 'ści', 'Cultural', 'mismatch', 'ferrer', 'loyee', 'sdl', 'ASC', 'COM', 'ниц', 'ős', 'Herm', 'ranch', 'ئ', 'язы', 'priv', 'Term', 'witz', 'bata', 'łuż', 'root', 'imo', 'privile', 'лм', '{[', 'ensa', 'layer', 'priv', 'wei', 'bráz', 'йт', 'Marsh', 'bot', '周', 'Zero', 'ragment', 'свя', 'matched', 'mapping', 'illet', 'Deport', 'refuge', 'grad', 'ház', 'Syntax', 'références', 'št', 'store', 'psum', '陳', 'Observ', 'eval', 'stav', '⅓', 'ília', 'ric', 'iwers', 'parenthes', 'broken', 'aggreg', 'окру', 'nyelven', 'library', 'ersch', 'bió', 'כ', 'kon', 'imas', 'Conne', 'mbH', 'unicí', 'factor', 'zych', 'skog', 'lip', 'NU', 'whites', 'Priv', 'rsg', 'шти', 'ゲ', 'groß', 'racc', '*/', 'зь', 'sef', 'Pointer', 'ichten', 'Match', 'rache', 'otta', 'Profil', 'aset', 'evalu', 'antage', 'matching', 'preview', 'reate', 'eles', '陈', 'Match', 'olis', 'остан', 'Попис', 'strateg', 'username', 'geme', 'တ', 'StackTrace', 'Id', 'сла', 'ában', 'atch', 'vić', '성', 'Zero', 'employed', 'synth', 'shout', 'RGB', 'espe', 'einges', 'asz', 'jší', 'ница', 'Серг', 'TS', 'elen', 'puesta', 'landet', 'esp', 'lesia', 'Zeitschrift', 'Cannot', 'strategy', 'weak', 'син', 'pid', 'estaven', 'groot', 'нього', 'holm', 'für', 'fonts']\n",
      "in Layer22 , sorted_indices_dimension8441:  ['injection', 'inha', 'male', 'male', 'ucht', 'onc', 'secret', 'Male', 'circ', 'Prime', 'circ', 'circum', 'ans', 'Beat', 'Secret', 'wing', 'Russ', 'ög', 'models', 'ill', 'Robin', 'Angel', 'phas', 'IU', 'cas', 'Model', 'BO', 'onen', 'bü', 'chas', 'Ivan', 'ゼ', 'Circ', 'pty', 'Academy', 'Mond', 'inject', 'rent', 'modelo', 'hem', 'escol', 'ář', 'chs', 'antes', 'enant', 'Rein', 'analysis', 'hom', 'dex', 'consulté', 'enen', 'rez', '�', 'Exit', 'anze', 'uler', 'Ira', 'Viv', 'Ö', 'цен', 'secretary', 'AML', 'model', 'housing', 'Inf', 'Private', 'unya', 'ev', 'extension', 'ambiguation', 'vard', 'anse', 'actor', 'intelligence', 'chan', 'ox', 'counter', 'Ocean', 'proportional', 'traditional', 'head', 'Proxy', '�', 'andr', 'inser', 'subst', 'Rugby', 'civile', 'cons', 'Ellen', 'Bere', 'arranged', 'x', 'upper', 'Ul', 'prep', 'Ib', 'benef', 'Anders', 'Koch', 'Occ', 'n', 'IN', 'Ind', 'ilen', 'lia', 'DC', '̀', 'mental', 'rais', 'url', 'огра', 'фор', 'nika', 'prime', 'Ox', 'arr', 'box', 'Model', 'login', 'Riv', 'bo', 'Observable', 'emer', 'prime', 'Oscar', 'bul', '=\\\\{', 'private', 'andenburg', 'icamente', 'essen', 'Marcel', 'param', 'inn', 'exit', 'Han', 'ра', 'ev', 'exit', 'proxy', 'nac', 'circuit', 'w', 'helm', 'extensions', 'Emer', 'chos', 'onda', 'oca', 'secret', 'increasing', 'spo', 'expressions', 'секре', 'Wales', 'beat', 'Ext', 'pin', 'ben', 'Masters', 'Ac', 'Toul', 'sons', 'pot', 'Circ', 'гра', 'anti', 'INF', 'lo', 'евич', 'órico', 'вания', 'Hart', 'inf', 'love', 'Ev', 'Mind', 'destruction', 'identical', 'Inv', 'iveness', 'Ser', 'oku', 'accident', 'legs', 'wend', 'minds', 'Hom', 'guard', 'licit', 'fu', 'occupation', 'Arr', 'egg', 'suggestion', 'pok', 'çu', 'instant', 'wt']\n",
      "in Layer22 , sorted_indices_dimension3195:  ['acts', 'Cab', 'circ', 'cab', 'Cir', 'interval', 'interval', 'bands', 'altung', 'ATP', 'Entertain', 'cabin', 'Zygote', 'act', 'фрон', 'Stein', 'onder', 'eso', 'oper', '�', 'ünstler', 'Act', 'Kab', 'intervals', 'perform', '⟨', 'Fiddle', 'bread', 'activ', 'Formula', 'ACT', 'щ', 'oci', 'Unter', 'ellen', 'spons', 'Bef', 'entertain', 'erta', 'andy', 'formula', 'Arist', 'Front', '◄', 'tring', 'clic', 'MDb', 'лон', 'cir', 'din', 'MC', 'string', 'aer', 'Hä', 'band', 'Schema', 'ета', 'oper', 'пре', 'Oper', 'Circ', 'manifest', 'zerw', 'scra', 'yci', 'vés', 'зв', 'ido', 'ак', 'rice', 'kou', 'rome', 'стра', 'stages', 'Ź', 'act', 'ை', 'moz', 'тра', 'бан', 'ac', 'stage', 'éro', 'тек', 'atif', 'ario', 'ци', 'Franz', '符', 'ghan', 'zat', 'ordnet', 'yk', 'Front', 'czy', 'christ', 'liber', 'archivi', 'ange', 'forge', 'völker', 'jar', 'ique', 'cir', 'ges', 'Perform', 'issement', 'Sic', 'ื', '局', '计', 'Ser', 'Aer', 'па', 'лаго', 'Buffered', 'ctrl', 'reader', 'lag', 'Alc', '親', 'рито', 'udni', 'carriage', 'Cold', 'Gaz', 'Client', 'ALSE', 'Ol', 'те', 'arning', 'instantiate', 'enschapp', 'stage', 'Liber', 'arct', 'adt', 'circ', '书', 'тому', 'atge', 'iven', 'operator', 'egründ', 'ще', 'bless', \"('.\", 'coefficients', 'anst', 'ases', 'perform', 'folder', 'performed', 'Luxemb', '̲', 'umb', 'ân', 'pav', 'erte', 'Big', 'ynomial', 'acted', 'heure', 'anv', '|}{', 'htaccess', 'agram', 'Kas', 'clock', 'weis', 'ibli', 'Berg', 'ńcz', 'ństw', 'Soviet', 'fal', 'Shakespeare', 'êt', 'chr', 'Kal', '才', 'band', 'arc', 'sah', 'dell', '�', 'opera', 'Kreis', 'lack', '≠', 'resident', 'piano', 'cabinet', 'Tal', 'phal', 'Constraints', 'cin', 'arias', 'Interval', 'yll']\n",
      "Key: model.layers.23.mlp.down_proj.weight\n",
      "in Layer23 , sorted_indices_dimension1096:  ['rig', 'rig', 'fruit', 'pace', '�', 'pou', 'ju', 'cons', 'Ju', 'vent', 'ore', 'da', 'cup', 'benef', 'tip', 'ipage', 'себя', 'ppers', '구', 'consec', 'ban', 'arc', 'ef', 'ore', 'spr', 'rate', 'ici', 'mat', 'mag', '果', 'fter', 'ists', 'merge', 'capture', 'iti', 'DA', '[@', 'Tar', 'Juan', 'jax', 'hill', 'ports', 'Gab', 'cab', 'pta', 'cod', 'ander', 'unst', 'ft', 'Gas', 'vide', 'config', 'mat', 'quin', 'RU', 'anus', 'ores', 'plants', '指', 'MC', 'aters', 'Mag', '道', 'orm', 'cord', 'ate', '়', 'ording', 'pat', 'ды', 'Rate', 'iate', 'program', 'Craig', 'port', 'ben', 'Aer', 'rate', 'null', 'bott', 'partners', 'aug', 'Autor', 'SI', 'asp', 'Len', 'View', 'зен', 'program', 'capt', 'vol', 'organ', 'Shape', 'manifest', 'enumer', 'ence', 'Mat', 'container', 'Fal', 'aug', 'andr', '�', 'Marc', 'FX', 'ären', 'active', 'fis', 'bird', 'Rosen', 'gan', 'bless', 'bit', 'ре', 'Wass', 'cert', '~', '&', 'nar', 'na', 'combin', '[,', 'nob', 'vent', 'фон', 'soft', '昌', 'ann', 'ia', 'able', 'appar', 'HI', 'Dream', 'crit', 'wł', 'anner', 'ruit', 'half', 'chestra', 'Ò', 'Components', 'Brit', 'ees', 'hov', '种', 'Case', 'reset', 'Elisabeth', 'ose', '共', 'fixed', 'known', 'da', 'DA', 'pour', 'arc', '海', 'ob', 'Oxford', 'BU', 'wet', 'requ', 'Form', 'form', 'ò', 'Capt', 'ift', 'quet', 'habe', 'suspect', 'ww', 'eed', 'Stanley', 'overrid', 'Basic', 'fred', 'ti', 'Ban', 'beh', 'куп', 'explicit', 'rer', 'IBM', 'Mag', 'formulas', 'Ó', 'gift', 'ash', 'alarm', 'merged', 'rę', 'snow', 'FORM', 'aster', 'otr', 'CM', '容', 'Invalid', 'res', 'Und', 'ters']\n",
      "in Layer23 , sorted_indices_dimension4297:  ['ляет', 'dzie', 'enta', 'ichtet', 'ází', 'ibt', 'iende', 'scheid', 'führt', 'czy', '<s>', 'ählt', 'utzt', 'ká', 'îne', 'wa', 'fasst', 'izza', 'textt', 'прави', 'legt', 'nim', 'yna', 'etta', 'endet', 'нва', 'ithmet', 'mina', 'odkazy', 'schließ', 'ówn', 'etra', 'ägt', 'abhäng', 'ęż', 'há', 'iza', 'ührt', 'wehr', 'chia', 'жет', 'cza', 'vá', 'fa', 'ifica', 'ppe', 'atica', 'ząd', 'ordnet', 'intrag', 'ieß', 'verwendet', 'vba', 'meck', 'вает', 'ział', 'forsch', 'annels', 'Ő', 'kee', 'giore', 'itza', 'Њ', 'stoff', 'ewrite', 'Хронологија', 'bru', 'para', 'uce', 'baut', 'orde', 'iert', 'zeichnet', 'esses', 'ienza', 'води', 'amerikanischer', 'istre', 'uteur', 'ucha', 'zeug', 'ignon', 'begin', 'ässt', 'idia', 'inks', 'oga', 'ogne', '&=\\\\', 'ńczy', 'inea', 'za', 'pobla', 'ène', '伊', 'gende', 'Население', 'agt', 'liest', 'prüfe', 'yter', 'że', 'gresql', 'FA', 'bt', 'ствует', 'iet', 'externas', 'unya', 'wrap', 'powiecie', 'ije', 'Π', 'audi', 'corre', 'ョ', 'YY', 'древ', 'zast', 'erna', 'oms', 'рит', '`|', 'erdings', 'phantom', 'ilities', 'rin', 'atta', 'CURLOPT', 'usk', 'entferne', 'arrive', 'ет', 'ová', 'носи', 'иде', 'Archivlink', 'ermann', 'joint', 'reproduce', 'ja', 'bü', 'Мексичка', 'ieves', 'entlicht', 'ría', 'aja', 'Longrightarrow', 'trif', 'othèque', 'lette', 'ϕ', 'rí', 'iesz', 'лян', 'ァ', 'Ћ', 'ží', 'prüft', 'tó', 'verte', 'лази', 'Binding', 'Mie', 'äu', 'conclude', 'LENG', 'Python', 'zyma', 'нен', 'geber', '중', 'ikt', 'ף', 'anstalt', 'texte', 'nungen', 'prime', 'fecha', 'jt', 'adata', 'ży', 'ga', 'module', 'восто', 'compression', 'Domain', 'fel', 'anta', 'pmod', 'sklär', 'wrap', 'stell', 'angularjs', 'ologique', 'ered', 'udni', 'perl', 'iß', 'дами']\n",
      "in Layer23 , sorted_indices_dimension6421:  ['supp', 'jump', 'Oper', 'oper', 'ass', 'oper', 'under', 'dop', 'Oper', 'Supp', 'upp', 'sous', 'daugh', 'Ass', 'operate', 'jud', 'onk', '�', 'ва', 'adre', 'categories', 'stwo', 'бка', 'hi', 'greg', 'Bron', 'Linear', 'irtual', 'cro', 'operated', 'ument', 'goes', 'ución', 'asant', 'quantities', 'making', 'дой', 'linear', 'pros', 'дь', 'opera', 'bron', 'u', 'lès', 'า', 'Supp', 'Vel', 'pre', 'Ż', 'go', 'awa', 'ready', 'хи', 'pres', '⚭', 'uario', 'Chal', 'chain', 'nem', '동', 'Pres', 'uset', 'tem', 'irectory', 'ass', 'rams', 'stan', 'minipage', 'тан', 'atem', '寺', 'ennes', 'Hockey', 'judgment', 'stwa', 'documentation', 'Hi', 'ítás', 'uper', 'ropol', 'Unity', 'ĝ', 'cente', 'ext', 'станов', 'category', 'aye', 'utton', 'ighth', 'operating', 'aget', 'bmatrix', 'unter', 'пе', '�', 'chain', 'ixen', 'amarin', 'omena', 'BI', 'ː', 'джа', 'flutter', 'aught', 'piano', 'bas', 'usb', 'onnes', 'Linear', 'FC', 'up', 'CCE', 'Opera', 'ovie', 'flutter', 'ban', 'Develop', 'igt', 'восто', 'adows', 'asynchronous', 'sotto', 'uh', 'Insel', 'agram', 'honneur', 'alion', 'jud', 'rito', 'île', 'subfigure', 'vc', 'confusing', 'Dorf', 'Kurt', 'Picture', 'ayer', 'Nan', 'quantity', 'bbe', 'hide', 'Tar', 'urr', 'azure', 'itan', 'Dragon', 'bajo', 'speed', 'mars', 'ront', 'imes', 'lient', 'rgb', 'aug', 'assa', 'rile', 'éd', 'anas', 'went', 'Kot', 'ším', '🌍', 'rob', 'category', 'vel', 'rowser', 'Drawable', 'etwork', 'Mountain', 'kö', 'veloc', 'Mos', 'usammen', 'валь', 'Mari', 'its', 'érica', '速', 'ant', 'free', 'mina', 'információ', '안', 'Olympedia', 'ством', 'Carolina', 'Ass', 'oce', 'async', 'mozilla', 'quan', 'će', 'ugby', 'emos', 'go', 'Autow', 'lij', 'oreign', '坂', 'Jud']\n",
      "in Layer23 , sorted_indices_dimension1925:  ['print', 'print', 'prints', 'Print', 'Print', 'isc', 'editor', 'asp', 'Setter', '\\x83', 'editor', 'blank', 'TV', 'euw', '那', 'cím', 'alia', 'prop', 'TV', 'Przyp', 'SE', 'television', 'tv', 'információ', 'ebook', 'printer', 'anka', 'ódigo', 'adata', 'жет', 'PR', 'matically', 'Fur', 'mathchar', 'idia', 'ĭ', 'дён', 'liest', 'тка', '✿', 'Edit', 'lea', 'asp', 'urale', 'blank', 'ķ', 'urable', 'leton', 'printed', 'zerw', '$}}%', 'ay', 'printing', 'kb', 'front', 'ło', 'Edit', 'eteor', 'Fernseh', 'ध', 'rank', 'verso', 'ant', 'geber', 'FR', 'uniform', 'utton', 'Asp', 'mina', 'javase', 'portal', 'onaut', 'Gent', 'continu', 'く', 'resid', 'engelsk', 'edeut', 'MB', 'edited', 'books', 'Ralph', 'Pack', 'Chr', 'cze', 'apply', 'fashion', 'ME', 'books', '根', 'embl', 'uma', 'dimen', 'Shape', 'kit', '術', 'uper', 'това', 'блі', 'aya', 'Отече', '`__', 'Television', 'batal', 'ļ', 'Ori', 'Front', 'shape', 'Mem', 'journal', 'mitt', 'obierno', '̂', 'analyt', 'Santi', 'ank', 'rank', 'tv', 'SE', 'umerate', 'repr', 'hmen', 'istique', 'front', 'Chiesa', 'ус', 'ACK', 'Credentials', 'advert', 'Flow', 'SESSION', 'ook', 'реда', 'ď', 'Vater', 'allen', 'Prima', 'Session', 'FK', 'blica', 'Spart', 'idenote', 'Drag', 'vi', 'éricaine', 'ath', 'erna', 'Jam', 'edit', 'amen', '=\"{', 'esso', 'unci', 'emeinde', 'èque', 'ije', 'wirtschaft', 'Mess', 'cza', 'Kit', 'Sitz', 'Prop', 'Fran', 'sess', 'mot', 'printf', 'Eliz', 'uellement', 'kter', 'анти', 'aur', 'idas', 'inha', 'шп', 'prime', 'direction', 'session', 'Front', 'Session', 'fallen', 'unde', 'brary', 'пр', 'seg', 'мах', 'för', 'ut', 'ücke', 'Flow', 'emb', 'jav', 'EDIT', 'detail', 'üh', 'ião', 'információk', 'braries', 'xcode', 'uki', 'ʾ']\n",
      "Key: model.layers.24.mlp.down_proj.weight\n",
      "in Layer24 , sorted_indices_dimension8611:  ['ibus', 'FAULT', 'Ris', 'prov', 'quent', 'perfect', 'Je', 'xic', 'ide', 'inherit', 'ixon', 'eclipse', 'Ban', 'DT', 'wise', 'emb', 'trial', 'ams', 'Λ', 'Ans', 'vic', 'Lit', 'oli', 'vie', 'Stan', 'acc', 'haupt', 'berta', 'liber', 'ynamic', 'blind', 'FIX', 'af', 'pres', 'IC', 'Grid', 'anno', 'na', 'exper', 'DOC', 'ideal', 'ife', 'vo', 'eri', 'Pit', 'ban', 'embro', 'weg', 'wis', 't', 'da', 'ten', 'Lib', 'pilot', 'isat', 'bitter', 'fan', 'oc', 'pit', 'насе', 'quadr', 'S', 'ixa', 'Sof', 'em', 'ens', 'fty', 'forward', 'rés', 'ban', 'пів', '�', 'dic', 'FF', 'mol', 'éra', 'erde', 'Mais', 'probabil', 'prime', 'olo', 'bol', 'Grid', 'ijd', 'opol', 'xt', 'ový', 'inter', 'et', 'муниципа', 'ento', 'bus', 'grid', 'inst', 'Intent', 'hom', 'Ara', 'zyk', 'ess', 'je', 'oman', 'IC', 'rok', 'gu', 'fault', 'Trad', 'VO', 'nap', 'ста', 'ha', 'inson', 'Rosen', 'wy', 'wo', 'episode', 'Hi', 'ellers', 'Century', 'ierte', 'view', 'fam', 'лев', 'ɾ', 'doc', 'мене', 'liberty', 'ley', 'radius', 'libre', 'shr', 'Je', 'zaj', 'öm', 'oph', 'Inst', 'af', 'accord', 'ensemble', '边', 'ierten', 'ten', 'reserve', 'migli', 'ateful', 'ding', 'ent', 'ване', 'li', 'prep', 'Wo', 'incre', 'IDE', 'abad', 'freedom', 'sup', 'els', 'bare', 'voices', 'hai', 'IDs', 'роз', 'anno', 'para', 'etto', 'special', 'vig', 'Rights', 'itis', 'abc', 'intent', 'sim', '容', 'capit', 'zb', 'personal', 'fault', 'Насе', 'lera', 'management', 'лимпий', 'Philipp', 'uts', 'owo', 'рела', 'allowed', 'свя', 'aj', 'invent', 'bl', 'etic', 'anc', 'ró', 'addy', 'Serial', 'Inst', 'ned', 'abase', 'tis', 'Í', 'Ens']\n",
      "in Layer24 , sorted_indices_dimension869:  ['Marg', 'ctl', ')--(', 'Û', 'нала', 'iale', 'unto', 'ober', 'schemes', 'Bitte', 'oph', '断', 'cito', 'Einzeln', 'pó', 'sta', 'idenote', 'DP', 'comb', 'baz', 'на', 'Len', 'ო', 'MQ', 'vba', 'Volk', 'preferred', 'ím', 'kih', '김', 'ſ', 'info', 'riv', 'oli', 'Max', 'Düsseld', 'Dick', 'CHAP', 'ictwo', 'дон', 'eto', 'abc', 'IAB', 'odon', 'baz', 'Scan', 'bum', 'Sequ', 'ници', 'MyClass', 'Stadium', 'Gruppe', 'Len', 'beskrevs', 'odia', 'na', 'ROP', 'анта', 'ongodb', 'GROUP', 'partiellement', 'group', 'prefer', 'цена', 'ña', 'lei', 'ceae', 'Ē', 'atrice', 'inta', 'Keys', 'лекс', 'SA', 'rg', 'odi', 'Kil', 'is', 'zza', 'ggplot', 'Fitz', 'centuries', 'agg', 'capit', 'basket', '鉄', 'list', 'DM', 'Max', '🌍', 'ragment', 'cile', 'criticism', 'Group', 'Price', 'Wes', 'į', 'qual', 'sequ', 'Parlament', 'ether', 'Jar', '////////', 'DB', 'Artikel', 'unto', 'anche', 'Capit', 'IAL', 'dbo', '�', 'CT', 'İ', 'grammar', '竹', 'critics', 'от', 'Ï', 'iente', 'кта', '∆', 'kil', 'DT', '联', 'urname', 'Unis', 'зь', 'öder', 'papel', 'Ke', 'бі', 'bat', 'INFO', 'illet', 'contre', 'nil', 'CT', 'exit', 'Wikip', 'theless', 'Camil', 'живело', 'oot', 'rende', 'ibus', 'journal', 'сельсов', 'beh', 'Lock', 'od', 'rieb', 'Genomsnittlig', 'MI', 'orte', 'Stad', 'sequ', 'scheme', '葉', 'préc', 'asm', 'nam', 'Tar', 'Soph', 'Pia', 'ket', 'lek', 'gor', 'Í', 'ród', 'okrat', 'etter', 'ли', 'eti', '群', 'Switch', 'trap', '報', 'scal', '宮', 'scratch', 'က', 'Group', 'var', 'scan', 'ớ', 'honneur', 'subst', 'larg', 'cres', 'unta', 'MC', 'յ', 'vars', '))`', 'thick', 'Sammlung', 'Hills', 'Gaz', 'क', 'ˌ', 'ila']\n",
      "in Layer24 , sorted_indices_dimension8682:  ['ob', 'bil', 'Pil', 'Sac', 'Arn', 'sig', 'bone', 'signature', 'iman', 'omm', 'leader', 'pil', 'alls', 'Dev', 'signed', 'ilon', '成', 'Bil', 'index', 'aza', 'grass', 'об', 'bin', 'ude', 'exchange', 'bing', 'bil', 'zo', 'b', 'Dev', 'pian', 'Parad', '➖', 'Sign', 'bum', 'signing', '�', 'ät', 'lemagne', '�', 'ober', 'menu', 'rand', 'Square', 'binom', 'osz', 'bay', 'dev', 'unsigned', 'ública', 'Sign', 'Sn', 'enas', 'sign', 'Pu', 'Newton', 'Over', 'wood', 'caller', '者', 'ienst', 'ractor', 'udes', 'Cold', 'sequ', 'bian', 'Flash', 'Exchange', '�', 'ber', 'Index', 'uden', 'committee', 'rel', 'ordo', 'Bun', 'spot', 'bere', 'Ald', 'window', 'zyż', 'sig', 'approved', 'national', 'Sach', 'mail', 'oltre', 'relationship', 'Alliance', 'menu', 'öl', 'sn', 'hon', 'nap', 'czy', 'icio', 'Bio', 'bin', 'ader', 'flying', 'odn', 'sign', '>>', 'ason', 'Wood', 'ijst', 'portal', 'onCreate', 'werp', 'őd', 'ov', 'Portal', 'Alo', 'cla', 'Ł', '调', 'cko', 'go', 'spectral', 'Call', 'friendship', 'ellow', 'ба', 'call', 'gre', 'ты', 'top', 'ees', 'acting', 'Zero', 'Aut', 'endorf', 'bay', 'mark', 'itect', 'lut', 'iano', 'olg', 'White', 'alk', '务', 'ifa', 'prog', 'ätze', 'vas', 'Ob', 'dry', 'ro', 'acity', 'pr', 'arbitrary', 'override', 'vex', 'tool', 'SN', 'Renaissance', 'pilot', 'Bin', 'aders', 'index', 'cab', 'Vog', 'otto', 'vess', 'rica', 'yy', 'rect', 'Congress', 'ty', 'Napole', 'Executive', 'rodu', 'ifica', 'Bab', 'Nap', 'appro', 'bod', 'zá', 'É', 'Node', 'orld', 'ุ', 'nab', 'exchange', '得', 'rep', 'ena', 'vote', 'líder', 'ordered', 'cord', 'patri', 'laugh', 'žit', 'obt', 'conjug', 'ɣ', 'bid', 'bia', 'bas']\n",
      "in Layer24 , sorted_indices_dimension5228:  ['式', 'доступ', 'esch', 'iso', 'ograph', 'Cursor', 'ős', 'metros', 'nbsp', 'shop', 'ра', 'asm', 'zes', 'uler', 'ío', 'ossen', 'Processor', 'iten', 'hausen', 'USER', 'quot', 'Station', 'bare', '제', 'inder', 'дена', 'érer', 'users', 'hnen', 'ensk', 'ֶ', 'unya', 'spectrum', 'rama', 'izo', 'mod', 'Xml', 'г', 'тый', '局', 'feld', 'пас', 'edic', 'useum', 'fff', 'aze', 'osas', 'Seg', 'zen', 'Interface', 'hyper', 'Jur', '向', 'Bund', 'werk', '显', 'ület', 'Station', 'Parameter', 'WM', 'Sony', 'Page', 'ography', 'konn', 'ogy', 'izon', 'ザ', 'Wikip', 'schemes', 'стор', 'Herm', 'abgerufen', 'beginner', 'weak', 'user', 'рт', 'esi', 'ingen', 'nio', '﹕', 'uras', 'appro', 'ńskim', 'adal', 'vim', 'chem', 'ombres', 'aison', 'BU', 'Spect', '野', '☉', 'papa', '镇', 'shop', 'Dam', 'tons', 'aron', 'дер', '⁹', 'usalem', 'него', 'ugel', 'ще', 'фе', '̌', 'wel', 'ado', 'Um', 'unkt', 'Zone', 'Fel', 'Sommer', 'starting', 'сер', '相', 'projects', 'ვ', 'дже', 'ographique', 'Zum', 'lag', 'neg', 'Cooper', 'Tun', 'hn', 'ogs', 'ä', 'russe', 'cki', 'Hyper', 'ços', 'lei', 'versary', 'uellement', 'istration', 'étique', 'ǐ', 'шо', 'topology', 'lua', 'ö', 'ARN', 'квітня', 'seguito', 'ке', 'ículo', 'scope', 'terre', 'isseur', 'icio', 'qualified', 'letin', 'leased', 'roller', 'ucker', '序', 'mass', 'Wies', 'fic', 'ზ', 'Scale', 'reserved', 'Close', 'Bé', 'удо', 'erta', 'Visible', 'neg', 'uss', 'ensis', 'jin', 'ေ', 'fil', 'xsd', '业', 'FilterChain', 'universitaire', 'Projects', 'ze', 'ança', 'гер', 'chn', 'Ban', 'レ', 'oty', 'кого', 'Originals', 'ula', 'serv', 'weak', 'trim', 'unker', 'стров', 'Ле', 'significa', 'hist', 'LE', 'structor', '户']\n",
      "in Layer24 , sorted_indices_dimension23:  ['Julia', 'Ruby', '�', 'ruby', 'Columbia', 'Richmond', 'iana', 'Jenkins', 'Clara', 'Lima', 'Rosa', 'inea', 'Kennedy', 'Marina', 'hina', 'Java', 'Java', 'erton', 'ana', 'Watson', 'ruby', '�', 'stata', 'selenium', 'Wagner', 'ная', 'Vienna', 'IMA', 'Roma', 'aya', 'Emma', 'Virginia', 'Oracle', 'nia', 'ima', 'medicine', 'IA', 'ская', 'java', 'ula', 'Victoria', 'bara', 'Korea', 'unda', 'java', 'ética', 'rice', 'axis', 'Perry', 'VBA', 'система', 'uola', 'formula', 'Valley', 'Raymond', 'Phoenix', 'Opera', '丸', 'ada', 'Laura', 'lica', 'delta', 'кова', 'lambda', 'aska', 'ina', 'Robinson', 'Leo', 'ária', 'oga', 'жена', 'onica', 'oda', 'Rome', 'VA', 'nea', 'ixon', 'axis', 'Warszawa', '_+', 'valley', 'AVA', 'ája', 'oracle', 'ska', 'merce', 'icus', 'olia', 'arta', 'лена', 'ська', 'osa', 'ée', 'тика', 'asma', 'aria', 'radius', 'mana', 'enda', 'iona', 'Anna', 'Eclipse', 'ocoa', 'ta', 'ала', 'Riemann', 'тина', 'scala', 'aña', 'opera', 'owa', 'Una', 'Meyer', 'yrus', 'ática', 'pta', 'Murray', 'ium', 'ola', 'Graham', 'rome', 'Ireland', 'atica', 'nica', 'Rudolf', 'ila', 'xspace', 'owana', 'ová', 'acja', 'onomy', 'Roberts', 'ropy', 'Python', 'eda', 'niu', 'Jerusalem', 'дина', 'Austria', 'onia', 'Mine', 'izada', 'мина', 'uela', 'arina', 'Medicine', 'railway', 'aza', 'coffee', 'leton', 'awa', 'rayed', 'Gamma', 'nodes', 'igua', 'ria', 'кая', 'ativa', 'riteria', 'Gregory', 'inity', 'icana', 'Georgia', 'atique', 'uka', 'ologia', 'runtime', 'node', '沢', 'ida', 'calculus', 'tei', 'racle', 'icum', 'gamma', 'ova', 'ǔ', 'numpy', 'adesh', 'éta', 'ney', '^-', 'Campbell', 'aka', 'lava', 'hausen', 'ava', 'piano', 'GA', 'eclipse', 'UTC', 'née', '身', 'oria', 'erna', 'Flora', 'runtime', 'python', 'Nova', 'arda']\n",
      "in Layer24 , sorted_indices_dimension6106:  ['mission', 'olog', 'mission', 'olo', 'aire', 'irm', 'essa', 'erme', 'ital', 'oa', 'issions', 'ern', 'ivent', 'dl', 'arde', 'itis', 'osis', 'yg', '♦', 'osen', 'osing', 'commission', 'د', 'erm', 'anden', 'kiem', 'Lat', 'dg', 'shall', 'Kong', 'SError', 'Vent', 'Mission', 'atur', 'etta', '�', 'uer', 'iennes', 'urr', 'ol', 'cias', 'дан', 'itter', 'esis', 'osed', 'odu', 'meteor', 'super', 'Eric', 'bom', 'Nar', 'CTYPE', 'rz', 'jet', 'ERR', 'emor', '秀', 'dz', 'и', 'local', 'asi', 'forEach', 'Depart', 'Zone', 'ció', 'ста', 'ygon', 'dienst', 'gé', 'ợ', 'zahl', 'reci', 'єм', 'sko', 'VF', 'fas', '字', 'ollow', 'ia', 'ér', 'aju', 'gate', 'oned', 'lear', 'ican', 'erc', 'ge', 'ats', 'ET', 'ias', 'Commission', 'yal', 'Maler', 'oom', 'unders', 'super', 'мо', 'Ernest', 'dm', 'idades', 'emb', 'eta', 'inha', 'dos', 'Shah', 'mal', 'itar', '«', 'zec', 'oj', 'lemagne', 'adm', 'df', 'Sid', 'Services', '�', 'im', 'тем', 'CL', 'imper', 'era', 'revel', 'oker', 'Ven', 'ydro', 'nja', 'tis', 'tres', 'omet', 'миче', 'Mal', 'rent', 'ohl', 'tp', 'ahl', 'ken', 'atol', 'Zone', 'iveau', 'ert', 'Situ', 'zeich', 'ry', 'ission', 'DT', 'dip', 'unde', 'civ', 'moy', 'gef', 'ння', '장', 'ji', 'ener', 'ió', 'atis', 'mine', 'hos', 'conda', 'isis', 'oben', 'сси', 'geo', 'opening', 'Services', 'Gó', 'oke', 'eses', 'éric', 'issa', 'services', 'wer', 'DF', 'iv', 'onda', 'shire', 'omena', 'dai', 'andon', 'SG', 'Bomb', 'puzz', 'FE', 'ial', 'kom', 'Lau', 'нь', 'bbe', '기', 'Schön', 'ertain', 'idal', 'ду', 'etr', 'ixon', 'ander', 'yen', '�', 'dal', 'vuel']\n",
      "Key: model.layers.25.mlp.down_proj.weight\n",
      "in Layer25 , sorted_indices_dimension969:  ['bi', 'Bi', 'me', 'etz', 'Salv', 'bi', 'Bl', 'di', 'pad', 'iglia', 'weg', 'icina', 'ält', 'Asset', 'Rog', 'iar', 'BI', 'brid', 'neg', 'eign', 'salv', 'Lehr', 'Buff', 'beg', 'Zum', 'Polen', 'andenburg', 'Union', 'eland', 'Bi', 'ennis', '�', 'бере', 'Hi', 'ml', 'cope', 'dep', 'atre', 'papers', 'Ы', 'auc', 'rees', 'arios', 'confer', 'aria', 'numer', 'empre', 'Bern', 'lem', '角', 'neg', 'anc', 'flat', 'surv', 'double', 'pl', 'apers', 'noreferrer', 'бка', 'moon', 'Einzeln', 'Star', 'Laz', 'Mor', 'jar', 'Cloud', 'arian', 'jax', 'agers', 'ilor', 'ilis', 'Client', 'true', 'Укра', 'slave', 'aben', 'BR', 'Q', 'ott', 'лежа', 'Ī', 'ker', 'Cloud', 'cur', 'SBN', 'Jones', 'reich', 'Cy', 'par', 'lieder', 'istr', 'ври', 'park', 'bright', 'Opera', 'w', 'emen', 'iae', 'руг', 'ivatal', '부', 'vendor', 'rb', 'ierno', 'aron', 'дина', 'bian', 'FD', 'Tree', 'alls', 'aff', 'Wild', 'endi', 'uv', 'yp', 'Leg', 'ientos', 'uclide', 'Land', 'wr', 'ocrat', 'eln', 'Ori', '制', 'illon', '景', 'Бі', 'union', 'v', 'tree', 'standard', 'Element', 'Om', 'paper', '云', 'achine', 'Double', 'zig', 'cycle', 'Cont', 'cloud', 'role', 'lar', 'вня', 'wa', 'icher', 'Begriffe', 'ari', 'Rec', 'Whe', 'Tur', 'izin', 'BS', 'Jam', 'Contract', 'word', 'ệ', 'sah', 'reme', 'Looking', 'capital', 'Bey', 'Park', 'cre', 'ста', 'lave', 'dy', 'ource', 'Res', 'Double', 'furt', 'trim', 'yl', 'symbol', 'land', 'fd', 'land', 'zw', 'meas', 'yk', 'Java', 'ebol', 'bl', 'Kon', 'True', 'na', 'Cr', 'akov', 'words', 'TR', 'iese', 'arium', '동', 'kele', 'bere', 'дже', 'izen', 'asset', 'role', 'лка']\n",
      "in Layer25 , sorted_indices_dimension9259:  ['lop', 'dup', 'inu', '(|', 'serial', 'serial', 'con', 'Rotten', 'dbc', 'net', 'rola', 'abi', 'duplicates', 'wol', 'tres', '니', 'wald', 'ksam', 'Wolf', 'ANT', 'midt', 'emi', 'unta', 'нец', 'background', 'cola', 'ун', 'agh', 'atori', 'instrument', 'agi', 'hang', 'paździer', 'posts', 'ή', 'kwiet', 'explos', 'lait', 'react', 'információ', 'wart', 'EL', 'oire', 'zur', 'actor', 'ги', 'zum', 'Olimp', 'direction', 'gun', 'ци', 'oster', 'ec', 'ǎ', 'Zum', 'Резу', 'listop', 'ubre', 'zel', 'Palmarès', 'Tube', 'FILE', '取', 'intrag', 'Jahrh', 'jm', 'otes', 'Kel', 'lef', 'obox', 'IM', 'react', 'њу', 'Vic', 'Herzog', 'steller', 'ung', 'Word', 'vic', 'ätze', 'externes', 'teck', 'hop', 'signal', 'defe', 'integer', 'este', 'Cong', 'unit', 'db', 'Dup', 'ni', 'mittel', 'fos', 'élé', 'Excel', 'ollar', 'CASE', 'plorer', 'Request', 'imiter', 'evolution', '\\x7f', \"']['\", 'Serial', 'Word', 'amil', 'igny', 'gior', 'nake', 'volution', 'extensions', 'abol', 'Club', 'пута', 'ḳ', 'тисти', 'bow', 'zm', 'Ant', 'тор', 'fter', 'Times', 'férences', 'motor', 'jar', 'lij', 'spraw', 'uga', 'pshire', 'kem', 'construction', 'ბ', 'antics', 'Ε', 'word', 'Shape', 'ppe', 'Clar', 'weit', '↑', 'astic', 'rog', 'нів', 'lí', 'POST', 'civil', '은', 'gart', 'inde', 'ャ', 'abor', 'angs', 'Laurent', 'resolution', 'él', '星', 'ThreadPool', 'stuck', 'ähr', 'Kle', 'pattern', 'modelo', 'steps', 'า', 'chmark', 'ymbol', 'chus', 'ϵ', 'jes', 'Defaults', 'sierp', 'erc', 'éral', 'wont', 'AF', 'pel', 'indre', 'oby', 'dup', 'rios', 'modo', 'kal', 'ostream', 'cols', 'laps', 'води', 'Constructor', 'Ac', 'piano', 'données', 'Serial', 'ph', 'Rund', 'ток', 'patron', 'Lage', 'Seiten', 'pond', 'omini']\n",
      "in Layer25 , sorted_indices_dimension3065:  ['agy', 'ville', 'bridge', '�', '�', 'aban', 'yn', 'nal', 'ard', 'hab', 'inaire', 'ouch', 'поль', 'яз', 'inal', 'lik', 'zin', 'uve', 'éré', 'lain', 'lik', 'éric', 'ined', 'iks', 'ogy', 'squ', 'itel', 'vier', 'inned', 'reens', 'Hab', 'Bor', 'prefer', 'rate', 'rut', 'zie', 'habit', 'Born', 'QL', 'Ung', 'agr', 'osi', 'Brook', 'rost', 'issance', 'uliar', 'unt', 'шения', 'ory', 'arp', 'iesen', 'append', 'uwe', 'sharp', 'Weg', 'Past', 'able', 'ates', 'yna', '[:', 'arts', 'omo', 'ге', 'ologies', 'sq', 'pace', 'ube', '�', 'Engel', 'isk', 'ply', 'inta', 'antal', 'Jenkins', 'parseInt', 'DK', 'wheel', 'van', 'sino', 'uario', 'View', 'atie', 'ук', 'ves', 'uk', 'Vier', 'erd', 'щу', 'ificación', '트', 'v', 'surv', 'urk', 'tv', 'heim', 'ár', 'hex', 'pt', 'les', 'istas', '?>', 'vi', 'ady', 'sharp', 'hinaus', '$(\".', 'ienst', 'arto', 'нии', 'conne', 'Him', 'SSN', 'Preferences', 'ines', 'diagonal', 'ут', 'ut', 'ny', 'Aless', 'voir', 'Пред', 'von', 'INIT', 'sí', 'ání', '[:', 'ué', 'amar', 'column', 'yw', 'ories', 'chen', 'lear', 'square', 'пред', 'lais', 'nych', 'angles', 'atiques', 'ital', 'tery', 'sen', 'Ress', 'образ', 'Tu', 'ž', 'соб', 'uerto', 'coach', 'лиза', 'ôme', 'Cannot', 'ienne', 'cial', 'slov', 'past', 'vos', 'aries', 'state', 'Бар', 'bourg', 'Ross', 'ppets', 'rror', 'rh', 'ван', 'чин', 'xes', 'Intent', 'IND', 'unes', '州', 'arte', 'ächst', 'inv', 'igny', 'File', 'ister', 'elor', 'ards', 'ạ', 'Resources', 'ousin', 'Cand', 'state', 'chrome', 'rees', 'ty', 'verse', 'sir', 'nett', 'Users', 'fav', '/>', 'гре', 'view', '[-', 'uncle', 'Beck', 'Christ']\n",
      "in Layer25 , sorted_indices_dimension2150:  ['eda', 'ales', '천', 'ALL', 'Wiel', 'ház', 'Li', 'eed', 'An', 'liquid', 'II', 'Höhe', 'Wol', 'elm', 'Jord', 'shot', 'Rock', 'shot', 'Inc', 'пара', 'ermo', 'acon', '산', 'ale', 'Lav', 'uses', 'Према', 'swap', 'действи', 'ese', 'ange', 'Su', 'ült', 'opo', 'ület', 'zon', 'SERVER', 'omány', 'Led', 'prov', 'Lang', 'Lac', 'ool', 'Tat', 'む', 'Spo', 'NN', 'ines', 'orientation', 'Es', 'Guer', 'ende', 'inal', 'ала', '�', 'eles', 'ій', 'ender', 'Michel', 'adó', '-}', '館', 'Pon', 'Tit', 'reference', 'мент', '[]{', 'ANCE', 'hner', 'inde', 'MD', '仁', 'imm', '성', 'angs', 'Car', 'aller', 'дия', 'Lib', 'benchmark', 'heel', 'joint', 'useum', 'diam', 'liqu', 'lea', 'Bob', 'Es', 'iller', 'Param', 'ย', 'świ', 'Bobby', 'Ferr', 'uniform', 'AN', 'aku', 'emein', 'fare', '天', 'dep', 'ipage', 'Cancel', 'Sad', 'iddle', 'стан', 'музе', 'Ori', 'cono', 'Revolution', 'azar', 'Er', 'Framework', 'Cry', 'iling', 'wol', 'INIT', 'SH', 'Western', 'iles', 'ії', 'lor', 'provider', 'ground', 'DBC', 'II', 'ства', 'Home', 'нен', 'allen', 'prü', 'ublik', 'PM', 'sein', 'Kan', 'connexes', 'crime', 'Vel', 'gang', 'Lamb', 'option', 'ake', 'Ser', 'lapse', 'inc', 'Ident', '◄', 'waters', 'Row', 'xe', 'getElementsBy', 'SS', 'Run', 'deep', 'Fr', 'п', 'imm', 'anst', 'INT', 'indu', 'Gem', 'uj', 'erne', 'li', 'INF', 'agan', 'ход', 'park', 'ˈ', 'blood', 'Ly', 'Pr', 'Bob', 'Kun', 'Einwo', 'imation', 'heck', 'agn', 'Sea', 'ülés', 'Sever', 'moth', 'ád', 'Fern', 'sake', 'wise', 'Nor', 'akespe', 'ará', 'Us', 'Creek', 'Doc', 'profession', 'Blood', 'tat', 'Parad', 'Robert', 'fake', '�', 'prise']\n",
      "Key: model.layers.26.mlp.down_proj.weight\n",
      "in Layer26 , sorted_indices_dimension8067:  ['rile', 'cod', 'út', 'onderwerp', 'ptop', 'íst', 'rijk', 'ats', 'ecz', 'зии', 'ijd', '型', 'enten', 'sten', 'Internacional', 'chron', 'ný', '�', 'TV', 'éc', 'Sig', 'ходит', 'ăr', 'besondere', 'ués', '�', 'inf', 'erg', 'nero', 'Chron', 'zetek', 'lang', 'pta', 'opher', 'cko', 'endar', 'gez', 'aturen', 'Chr', 'container', 'lum', 'Dies', 'CREATE', 'irtual', 'abi', 'provincie', 'rappres', 'internationale', 'tit', 'Defaults', 'гер', 'chron', 'autorité', 'ettings', 'zeg', 'UG', 'icos', 'Sans', 'ез', '‰', 'Ţ', 'ográ', 'données', 'Première', 'ily', 'eigenvalues', 'Intent', 'ᾶ', 'parser', 'ajn', 'defaults', 'orio', 'Tit', 'onnées', 'cron', 'ǧ', 'stal', 'Ő', 'lando', 'valid', 'ɔ', 'espe', 'чей', 'tarde', '^{', 'jú', 'tegen', 'erner', 'fahrt', 'bio', 'international', 'cret', 'amos', 'internacional', 'Rotten', 'IMDb', 'inea', 'intent', 'aron', 'vij', 'annten', 'près', 'ając', 'kord', 'imo', 'ésie', 'kör', 'iko', 'ک', 'Drag', '$(\".', 'tank', 'ajes', 'pubblicato', 'тен', 'tort', 'topological', '章', 'Tout', 'consulté', 'округу', 'lij', 'repres', 'container', 'esterd', 'rame', 'ším', '球', 'eft', 'Author', 'fos', 'Container', 'ogne', 'igny', 'ši', 'oco', 'urger', 'conten', 'ố', 'consultato', 'zett', 'rgba', 'ér', 'Та', 'ℂ', 'сей', 'bres', 'esch', 'calc', 'omi', 'esh', 'render', 'arring', 'rii', 'iler', 'ymi', 'ston', 'artific', 'hä', 'Scal', 'conte', '->_', 'atr', 'タ', 'tk', 'endor', 'chor', 'edificio', 'hui', 'blem', 'beskre', 'opt', 'declar', 'Tag', 'weer', 'зей', 'Tam', 'uber', \"$('.\", 'cí', 'edeut', 'ciu', 'ico', 'iji', 'suppose', 'آ', 'intern', 'род', 'зда', 'urer', 'ell', 'Amt', 'ischof', 'phony', '모', 'נ', 'mesh', 'prix', 'valid', 'cito']\n",
      "in Layer26 , sorted_indices_dimension8069:  ['und', 'Und', 'Und', 'und', 'undo', 'unde', 'mit', 'UND', 'listade', 'undefined', 'Mit', 'undes', 'oder', 'сов', 'fra', 'sowie', 'progetti', 'Begriffsklär', 'unders', 'Bin', 'dar', 'ivel', 'unda', 'éo', 'ór', 'esi', 'iae', 'arguments', 'Laz', 'undefined', 'ін', 'mit', 'ун', 'liche', 'urname', 'une', 'otto', 'esterni', 'dom', 'ondo', 'atter', 'Bran', 'aniu', 'Uns', 'ací', 'tha', 'Mitchell', 'rito', 'zó', 'ће', 'Hir', 'mv', 'ént', 'ᾶ', 'ństw', 'racy', 'SR', 'imoine', 'era', 'licher', 'zos', 'unya', 'Rav', 'lan', 'chia', 'rá', 'op', 'bin', 'út', '�', 'columns', 'nię', 'brary', 'onderwerp', 'zo', 'atuur', 'ima', 'lers', 'cker', 'gresql', 'Référence', '同', 'vol', 'clip', 'trightarrow', 'Mitt', 'ό', '�', 'ackage', 'ges', '弘', 'ҡ', 'discipl', 'dar', '►', 'under', '场', 'BI', 'INNER', 'ystycz', 'INSERT', 'diction', 'bzw', 'etwork', 'Davis', 'zte', 'reb', 'stock', 'xelles', 'uo', 'Conf', 'LOAD', 'oder', 'pul', 'ök', 'BF', 'nea', 'volt', 'свою', 'bin', 'ieu', 'arie', 'bráz', 'oma', 'Kaiser', 'provin', 'Одна', 'mitt', 'tag', 'bras', 'relax', 'ocker', '�', 'channel', 'な', 'MD', 'laz', 'ній', '�', 'ání', 'BU', 'bers', 'Pul', 'nam', 've', 'liches', 'jön', 'ра', 'Bi', 'Fra', 'leich', 'fra', 'eti', 'дво', 'applic', 'iger', 'anz', 'MIT', 'Batch', 'раз', 'Dar', 'gra', 'iali', 'nek', 'Tag', 'blog', 'DD', 'imo', '�', 'ční', 'ätz', 'derr', 'Conf', 'accept', '断', 'rade', 'ères', 'над', 'heid', 'uela', 'under', 'зер', 'Mitch', 'ồ', '_{{\\\\', 'unden', '場', 'hang', 'Track', 'SR', 'jas', 'anje', '論', 'nil', 'règ', 'Za', 'lass', 'wechsel', 'gens', 'UMN']\n",
      "in Layer26 , sorted_indices_dimension10511:  ['esta', 'Хронологија', 'subs', 'ogo', 'onymes', 'länkar', 'Ig', 'Leo', 'cej', 'acco', 'ierno', 'Leop', 'Bast', 'iso', 'aws', 'idente', 'тета', 'nap', 'patch', 'нім', 'Compos', 'finger', 'jack', 'Inf', 'eno', 'opp', 'öll', 'Попис', 'onto', 'yw', 'eredetiből', 'apers', 'ǒ', 'olds', 'pochod', 'lava', 'ouv', 'fficiale', 'ждения', 'wand', 'EB', 'èce', 'idense', 'rès', 'etto', 'кін', ')^{-', 'Ī', 'oreign', 'ссий', 'NSURL', 'endi', 'Old', 'Stanley', 'ף', 'ście', 'udo', 'EXISTS', 'イ', 'ota', 'annot', 'jack', 'Albums', 'avam', 'Voll', 'Einzelnach', 'herm', 'Sender', 'enk', 'aper', 'olan', 'edes', '�', 'ális', 'zvuky', 'ivos', 'igten', 'XXX', 'ijd', 'же', '\\u202d', 'lan', 'Flor', 'arna', 'Nu', 'otal', 'ási', 'Jack', '体', 'unto', 'oro', 'nar', 'aki', 'Jersey', 'idenote', 'CSS', 'Refer', 'Bush', 'est', 'doi', 'fic', 'Müller', 'ქ', 'NN', 'Naz', 'Annotation', 'cip', 'си', 'trivial', 'printStackTrace', 'Mun', 'enso', 'sender', 'etter', 'ʂ', 'iki', 'Este', 'SERVER', 'flowers', '茶', 'Eb', 'Eva', 'aw', 'Мексичка', 'ภ', 'stab', 'Intel', 'opera', 'eti', 'Album', 'borough', 'Baker', 'Ingl', 'esti', 'то', '&=\\\\', 'DOCTYPE', 'kreich', 'чита', 'oto', 'attan', 'polski', 'Rotten', 'Template', 'aken', 'Template', 'aces', 'urn', 'edo', 'Tol', '阿', 'ferrer', 'uffer', 'Transfermarkt', 'archiviato', 'ober', 'mé', 'Upper', 'вен', 'flux', 'irks', 'externs', 'xxx', 'yaml', 'shadow', 'ʹ', 'ds', 'oups', 'Texture', 'inental', 'qual', 'nez', 'Created', 'az', 'ũ', 'え', 'deg', 'VIAF', 'Jack', 'Parti', 'Á', 'appendChild', 'йн', 'tracks', 'зи', 'flor', 'isen', 'iné', 'стату', 'plorer', 'lyn', 'ais', 'inequality', 'schluss', 'fé', 'happ', 'dire', 'uto', 'rän', 'lamp']\n",
      "in Layer26 , sorted_indices_dimension2707:  ['raste', 'jú', 'ske', 'ublik', 'rvm', '공', 'ria', 'printStackTrace', 'jahr', 'amet', 'меня', 'ရ', 'induction', 'дер', 'ken', 'uwe', 'arie', 'rum', 'condu', 'uset', 'Transfermarkt', 'aren', 'aplic', 'sdl', 'kont', 'konst', 'Freund', 'Cir', 'eren', 'nr', 'ņ', 'vn', 'кон', 'refix', 'pages', '@\"', 'bibli', 'igne', 'med', 'rowser', 'ham', 'Nil', 'protocol', '�', 'étr', 'ált', 'multip', 'rique', 'tém', 'dict', 'простра', 'itzen', 'krie', 'ędzy', 'တ', 'Bian', 'rou', 'Japon', 'alls', 'données', '%).', 'ultado', 'sterd', 'ház', 'Valle', 'Савезне', 'laid', 'itie', 'ђе', 'acc', 'opera', 'estaven', 'platz', '拳', 'teger', 'unicí', 'por', 'onde', 'acker', 'conde', 'ále', 'hd', 'ֶ', 'contin', 'atori', 'iada', 'iti', 'гани', 'Observer', 'ких', 'Jim', 'contrib', 'Lied', '=\\\\\"', 'ケ', 'ض', 'Según', 'há', 'pply', 'ange', 'fra', 'contribu', 'Por', 'iné', 'zewnętrzne', '�', 'Palmar', 'mbH', 'hu', 'idense', 'SET', 'Napole', '�', 'FAULT', 'rane', 'Opera', 'Nap', '�', 'friend', 'dav', 'apply', 'contre', 'intro', 'ingår', 'ál', 'ouve', 'rig', 'roke', 'ine', 'copy', 'Lig', '親', 'copying', 'кон', 'weap', 'tz', 'contra', 'tm', 'Dict', 'jourd', 'widet', 'konn', 'ône', 'ferrer', 'mlung', 'raise', 'Laz', 'diffusion', 'doc', 'dog', 'Bomb', 'induct', 'ₗ', 'rugu', 'Niem', 'Temp', 'dess', 'listade', 'iges', 'bridge', 'alias', 'zaw', 'ільки', 'lias', 'pler', 'Jac', 'avant', 'лек', 'zig', 'dict', 'Jed', 'zott', 'приз', 'gew', 'canvas', 'မ', 'Film', 'Explorer', 'dagger', 'acia', 'friend', 'lax', 'iso', 'gebra', 'inus', 'itza', 'japon', 'shall', '宗', 'putation', 'Documents', '友', '(\"<', 'erne', 'DECLARE', '茶', 'rodu', '計', 'вне', 'halb']\n",
      "in Layer26 , sorted_indices_dimension6684:  ['light', 'ー', 'Light', 'catch', 'зе', 'ze', 'ZE', 'han', 'Blue', 'lu', 'Red', 'yst', 'itzer', 'ker', 'ido', 'atur', 'поли', 'rn', '�', 'UITableView', 'zing', 'DS', 'edit', 'ernal', 'lights', 'Cru', 'Est', '�', 'Ross', 'scop', 'itä', 'infty', 'łod', 'Gegen', 'catch', 'flash', 'agh', 'GR', 'je', 'alu', 'aters', 'light', 'จ', 'Free', 'ops', 'Ча', 'orf', 'luc', '包', 'pier', 'лим', 'Erd', 'lu', '路', 'guard', 'SERVER', 'mania', 'Blue', 'Davis', 'Butler', 'uh', 'orsz', 'Zeit', 'WS', 'enten', 'yp', 'férés', 'etime', 'idi', 'contre', 'SY', 'poss', 'uby', 'heav', 'Lan', 'Gast', 'wn', 'LENGTH', 'екси', 'ensen', 'rug', 'Lu', 'aturen', 'Chap', 'כ', 'Red', 'é', 'Controller', '~~', 'Grand', 'nu', 'pc', 'pose', 'préc', 'obil', 'Root', 'юз', 'Belle', 'annot', 'ố', 'Root', 'PC', 'ry', 'live', 'messages', 'ições', 'ern', 'Light', 'it', 'ted', '长', 'gap', '�', '長', 'nas', 'Gre', 'pag', 'schau', 'opo', 'redis', '序', 'ala', 'length', 'auch', 'ye', 'lin', 'мости', 'root', 'inaugur', 'sys', 'sync', 'ess', 'Dor', 'зо', 'Pier', 'imo', 'scroll', 'saison', 'zer', 'хан', 'lette', 'icher', '✓', '~~~~~~~~', 'enc', 'iten', 'Dictionary', 'Arr', 'essional', 'tempo', 'Luke', 'lov', 'Jed', 'Edit', 'compose', 'д', 'wing', 'Guard', 'lesia', 'li', '斯', 'aught', 'Alex', 'geme', 'contrary', 'men', 'note', 'контра', 'ource', 'Car', 'Conc', 'ynchronous', 'Chem', 'Jes', 'Lu', 'graph', 'uzz', 'Read', 'session', 'historian', '~~~~', 'Edit', 'Españ', 'Dub', 'ros', 'lambda', 'Ale', 'lum', 'Halle', 'свобо', 'Wing', 'iec', 'Children', 'lek', 'Case', 'Len', 'Id', 'ly', 'participated', 'состоя']\n",
      "Key: model.layers.27.mlp.down_proj.weight\n",
      "in Layer27 , sorted_indices_dimension1722:  ['utz', 'onian', 'рода', 'bullet', 'ünd', 'sense', 'eton', 'yk', 'cite', 'jsf', 'sac', 'axis', 'vre', 'bullet', 'View', 'oret', 'bien', 'tres', 'hm', 'hum', 'áj', 'zel', 'agnet', 'SB', 'hop', '씨', 'oux', 'urre', 'Hugo', 'proxy', 'View', 'mock', 'agli', 'rag', 'ptic', 'gehör', 'igg', 'fal', 'iw', 'aggi', '단', 'bod', 'isen', 'uder', 'DM', 'airo', 'arian', 'Mock', 'require', 'zi', 'elte', 'igli', 'gnu', 'req', 'нва', 'ún', 'Dre', 'ouss', '�', 'owanie', 'Dum', 'чних', 'agn', 'ANT', 'ження', 'yan', 'ан', 'arias', 'ville', 'arp', 'urban', 'yg', 'andro', 'oni', 'iga', 'там', 'mise', 'aszt', 'seed', 'ĭ', 'éné', 'buch', '象', 'seasons', 'ök', 'API', 'REG', 'dus', 'жён', 'urk', 'criter', 'cook', 'iani', 'andy', 'imum', 'ája', 'epen', 'modifier', 'disease', 'ello', 'дол', 'пис', 'Meister', 'widet', 'Haus', '体', 'vista', 'хан', 'dbo', 'ico', 'fe', 'юр', 'чне', 'slider', 'Visible', '$-', 'templates', 'aro', 'ute', '称', 'like', 'opt', 'modify', 'enburg', 'sur', 'matter', 'zie', 'regon', '败', 'égl', 'sym', 'desarroll', 'людей', 'лан', 'шей', 'Jeux', 'incor', 'chan', 'romagnet', 'roc', 'inen', 'AR', 'estig', 'sprite', 'argv', 'ounding', 'timp', 'ato', '断', 'substitute', 'ienn', 'nut', 'nerv', 'USA', 'äft', '$-', 'zott', 'тал', 'erve', 'debug', 'sets', 'scra', 'imenti', 'живело', 'je', 'etal', 'стана', 'nof', 'wise', 'сто', 'periodic', 'repeat', 'overcome', 'ници', 'mater', 'season', 'owych', 'ialog', 'season', 'atorio', 'Hem', 'pian', 'voit', 'ven', 'figura', 'Tür', 'vic', 'apr', 'TX', 'Season', 'setText', '§', 'Consultado', 'template', 'fest', 'Rails', '完', 'anha', 'де', 'Selection']\n",
      "in Layer27 , sorted_indices_dimension9495:  ['iore', 'von', 'orage', 'ottom', 'otes', 'HC', 'ienne', 'Exchange', 'mut', 'om', 'ères', 'cat', 'ble', 'References', '麻', 'exchange', 'jub', 'савез', '然', 'joint', 'McC', 'incor', 'Cost', 'ahn', 'сто', 'Academia', 'Rost', 'jin', 'iness', 'Mot', 'рона', 'SV', 'cido', 'harm', 'sub', 'sub', 'stud', 'сту', 'Nature', 'zan', 'vity', 'host', 'пос', 'Federation', 'za', 'mounted', 'Bound', 'negative', 'Host', 'roman', 'ready', 'subscribe', 'flow', 'Reference', 'Lars', 'subclass', 'Salvador', 'Seb', 'adin', 'enc', 'Harrison', 'ян', 'Whe', 'fiddle', 'бу', 'oin', 'ica', 'disposition', 'Cat', 'Hell', 'pou', 'kost', 'Cur', 'Host', 'hell', 'деревня', 'kur', 'kiss', 'sink', 'ASH', 'Gemeinsame', 'Committee', 'Stim', 'konn', 'adjust', 'sier', 'nada', 'curl', 'tag', 'access', 'рома', 'bur', 'Resources', 'esz', 'dio', 'ồ', 'icano', 'лова', 'jo', 'htaccess', 'äll', 'Flow', 'cov', 'references', 'пун', 'amar', 'avas', 'зова', 'Geb', 'pia', 'Fac', 'Cur', 'itza', 'Station', '_+', 'Lloyd', 'alls', 'ils', 'equival', 'Cult', 'alc', 'Fine', 'Ready', 'Von', 'head', '�', 'iest', 'ad', 'format', 'powiat', 'go', 'slider', 'botan', 'льта', 'ieurs', 'Inga', 'st', 'зне', 'ount', 'Red', 'гато', 'cultiv', 'aw', 'perl', 'ina', 'invited', '克', 'Zur', 'al', 'icz', 'HEAD', 'Lab', 'Diplom', 'hu', 'oun', 'fatt', 'omm', 'ље', 'seed', 'евич', 'tou', 'dov', 'João', 'station', 'McK', 'hook', 'join', 'կ', '¨', 'flow', 'Train', 'Red', 'hina', 'Cov', 'allenge', 'Map', 'ALL', 'gc', 'correct', 'tin', 'matically', 'corners', 'ativity', 'Mount', 'cur', 'aml', 'ibility', 'slov', 'i', 'ic', 'gif', 'orem', 'utf', 'thead', 'zat', 'notes', 'Ath', 'тво', 'онов', 'diplom']\n",
      "in Layer27 , sorted_indices_dimension9863:  ['̥', 'annon', 'toire', 'Zam', 'igs', 'attice', 'amb', 'vr', 'DL', 'бур', 'ancer', 'sit', 'Akademie', 'bl', 'til', 'RA', 'ride', 'dia', 'Ans', 'ник', 'Opera', '<!', 'Gonz', 'Brad', 'fra', 'RES', 'tz', 'itzen', 'ра', 'green', 'comm', 'rain', 'van', 'rör', 'сезо', 'atin', 'chos', 'Ger', 'län', 'astr', 'släktet', 'f', 'fraction', 'dl', 'ierz', 'cko', 'progetti', 'gez', 'exception', 'Elis', 'imper', 'cul', 'esia', 'usk', 'antes', 'Phone', 'ierre', '�', 'ush', '&=\\\\', 'til', 'bl', 'obe', 'neut', 'neutral', 'едера', 'zil', 'igen', 'стра', '平', 'cond', 'plan', 'Blues', 'rane', 'verw', 'gue', 'iat', 'ger', 'rép', 'abstra', 'genomsnitt', 'udent', 'uten', 'Drop', 'sem', 'ownik', 'BR', 'mvc', 'raine', 'cam', 'IAB', 'concepts', 'fra', 'tbl', 'hibernate', 'R', 'ью', 'till', 'ней', 'Chiesa', 'sequence', 'capit', 'concept', 'inden', 'mat', 'Cam', 'grave', 'mi', 'ichen', 'ède', 'ide', 'familjen', 'ď', 'scene', 'tar', 'sprech', 'Kaiser', 'foot', 'maj', 'ва', 'green', 'commun', 'late', 'siège', 'рес', 'ambient', 'тися', 'ť', 'жов', 'trop', 'Factory', 'lö', 'ús', 'al', 'puzz', 'force', 'phon', 'gz', 'ature', 'ental', '�', 'anni', 'spec', 'Health', 'mental', 'bud', 'ље', 'Begriff', 'mate', 'intér', '어', 'Exception', 'raint', 'hoz', 'lopedia', 'Fra', 'exception', ':#', 'mat', 'force', 'heimer', 'cas', 'refuge', 'edes', 'Config', 'ví', 'imperial', 'Belle', 'vul', 'Hof', 'ango', 'gren', 'cke', 'Entertainment', 'util', 'enig', 'wireless', 'Pear', 'González', 'hello', 'Util', 'T', 'дня', 'Comm', 'cat', 'ī', 'physical', 'anes', '身', 'advent', 'zyk', 'ód', 'fig', 'blind', 'yrus', 'phone', 'until', 'bia', 'host', '思']\n",
      "Key: model.layers.28.mlp.down_proj.weight\n",
      "in Layer28 , sorted_indices_dimension10432:  ['classical', 'Compos', 'viol', 'sym', 'compos', 'Sym', 'Jazz', 'opera', 'jazz', 'Opera', 'orch', 'compos', 'opera', 'bal', 'Orchestra', 'cho', 'Gram', 'Sym', 'compose', 'band', 'pop', 'composition', 'recorded', 'Fine', 'concert', 'pian', 'recording', 'composer', 'компози', 'Record', 'exhib', 'Bal', 'band', 'opt', 'Perform', 'composite', 'Quart', 'Ens', 'bal', 'Shakespeare', '�', 'vn', 'sym', 'сим', 'ensemble', 'stamp', 'Bal', 'march', 'ewrite', 'fine', 'record', 'walt', 'piano', 'swing', 'Record', 'compose', 'invest', 'record', 'performing', 'opt', 'composed', 'chestra', 'produ', 'cho', 'bands', 'Wagner', 'Kompon', 'Moz', 'ona', 'answering', 'trom', '故', '◄', 'Vi', 'gem', 'motion', 'Animation', 'rock', 'yen', 'webdriver', 'performances', 'grammar', '\\u202d', 'Class', 'pert', 'Wor', 'Shakespe', 'sheet', 'esti', 'iley', 'circ', 'ouc', 'ĩ', 'ogn', 'Produ', 'Opt', 'enen', 'ignon', 'gram', 'Chor', 'PR', 'beskre', 'PR', 'Wir', 'accord', 'dv', 'Band', 'ieu', 'amp', 'iny', 'Class', 'ор', 'Rec', 'lac', 'Mot', 'Mann', 'Pop', 'exponent', 'ven', 'conduct', 'animated', 'pop', 'isie', 'Pop', 'Maria', 'illon', 'chor', 'Opt', 'indi', 'Early', '指', 'Classic', 'sop', 'yna', 'drama', 'ín', 'ragma', 'Astronom', 'olin', 'chia', '�', 'ISTS', 'ǧ', 'Char', 'wor', 'background', 'picture', 'Reference', 'surr', 'cipl', 'CP', 'telt', 'Mult', 'ens', 'LP', 'orbit', 'ensch', 'classic', 'ogram', 'Con', 'Reference', 'indre', 'öll', 'ót', 'Kinder', 'Weltkrieg', 'Coun', 'wp', 'Zie', 'orch', 'JQuery', 'reported', 'ensemble', 'rup', 'tut', 'eredet', 'mans', 'EY', 'plane', 'allo', 'ji', 'rip', 'пописа', 'inds', 'ez', '바', 'Thé', 'fingers', 'allo', 'azz', 'olk', 'CD', 'brie', 'gov', 'gg', 'aval', 'dot', 'agini', 'Register', '富']\n",
      "in Layer28 , sorted_indices_dimension6085:  ['studio', 'Studio', 'Studio', 'studio', 'Studios', 'artist', 'Shakespeare', 'Entertainment', 'Hollywood', 'artists', 'genre', 'comedy', 'Arts', 'literary', 'poetry', '舞', 'Creative', 'Dance', 'dance', 'poet', 'Disney', 'Music', 'arts', 'Entertain', 'entertain', 'твор', 'music', 'Movie', 'Shakespe', 'movie', 'actor', 'theatre', 'audience', 'Warner', 'musical', 'Movie', 'Music', 'actors', 'Sony', 'Theater', 'Theatre', 'stud', 'театра', 'movie', 'opera', 'music', 'Festival', 'poem', 'jazz', 'Jazz', 'composer', 'ensemble', 'Musical', 'singer', 'MTV', 'actress', 'poeta', 'festival', 'muse', 'estival', 'chestra', 'akespe', 'Produ', 'udio', 'producer', 'теа', 'musicale', 'udi', 'худож', 'reactjs', 'сту', 'Marvel', 'cinema', 'fiction', 'piano', 'scène', 'Scene', 'lyr', 'Teatro', 'Billboard', 'guitar', 'Opera', 'teatro', 'музы', 'copy', 'scene', 'lywood', '歌', 'audi', 'aud', 'actor', 'rama', 'agh', 'музи', 'Cinema', 'Kultur', 'sang', 'Ent', 'ctor', 'Broadway', 'stars', 'oug', 'littérature', 'ent', 'Muse', 'Madonna', 'painter', 'Comics', 'Stars', 'dan', 'scenes', 'drama', 'música', 'Künstler', 'IMDb', 'humor', 'festiv', 'кино', 'estudio', 'musique', 'aud', 'роман', 'album', 'iza', 'quence', 'crew', 'автор', 'studi', 'Theme', 'théâtre', 'aters', 'writers', 'ola', 'edy', 'etry', 'performances', '楽', 'rez', 'Renaissance', 'ael', 'Schauspieler', '片', 'leng', 'Writer', 'albums', 'Orchestra', 'atr', 'Pac', 'songs', 'cele', 'theme', 'ater', 'ografie', 'teat', 'cens', 'stage', 'copy', 'тан', 'худо', '館', 'nb', 'Songs', 'agy', 'emat', 'ací', 'characters', '♥', 'Monte', 'agne', 'writer', 'û', 'cinemat', 'scen', 'Oscar', 'Visual', 'Anne', 'pac', 'Play', '式', 'xi', 'pian', 'ppings', 'decla', 'avant', 'laughed', 'scene', 'eme', 'produ', 'від', 'agn', 'cinéma', 'oder', 'Film', 'Ÿ', 'NBA', 'arring', 'criptor', '~', 'gallery', 'Samuel']\n",
      "in Layer28 , sorted_indices_dimension10988:  ['imm', 'automatisch', 'шта', 'Ho', 'ách', 'Seb', 'imm', 'arch', 'boot', 'herr', '通', 'ho', '麻', 'chi', 'mbH', 'Dor', 'Operator', 'iec', 'ozzá', 'omo', '串', 'prakt', 'ways', 'писи', 'corpor', 'Hud', 'horn', 'iders', '̌', 'শ', 'чик', 'Ces', 'what', 'ongo', 'öff', 'бе', 'anim', 'rav', 'остан', 'open', 'beste', 'pill', 'Pac', 'aget', 'пр', 'chia', 'стрі', 'aso', 'Open', 'Boot', 'ça', 'fab', 'ifié', 'abl', 'tcp', 'fw', 'masses', 'oused', '�', ')^{-', 'mutable', 'indicator', 'ど', 'isé', 'Mode', 'specie', 'fonts', 'rence', 'ство', 'isée', '州', 'enk', 'otlin', 'Dol', 'coming', 'Albert', 'ous', 'davon', 'mit', 'Кра', 'aml', 'pass', 'licher', 'papers', '�', 'osen', 'öß', 'mode', 'esian', 'rix', 'ף', '開', 'mutable', 'ings', 'Rud', 'Corporation', 'unal', 'wij', 'Harrison', 'Next', 'ษ', 'unit', 'pmod', '�', 'uf', 'Boot', 'atus', '{-', 'Corpor', '郡', 'open', 'LENG', 'hav', 'igkeit', 'ström', 'baum', 'Jag', '否', 'sov', 'Cow', '弘', 'vice', 'py', 'cord', 'ichen', 'raw', 'teor', 'onic', 'indic', 'resist', '开', 'where', 'cow', 'borough', 'voit', 'pi', 'kbd', 'ка', 'gar', 'мир', 'letin', 'stelling', 'кам', 'identifier', 'pa', '衛', 'ord', 'Kaiser', 'inc', 'waar', 'unker', 'opens', 'ˇ', 'tz', 'pia', 'alf', 'komm', 'achment', 'Sab', 'sheet', 'vill', 'selbst', 'ört', 'mitt', 'управ', '孝', 'откры', 'Ce', 'erner', 'arch', 'horizon', 'verkehr', 'subseteq', 'Oxford', 'пису', 'abs', 'mari', 'sizeof', 'sten', 'imon', 'ublic', 'Dav', 'Patri', 'Unit', 'Arch', 'eszt', 'Libert', 'сам', 'horn', '�', 'ович', 'ula', 'telep', 'chapter', 'prü', 'vare', 'uten', 'URN', 'ernal', 'ката']\n",
      "in Layer28 , sorted_indices_dimension8464:  ['ous', 'Cas', 'int', 'pit', 'cas', 'math', 'pport', 'pragma', 'int', 'ou', 'ned', 'ijn', 'Ma', 'MA', 'ba', 'ons', 'ye', 'taire', 'mania', 'endo', 'INT', 'sal', 'wald', 'iae', 'Sin', 'oun', 'sal', 'Mak', 'IR', 'draw', 'cas', 'sein', 'oul', 'end', 'ma', 'niem', 'pit', 'mass', 'ý', 'ould', 'aux', 'ht', 'ML', 'fal', 'Ma', 'andom', 'iance', 'aire', 'enne', 'short', 'Mac', 'ird', 'mund', 'uf', 'ild', 'inflate', '松', 'пи', 'cel', 'organ', 'outh', 'innoc', 'schen', 'fter', 'HERE', 'Inflater', 'ational', 'üt', 'Brad', 'kill', 'SE', 'tut', 'old', 'fl', 'affili', 'crowd', 'Finale', 'lord', 'mac', 'ence', 'зда', 'mass', 'rou', 'orm', 'ennes', 'wen', 'PUT', 'red', 'hu', 'resid', 'coh', 'ำ', 'MR', 'schließ', 'inn', 'Autor', 'aste', 'Opera', 'Gon', 'porte', 'IB', 'я', 'infl', 'ith', 'uclidean', 'unct', 'raid', 'па', 'sé', 'Tax', 'brary', 'rac', 'ound', 'bd', 'Kingdom', 'Male', 'assignment', 'Ende', 'cô', 'pied', '�', 'au', 'u', 'caus', '局', 'asi', 'sers', 'hi', 'nde', 'iral', 'tax', 'Pad', 'INT', '\\\\/', 'sin', 'uk', 'fty', 'carriage', 'ppa', 'ред', 'ouss', 'low', 'ak', 'porta', 'грома', 'Einz', 'Pit', 'Ye', 'Blan', 'слов', 'Ce', 'ld', 'baz', 'cen', 'Seine', 'aine', 'BA', 'сай', 'raz', 'стра', 'seau', 'port', 'NaN', 'mom', 'Pierre', 'wij', 'Cla', 'ု', 'Short', 'orb', 'irtual', 'laim', 'acht', 'maste', 'реди', 'ма', 'ITH', 'Pictures', 'Bruno', 'Pir', 'ャ', 'Luxemb', 'str', 'acci', '∞', 'cube', 'ama', 'Neben', 'comb', 'uns', 'Mass', 'oux', 'ê', 'put', 'uint', 'HT', '❯', 'pad', 'fre', 'phan']\n",
      "in Layer28 , sorted_indices_dimension3833:  ['sw', 'sw', 'Sw', 'imar', 'Sw', 'stroke', 'województ', 'stroke', 'wat', 'Stat', 'statement', 'ci', 'swap', 'vil', 'Rudolf', 'dent', 'roke', 'row', 'ή', 'bog', 'marine', 'statements', 'waters', 'сви', 'сь', 'ando', '☆', 'bla', 'Stock', 'Cry', 'opol', 'marine', 'brary', 'wr', 'ゃ', 'stro', 'Band', '息', 'equality', 'bre', 'ülés', 'rivers', 'gmina', 'band', 'clouds', 'ódigo', 'peat', 'rows', 'athol', '‡', 'lections', 'water', 'idenote', 'enze', 'swap', 'èg', 'ด', 'ån', 'hart', 'RelativeLayout', 'polar', 'vil', 'XX', 'ắ', 'рь', 'што', 'holds', 'Footnote', 'ált', 'Docker', 'him', 'UD', 'TS', 'inds', '�', 'leaf', 'band', 'amo', 'shut', 'heart', 'council', 'тов', 'CURL', 'дов', 'Cet', 'Glad', 'guez', 'cil', 'atz', 'ந', 'Heart', 'Kan', 'giore', 'UES', 'Marine', 'xaml', '乐', 'Lü', 'berta', 'mouth', 'Amts', 'ultan', 'heaven', 'Gan', 'usz', 'ゼ', 'äl', 'users', 'heart', 'stadt', 'onial', 'postal', 'stir', '�', 'ibrary', 'racle', 'zyk', 'atr', 'isé', 'пла', 'powiat', 'coast', 'нд', 'hearts', 'MainActivity', 'oko', 'Wat', 'lah', 'Werner', 'Dit', 'бран', 'SW', 'init', 'entin', 'inse', 'resize', 'stad', 'Bischof', 'zeg', 'footnote', 'Hat', 'uba', 'cors', 'Sto', 'кри', 'aña', 'ximo', 'owie', 'scra', 'Cloud', 'Statement', 'Constraints', 'zes', 'bolds', 'CLARE', 'rund', 'heap', 'ена', 'nuc', '�', 'predicate', 'eerd', 'ionic', 'sto', 'Compiler', 'incie', 'git', 'cs', 'tropical', 'stract', 'ляр', 'ською', '章', 'idense', 'stops', 'craw', 'legend', 'atorio', 'februari', 'LM', 'Ind', 'iami', 'igs', 'Seite', 'grounds', 'рай', 'ounce', 'IMA', 'krie', '¤', 'огра', 'Cs', 'ighth', 'settings', '도', 'unning', 'ént', 'Council', 'itsch', 'gens']\n",
      "Key: model.layers.29.mlp.down_proj.weight\n",
      "in Layer29 , sorted_indices_dimension800:  ['ar', 'spr', 'morrow', 'Ć', 'rai', 'iero', 'retir', 'emento', 'Données', 'Encyclop', 'tml', '\\u202d', 'wei', 'Hof', 'olin', 'spr', 'pole', 'проти', 'arithmetic', 'imal', '�', 'aria', 'Factory', 'Stern', 'Torre', 'Joan', 'apis', 'laps', 'Ela', 'arrison', 'Springer', 'Gli', 'нове', 'FALSE', 'по', 'pend', 'Fields', 'hof', 'поле', 'sko', 'Schles', 'ierre', 'Fichier', 'ardin', 'noreferrer', 'Gram', 'iare', 'aña', 'Svens', 'Milano', 'mirror', 'oop', 'pid', 'см', 'ScrollView', 'cciones', 'pped', 'Encyc', 'uky', 'iture', 'ansion', 'ogonal', 'wx', 'topological', 'Bed', 'armed', 'hoff', 'gleich', 'Й', 'bey', 'bles', 'uf', 'Pane', 'linea', 'ế', 'feld', 'зар', 'archy', 'Tomatoes', 'ien', 'Kirch', 'Sche', 'fiel', 'aby', 'fat', 'ogram', 'tér', 'agyar', '면', 'ologe', 'loped', 'rupted', 'laid', 'hov', 'iri', 'download', 'uture', 'CURLOPT', 'ar', 'zony', 'cke', 'Dup', ':`', 'Download', 'тка', 'Spring', 'cji', '__(', 'roc', 'pan', 'osc', 'lo', 'lap', 'Gian', 'Gan', 'spring', 'cím', 'DAT', 'aan', 'ných', 'âr', 'acles', 'externos', 'xelles', 'рис', 'TEXT', 'bed', 'orage', 'iony', 'száz', 'Florence', 'extens', 'aval', 'rii', 'тен', 'Deze', 'await', 'Factory', '(@\"', 'ills', 'Jos', 'Grand', 'polar', '◦', 'lemagne', 'жовт', 'XVIII', 'Forms', 'cm', 'gor', 'Riemann', 'false', 'uniform', 'unal', 'date', 'wür', '□', 'field', 'Accessor', 'yter', '击', 'oby', 'sprite', 'ள', 'Encyclopedia', 'duplicate', 'embros', 'brázky', 'WF', 'Nil', 'uniform', 'Pere', 'tar', 'Histoire', 'texts', 'ospod', 'Field', 'orth', 'izo', 'мости', 'Setter', 'рит', 'emble', 'ному', '春', 'ragma', 'мой', 'urt', 'إ', 'enced', 'ˆ', 'поль', 'led', 'aten', 'empl', 'Pierre', 'fields', 'ộ', 'пута', 'Februar']\n",
      "in Layer29 , sorted_indices_dimension1185:  ['c', 'c', 'ba', 'sted', 'rok', 'iore', 'p', 'lay', 'lay', 'length', 'organ', 'length', 'hot', 'RC', 'Ba', 'Ch', 'ui', 'TD', 'ton', 'ink', 'la', 'man', 'Ћ', 'Pages', 'land', 'ま', 'lengths', 'feedback', 'ed', 'g', 'Da', 'fra', 'ok', 'Da', 'red', 'Fix', 'j', 'hot', 'ois', 'ham', 'attract', 'edo', 'SD', 'Tok', 'prop', 'bal', 'Fra', 'anstalt', 'TA', '打', 'rein', '草', 'wa', 'cro', 'drawn', 'hrer', 'PD', 'platz', 'Columbia', 'kar', 'jb', 'alias', 'ale', 'rot', 'zew', 'assign', 'wa', 'guest', 'ピ', '真', 'live', 'chten', 'Ax', 'asp', 'Alliance', 'polar', '录', 'Џ', 'p', 'du', 'arr', 'ser', 'type', 'assign', 'cer', 'athedral', 'Arnold', 'zem', 'Can', 'Felix', 'app', 'bru', 'positive', 'Politik', 'Cro', 'Redirect', 'ar', 'prote', 'bel', 'бар', 'coded', 'initi', 'Gott', 'Pos', 'take', 'LD', '福', 'ds', 'jem', 'jąc', 'jahr', 'aland', 'Cs', 'orange', 'fix', 'anonymous', 'plat', 'sin', 'Roger', 'cow', 'tor', 'DB', 'amateur', 'Hot', 'cript', 'cro', 'itz', 'Cer', 'ard', '�', 'év', 'anim', 'Pixel', 'foot', 'exchange', 'Prom', '{#', 'qu', 'C', 'руд', 'Orange', 'Gray', 'da', 'ツ', 'Tam', 'com', 'JB', 'lete', 'ffen', 'ouch', 'accord', 'azon', 'aben', 'ere', 'agne', 'gal', 'дан', 'cel', '라', 'тон', 'inks', 'Bal', 'greater', 'lake', 'rough', 'extract', 'cust', '්', 'Type', 'bog', 'bit', 'liquid', 'dom', 'rec', 'nex', 'care', 'prec', 'apps', 'App', 'writes', 'jan', 'complex', 'BIT', 'Pred', 'tokens', 'animate', '長', 'ね', 'stress', 'red', 'Bomb', 'Organ', 'animal', 'drivers', 'rait', 'den', 'laid', 'ze', 'mirror', 'Cad']\n",
      "in Layer29 , sorted_indices_dimension3715:  ['routes', 'acceler', 'route', 'paths', 'path', 'econom', 'def', 'Isaac', 'exped', 'sou', 'Path', 'invest', 'multiple', 'wor', 'Path', 'nero', 'rimin', 'bar', 'sex', 'routes', 'OU', 'route', 'UG', 'avia', 'lib', 'Rolle', 'allo', 'FO', 'har', '見', 'dispos', 'ison', 'cal', 'bar', 'rible', 'isu', 'Si', 'aron', 'li', 'align', 'kiss', 'Хронологија', 'fo', 'path', 'ch', 'acceleration', 'Intent', 'Federal', 'ycz', 'omo', 'atal', 'ally', 'buff', 'alignment', 'спо', 'Sou', 'Hin', '©', 'uwe', 'nia', 'izzato', '昭', 'Gul', 'Alignment', 'och', 'Movie', 'PT', 'Bry', 'Baker', 'Match', 'Route', 'fo', 'res', 'ug', 'dep', 'MQ', 'arter', '�', 'ahu', 'lr', 'Cy', 'Fu', 'matches', 'blob', 'volumes', 'Mo', 'ръ', 'uga', 'oss', 'extern', 'Mode', 'Match', 'American', 'dock', 'consp', 'iennes', 'system', '孝', 'рия', 'Kill', 'DEX', 'psych', 'oul', 'Calendar', 'cv', 'euw', 'alom', 'Route', '안', 'bah', 'match', 'циона', 'ahr', '̂', 'rach', 'tz', 'Ehren', 'def', 'oz', 'och', 'hack', 'cul', 'chestra', 'halten', 'Фо', 'alis', 'лия', 'uden', 'soul', 'rel', 'Fitz', 'jud', 'libre', 'alia', 'ツ', 'tom', 'дже', 'safe', 'Orientation', 'shell', 'System', 'Email', 'Movie', 'appreci', 'Edmund', '์', 'azzo', 'wal', 'oko', 'ps', 'etz', 'foo', 'modal', 'áz', 'athlet', 'yar', 'Navigation', 'lean', 'ellan', 'fu', 'rito', '{#', 'Ring', 'worst', 'matching', 'zel', 'Mode', 'PATH', 'Wal', 'Reyn', 'hbar', 'дар', 'Multiple', 'brary', 'iner', 'ris', 'sem', 'alf', 'ouch', 'ensa', 'sciences', 'Li', 'federal', 'Dios', 'arab', 'mier', 'sport', 'front', 'Мос', 'oport', 'kmal', 'хар', 'цима', 'prit', 'yter', 'prospect', 'Move', 'electric', '巴', 'ownership']\n",
      "in Layer29 , sorted_indices_dimension296:  ['hair', 'species', 'fame', 'income', 'resolution', 'venue', 'leadership', 'movements', 'security', 'household', 'defense', 'movement', 'policy', 'Species', 'maintenance', 'versions', 'movie', 'attention', 'behavior', 'decision', 'sister', 'neighborhood', 'abgerufen', 'activity', 'reception', 'izontal', 'currency', 'utility', 'safety', 'mole', 'performance', 'victory', 'security', 'intelligence', 'signature', 'territory', 'subscription', 'cand', 'energy', 'coverage', 'confidence', 'session', 'routine', 'legs', 'corps', 'attachment', 'memory', 'persona', 'music', 'freedom', 'occas', 'software', 'refuge', 'membership', 'consumption', 'business', 'application', 'laten', 'species', 'office', 'regime', 'usage', 'battery', 'td', 'media', 'treatment', '}$-', 'cdot', 'opposition', 'equipment', 'brother', 'column', 'spectrum', 'Airport', '条', 'attitude', 'completion', 'disease', 'sessions', '業', 'basket', '技', 'economy', 'columns', 'audience', 'destruction', '씨', 'vehicle', 'library', 'perspective', 'legacy', 'production', 'cousin', 'college', 'destination', 'substr', 'death', 'genus', 'havior', '●', 'independence', 'family', 'sib', 'skills', 'energy', '️', 'beauty', 'nik', 'hotel', 'cabinet', 'adaptation', 'potential', '业', 'animation', 'sales', 'Error', 'traffic', 'vba', 'guidance', 'medical', 'atience', 'door', 'camera', 'basketball', 'limitation', 'traject', 'sv', 'essa', 'community', 'metadata', 'kitchen', 'song', 'soort', '屋', 'rew', 'wealth', 'recommendation', 'guitar', 'growth', 'LP', 'lamp', 'isy', 'skin', 'events', 'mission', 'capacity', 'fel', 'goal', 'facility', 'separation', 'extension', 'efficiency', 'television', 'EV', 'DVD', 'division', 'nie', 'BS', 'arrival', 'iversity', 'ECT', 'noise', 'curr', 'policies', 'права', 'succès', 'job', 'paper', 'imit', 'Movie', 'management', 'versión', 'uo', 'infrastr', 'currency', 'temple', 'memb', 'resistance', 'edad', 'że', 'idea', 'scenario', '氏', 'submission', 'ector', 'CSV', 'weapons', 'asset', 'presence', 'life', 'actor', 'pover', 'principale', 'life', 'office', 'ego', 'ü', 'tea', 'medicine', 'consumer']\n",
      "in Layer29 , sorted_indices_dimension5002:  ['eben', 'miss', 'eb', 'amps', '付', 'pitch', 'sla', 'ns', 'rez', 'ben', 'ora', 'äft', 'Miss', 'kwiet', '�', 'gif', 'moz', 'hem', 'Latin', 'Reichs', 'Comun', 'days', 'Ú', 'zu', 'Sant', 'OF', 'Selon', 'pare', 'acc', 'Während', 'async', 'hp', 'Amer', 'ebb', 'бе', 'HP', 'Honor', 'iani', 'wet', 'mez', 'nich', 'Acc', 'ionario', 'kat', 'aby', 'BER', 'nell', 'Brit', 'ologist', 'кс', 'стро', 'arios', 'abet', 'ounce', 'сви', 'filtering', 'desen', 'sierp', 'ɵ', 'bir', 'snapshot', 'slot', 'icher', 'MIT', 'gebra', 'nost', 'z', 'ber', 'ector', 'atura', 'actory', 'Solo', 'arc', 'Mobile', 'shout', 'attach', 'ML', 'ego', 'пописа', 'Preferences', 'atif', 'miss', 'DO', 'ede', 'bek', 'GM', 'throw', 'CAT', 'skip', 'bn', 'клад', 'rate', 'bil', 'ellite', 'Girls', 'latin', 'Miss', 'Current', 'mens', 'xs', 'Naz', 'ölker', 'бан', 'ा', 'vu', 'onen', 'af', 'торы', 'emos', 'Begriffe', 'stycz', 'onomy', 'elen', 'ベ', 'kan', 'elve', 'ounced', 'Wikiped', 'zó', 'CF', 'Santiago', 'présente', 'arca', 'nie', 'thrown', 'orthogonal', 'nose', 'Boliv', 'iele', 'ズ', 'ange', 'transaction', 'Bildern', 'ните', 'transaction', 'computational', 'óm', '索', 'Britannica', 'JOIN', 'agem', 'Singles', 'volume', 'emein', 'дей', 'dating', 'partiellement', 'règ', '男', 'DP', 'lą', '密', 'źdz', 'adow', 'tract', 'leak', '崎', 'trif', 'rates', 'eln', 'usetts', 'filtered', 'ancing', 'iez', 'Ú', 'ks', 'Hon', 'stress', 'ку', 'Volume', 'Bu', 'throw', 'EB', 'amb', '}{|', 'стана', 'face', 'Benjamin', 'jpg', 'snap', 'ktet', 'ei', 'lau', 'gor', 'x', 'yz', 'eler', 'addle', 'Museo', 'рей', 'тель', 'ому', 'iali', 'plex', 'Kat', 'Jordan', 'zap', 'oust', 'rai', 'honour']\n",
      "in Layer29 , sorted_indices_dimension4748:  ['base', 'ily', 'base', 'lass', 'Base', 'BASE', 'ley', 'bum', 'Enum', 'ifice', 'lock', 'ings', 'em', 'ύ', 'cal', 'cole', 'uda', 'Spect', 'quelle', 'elo', 'Є', 'icht', 'pir', 'rror', 'aki', 'erte', 'wehr', 'piano', 'ío', 'lock', 'elia', 'ener', 'энциклопеди', 'Wes', '�', 'erton', 'bolds', 'hair', 'стей', 'EGIN', 'equ', 'lists', 'asym', 'ropy', '្', 'gio', 'Gary', 'hai', 'sequ', 'spect', 'Kim', 'fur', 'Lock', 'ignon', 'нар', 'ichter', 'atica', '运', 'dass', 'CO', 'Anth', 'Auflage', 'byte', 'eno', 'Ener', 'ichten', 'enk', 'Baseball', 'finit', 'ier', 'feder', 'ih', 'ী', 'лосо', 'Hed', 'arsi', 'ję', 'branch', 'main', 'ques', 'cript', 'extern', 'igner', 'Te', 'aker', 'gren', 'HD', 'te', 'rem', 'лез', 'Foo', 'linux', 'fter', 'arts', 'én', 'Boh', 'crete', 'là', 'McC', 'ι', 'issue', 'endes', 'kil', 'kel', 'tap', 'Sdk', 'glass', 'intern', 'yrus', 'Ar', 'heb', 'бро', 'ként', 'lichkeit', 'ism', 'hav', 'out', 'bir', 'onda', '�', 'hav', 'bour', 'eft', 'показа', 'rok', 'out', 'kre', 'stran', 'outs', 'Advent', 'itto', 'lak', 'emes', 'udo', 'extend', 'Base', 'Frei', '加', 'arie', 'fung', 'OH', 'ķ', 'operation', 'ʁ', 'opera', 'èg', 'hosts', 'сини', 'agas', 'ely', 'energy', 'V', 'Position', 'structure', 'lah', 'equ', 'ather', 'ESP', 'directive', 'usammen', 'eus', 'íos', 'départ', 'bourne', 'SERT', 'aro', 'рав', 'afka', 'Energy', 'зько', '然', 'thor', 'schen', 'Rotten', 'eti', 'chain', 'sock', 'нове', 'ʎ', 'води', 'жу', 'pull', 'inaire', 'golf', '导', 'enso', 'amos', 'oe', 'Stu', 'Arena', 'iness', 'edia', 'phia', 'во', 'asm', 'cri', 'zysk', 'led', 'Arts', 'Ignore']\n",
      "in Layer29 , sorted_indices_dimension2190:  ['acc', 'Gen', 'ogene', 'holm', 'schließ', 'uent', 'ogle', 'uest', 'стр', 'ogo', 'Generated', 'lach', 'asz', 'Tat', 'atto', 'unc', 'boa', 'iei', 'FAULT', 'ennes', 'lock', 'iclopedia', 'ep', 'Times', 'att', 'point', 'Gen', 'mana', 'urn', 'arta', 'confusion', 'Niem', 'ordinary', 's', 'onk', 'Times', 'accepted', 'stock', 'baum', 'Schwar', 'Emil', 'issen', 'shed', 'anga', 'SP', 'ependant', 'ogne', 'incl', 'aton', 'beck', 'atten', 'leted', 'öm', 'iley', 'iness', '�', 'ご', 'ump', 'gen', '/:', 'lette', 'consultato', 'agini', 'oup', '\\u200e', 'mass', 'esty', 'usch', 'ordnung', 'Erd', '尾', 'Ski', 'times', 'Kenn', 'vier', 'atti', 'Atlas', 'LOCK', 'MDb', 'Sz', 'Time', '≃', 'atri', 'SP', 'go', 'lauf', 'Bez', 'chor', 'AXI', 'iese', 'Studio', 'port', 'cart', 'ted', 'хе', 'aver', 'oud', 'umps', '์', 'oppos', 'ordinary', 'osc', 'hausen', 'item', '月', 'yw', 'object', 'ced', 'ак', 'haft', 'rag', 'gef', 'IES', '�', 'жива', '#>', 'лович', 'issent', 'locked', 'WR', 'iente', 'xspace', 'itement', 'mass', 'loss', 'wood', 'евич', 'n', 'emberg', '�', 'wr', 'corre', 'ski', 'rown', 'schnitt', 'art', 'Schne', 'Art', 'sey', 'enu', 'віт', 'éné', 'Collins', 'onc', 'Bou', 'infer', 'soit', 'ordin', 'share', 'atum', 'кая', 'asc', 'Bog', 'reg', 'complet', 'ongo', 'Acc', 'lac', 'loss', 'obre', 'Sie', 'uncertainty', 'Gé', 'ș', 'AX', 'opt', 'igen', 'Sed', '},{', 'vc', 'zess', 'punt', 'GM', 'assembly', 'ium', 'selected', 'tat', 'ore', 'constraint', 'cla', 'stock', 'at', 'consent', 'printStackTrace', 'point', 'iante', 'liest', '중', 'ajo', 'get', 'XI', 'Á', 'indexing', 'psilon', 'licht', 'ach', 'roe', 'гра', 'nat', 'fr']\n",
      "in Layer29 , sorted_indices_dimension3409:  ['Newton', 'physics', 'Ein', 'Physics', 'quantum', 'nan', 'physics', 'Nan', 'astronom', 'Astronom', 'particle', 'nan', 'astr', 'stronom', 'teles', 'particles', 'meteor', 'astr', 'Meteor', 'gravity', 'gravity', 'Watson', 'NaN', 'numpy', '宇', 'eclipse', 'gravit', 'atoms', 'icle', 'numpy', 'NASA', 'ein', 'eteor', 'atomic', 'Philip', 'geometry', 'Eclipse', 'astero', 'Quant', 'mathematics', 'Quant', 'atom', 'eclipse', 'Unity', 'Napoleon', 'NaN', 'Aur', 'appen', 'Pascal', 'tick', 'ilon', 'pson', 'python', 'Nova', 'cos', 'Phili', 'phy', 'acher', 'Spider', 'radiation', 'gart', 'sson', 'kmal', 'éon', 'adesh', 'onaut', 'nde', 'ermann', 'ář', 'ühle', 'piano', 'Engine', 'auch', 'OIN', 'np', 'galaxies', 'Philosoph', 'algebra', 'icles', 'ôme', 'atomic', 'eken', 'Entity', 'Attributes', 'ფ', 'Jup', 'pian', 'nap', 'scop', 'Neu', 'tek', 'inson', 'годов', 'excel', 'ara', 'mathemat', 'quarters', 'ος', 'ül', 'Mercur', 'orp', 'avigation', 'IL', 'entially', 'lun', 'quant', 'Springer', 'Cambridge', 'мате', 'nius', 'Mathemat', 'ucht', 'ék', 'cinemat', 'omi', 'eor', 'PHP', 'ongodb', 'ilities', 'dátum', 'philosophy', 'ayer', \"']))\", 'lattice', 'Shakespe', 'oust', 'gle', 'ugen', 'Нью', 'Python', 'ɕ', 'formatt', 'Napole', 'lichkeit', 'pon', 'totalité', 'kwietnia', 'Engineering', 'naio', 'mole', 'Cos', 'vity', 'irus', 'beam', 'ilian', 'ugby', 'engineering', 'ól', 'ниц', 'Phoenix', 'textt', 'acs', 'Chem', 'ether', 'ilis', 'unicí', 'tät', 'Abraham', '龙', 'clipse', 'arias', 'äs', 'Isaac', '台', 'ourd', 'np', 'sé', 'anged', 'nucle', 'Spring', 'рона', 'ango', 'lès', 'agini', 'pandas', 'lius', 'mq', 'pandas', 'ляр', 'othèque', 'rez', 'uclide', 'Aires', 'quia', 'NGC', 'andom', 'erm', 'que', 'џ', 'cules', 'xiv', 'ayout', '昌', 'nuclear', 'nings', 'aret', 'achsen', 'Ara', 'fon', '�']\n",
      "in Layer29 , sorted_indices_dimension9555:  ['illon', 'ent', 'enty', 'lu', 'eur', '⁰', 'ห', '条', 'bent', '形', 'iesen', 'ент', 'PDF', 'onnes', 'ENT', 'lu', 'teck', 'ensch', 'endpoint', 'je', 'leads', 'ixel', 'fancy', 'cor', 'entre', 'oce', 'Ent', '沢', 'ante', 'cean', 'endpoint', 'hill', 'olu', 'ahlen', 'orf', 'pan', 'ulu', 'vu', 'cem', 'iese', '神', 'xt', 'эн', 'ype', 'conv', 'ent', 'Descriptor', 'Juan', 'pper', 'brains', 'estra', 'end', 'шения', 'eca', 'писко', 'aylor', 'yan', 'zip', 'compatible', 'etti', 'führt', 'ye', 'espèce', 'века', 'ек', 'śc', 'Square', 'če', 'speed', 'enter', 'onk', 'пера', 'hill', 'yp', 'Estado', 'cousin', 'Ress', 'писок', 'evolution', 'fog', 'akespe', '><', 'ette', 'ytics', 'eye', 'exponent', 'om', 'az', 'Grid', 'esse', 'Cés', 'lex', 'lead', 'quare', '雪', 'conda', 'LayoutParams', 'pn', 'Ana', 'enda', 'Az', 'entropy', 'Speed', 'mi', 'Ern', 'Bent', 'por', 'TX', 'Speed', '[@', 'Santi', 'тал', 'González', 'cole', 'Enabled', 'omer', 'onn', 'Illustration', 'Terminal', 'End', 'camb', 'Grid', 'KEY', 'enter', 'Hir', 'wie', '标', 'Ce', 'рож', 'bill', 'zet', 'État', 'getInstance', 'atan', 'beskre', 'Serial', 'azz', 'hi', 'handled', 'SP', 'zien', 'ensoort', 'Visibility', 'Serge', 'Wald', 'Lexikon', 'stringify', '百', 'na', 'jango', 'же', 'jö', 'integer', 'Encyclop', '效', 'erc', 'Tak', 'hu', 'зяй', 'enza', 'Seiten', 'tac', 'zan', 'Cec', 'Visible', 'și', 'endet', 'Antonio', 'ke', 'pit', 'rix', 'sr', 'veh', 'nym', 'p', 'kern', 'hung', 'Century', 'ʹ', 'naio', 'hire', 'савезној', 'rop', 'perm', 'joins', 'enen', 'HttpRequest', 'enberg', 'Switch', '↳', 'onne', 'Otto', 'стру', 'ilen', 'isme', 'dll', 'DR', 'entry', 'bid', 'END']\n",
      "in Layer29 , sorted_indices_dimension3605:  ['repeat', 'Phys', 'лях', 'osh', '트', 'olf', 'os', 'hens', 'bos', 'OS', 'physics', 'gebra', 'Physics', 'phys', 'бай', 'physics', 'aju', 'onk', 'Ring', 'h', 'base', 'Phys', 'ley', 'oli', 'ka', 'enders', 'gr', 'olo', '�', 'nehm', 'ров', 'prec', 'Che', 'inst', 'gle', 'OS', 'gra', 'MyClass', 'polar', 'conten', '�', 'Bh', 'OUT', 'zten', 'ouses', 'permanent', 'tery', 'ks', 'Mus', 'лю', 'font', '�', 'цев', 'lio', 'Depart', 'fís', 'af', 'phys', 'POS', 'ero', 'akt', 'ouve', 'Kaiser', 'gren', 'iga', 'gap', 'цу', 'la', 'ring', 'erd', 'passing', 'coming', 'Hay', 'yna', 'дов', 'ós', 'akh', 'pton', 'Emil', '�', 'earch', 'PO', 'oi', 'iemann', 'cha', 'fu', 'Spart', 'proof', 'ons', 'LC', 'base', 'општи', '基', 'repeat', 'avam', 'depart', '府', 'els', 'jsp', 'gart', 'кри', 'тро', 'Bos', 'produ', 'uto', 'ala', 'cies', 'endes', 'inde', 'enst', 'quot', 'dig', 'ava', 'quot', 'piano', 'ijst', 'ears', 'Niem', 'infinite', 'Kais', 'fonts', 'Jess', 'нос', 'uta', 'MD', 'uli', 'borough', 'ный', 'neur', 'Archives', 'лё', 'arch', 'ся', 'oracle', 'append', 'Cow', 'ос', 'éter', 'osph', 'ory', 'configur', 'hadoop', 'oco', 'gesellschaft', 'sorted', 'Rosen', 'áš', 'icles', 'physical', 'Kol', 'ial', 'Os', 'endre', 'uniform', 'adas', '重', 'avas', 'ky', 'repeated', 'dia', 'blind', 'Ль', 'Bow', 'igger', 'bald', 'AF', 'coach', 'Che', 'ev', 'unlikely', 'stellen', 'cos', 'руп', 'bor', 'uga', 'GL', 'original', 'жовт', 'lac', 'plants', 'original', 'oc', 'instit', 'ORY', 'wsp', 'дова', 'erman', 'ED', 'ế', 'Instit', 'che', 'Giorg', 'lace', 'apost', 'ED', 'lifted', 'testim', 'Classes', 'NET', 'isi']\n",
      "in Layer29 , sorted_indices_dimension5016:  ['string', 'string', '◄', 'oms', 'async', 'penas', 'String', 'DM', 'urt', 'rol', 'vé', 'uld', 'async', 'сте', 'ilor', 'Squadron', 'Kur', 'substring', 'at', 'stan', 'nil', 'esk', 'String', 'loss', 'び', 'itas', 'wire', 'ató', 'ènes', 'adj', 'ctr', 'лів', 'als', 'ulen', 'kur', 'AF', 'ᾶ', 'li', 'circuit', 'cres', 'DM', 'delegate', 'Fur', 'dll', 'loss', 'Ind', 'equal', 'correct', 'GP', 'aden', 'einges', 'strings', 'excel', 'MDb', 'Dj', 'φ', 'ň', '̩', 'Curt', 'ions', 'sudo', 'Ing', 'qu', 'nehm', 'aux', 'stat', 'ufe', 'strings', 'rium', 'ITE', 'usammen', 'Dic', 'facebook', 'ivatal', '弘', 'zil', 'lande', 'oug', 'च', 'ropy', 'bor', 'asa', 'zig', 'ustr', 'dm', 'Хро', 'визи', 'archiv', 'dj', 'wetenschapp', 'nel', 'Vor', 'lá', 'icina', 'ieur', 'azon', 'niu', 'нього', 'љ', 'Updated', 'obar', 'embre', 'Ludwig', '̪', 'ingo', 'coll', 'esto', 'lé', 'usk', 'wi', 'дро', 'parti', 'vict', 'Cuba', 'Solo', '角', 'SR', 'чин', 'EQ', 'ades', 'ifice', 'Sommer', 'vl', 'brary', 'agn', 'gemäß', 'rop', 'ździer', 'заме', 'GP', 'Ingl', 'руг', 'EXISTS', 'dens', 'rade', 'ствии', 'Syd', 'proprio', 'zam', 'ing', 'Fut', 'neh', 'dbo', 'Stat', 'sero', 'orio', '￼', 'inde', 'ere', 'shr', 'perd', 'asc', 'stre', 'ics', 'ade', 'Hozzáférés', 'ства', 'zenia', 'ル', 'Strings', 'DN', 'enz', 'atten', 'RC', 'LP', 'kis', 'chamber', 'omo', 'icio', 'Internacional', 'ulate', 'AE', 'gz', 'riction', 'lub', 'ril', 'xls', 'jö', 'JQuery', 'сті', 'Hern', 'indo', 'ни', 'lips', 'дж', '음', 'ihe', 'Ю', '�', 'curs', 'Coll', 'folge', 'illas', 'ruolo', 'Sverige', 'zs', 'ieg', 'Pop', 'icos', 'Entertain']\n",
      "in Layer29 , sorted_indices_dimension6040:  ['aval', 'iante', 'emat', 'land', 'rut', 'imenti', 'órico', 'Хронологија', 'emas', 'loading', 'sty', 'рос', 'amet', 'зни', 'ivent', 'arget', 'jewe', 'vul', 'avigation', 'elo', 'iu', 'рак', 'хі', 'strik', 'Roberts', 'figure', 'urz', 'CAT', 'Zone', 'doc', 'itore', 'cot', 'jou', 'ст', 'sharp', 'recensement', 'лта', 'figure', '局', 'ode', 'oreign', 'atro', 'unto', 'unft', 'хів', 'ivi', 'moz', 'Auth', 'parenthes', 'LOAD', 'Zone', 'thesis', 'rust', 'ler', 'Paz', 'esso', 'VALUES', 'bread', 'load', 'archar', 'piano', 'estellt', 'jango', 'lands', 'genomsnitt', 'кли', 'estro', 'cru', '%=', 'DEX', 'rik', 'óp', 'eten', 'TV', 'oti', 'alb', 'års', 'ource', '},{', 'untu', 'rico', 'etwa', 'subfigure', 'Alt', 'moon', 'ibile', 'arte', 'ération', 'ox', '载', 'ut', 'vera', 'Ox', 'ns', 'da', 'ovie', 'če', 'riction', 'üsseld', 'contro', 'Alt', 'leqslant', 'Count', 'ee', 'щу', 'ogo', 'ambda', 'izo', 'ägt', 'boa', 'load', 'шь', 'aft', 'Cl', 'mutable', 'wo', 'ormal', 'Scope', 'ered', 'Cru', 'vex', 'ger', 'Load', 'thumb', 'yclerView', 'catt', 'EE', 'spre', 'avam', 'orithm', 'ź', '友', 'Cruz', 'agg', 'Subview', 'owie', 'entry', 'substant', 'cors', 'ump', 'CAA', 'ben', 'scher', 'ahoo', 'loaded', 'ǎ', 'oden', 'ufe', 'pla', 'EQ', 'ongo', 'alt', 'arp', 'iron', 'Perú', 'Ign', 'руг', 'pro', 'Ziel', 'cription', 'iver', 'NS', 'ixen', 'CLA', 'Load', 'IX', 'river', 'arab', 'ги', 'ред', 'odes', 'angol', 'incipal', 'chem', 'rollo', 'DOM', '�', 'lyph', 'ʰ', 'rror', 'pert', 'LT', 'ピ', 'limitation', 'uploaded', 'zef', 'heure', 'ależ', 'ut', 'cast', 'Ши', 'riter', 'onces', 'helm', 'Gene', '³', 'еру', 'surr', 'istiques', 'Alabama']\n",
      "in Layer29 , sorted_indices_dimension6781:  ['pl', 'oph', 'inaugur', 'Serv', 'ute', 'lege', 'illa', 'ime', 'Histor', 'кате', '断', 'utter', 'ut', 'oma', 'inta', 'Senate', 'serv', 'tel', 'lices', 'sog', 'Mit', 'uno', 'odon', 'GS', 'hat', 'pu', 'MD', 'cza', 'hat', 'nahme', 'awa', 'ase', 'ilt', 'ils', 'ilia', 'pl', 'unde', 'Hat', 'Ph', '嘉', 'eren', 'legen', 'bund', 'Comun', 'lif', 'aff', 'fon', 'Fir', 'pó', 'lywood', 'mo', 'oru', 'च', 'enf', 'raph', 'plans', 'onom', 'Abb', 'Pl', 'sess', 'omp', 'nod', 'ião', 'рови', 'r', 'chat', 'voice', 'UT', 'ran', 'iten', 'iw', 'сло', 'atura', 'пра', 'gest', 'elf', 'iam', 'ali', 'inding', 'Ils', 'ografia', 'Fon', 'names', 'decode', 'urg', 'ol', 'aucoup', 'prest', 'Intent', 'Χ', 'ases', 'ought', 'Beruf', 'rav', 'illi', '塔', 'recovery', 'ague', '�', '定', 'ple', 'agt', 'äler', 'intr', 'figure', 'rig', 'mit', 'te', 'essional', 'tp', 'md', 'Impl', 'wald', 'UTE', 'ured', 'phases', 'Unidos', 'gir', 'DECLARE', 'ignes', 'ello', 'Wald', 'Minn', 'ография', 'dec', 'Jazz', 'lop', 'serving', 'Ung', 'ții', 'ustr', 'ho', 'lett', 'uclide', 'Esp', 'Mitchell', 'top', 'Sol', 'še', 'atorio', 'ily', 'Gr', 'cens', 'Albert', 'quit', 'land', 'default', 'om', 'Juni', 'omm', 'Pl', 'Personal', '�', 'Fig', 'othy', 'otrop', 'conform', 'ptop', 'lift', 'genommen', '雄', 'edo', 'lesh', 'oline', 'sol', 'Herbert', 'eno', 'life', 'Jenn', 'endl', 'ids', 'flush', 'стран', 'pad', 'Flor', 'berg', 'Нов', 'itte', 'l', 'ante', 'patr', 'lyn', 'iens', 'opp', 'Gustav', 'teeth', 'Ela', 'Te', 'lette', 'дія', 'Bass', 'Short', 'categ', 'personal', 'short', 'тел', 'port', 'ourt', 'òria', 'thumb']\n",
      "Key: model.layers.30.mlp.down_proj.weight\n",
      "in Layer30 , sorted_indices_dimension7364:  ['Liv', 'operator', 'operator', 'ety', 'tta', 'ksam', 'Emb', 'avel', 'assault', 'hens', 'Nie', 'pup', 'Ivan', 'compl', 'ip', 'Av', 'operators', 'Av', 'Operator', 'า', 'Cos', 'usc', 'Nav', 'utz', 'rack', 'Nur', 'Ces', 'dor', 'rut', 'yc', 'pian', 'attung', 'bia', 'ban', 'sop', 'cus', 'Music', 'cos', 'CCE', 'Rails', 'yan', 'Errors', 'Evans', 'area', 'cel', 'ē', 'NN', 'swe', 'avan', 'threshold', 'liv', 'ISO', 'éroï', 'Cés', 'geb', 'ɯ', 'AVA', 'ppa', 'cc', 'otr', 'цер', 'row', 'track', 'ITable', 'esso', 'ienn', 'spos', 'neutral', 'batter', 'direct', 'Convert', 'exchange', 'shortcut', 'nisse', '#>', 'quer', 'wechsel', 'schau', 'ondo', 'iled', 'draft', 'Comp', 'abled', 'ств', 'elor', 'unicí', 'av', 'craft', 'goods', 'able', 'cref', 'Rail', 'ép', 'idd', 'ɛ', 'Richmond', 'aze', 'av', 'guitar', 'Palmarès', 'pert', 'raid', 'atic', 'cap', 'sson', 'ba', 'Mes', 'mannschaft', 'ruf', 'pip', 'zeuge', 'ick', 'Bres', 'aval', 'Gui', 'bomb', 'Opera', 'otimes', 'Oliver', 'ogo', 'ách', 'Apost', 'icz', 'oust', 'emb', 'ette', 'zet', 'ego', 'usz', 'лена', 'Row', 'Vien', 'area', 'iful', 'comp', 'kö', 'schluss', 'část', 'Track', 'Hen', 'isu', 'rows', 'erman', 'пози', 'Span', 'actic', 'ева', 'ero', 'opera', 'Eli', 'Ē', 'nav', 'iev', 'avant', 'Angel', 'дна', 'Volume', 'engineer', 'éc', 'iso', '\"_', 'cade', 'ifiable', 'line', 'carre', 'theme', 'Affairs', 'izable', 'ave', 'comp', 'Zum', 'axis', 'Mul', 'жу', 'nur', 'nn', 'elenium', 'adic', 'рист', 'Ban', 'Ne', 'whites', 'ena', 'Stadium', 'ung', 'bew', 'skład', 'utor', 'nis', 'Rich', 'lef', 'thy', 'ematic', 'svě', 'til', 'ec', 'AA', 'pu', 'answer', 'line']\n",
      "in Layer30 , sorted_indices_dimension3590:  ['pixels', 'depend', 'irrelevant', 'involve', 'cache', 'laptop', 'cached', 'tie', 'sought', 'erg', 'existed', 'rely', 'require', 'egeben', 'requiring', 'itchen', 'Unicode', 'lever', 'require', 'involves', 'obsc', 'ora', '�', 'caching', 'misunder', 'pose', 'LaTeX', 'relevant', 'odore', 'academic', 'ASCII', 'vain', 'ково', 'соответ', 'Cz', 'ino', 'oss', 'ignored', 'propriet', 'pok', '発', 'redundant', 'ling', 'lying', 'exist', 'multimedia', 'Publications', 'restaur', 'neglect', 'fiction', 'eng', 'dict', 'invol', 'Films', 'involving', 'Prize', 'widget', 'gibt', 'wire', 'ule', 'depends', 'ules', 'ieben', 'Academia', 'aware', 'interfaces', 'ambigu', 'pedig', 'disput', 'unlikely', 'whis', 'Arist', 'javascript', 'ч', 'ту', 'toolbar', 'Athlet', 'toe', 'useless', 'Comics', 'atto', 'puzz', 'fonts', 'imply', 'Widget', 'pixel', 'requirement', 'č', 'reson', 'browsers', 'Hmm', 'computers', 'forgotten', 'fasc', 'Cache', 'Anyway', 'cookie', 'uit', 'amp', 'intuit', 'vend', 'andbox', 'AllMovie', 'pian', 'guns', 'Hello', '相', 'museum', 'encrypt', 'шин', 'semantic', 'folders', 'yours', 'при', 'dod', '要', 'quent', '========', 'tuple', 'ipedia', 'implicit', 'Ї', 'Shakespeare', 'tennis', 'Academ', 'optical', '\"></', 'irk', 'hoped', 'requires', 'readable', 'Encyclopedia', 'intellectual', 'perce', 'Monument', 'sv', 'obe', 'Д', 'unicode', 'hosp', 'Museo', 'OK', 'Unix', 'databases', 'Bibliothèque', 'fet', 'opera', 'consp', 'Cinema', 'piano', 'breakfast', 'ком', 'programmer', 'distingu', 'whitespace', 'required', 'jur', 'tied', 'NCAA', 'poss', 'SQLite', 'implies', '画', 'imag', 'レ', 'Napole', 'evol', 'necess', 'TP', '官', 'laughed', 'bat', 'Bootstrap', 'Oktober', 'hockey', '�', 'ok', 'Ubuntu', 'Bundes', 'Disney', 'stupid', 'oplus', 'во', 'apps', 'involved', 'anche', 'ampf', 'arose', 'anus', 'gr', 'Г', 'exists', 'oor', 'ignore', 'occ', 'вос', 'Assume', 'json', 'hoff', 'igkeit']\n",
      "in Layer30 , sorted_indices_dimension10891:  ['ouwen', 'eared', 'kim', 'oren', 'ski', 'DEX', 'tring', 'immer', 'estra', '�', 'ouw', 'Schwe', 'marker', 'нар', 'vis', 'gresql', 'iod', 'ymen', '/~', 'illing', 'сви', 'ople', 'esta', 'rew', 'premiers', 'Linux', 'Sv', 'ske', 'kw', 'ace', 'combin', 'amer', 'Ē', 'assass', 'amen', 'ilor', 'xy', 'ave', 'SSN', 'õ', 'дро', 'ede', 'ymi', 'нина', 'ÿ', 'Western', 'nome', 'ums', 'wicklung', 'dél', '�', 'aser', 'Visible', 'amentos', 'inge', 'mult', 'quier', 'yntax', 'itants', 'Autor', 'religios', 'hner', 'Picture', 'fw', 'ḫ', 'Nau', 'ря', 'Bundle', 'ensus', 'heb', 'Ə', 'race', 'ñas', 'éma', 'twe', 'wik', 'omena', 'atten', 'ske', 'log', 'ccess', '�', 'Accessor', '소', 'records', 'interpol', 'aken', 'tó', 'pios', 'SBN', 'usa', 'yter', 'famil', 'Herzog', 'ве', 'pill', 'Version', 'Clement', 'Mountains', 'qué', 'attend', 'Glo', 'ardi', 'Route', 'Gilbert', 'yle', 'Dav', 'ibus', 'igt', 'eor', 'hrer', 'ig', 'attend', 'linux', 'Ṣ', 'Version', 'Rows', 'indexes', 'Wikimedia', 'skip', 'iki', 'ului', 'eil', 'cock', 'ué', 'atif', 'ilder', 'ḍ', 'igten', 'createElement', 'kv', 'uno', 'dro', 'Ski', 'culo', 'ipo', 'ki', 'Twe', 'speed', 'pog', 'structor', 'América', 'œuv', 'Mult', 'IM', 'ambient', 'EB', 'Wik', 'лм', 'ski', 'ド', 'iew', 'Stre', '‾', 'ango', 'visible', 'composite', 'Ḫ', 'frak', 'INF', 'logical', 'kör', 'pply', 'yrus', 'urale', 'ikus', 'LENG', 'aña', 'estro', 'olu', 'istra', 'Ξ', '>;', 'iech', 'numerical', 'kie', 'race', 'density', 'hé', 'ierno', 'стро', 'Forum', 'Amer', '¤', 'macht', 'liberty', 'rows', 'ois', 'ões', 'compon', 'obs', 'ḳ', 'ivo', 'wick', 'ardo', 'силання', 'nouvelles', 'Arg', 'Linux', 'ศ']\n",
      "in Layer30 , sorted_indices_dimension8876:  ['tar', 'entin', '�', 'прово', 'Gut', 'Données', 'legate', 'igung', 'ole', 'inst', 'rikt', 'lä', 'incie', 'aupt', 'erb', 'ponent', 'igent', 'Axis', 'orbit', 'pie', 'ogne', 'rear', 'zej', 'keit', 'kou', 'arten', 'Jup', 'сите', 'crown', 'Jos', 'liqu', 'ǒ', 'skim', 'äu', 'nginx', 'mos', 'un', 'ogram', 'zung', 'sole', 'tocol', 'Crown', 'achim', 'ju', 'Ju', 'reib', 'protocol', 'za', 'lan', 'lying', 'жду', 'Tags', 'жно', 'rak', 'Gan', 'erem', 'asy', 'gut', 'temper', 'liqu', 'component', 'Laurent', 'ethod', 'quit', 'ance', 'nez', 'uby', 'target', 'major', 'legen', 'lain', 'ador', 'rent', 'andas', 'س', 'reu', 'nej', 'edish', 'pos', 'lap', 'ued', 'кой', 'intellect', 'pla', 'atform', 'fest', 'zés', 'ningen', 'quis', '�', 'rece', 'ׁ', '介', 'sku', 'aris', 'ission', 'Pub', 'lacement', '手', 'osas', 'Juan', 'odn', 'Champ', 'rows', 'arded', 'ʊ', 'ù', 'otto', 'Target', 'around', 'coun', 'eden', 'emein', 'tes', 'seau', 'ugins', 'gem', '切', 'rare', 'Pub', 'File', 'mayoría', 'filters', 'lichen', 'Stuart', 'ly', '夫', '雲', 'pose', 'Target', 'Rica', 'CHAP', 'ữ', 'bef', 'intens', 'EXISTS', 'udent', '置', 'rent', 'geben', '朱', 'Tar', 'ovan', 'pub', 'ța', 'host', '�', 'locked', 'rela', 'pher', 'qua', '�', 'ával', 'country', 'ɕ', 'interaction', 'provision', 'corner', 'Archive', 'pub', 'EC', '�', 'pent', 'nius', 'array', 'igg', 'zó', 'werp', 'TI', 'agg', 'Host', 'тка', 'heb', 'Herzog', 'проводи', 'zos', 'widet', 'aju', 'LY', 'ctic', 'legt', 'protocol', 'Pent', 'mix', 'asp', 'host', 'Bool', 'cour', 'skiego', 'aben', 'tags', 'ared', 'Mut', 'tinha', '백', 'ogn', '方', 'ự', 'k', 'baz']\n",
      "in Layer30 , sorted_indices_dimension1581:  ['estaven', 'ite', 'ected', 'сини', 'oure', 'EGIN', 'iante', 'Bedeut', 'Sciences', 'lava', 'eling', 'Према', 'ECK', 'era', 'Eug', 'ITE', 'lete', 'Ins', 'く', 'Builder', 'nę', 'ogle', 'entertain', 'ének', 'nek', 'aland', 'ández', 'omorphic', 'aft', 'avam', 'ga', 'opro', 'cite', '}}%', 'totalité', 'eared', 'gart', '방', 'holds', 'ection', 'diction', 'arded', 'kn', '泰', 'ɨ', 'Front', 'ucion', 'Blue', 'eria', 'ART', 'anzen', 'nan', 'amy', 'EG', 'terne', 'nan', 'ex', 'illon', 'ente', 'nit', 'Child', 'ander', '�', 'antine', 'фек', 'HI', 'nica', 'ender', 'heimer', 'tring', 'Ont', 'esterd', 'input', 'older', 'NaN', 'gepubliceerd', 'nez', 'CP', 'operator', 'ниц', 'cit', 'olu', 'corner', 'lar', 'nia', '兴', 'olas', 'harm', 'yer', 'fty', 'ings', 'Ő', 'City', 'দ', '故', '~~~~~~~~', 'ientes', 'erea', 'Harry', 'iegel', 'orte', 'limited', 'ис', 'SError', 'Cre', 'nog', 'нок', 'ibt', 'hex', 'cri', 'nat', 'orted', 'gue', 'hire', 'опера', 'ieck', 'tf', 'iger', 'eca', 'Rain', 'ето', 'osex', '➖', 'eft', 'rez', 'ders', 'нва', 'mission', 'onia', '寺', 'arte', 'LR', 'tras', 'events', 'inks', 'operators', 'едера', 'Testament', 'meister', 'Knight', 'eries', 'cription', 'tritt', 'ATE', 'oten', 'Einzel', 'mission', 'holder', 'Opera', 'esse', 'ect', 'гли', 'abase', 'Cre', 'kins', 'nost', 'шка', 'ali', 'гар', 'ington', 'sector', '════', 'тре', 'Entertain', 'кор', '↵', 'gb', '}))', 'Cas', 'esterday', 'RewriteCond', 'lower', 'amerikanischer', 'kit', 'cas', 'actory', 'կ', 'antes', 'prec', 'Publications', 'inct', 'слу', '師', 'Af', 'enten', 'omorph', 'heut', 'ни', 'loyd', 'na', 'Enter', 'द', 'buch', 'рус', 'developer', 'ciente', 'sect', 'enter', 'blank', 'ächst']\n",
      "in Layer30 , sorted_indices_dimension2573:  ['beskre', 'viv', 'hui', 'anga', 'Route', 'haft', 'ش', 'Abstract', 'Orchestra', 'Ē', 'Bast', '�', 'Species', 'huvudstaden', 'aur', 'IMA', 'Highway', 'ise', 'banda', 'intro', 'Anleitung', 'ink', 'LM', 'meister', 'ota', 'Abstract', 'quelle', 'intro', 'mit', 'nahm', 'plata', 'animate', '�', 'forward', '洞', 'SA', 'Doc', 'Rosa', '汉', 'ffic', 'usa', 'Offiz', 'isseur', 'vek', 'imal', 'ogram', 'Künstler', 'campo', 'kup', 'wyn', 'ortheast', 'hina', 'Township', 'SON', 'ama', 'adora', 'igua', 'ipage', 'rw', 'ratio', 'Rund', 'хи', 'ォ', 'field', 'MY', 'bou', 'specie', 'contr', 'Hans', '�', 'rup', 'lex', 'ppe', 'Mine', 'cid', '帝', 'pper', 'fter', 'ót', 'dy', 'hydro', 'ym', 'unnel', 'agem', '&=\\\\', 'Reichs', 'TT', 'formula', 'lease', 'ymnas', 'Route', 'dm', 'mut', 'ural', 'Field', 'Fra', 'idence', 'obil', 'Mand', 'hire', 'init', 'lichkeit', 'ével', 'Hockey', 'Html', 'my', 'kiss', 'cot', 'Й', 'hner', 'Bass', 'estro', 'oldal', 'neur', 'fra', 'upper', '進', 'ection', 'GM', 'TC', 'oport', 'RC', 'triangle', 'mine', 'inus', 'amplitude', 'mys', '樹', '漢', 'checked', 'groupby', 'genommen', 'uclide', 'USA', 'zag', 'Wit', 'Articles', 'ymnasium', 'idae', 'westen', 'verte', 'FAULT', 'Formula', 'zig', 'RY', 'agram', 'ہ', 'вер', 'ebol', 'mina', 'Arten', 'Andrea', 'шее', 'ор', 'oop', 'ﬁ', 'species', 'arc', 'ha', 'fra', 'sole', 'oto', 'ling', 'üssen', 'fico', 'logged', 'login', 'hm', 'litt', 'fields', 'jango', 'Rat', 'Html', 'ols', 'shal', 'Lexikon', 'Ő', 'eng', 'field', 'ectors', 'ister', 'hein', 'rat', 'Cs', 'han', 'fiel', '息', 'esa', 'cabin', 'Wang', 'Ka', 'urt', 'west', 'Ě', 'movie', 'Beruf', 'relationships', 'Complex', 'руд', 'DEX']\n",
      "in Layer30 , sorted_indices_dimension429:  ['Ye', 'yo', 'yo', 'o', 'ures', 'fa', 'ye', 'enburg', 'gz', 'oa', 'orial', 'ран', 'iddle', 'ra', 'WR', 'enas', 'hou', 'O', 'o', 'dom', 'び', 'Ot', 'fa', 'лу', 'BO', 'agy', 'Dal', 'ole', 'vos', 'YY', 'ocas', 'vi', 'Num', 'bo', 'Cass', 'illery', 'vo', 'kem', 'bb', '�', 'Chr', 'oco', 'fos', 'oca', 'hr', 'ag', 'zeg', 'Session', 'ury', 'BY', 'Hin', 'by', 'fe', 'viol', 'alberga', 'URE', 'occasion', 'Wies', 'utt', 'obox', 'Tat', 'га', 'EY', '屋', 'Fur', 'ooth', 'bles', '量', 'Y', 'Bow', 'amento', '茶', 'bullet', 'arg', 'rig', 'ko', 'hnen', 'ennis', 'Egy', 'ikz', 'f', '̍', 'ocs', 'ow', 'iano', 'gex', 'ocr', 'ient', 'macht', 'Bowl', 'ol', 'va', 'vy', 'ov', 'erset', 'Yang', 'Io', 'Ol', 'خ', 'err', 'hos', 'Coppa', 'cola', 'Cet', '진', 'ó', 'idia', 'Eliz', 'VO', 'oci', 'idd', 'gart', 'ieg', 'ow', 'rum', 'f', 'yn', 'tan', 'Session', 'ey', 'cod', 'rs', 'ivalent', 'battery', 'ovis', 'ülés', 'blo', 'litt', 'IO', 'bol', 'ek', 'contre', 'tard', 'alignment', 'oty', 'arrow', 'што', 'ov', 'üng', 'fu', 'O', 'Britannica', 'anci', 'rh', 'Ya', 'yth', 'ocracy', 'al', 'rze', 'alu', 'tenia', 'rey', 'ards', 'viv', 'esc', 'öffentlich', 'num', 'eria', 'OW', 'bat', 'últ', 'ರ', 'ob', 'owel', 'aqu', 'attung', 'Rh', 'Memorial', 'attice', 'lap', 'Buen', 'nehm', 'Ital', 'Laz', 'Vi', 'boundaries', 'ovi', 'inger', 'Ó', 'fal', 'ist', '__', 'Schrift', 'pg', 'Gir', '┤', 'igo', 'yard', 'arz', 'oth', 'rale', 'шин', 'ⁿ', 'érica', 'boa', 'rica', 'ured', 'UN', 'VI', 'urm']\n",
      "in Layer30 , sorted_indices_dimension6603:  ['pro', 'vl', 'tes', 'tem', 'esh', 'ates', 'át', 'uw', 'imo', 'там', 'haupt', 'icle', 'Adam', 'lish', 'ards', 'engers', 'etto', 'otti', 'fram', 'Fre', 'olo', 'oup', 'Short', 'wahl', 'ville', 'Tem', 'suite', 'quia', 'fre', 'stress', 'Gay', 'Temple', 'Lane', 'ennen', 'gh', 'рит', 'suite', 'Patrick', 'ots', 'it', 'Lin', 'ứ', 'Alfred', '方', 'circul', 'alone', 'ishes', 'introduced', 'Fre', 'Cub', 'SU', 'Clay', 'zyż', 'Southern', 'tm', 'divis', 'rent', 'ō', 'ť', 'vity', 'territorial', 'Pla', 'essen', 'Steven', 'Ir', 'Deutschen', 'ception', 'piano', 'encode', 'Cost', 'fresh', 'Ú', 'èce', 'anne', 'temple', 'icy', '⊙', 'Lip', 'яз', 'ounce', 'ets', 'ical', 'ú', 'pace', 'Arr', 'phas', 'Ps', 'нец', 'tem', 'CC', 'burn', 'Docker', 'álva', 'emphas', 'Say', 'ность', 'Su', 'ouch', 'ants', 'fest', 'Pac', 'Bac', 'ans', 'ulaire', 'эн', 'ours', 'Kriegs', 'seized', 'ess', 'fre', 'Pointer', 'eli', 'temps', 'ợ', 'trial', 'angol', 'un', 'iano', 'frame', 'fran', 'han', 'samples', '-->', 'appeal', 'rg', 'Mov', 'alle', 'ital', 'Ryan', 'Tem', 'Press', 'opol', 'Co', 'ulle', 'дели', 'inherited', 'icus', 'Afghan', 'ớ', 'Volume', 'бен', 'accomp', 'onal', 'ographical', 'ats', 'atorio', 'Short', 'Cla', 'African', 'Rein', 'contro', '�', 'css', 'irks', 'feature', 'pole', 'attacked', 'йт', 'inline', 'HTTP', 'enso', 'arr', 'otto', 'git', 'conte', 'Volume', 'regular', 'refresh', 'uit', 'youth', 'Wahl', 'itle', 'Dup', 'du', 'btn', 'regular', 'du', 'eto', 'su', 'ха', 'Vit', 'Peter', 'mixing', 'imper', 'onne', 'Mix', 'behind', 'atos', 'docker', 'inas', 'odot', 'pian', 'Amt', 'decis', 'connected', 'invoke', 'Gard', 'sampling', 'onial', 'nitt']\n",
      "in Layer30 , sorted_indices_dimension10450:  ['activ', 'ady', 'rab', 'OD', 'ck', 'ion', 'usta', 'anim', '夫', 'activ', 'anim', 'animate', 'Gü', 'Activ', 'aggio', 'OP', 'ain', 'supports', 'ко', 'tera', 'pe', 'arta', 'Activ', 'oud', 'rack', 'iak', 'pc', 'yp', 'plate', 'Gesture', 'gren', 'activation', 'dom', 'GT', 'orb', 'län', 'ülés', 'Cab', 'exit', '�', 'sd', 'Float', 'Anim', 'zett', 'tte', 'ioned', 'ignon', 'iony', 'PC', 'asy', 'anes', 'odb', 'ally', 'árt', 'usr', 'rock', 'inition', 'Animation', 'вор', 'ysz', 'Para', 'Eisen', 'ACK', 'ู', 'CO', 'atta', 'uez', 'Bahnhof', 'ter', '居', 'Statist', 'ownership', 'bindung', 'ago', 'ype', 'chain', 'Pse', 'chor', 'պ', 'po', 'py', 'PE', 'raid', 'OC', 'aining', 'adding', 'aba', 'reich', 'Rico', 'Gren', 'adi', 'iu', 'Frame', 'rou', 'лю', 'ätter', 'lament', 'etta', 'raint', '紀', 'Arag', 'ˇ', 'ma', '光', 'bos', 'George', 'pend', '�', 'acht', 'oda', 'ionale', 'czy', 'Browser', 'es', '水', 'lyn', 'bef', 'od', 'PC', 'cken', 'cera', 'cab', 'Es', 'irth', 'Reich', 'rock', 'inu', 'animation', 'FILES', 'pec', 'cookie', '```', 'pill', 'LOCK', 'chter', 'lan', 'asta', 'bb', 'Ry', 'war', 'rage', 'Anim', 'CK', 'ido', 'մ', 'nehmen', 'π', 'olf', 'visible', '理', '川', 'fond', 'ask', 'wra', 'Ara', 'тка', 'windows', 'owan', 'contrary', 'ände', 'pro', 'edad', 'lay', 'po', 'mart', 'Geb', 'Ortste', 'ys', 'elly', 'onomy', 'enne', 'fen', 'phen', '火', 'SR', 'htt', 'ane', 'administr', 'ậ', '活', 'Wayback', 'staw', 'OIN', 'autorité', 'les', 'Orchestra', 'Iter', 'Bürger', 'pra', 'Exit', 'cookie', 'opol', '志', 'Inf', 'роме', 'init', 'Nu', 'tcp', '강', 'w']\n",
      "in Layer30 , sorted_indices_dimension9588:  ['ger', '添', 'house', 'unit', 'usion', 'ур', 'ves', 'lej', '�', 'leaf', 'GER', 'án', 'ova', 'ady', 'yci', 'ƒ', 'adv', '越', 'utes', 'вод', 'Springer', 'ther', 'WN', 'тор', 'по', 'hrer', 'fte', 'того', '�', 'indre', 'ppo', 'vement', 'всего', 'utorial', 'nete', 'penas', 'Pref', 'yer', 'ŭ', 'СР', 'unst', 'ument', 'Din', 'häng', 'enium', 'utat', 'Storm', 'рия', 'amma', 'uther', 'geg', 'ш', 'unit', '�', 'quest', 'jective', 'inition', 'води', 'Ib', 'ʊ', 'ześ', 'hel', 'athers', 'эн', '�', 'su', 'anger', 'pit', 'gemeinde', 'utsch', 'adas', 'тв', 'atorial', 'xic', 'aming', 'urale', 'ه', 'рий', 'ICE', 'enn', 'ennessee', 'units', 'спе', 'ach', 'irm', 'arguments', '頭', 'ffe', 'ñas', 'our', 'UI', 'iza', 'cod', 'dział', 'codes', 'uls', 'Wit', 'wall', 'Asp', 'wetenschapp', 'illo', 'ork', 'Reich', 'će', 'ս', 'ifts', 'FirstName', 'particul', 'enes', 'asp', 'betre', 'amt', 'VB', 'automatisch', 'ɯ', 'ysis', 'xf', 'hm', 'usalem', 'fac', 'führt', 'cej', 'Unit', 'great', 'ory', 'otal', 'erva', 'Botan', 'usto', 'onnées', '�', 'Liver', 'Ñ', 'Found', 'orithm', 'pse', 'agar', 'vb', 'vee', 'fection', 'Media', 'corre', 'che', 'bia', 'unction', 'fatt', 'cod', 'endar', 'req', 'adj', 'sf', 'repeating', 'Bot', 'hem', 'polity', 'Nem', 'Collect', 'remaining', 'ènes', 'prü', 'bud', 'igneur', 'fus', 'listade', 'ces', 'Node', 'vention', 'Ć', '<?', 'ɨ', 'áció', 'uli', 'hy', 'US', 'borough', 'str', 'liver', 'cases', 'woord', 'дня', 'ért', 'ikus', 'fasst', 'ées', 'anha', 'vall', 'ół', 'úl', 'тт', 'ouse', 'ño', 'recon', 'ふ', 'Private', 'ural', 'lou', 'pois', 'qué', 'ham', 'Ok']\n",
      "in Layer30 , sorted_indices_dimension9334:  ['Theatre', 'theatre', 'Theater', 'ater', 'Broadway', 'Teatro', 'aters', 'teatro', 'atre', 'театра', 'théâtre', 'теа', 'Shakespeare', 'teat', 'Thé', 'cinema', 'Cinema', 'opera', 'atr', 'Opera', 'Shakespe', 'drama', '舞', 'opera', 'Schaus', 'thé', 'dram', 'actors', 'theorem', 'cinéma', 'actor', 'actor', 'akespe', 'дра', 'Cin', 'cin', 'cin', 'improv', 'rama', 'actress', 'Oper', 'Schauspieler', 'ctor', 'θ', 'theta', 'Theorem', 'Hollywood', 'кино', 'âtre', 'Orchestra', 'comedy', 'Perform', 'atern', 'atro', 'тера', 'chestra', 'ctr', 'cinemat', 'Theorem', 'antom', 'Stadium', 'Dance', 'Castro', 'acter', 'mbH', 'atter', 'ombres', 'performing', 'äter', '�', 'plays', 'JavaScript', 'Jazz', 'тери', 'eters', 'concert', 'uther', 'акт', 'jazz', 'oper', 'thee', 'Theta', 'theorem', 'aterial', 'eter', 'Θ', 'erno', 'Arts', 'ǎ', 'stad', 'acting', 'sr', 'atra', 'actory', 'Disney', 'cache', 'scène', 'Movie', 'oper', 'Dy', '座', 'Television', 'Renaissance', 'baum', 'arts', 'Arena', 'plays', 'circ', 'Stage', 'Liter', 'Marina', 'projection', 'gresql', 'ACT', 'ologies', 'literature', 'Shaw', 'ètres', 'дра', 'teor', 'ث', 'chrome', 'tap', 'dance', 'stad', 'akter', 'osoph', 'лем', 'zat', 'Wrestling', 'Scala', 'Thor', 'soap', 'poetry', 'тер', 'cache', 'ля', 'ház', 'istr', 'rå', 'тей', 'Rotten', 'те', 'perform', 'din', 'perform', 'aten', 'Bag', 'Tony', 'Inga', 'ctrine', 'Wagner', 'тео', 'atura', '串', 'nak', 'лях', 'sciences', 'RAM', '寺', 'shadow', 'udes', 'Rugby', '话', 'Stage', '码', 'ť', 'classical', 'jb', '状', 'movie', 'doctrine', 'Oscar', 'lywood', 'tml', 'цен', 'etter', 'Bü', 'Musical', 'Movie', 'Cache', 'uter', 'performed', 'asha', 'IMDb', 'tered', 'Films', 'dent', 'aste', 'ology', 'iza', 'restaurant', 'rör', 'tery', 'Din', 'orie', 'insc', 'THE', 'ological', 'AllMovie']\n",
      "in Layer30 , sorted_indices_dimension9207:  ['race', 'Race', 'race', 'races', 'dance', 'ACE', 'Dance', 'Senate', 'ace', 'rac', 'rac', 'Database', 'database', 'racing', 'language', 'tribe', 'Database', 'domain', 'battery', 'Conference', 'railway', 'aces', 'Bible', 'Racing', 'registry', 'database', 'lattice', 'Avenue', 'suite', 'floor', 'Office', 'circle', 'sphere', 'Domain', 'aceae', 'Census', 'army', 'Office', 'zone', 'river', 'census', 'Institute', 'pipe', 'Railway', 'library', 'valley', 'Bridge', 'Library', 'Orchestra', 'cycle', 'domain', 'pipeline', 'Registry', 'conference', 'palace', 'Championship', 'language', 'fork', 'Festival', 'office', 'Library', 'trail', 'archive', 'Sprache', 'battle', 'calendar', 'dan', 'disease', 'Language', 'bridge', 'seat', 'Bowl', 'Calendar', 'base', 'base', 'license', 'festival', 'factory', '語', 'Language', 'audience', 'Council', 'Palace', 'Factory', 'athedral', 'Assembly', 'queue', 'Calendar', 'Academy', 'River', 'interface', 'Archive', 'License', 'Airport', 'lake', 'surface', 'Straße', 'throne', 'Association', 'Circle', 'cache', 'train', 'Kate', 'emetery', 'virus', 'Party', 'camera', 'dataset', 'ensus', 'Code', 'marriage', 'crisis', 'population', 'ipeline', '族', 'temple', 'phone', 'crowd', 'Repository', 'coat', 'kitchen', 'League', 'rivière', 'ensemble', 'itchen', 'highway', 'Domain', 'Prize', '橋', '舞', 'keyboard', 'arium', 'sjö', 'Temple', 'Base', 'ocracy', 'Valley', 'grid', 'zoo', 'amt', 'sequence', 'office', 'House', 'Camera', 'carrera', 'dictionary', 'party', 'restaurant', 'cycle', 'pace', 'Beach', 'beach', 'religion', 'Foundation', 'anguage', 'library', 'Cup', 'axis', 'landscape', 'pipe', 'Framework', 'cube', 'estival', 'camera', 'repository', 'eclipse', 'Interface', 'Arena', 'frame', 'lace', 'Cache', 'Empire', 'Army', 'ospel', 'phere', 'Zone', 'Factory', 'timezone', 'suite', 'gate', 'residence', 'nic', 'train', 'phone', 'ра', 'University', 'prison', 'circle', 'acing', 'uce', 'Datenbank', 'runtime', 'tunnel', 'ra', 'currency', 'cache', 'Committee', 'legate', 'ite', 'zone']\n",
      "Key: model.layers.31.mlp.down_proj.weight\n",
      "in Layer31 , sorted_indices_dimension5152:  ['eur', 'ype', 'glass', 'Morgan', 'Ç', 'ън', 'cke', 'nb', 'vba', 'inary', 'ép', 'Memorial', 'iada', '�', 'rack', 'ea', 'beskre', 'gemeinde', 'Ù', 'wär', 'rä', 'Mem', 'anja', 'turn', 'emento', 'inaire', 'enst', 'gow', 'fass', 'yp', '{#', '丁', 'sock', 'omi', 'LETE', 'iment', 'icane', 'annotation', 'isie', 'ől', 'Constra', 'castle', 'itung', 'läu', 'schap', 'aju', 'est', 'wr', 'unker', 'asket', 'ni', 'ags', 'hub', 'ulp', 'и', 'iba', 'scheidung', 'ën', 'jen', 'esta', 'mem', '段', 'marc', 'news', 'Est', 'igare', 'rael', 'bbe', 'geg', 'eas', 'aga', '%=', 'aja', 'heck', 'pac', 'êt', 'èse', 'ries', 'я', 'pace', 'lą', 'indicator', 'неза', 'wahl', 'Flags', 'unic', 'ogene', 'Springer', 'incons', '園', 'irst', 'ær', 'oe', 'ipe', 'Роз', 'indu', 'ycz', 'tu', 'izen', ']_', 'Upper', 'ilty', '%),', 'sted', 'Ober', 'ensa', 'Cass', '制', 'ственного', 'basket', 'ügel', 'yaume', 'uru', 'Constants', 'usch', 'ень', \"{'\", 'estellt', 'atore', '玉', 'ommen', 'dot', 'Denkmal', 'owi', 'endar', 'nom', 'abhäng', 'demselben', 'contrad', 'doubles', 'ých', 'indic', 'дже', 'pi', 'uca', 'urg', 'obe', 'loor', 'iken', 'tres', 'osta', 'Enabled', 'jpg', 'Hoch', 'imet', 'ַ', 'Ş', 'ree', 'cad', 'par', 'Jen', 'är', 'Calendar', 'тру', 'età', 'ync', 'router', 'Monde', 'ша', 'роб', 'turno', 'inte', 'communes', 'дія', 'indo', 'jug', 'cn', 'ocal', 'Ira', 'ache', 'wrapper', 'aber', 'ping', 'ln', 'Fland', 'ủ', 'illon', 'łod', 'oute', 'osto', 'uns', 'iae', 'ario', 'čka', 'Géographie', 'iből', 'icile', 'exact', 'River', 'strugg', 'icano', 'Dj', 'фа', 'сона', 'ờ', 'Ros', '╔', 'turned', 'Stanley', 'noreferrer']\n",
      "in Layer31 , sorted_indices_dimension10178:  ['ass', 'ran', 'won', 'anno', 'arg', 'zo', 'alone', 'induction', '�', 'ńskiego', 'enough', '�', 'wel', 'run', 'runner', 'var', 'worth', 'health', 'зо', 'ens', '�', 'sufficient', 'nur', 'illo', 'ync', 'ri', 'Micro', 'lear', 'phabet', 'well', 'vos', 'Одна', 'zo', 'necess', 'nor', 'ńskim', 'sob', 'holder', 'orb', 'rend', 'suff', 'ocal', 'gover', 'ign', 'dc', 'charg', 'gone', 'Sold', 'információ', 'äß', 'vers', 'ova', 'confirm', 'username', 'nu', 'じ', 'yet', 'нок', 'ste', 'ou', 'mis', 'ir', 'mil', 'east', 'inners', 'pav', 'pod', 'ril', 'war', 'confirm', 'runs', 'cord', 'wohl', 'бой', 'cinema', 'ear', 'ensor', 'waited', 'aga', 'lide', 'accompan', 'joint', 'Données', 'wicht', 'heard', 'Unterscheidung', 'pine', 'py', 'noted', 'nast', 'diag', 'clar', 'stra', 'wont', 'bien', 'nep', 'science', 'sop', 'nick', 'legt', 'учи', 'inha', 'yes', 'li', 'appreciated', 'sans', 'led', 'inet', 'ouvern', 'soon', 'sender', 'ństw', 'west', 'nice', 'czy', 'cour', 'running', 'Lauf', 'onte', 'zeit', 'wieder', 'pleasant', 'ingers', 'bene', 'drew', 'wsz', 'oct', 'adm', 'ajes', 'winner', 'diction', 'nic', 'entered', 'inx', 'inj', 'Socket', 'Mih', 'horror', 'safe', 'zewnętrz', 'pri', 'exclus', 'ker', 'uvud', 'rang', 'ld', 'pres', 'anal', 'Loop', 'blan', 'offset', 'membership', 'val', 'ign', 'oka', 'esser', 'ska', 'usammen', 'runtime', 'enjo', 'hous', 'burg', 'már', 'lä', 'па', 'leben', 'Bi', 'certainly', 'led', '次', 'info', 'vary', 'sci', 'Squad', 'seen', 'solo', 'ícula', 'liv', 'uga', 'prompt', 'data', 'inside', 'hon', 'Cord', 'кры', 'Außer', 'appreciate', 'ren', 'held', 'Delegate', 'DC', 'uma', 'datab', 'clearer', 'nieder', 'portrait', 'hur', 'pover', 'scheid', 'mi']\n",
      "in Layer31 , sorted_indices_dimension10379:  ['onderwerp', 'clés', 'desar', 'wetenschapp', 'recens', 'externe', 'superfic', 'eerst', 'grote', 'Außer', 'programma', 'hoofd', 'provin', 'nieuwe', 'Bedeut', 'références', 'eeuw', 'esterni', 'gouvern', 'statunit', 'jourd', 'protagonista', 'inwon', 'gebied', '`_', 'progetti', 'seizo', 'Begriffe', 'connexes', '“)', 'departamento', 'Gemeins', 'cerem', 'épisode', 'Données', 'alberga', 'recensement', 'consulté', 'etapa', 'équip', 'localidad', 'perí', 'geslacht', 'přek', 'wereld', 'prü', 'jú', 'automatisch', 'heut', 'provincie', '\"\")', 'mouv', 'aantal', 'belang', '\",\\r', 'tweede', 'vess', '()\"', '_)', 'estaven', 'intitul', 'inwoners', 'totalité', '`__', \"`'\", 'réseau', 'Einzeln', 'desen', 'superficie', 'compag', 'století', 'telt', 'schließ', 'dessin', '>\",', '].[', '=\"$', '.):', '.](', 'stycznia', 'immagini', 'gepubliceerd', '%),', 'még', 'región', 'geme', 'Hinweis', 'rivière', 'ufficiale', 'verschill', 'groot', 'virtuel', 'ruolo', '%).', 'moyenne', 'lutego', 'seizoen', 'soort', 'eigenen', 'péri', 'nazionale', 'pó', 'particolare', 'eredet', 'hoog', 'figura', 'rappres', '?](', 'género', 'proget', '(@\"', 'proble', '%)', 'conseil', 'listopada', 'tijd', 'siège', 'producción', 'października', 'grado', 'września', 'binnen', 'quartier', '\\\\[\\\\', 'heutigen', 'squadra', 'május', 'citt', 'Vertrag', 'vš', 'civile', 'titolo', 'општи', 'disponible', 'landet', 'Unterscheidung', 'száz', '+)', 'geprüft', 'études', 'historiques', 'tedes', 'compét', 'dokument', 'Fiche', 'sierpnia', 'kwietnia', '_)', 'dinast', '`:', 'teatro', 'több', 'filme', 'territoire', 'tít', 'sigu', 'cím', 'población', 'szeptember', 'stackoverflow', 'Obrázky', 'arbeit', 'totale', 'Anleitung', 'beskre', 'պ', 'póź', 'altres', 'majd', 'mondiale', ')».', \"'')\", 'tedesco', '²).', 'listop', 'Bitte', 'grudnia', '=\".', 'Begriff', '?}', '\"`', 'gruppo', 'sierp', 'Système', 'március', 'szó', 'Ы', 'zes', 'spole', 'stagione', 'achter', 'június', 'Schrift', 'categorie', 'lipca', 'havet', 'presente', 'információ', 'niveau', 'stessa']\n",
      "in Layer31 , sorted_indices_dimension51:  ['textt', 'Хронологија', 'висини', 'makeText', 'oreign', 'AccessorImpl', '<s>', '$}}%', 'Fichier', 'brázky', 'ViewById', 'idense', 'Kontrola', 'externas', 'länkar', 'archivi', 'nederbörd', 'entferne', 'homonymes', 'odkazy', 'Portail', 'ѫ', 'imoine', 'ungsseite', 'geprüft', 'tembre', 'eerd', 'mlung', 'Begriffsklär', 'gresql', 'sime', 'pobla', '&=\\\\', 'prü', 'éricaine', 'zvuky', 'ightarrow', 'ципа', 'yntax', 'Zygote', 'doFilter', \"]{'\", 'itmap', 'пописа', 'Википеди', 'incie', 'челов', 'ITableView', 'Düsseld', 'Einzeln', 'prüfe', 'listade', 'mathchar', 'azionale', 'xtart', 'loyee', 'atform', 'Audiodateien', 'ugust', 'invån', 'ALSE', 'geldig', 'autory', 'źdz', 'prilis', 'Audiod', 'eredetiből', 'Unterscheidung', 'RewriteCond', '▇', 'ionali', 'lês', 'connexes', 'bolds', 'videa', 'perties', 'ipage', 'prüft', 'ewnętrz', 'reducible', 'Ḩ', 'virti', 'Licencia', 'giore', 'dátummal', 'ℚ', 'člán', 'Савезне', 'kreich', 'ionario', 'entication', 'partiellement', 'eltemperaturen', 'consultato', 'iedenis', 'Webachiv', '╬', 'sklär', 'bezeichneter', 'Мексичка', 'äsident', 'printStackTrace', 'gepublic', 'ército', 'metros', 'empio', 'љашње', 'Hinweis', 'ètres', '┈', 'sierp', 'zetek', 'entlicht', 'ździer', 'Genomsnitt', '\"?>', 'Sito', 'ingsområ', 'istiche', 'CURLOPT', 'varmaste', 'ambiguation', 'énario', 'ActivityThread', 'poque', 'mieszkań', '𝓝', 'átum', 'regnig', 'zeum', 'iből', '⸮', 'Ə', 'externs', 'ermeister', 'teger', 'huvudstaden', 'ímp', 'órico', 'ḩ', 'konn', 'ₗ', 'fico', 'ftrag', 'tématu', '⍵', 'ongodb', 'strij', 'ershell', 'javase', 'Stutt', 'érature', 'Ű', '﹕', 'ksam', 'kwiet', 'adratkil', 'ARCHAR', 'ederb', 'usetts', 'äler', 'anterie', 'Ė', 'yaume', '#>', 'кипеди', 'temperaturen', 'formatt', 'pción', 'unicí', 'brary', 'zös', '%;\\r', 'gepubliceerd', 'prüng', 'datei', 'aturen', 'achiv', 'omsnitt', 'zewnętrzne', 'Википедии', 'ewnę', 'Obrázky', 'rinningsområ', 'kmal', 'adratkilometer', '╩', '╔', 'ніципалі', 'Normdaten', 'ionales', 'archiviato', 'ateien', 'cowo', 'ampio', 'Қ', 'gebras', 'надморској', 'données', 'onderwerp']\n",
      "in Layer31 , sorted_indices_dimension10259:  ['orn', 'decor', 'flowers', 'dress', 'celebrated', 'festiv', 'flower', 'alc', 'festival', 'celebr', 'museum', 'sculpt', 'beaut', 'cher', 'flor', 'poet', 'beautiful', 'artist', 'painter', 'arts', 'fres', 'Хронологија', 'dressed', 'piano', 'icon', 'antin', 'poetry', 'botan', 'cult', 'monuments', 'sacred', 'fond', 'artists', 'Valent', 'pra', 'atica', 'chni', 'viron', 'dance', 'Dam', 'codes', '�', 'cipl', 'attra', 'fest', 'Debug', 'Discogs', 'czy', 'dign', 'surrounded', 'opera', 'decor', 'renov', 'medieval', 'dinner', 'uset', 'garden', 'tl', 'erg', 'ella', 'jazz', 'Configuration', 'ím', 'Test', 'scen', 'magnific', 'lav', 'phil', 'volunte', 'hung', 'musical', 'icia', 'charm', 'cultiv', 'avant', 'gard', 'invited', 'beauty', 'spiritual', 'dess', 'dé', 'config', 'flu', 'cultural', 'itare', 'lyr', 'erta', 'iten', 'honor', 'recre', 'grass', 'Einzelnach', 'worship', 'ières', 'Commons', 'Fou', 'bronze', 'zym', 'chef', 'listview', 'champ', 'grande', 'champion', 'há', 'Memorial', 'andbox', 'pictures', 'eleg', 'Parameter', 'zz', 'ner', 'externs', 'ière', 'iers', 'noble', 'iana', 'Gast', 'aña', 'ynt', 'template', 'guest', '�', 'guests', 'Renaissance', 'patron', 'Config', 'Sto', 'imperial', 'GE', 'monument', 'bath', 'solemn', 'ruits', 'summer', 'estival', 'ǎ', 'nur', 'etta', 'gradle', 'valor', 'ój', 'Broadway', 'itza', 'evening', 'xygen', 'ství', '关', 'anten', 'proud', 'prest', 'lux', 'ńczy', 'cz', 'compute', 'mét', 'ów', 'inaug', 'Oriental', 'ti', 'belle', 'Html', 'MT', 'stackexchange', 'chant', 'Goth', 'patri', 'JQuery', 'пе', 'Testament', 'rera', 'Flora', 'influ', 'укра', 'reload', 'лле', 'ante', 'Tab', 'enst', 'Text', 'techni', 'singer', 'Архив', 'developer', '止', 'rez', 'ceremony', 'Template', 'Transaction', 'payload', 'temple', 'Gli', 'Ris', 'Component', 'PC', 'gift', 'Mine', 'utz', 'nek', 'clubs', 'poem']\n",
      "in Layer31 , sorted_indices_dimension8756:  ['album', 'Album', 'albums', 'geometric', 'exterior', 'adjacent', 'Albums', 'lyr', 'drums', 'interior', 'renov', 'bass', 'geomet', 'decor', 'album', 'musical', 'sculpt', 'diagonal', 'geometry', 'dens', 'ambient', 'guitar', 'piano', 'canvas', 'lattice', 'square', 'density', 'vocals', 'pian', 'wooden', 'spatial', 'orb', 'dense', 'Orchestra', 'rectangle', 'Gallery', 'Musical', 'terra', 'scen', 'gallery', 'Monument', 'Jazz', 'curv', 'composer', 'Square', 'jazz', 'metal', 'angular', 'compact', 'Architecture', 'cyl', 'artists', 'painter', 'nearby', 'orn', 'pav', 'meters', 'optical', 'horizontal', 'radial', 'spraw', 'architecture', 'surfaces', 'diameter', 'artist', 'trom', 'Billboard', 'Galerie', 'thermal', 'vertical', 'Layout', 'painted', 'squares', 'dimensional', 'Beautiful', 'Metal', 'elegant', 'drum', 'width', 'terrain', 'texture', 'furn', 'decor', 'Denkmal', 'Layout', 'resize', 'polygon', 'coat', 'paint', 'walls', 'spacing', 'songs', 'orbit', 'beautiful', 'pixel', 'spaces', 'tile', 'museum', 'monuments', 'buildings', 'roof', 'orb', 'acres', 'architect', 'Bass', 'bands', 'LED', 'singer', 'sq', 'Terra', 'architecture', 'compress', 'vin', 'compression', 'thick', 'cres', 'algebraic', 'Width', 'dens', 'Discogs', 'alto', 'tower', 'fitted', 'rear', 'beam', 'painting', 'millimeter', 'square', 'layout', 'Songs', 'situated', 'Museum', 'coordinates', 'Kunst', 'meter', 'opera', 'Maler', 'containers', 'ensemble', 'spac', 'demol', 'outer', 'magnetic', 'Historic', 'canal', 'topological', 'metres', 'amplitude', 'vert', 'imeter', 'ly', 'singing', 'punk', 'deck', 'Rect', 'habitat', 'pixels', 'ere', 'Compos', 'convex', 'overlay', 'geom', 'avant', 'альбо', 'surface', 'mez', 'Museo', 'compos', 'tunnel', 'lamp', 'amplit', 'sty', 'symmet', 'spectral', 'landscape', 'chestra', 'circular', 'mechanical', 'DJ', 'slope', 'concert', 'radius', 'amen', 'designer', 'Musée', 'storage', 'kunst', 'tamb', 'composite', 'vertex', 'wood', 'mesh', 'Lux', 'parc', 'Container', 'posterior', 'atmos', 'chor', 'elli', 'atial']\n",
      "in Layer31 , sorted_indices_dimension7764:  ['water', 'data', 'text', 'text', 'film', 'audio', 'water', 'food', 'computer', 'tele', 'music', 'graph', 'video', 'data', 'digital', 'air', 'radio', 'image', 'electric', 'graphics', 'aer', 'wood', 'fish', 'visual', 'gas', 'oil', 'transport', 'electronic', 'metal', 'image', 'texture', 'print', 'mobile', 'electron', 'media', 'cell', 'color', 'phot', 'Water', 'elect', 'energy', 'photo', 'veget', 'light', 'tele', 'computing', 'phone', 'elect', 'rail', 'télé', 'animation', 'autom', 'camera', 'cinema', 'screen', 'motor', 'music', 'material', 'multimedia', 'printing', 'wireless', 'plant', 'soil', 'animal', 'graph', 'cloud', 'television', 'comput', 'wind', 'air', 'video', '電', 'ice', 'film', 'broadcast', 'forest', 'machine', 'fire', 'map', 'fil', 'materials', '水', 'transmission', 'chemical', 'physics', 'color', 'print', 'hydro', 'mass', 'computers', 'photograph', 'natural', 'dig', 'agua', 'design', 'ph', 'rock', 'audio', 'images', 'agricult', 'carbon', 'marine', 'ocean', 'musique', 'vector', 'sound', 'mathematics', 'aircraft', 'cinemat', 'textt', 'art', 'waters', 'flow', 'computational', 'communication', 'rock', 'flow', 'agua', 'medicine', 'música', '音', 'noise', 'painting', 'foot', 'тек', 'font', 'водо', 'phon', 'football', 'wire', 'ph', 'language', 'wire', '电', 'font', 'cell', 'paint', 'mobile', 'cable', 'cloud', 'math', 'tree', 'bio', 'wine', 'fish', 'streaming', 'makeText', 'rice', 'films', 'plant', 'web', 'architecture', 'technology', 'igne', 'wet', 'meteor', 'micro', 'liter', 'milk', 'movie', 'script', 'fluid', 'land', 'communic', 'storage', 'hyd', 'cinéma', 'wind', 'landscape', 'embedded', 'electro', 'baseball', 'container', 'videa', 'motion', 'document', 'thermal', 'mole', 'energy', 'texts', 'eau', 'computation', 'memory', 'math', 'stream', 'sea', 'heat', 'optical', 'screen', 'colour', 'musical', 'cook', 'radiation', 'magnetic', 'elektr', '음', 'cook', 'botan', 'compute', 'transport']\n",
      "in Layer31 , sorted_indices_dimension6711:  ['Lee', 'Graham', 'Gary', 'rolle', '⅓', 'iso', 'Jose', 'oks', 'cos', 'ado', 'Clar', 'éral', 'oli', 'ero', 'clar', 'ter', 'ark', 'arlo', 'Benjamin', 'ale', 'Grund', 'ks', 'ino', 'ole', 'arz', 'rollo', 'comp', 'Jose', 'cha', 'asp', 'WI', 'erde', 'ăr', 'ම', 'xico', 'Gand', 'ia', 'Desp', 'José', 'fter', 'ktr', 'ún', 'dead', 'ede', 'Op', 'izzato', 'sang', 'commit', 'ர', 'je', 'exterior', 'Gonz', 'ags', 'xy', 'Dak', 'TER', 'ungs', 'Cand', 'sak', 'Pass', 'Sang', 'esa', 'gi', 'terior', 'che', 'deleg', 'cole', 'INIT', 'pass', 'fico', 'fs', 'yo', 'Алек', 'eren', 'кар', 'lifetime', 'edo', 'Deb', 'логи', 'ERR', 'cos', 'lier', 'Pass', 'ario', 'ро', 'ise', 'tor', 'apan', 'pas', 'fp', 'vere', 'рів', 'лії', 'izo', 'cers', 'Dead', 'ram', '理', 'Aleks', 'commits', 'pole', 'reactjs', 'Wikimedia', 'Cole', 'beit', 'fi', 'ciale', 'LIN', 'displaystyle', 'versary', 'шко', 'edor', 'Rechts', 'cand', 'uter', 'sono', 'term', 'ǐ', 'sw', 'ex', 'vers', 'Cha', 'clar', 'erade', 'ји', 'Vol', 'aren', 'ata', 'prem', 'oles', 'maximal', 'Sammlung', 'undes', 'González', 'amps', 'isat', 'arg', 'orb', 'ᾶ', 'erb', 'enden', 'ar', 'Cambridge', 'theme', 'Thank', 'пы', 'Volume', 'IB', 'ales', 'fileName', 'arms', 'chim', 'security', 'easy', 'rol', 'PASS', 'rice', 'lieder', 'Esp', 'aines', 'cav', 'op', 'województ', 'iation', 'Pia', 'Wonder', 'LENG', 'oto', 'Sold', 'orientation', 'orter', 'Library', 'cookie', 'odu', 'arrow', 'ta', 'fire', 'hnen', 'TA', 'iembre', 'vier', 'zos', 'fi', 'KS', 'ју', 'Rick', 'pen', 'Ț', 'Cos', 'cio', 'Ez', 'arks', 'Erik', 'han', 'clarify', 'angularjs', 'genommen', 'agas', 'tero', 'живело']\n",
      "in Layer31 , sorted_indices_dimension8918:  ['hospital', 'factory', 'school', 'church', 'hotel', 'court', 'restaurant', 'studio', 'factory', 'Hospital', 'library', 'prison', 'school', 'store', 'Factory', 'Factory', 'ospital', 'court', 'bank', 'store', 'club', 'temple', 'office', 'college', 'palace', 'university', 'studio', 'library', 'Hotel', 'Studio', 'museum', 'database', 'gallery', 'farm', 'club', 'Court', 'Store', 'zoo', 'newspaper', 'office', 'Studio', 'database', 'repository', 'castle', 'bank', 'park', 'magazine', '院', 'Store', 'ourt', 'campus', 'festival', 'shop', 'stad', '館', 'шко', 'School', 'Schule', 'Library', '寺', 'institution', 'emetery', '库', 'estaur', 'theatre', 'Office', 'Church', 'église', 'Kirche', 'beach', 'camp', '校', 'museum', 'Library', 'server', 'kitchen', '店', 'actory', 'facility', 'lab', 'forum', 'athedral', 'клуб', 'Office', 'estore', 'Database', 'schule', 'village', 'monaster', 'церкви', 'Database', 'Palace', 'pository', '駅', 'shop', 'repository', 'arium', 'station', 'registry', 'league', 'klub', 'server', 'itchen', 'park', 'chiesa', 'archive', 'othek', 'useum', 'cinema', 'parish', 'Bank', 'garden', 'ibrary', 'kirche', 'allery', 'railway', 'pool', 'Museum', 'церков', '園', 'ymnasium', 'oteca', 'бан', 'afé', 'resort', 'dictionary', 'chamber', 'camp', 'Datenbank', 'Stadium', 'hosp', 'atabase', 'Repository', 'council', 'Kloster', 'Airport', 'highway', 'школа', 'château', 'irche', 'lake', 'parliament', 'courts', 'Temple', 'Kirchen', 'deli', 'College', 'bibliothek', 'село', 'regiment', 'Club', 'yard', 'station', 'brary', 'Gallery', 'хра', 'ôtel', 'shelter', 'musée', 'estudio', 'forum', 'yard', 'town', 'island', 'Magazine', 'gericht', 'Server', 'army', 'fleet', 'album', 'cademy', 'клу', 'conference', 'stores', '堂', 'Bahnhof', 'ansion', 'restaur', 'Festival', 'estate', 'bridge', 'tower', 'repo', 'municipality', 'arden', 'Theater', 'offices', 'музе', 'teatro', 'department', 'kyr', 'мона', 'forest', 'Farm', 'tournament', 'Theatre', 'network', 'othèque', 'stored', 'Server']\n",
      "in Layer31 , sorted_indices_dimension2231:  ['ث', 'ington', 'aha', 'irk', 'trat', '⟶', 'sap', 'cl', 'pers', 'ea', 'ce', 'tersuch', 'tre', 'perf', '丁', 'дол', 'tut', 'tro', 'ping', 'compar', 'permanent', 'ус', 'compl', 'skich', 'chi', 'umerate', 'sp', 'град', 'irie', 'izi', 'us', 'cle', 'ch', 'externos', 'cors', '治', 'verso', 'Compar', 'quer', 'Õ', 'Voll', 'lings', 'Ê', 'теа', '왕', 'spos', 'Fern', 'eus', 'Dub', 'pole', 'Vent', 'Петер', 'onen', 'Foo', 'вропей', 'tre', 'arf', 'treat', 'partiellement', 'surr', 'cles', 'civil', 'gener', '座', '令', 'rett', 'cile', '�', 'ao', 'aran', 'cap', 'commercial', 'Fern', 'iera', 'lands', 'сов', 'conven', 'repla', 'chus', 'partic', 'decrease', 'ząd', 'Alt', 'arz', 'amen', '�', 'tr', 'ště', 'ORS', 'tort', 'sze', 'Leist', 'vent', 'gminie', 'pleased', 'прод', 'òria', 'wieku', 'պ', 'spons', 'yd', 'Civil', 'Ď', 'Gam', 'torn', 'sempre', 'decre', 'conquist', 'contra', 'ʂ', 'isms', 'cock', 'ternal', '昌', 'Украи', 'colon', 'ARN', 'invas', 'Iter', 'связи', 'kiem', 'lei', 'OP', 'ivel', 'Next', 'postgresql', 'otten', 'ณ', 'ум', 'Klaus', '食', 'amment', 'izations', 'chia', 'óm', 'tele', 'irs', 'osis', 'colon', 'チ', '省', 'lán', 'лта', '性', 'sost', 'DDR', 'contract', 'phr', 'perm', 'Cec', 'ican', 'ecc', 'persist', 'Gran', 'stamp', 'comun', '성', 'Background', 'commun', 'geben', 'infatti', 'andr', 'onde', 'contra', 'rott', 'wig', 'maste', 'cis', 'str', 'Á', 'ifa', 'catt', 'premi', 'бри', 'Alt', 'presently', 'bronze', 'ring', 'Sant', 'ズ', 'ag', 'cul', 'babel', 'tran', 'Pacific', 'Ґ', 'Quellen', 'ius', 'nię', 'anch', 'spl', 'Orig', '우', 'untime', 'lí', 'chev', 'split', 'Commun', 'driv', 'Ath']\n",
      "in Layer31 , sorted_indices_dimension9012:  ['entertain', 'Entertainment', 'Entertain', 'music', 'musical', 'artist', 'Musical', 'artists', 'studio', 'games', 'Music', 'Games', 'Studios', 'Studio', 'Theatre', 'cinema', 'film', 'Film', 'dance', 'Dance', 'guitar', 'Theater', 'films', 'movie', 'comedy', 'jazz', 'album', 'piano', 'Cinema', 'albums', 'theatre', 'Sports', 'Music', 'festival', 'sports', 'Movie', 'stud', 'Festival', 'Arts', 'Hollywood', 'cinemat', 'football', 'Football', 'Basketball', 'Films', 'Studio', 'Album', 'DVD', 'video', 'arts', 'basketball', 'exhibition', 'Comics', 'music', 'singer', 'tournament', 'Teatro', 'Video', 'songs', 'Spiel', 'animation', 'tennis', 'Disney', 'play', 'streaming', 'Jazz', 'Movie', 'Albums', 'recre', 'Tennis', 'Musik', 'FIFA', 'festiv', 'singing', 'Künstler', 'Tournament', 'clubs', 'painting', 'videos', 'gallery', 'Play', 'Orchestra', 'pian', 'baseball', 'sport', 'film', 'painter', 'playing', 'golf', 'genre', 'composer', 'Soccer', 'opera', 'museum', 'sculpt', 'música', 'club', 'stad', 'cinéma', 'MTV', 'mov', 'Gallery', 'coach', 'Opera', 'Billboard', 'concert', 'Baseball', 'Stadium', 'song', 'audio', 'lyr', 'Wrestling', 'Songs', 'cin', 'Sport', 'Play', 'vide', 'imation', 'multimedia', 'musicale', 'NBA', 'Audio', 'fans', 'NFL', 'hockey', 'chestra', 'Sony', 'Athletics', 'audi', 'NCAA', 'actress', 'athlet', 'Club', 'Olympics', 'pygame', 'YouTube', 'Warner', 'movie', 'amateur', 'camera', 'Camera', 'Museum', 'performances', 'animated', 'rugby', 'musique', 'interactive', 'DJ', 'game', 'Hockey', 'IMDb', 'Game', 'Player', 'UEFA', 'Broadway', 'Championship', 'Videos', 'album', 'музы', 'recording', 'Marvel', 'studio', 'Olympic', 'photograph', 'guest', 'usement', 'Perform', 'exhib', 'audience', 'Video', 'Discogs', 'filme', 'football', 'película', 'guests', 'Kunst', 'Television', 'resort', 'play', 'attend', 'championship', 'Cin', 'Enter', 'Musée', 'ticket', 'Athlet', 'drama', 'broadcast', 'ünstler', 'tour', 'hotel', 'Stad', 'fiddle', 'Pictures', 'tutorials', 'player', 'television', 'video', 'Racing', 'bass']\n",
      "in Layer31 , sorted_indices_dimension8766:  ['ify', 'LA', 'SR', 'ice', 'vano', 'abol', 'tent', 'SD', 'aty', 'ф', 'nam', 'Davis', 'LOW', 'obierno', 'VA', 'ru', 'ische', 'Syn', 'Tras', 'RS', 'Bar', 'Tree', 'oc', 'corte', 'uen', 'gates', 'Mond', 'rund', 'syn', 'va', 'esta', 'flesh', 'ché', 'prü', 'gs', 'óm', 'Cost', 'länd', 'PU', 'unte', 'Syn', 'pd', 'iet', 'TR', 'ina', 'WA', 'shop', 'low', 'actér', 'Blue', 'zin', 'atori', 'Tree', 'atti', 'bolds', 'atica', 'othe', 'mouv', 'PM', 'threshold', 'Reform', 'UE', 'ob', 'glass', 'zett', 'FE', 'practical', 'atif', 'Pos', 'publi', 'zewnętrz', 'ью', 'uder', 'propri', 'kal', 'elim', 'atar', 'deli', 'ICE', 'Total', 'mano', 'ifié', 'laravel', 'Blue', 'sterd', '微', 'ong', 'ox', 'ovat', 'adin', 'rà', 'rice', 'oby', 'piano', 'зо', 'Lau', 'GS', 'nelle', '@{', 'AppData', '司', '�', 'WM', 'pu', 'Bis', 'neg', 'Marg', 'saf', 'Sta', 'Sm', 'bars', 'stor', 'ROW', 'lag', 'ader', 'cas', 'cite', 'lain', 'runtime', 'Del', 'chia', '(\"@', '機', 'Cab', 'tree', 'Historic', 'comprom', 'terre', 'Pos', 'b', 'п', 'syn', 'Self', 'PG', 'gut', 'Cas', 'efined', 'van', 'ischen', 'SI', 'gram', 'ра', 'geme', 'pm', 'Те', 'yter', 'giv', 'на', 'ラ', 'card', 'Int', 'Auth', 'unge', 'cis', 'attro', 'g', 'keyword', 'isons', 'mic', 'ob', 'Dabei', 'ante', 'tend', 'obar', 'sci', 'stör', 'dependencies', 'OB', 'ente', 'lang', 'porte', 'lyph', 'aph', 'Court', 'Wu', '条', 'onel', 'Motor', 'ober', 'egründ', 'bernate', 'ocy', 'stor', 'lac', 'Ros', 'twice', 'UR', 'ok', '\\x00', 'Ρ', 'Convert', 'う', 'SD', 'ุ', 'ulaire', 'Lang', 'poste', 'blue', 'DE', 'ster']\n",
      "in Layer31 , sorted_indices_dimension7384:  ['interest', 'text', 'Interest', 'dispar', 'Response', 'Response', 'session', 'Session', 'text', 'nie', 'Text', 'tut', 'press', 'cite', 'session', 'interested', 'respons', 'stadt', 'Oper', 'st', 'texture', 'respond', 'response', 'interests', 'terms', 'utter', 'opera', 'ensch', 'texts', '線', 'essions', 'response', 'osto', 'omena', 'тек', 'Text', 'nu', 'effic', 'rei', 'respond', 'operator', 'operators', 'ser', 'asp', 'Rub', 'Wik', 'Office', 'Gemeinsame', 'onymes', 'Paint', 'imper', 'buch', 'txt', 'select', 'operator', 'Ign', 'zych', 'gor', 'textarea', 'panel', 'erm', 'wig', 'Label', 'Verb', 'selected', 'class', 'tun', '例', 'studio', 'font', 'sample', 'Imper', 'opt', 'ici', 'icht', 'arter', 'vie', 'etwork', 'liber', 'Queensland', 'Stanis', '食', 'verk', 'tradu', 'trim', 'sessions', 'Oper', 'jure', 'Studio', 'fragment', 'ser', '音', 'responses', 'modal', 'ui', 'vendor', 'respons', 'TEXT', 'iter', 'ell', '打', 'INE', 'pian', 'ye', 'diagonal', 'arte', '�', 'ael', 'male', 'Press', '手', 'Layer', 'paint', 'label', 'ellan', 'guer', 'terme', 'touch', 'ground', 'tät', 'que', 'Rein', 'vend', 'Sample', 'male', 'zer', 'modal', 'powiat', 'Session', 'Sample', 'ines', 'iero', 'хе', 'tone', 'gminy', 'Chamber', 'parl', 'ine', 'Term', 'oman', 'Son', 'intér', 'oper', 'vid', '�', 'liberal', 'touched', 'Hand', 'се', 'Texture', '�', 'ab', 'room', 'Press', 'appe', 'interesting', 'iek', 'ted', 'perspective', 'ott', '雄', 'growing', 'txt', 'iera', 'room', 'vocal', 'egg', '\\x0b', 'oper', 'trem', 'Testament', 'Opt', 'font', 'Liber', 'Room', 'Anders', 'striking', 'nitz', '智', 'Class', 'este', 'Office', 'inter', 'Sender', 'strugg', 'eleg', 'tong', 'ells', 'ℓ', 'lac', 'eggs', 'Opt', 'Opera', 'Secret', 'Cook', 'це', 'Liberal', 'Asp', 'eye', 'intellig']\n",
      "len(values_id):  32\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "E = mt.model.get_output_embeddings().weight.detach() \n",
    "model_state_dict = mt.model.state_dict()\n",
    "#print(model_state_dict)\n",
    "\n",
    "ix = 0\n",
    "top_k=200\n",
    "\n",
    "for key, values in model_state_dict.items():\n",
    "    if 'mlp.down_proj' in key:\n",
    "        #print(f\"Key: {key}, Values: {values}\")\n",
    "        print(f\"Key: {key}\")\n",
    "        values_map = values.T.matmul(E.T)        \n",
    "        if len(list_common_nums[ix]) != 0:\n",
    "            for item in list_common_nums[ix]:\n",
    "                _, sorted_indices_item = torch.sort(values_map[item,:], descending=True) \n",
    "                #print('values_map[item,:]: ',values_map[item,:])\n",
    "                values_map_softmax = F.softmax(values_map[item,:], dim=0)\n",
    "\n",
    "                #entropy = torch.sum(values_map[item,:] * torch.log2(values_map[item,:]))\n",
    "                #print('entropy: ',entropy)\n",
    "                \n",
    "                sorted_indices_item = sorted_indices_item.cpu().numpy()\n",
    "                print(f'in Layer{ix} ,', f'sorted_indices_dimension{item}: ',[decode_tokens(mt.tokenizer, [i])[0] for i in sorted_indices_item[:top_k]])\n",
    "        ix +=1    \n",
    "        \n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        # 22 层 7411 6850\n",
    "        # 23 层 2714, 6014\n",
    "        if '22' in key:\n",
    "            _, sorted_indices7411 = torch.sort(values_map[7411,:], descending=True) \n",
    "            _, sorted_indices6850 = torch.sort(values_map[6850,:], descending=True)  \n",
    "\n",
    "            sorted_indices7411 = sorted_indices7411.cpu().numpy()\n",
    "            sorted_indices6850 = sorted_indices6850.cpu().numpy()\n",
    "\n",
    "            print('top_k_preds7411: ',[decode_tokens(mt.tokenizer, [i])[0] for i in sorted_indices7411[:120]])\n",
    "            print('top_k_preds6850: ',[decode_tokens(mt.tokenizer, [i])[0] for i in sorted_indices6850[:120]])\n",
    "\n",
    "\n",
    "        if '23' in key:\n",
    "            _, sorted_indices2714 = torch.sort(values_map[2714,:], descending=True) \n",
    "            _, sorted_indices6014 = torch.sort(values_map[6014,:], descending=True)  \n",
    "\n",
    "            sorted_indices2714 = sorted_indices2714.cpu().numpy()\n",
    "            sorted_indices6014 = sorted_indices6014.cpu().numpy()\n",
    "\n",
    "            print('top_k_preds2714: ',[decode_tokens(mt.tokenizer, [i])[0] for i in sorted_indices2714[:120]])\n",
    "            print('top_k_preds6014: ',[decode_tokens(mt.tokenizer, [i])[0] for i in sorted_indices6014[:120]])  \n",
    "        \"\"\"    \n",
    "\n",
    "print('len(values_id): ',len(values_id)) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6048, 10287])\n",
      "tensor(6048)\n",
      "tensor(10287)\n",
      "tensor(1762)\n",
      "tensor(8402)\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([ 6048, 10287,  1762,  8402])\n",
    "print(tensor[:2])\n",
    "for item in tensor:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_act_get_hooks(model, tok_index, mlp=False, mlp_coef=False):\n",
    "    \"\"\"\n",
    "    Works on LLaMA-2\n",
    "    \"\"\"\n",
    "    # Make sure that these are not set to True at the same time \n",
    "    #  so we don't put two different hooks on the same module.  \n",
    "    #assert not (attn is True and attn_out is True)\n",
    "    \n",
    "    for attr in [\"activations_\"]:\n",
    "        if not hasattr(model, attr):\n",
    "            setattr(model, attr, {})\n",
    "\n",
    "    print('tok_index: ',tok_index)\n",
    "\n",
    "    def get_activation(name):\n",
    "        def hook(module, input, output):\n",
    "            if \"m_coef\" in name:\n",
    "                # num_tokens = list(input[0].size())[1]  # (batch, sequence, hidden_state)\n",
    "                #print('output[0].size(): ',output[0].size())\n",
    "                #print('input[0].size(): ',input[0].size())\n",
    "                model.activations_[name] = input[0][:, tok_index].detach()\n",
    "            elif \"m_out\" in name:\n",
    "                model.activations_[name] = output[0][tok_index].detach()\n",
    "        \n",
    "        return hook\n",
    "\n",
    "    hooks = []\n",
    "    for i in range(32):\n",
    "        if mlp_coef is True: #co-effciency\n",
    "            hooks.append(model.model.layers[i].mlp.down_proj.register_forward_hook(get_activation(\"m_coef_\" + str(i))))\n",
    "        if mlp is True:\n",
    "            hooks.append(model.model.layers[i].mlp.register_forward_hook(get_activation(\"m_out_\" + str(i))))\n",
    "            \n",
    "    return hooks\n",
    "\n",
    "def remove_hooks(hooks):\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:  What is Yakuza 2?\n",
      "subject:  Yakuza\n",
      "e_range:  [3, 4, 5]\n",
      "tok_index:  5\n",
      "top_indices:  tensor([[ 5432, 10058,  5899, 10559,  6892, 10693,  4693,  9810,  4355,  6552,\n",
      "          3291,  4238,  6823,   857,    25,  5385, 10704,  5705,  6450,  1926,\n",
      "          9581,  5453,  6732,  3441,  2657,  2066,  6572,  9478,  6072,   912,\n",
      "          7891,  9486,  1261,  6300,  7363,  9150,   497,  8571,  8543,  6248,\n",
      "          9033,  6889,  3455,  9510, 10857, 10875, 10213,  1213,  2774,  1387]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[ 4377,  2069,  7037,  3966, 10957,  7890,  1691,  4299, 10963,  6954,\n",
      "          7507,  4698,  8179,  6540,  5881,  5173,  7348,  2770,  4225,  2045,\n",
      "          8634,  1170,  9014,  8731,  8528,  6933, 10474,  4220,  1837,  5158,\n",
      "          4634,   785,  3839,  1488,  8884,  9350,  5990,  9019,  9124,  7146,\n",
      "         10654,  9154,  3235, 10366,  4842,    69,  5536,  4812,  9675,  9967]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[ 7598,  7378,  8030,  6689, 10641,   873,  2247,  3664,  2703,  6192,\n",
      "          4385,  2950,  1661,  2014,  7774,  1678,  6419,   418,  8177,  4666,\n",
      "          1190,  4568,  7649,  7722,  4837,  4086,  3849,  5038,  8750,  9176,\n",
      "          6367,   798,  6418,   941,   466,  5386,  8396,  2565, 10549,  2490,\n",
      "          6618,  6866, 10061,  9499,  2323,   390,  8085,  1208,  3005,  6856]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[ 7407,  9215,    25,  4714,  3332,  4412,  2810,   156, 10536,   220,\n",
      "          4036,  5168,  9818,  5525,  2012,  8240,  1078,  9827,   392,  9526,\n",
      "          4257, 10538,  8419,  8134,   927, 10133,  8229, 10453,  2313,  7917,\n",
      "          3897,    37,  5304,  3073,  7089,  7615,  9808,  2416,   949,  4377,\n",
      "          4733,    44,  7779,  3633,  6666,  1589,  3291,   538,  1309,  3703]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[ 7382,  8876,  2982,  3919,  1321,  6142,  1961,  5064,  7989,    80,\n",
      "          6439,  5088,  4305,  9070,  1624,  7943,  5126, 10384,   858,  2613,\n",
      "          1757, 10519,  7419,  5894,  3131,  4895,  7487,  5909,  1140,  1886,\n",
      "          3512,  6679,  6725,  4189,  5137,  3497,  5226,  6169, 10100,  5142,\n",
      "          6296,  6766,  2028,  5112,  7659, 10360, 10819,  8867,  2525,  9331]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[ 3672,  1965, 10163,  2624,  5549,   612,  7883,  5848,  5196,  8391,\n",
      "          1407,  6120,  2577,  9501,  5987, 10061,  1824, 10344,  9070,  4237,\n",
      "          6665,  4909,  5687,  8553,  6260,  2236, 10501,  2273,   633,  9224,\n",
      "          2898,  8415,  7185,  9404,  8290,  8633,  8693,  9670,  8888,  6390,\n",
      "          2767, 10393,  2605,  4432,  3056,  5288,  7388,  5013,  9187,  6152]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[ 7558,   484,  7574,  6164,  9125,   717,  5877,  4773,  3723,  6051,\n",
      "          9147,  8765,  8328,  6627,  9105,  6485,  8186,  7131,  9786,  5401,\n",
      "         10222,  5933, 10702,  4229,  8356,  4921,  9890, 10315,  4484,  6589,\n",
      "          1100,  5204,  9400,  5024,  5805,  3513,  9423,  5851,  9987,  9074,\n",
      "          6268,  9053,  8753,  8517,  3679,  9361,  5815,  1159,  3542,  9798]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[ 3654,  4403,  1615,  8544,  9075,  5774,  4196,  4616, 10413,  2169,\n",
      "          2529,  2700,  2812,  9477,  1917,  2422,  1165, 10468,  6223,  7532,\n",
      "          3429,  8441,  8592,  8341,  7407,  1351,  4605,  2238,  1199,  2218,\n",
      "          4950,  6732, 10060,  5331,  9221,  3832,  1773,  3842,  7531,   498,\n",
      "          7584,  9525,  3920,  2699,  7325,  8645,  5826,  8923,  1404,  8511]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[  586,  8650,  9504, 10334,  4407,  8065,   550,   349,  5074,  3697,\n",
      "          3220,  9612,  3527,  5017,  1558,  6248,  5554,   313,  5297,  9777,\n",
      "          2380,  8888,  4829,    80,   985,  8091,  8159,  3353,  7389,  2659,\n",
      "          6849,  5208, 10778,  2067, 10448,  6259,  5292,  8468,  3889,  7236,\n",
      "          5298,  7535,  4973,  4561,  1443,  2930,  6538,  2749,  1939,  6027]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[ 3509,  9797, 10163,  1416,  9144,  8110,  7925,  6908,  6376,  7177,\n",
      "          4251,  9470, 10801, 10836,   557,  2946,  1983,  1948,  7918,   438,\n",
      "          5425, 10708,  7233,  1063, 10732,  6773, 10598,  3678,  8573,   320,\n",
      "          8625,   526,  9818,  3392,  9228,  4570,  3781,  7390,  5757, 10050,\n",
      "          8653,  2348,  1677,  5903,  8447,   326, 10358,  5133,  6476, 10238]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[ 1853,  1605,   475,  6985,  7630,  5727,  2847,  9502,  1191,  7765,\n",
      "           780,  5946,  6042,  5839,  7360,  1232, 10252,  3410,  7571,  1926,\n",
      "          1009,  4357,  2633,  8286, 10196,  1170,  7029,  3931,  1661,  3779,\n",
      "          9238,  4568,  7601,  7181,  5391,   471,  8545,  9457,  3252,  6707,\n",
      "            49,  9065,  8809,  3614,   221,  7052,  5687,  1079,  9831,  7281]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[ 2502,  4230,  1924,  9370,  8721,  2187,  1886,  9576,   156, 10494,\n",
      "          5233,  6865,  7499,  9512,  2242,  7209,  3723,  3445,  7516,  8710,\n",
      "           112,   927,  3489,  7601,  5480,  8855, 10779,  3682,  6407,  6914,\n",
      "          4981,  1480,    62,  3707,  9355,  5774,  6773,  5821,  6324,  3709,\n",
      "          9554,  2691,  3097,  7541,  6510,  3994,  4508,   724,  9791,  7104]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[ 9010,  7710,  5124,  4196, 10135,  6825,  2842,  7696, 10266,  8266,\n",
      "          6843,  6425,  2835,   608,  4009,  6653,  5082, 10447,  5242,  5260,\n",
      "          7068,  7229,  7313,  4051,   823,  2467,  8219,  7483,  8316,  7497,\n",
      "          7257,  7050,  5489,  2591,  1207,  2407,  4012,  4203,    42,  2449,\n",
      "         10080,  1888, 10669,  7060,  7120,  6784,  5598,  7062,  6166,  1434]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[ 9001,  5910, 10248,  4762,  9893,  1603,  1016,  4453,   688,   330,\n",
      "          8790,  3051,  1248,  5415,  7315,  6245,  4329,  8065,  2428,  1733,\n",
      "         10775,  2286,  5751,  2246,  9602,  7276,  7047,  6941,  9727,  2922,\n",
      "          4738,  7584,  3288,  7879, 10801,  1101, 10677,  3370,  1155,  6115,\n",
      "          4200,  6610,  1163,  6853,   226,  5540,  1944, 10906, 10172,  2526]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[ 3230, 10071,  1488,  7079,   674,  9313,   650,  9488, 10950,  3792,\n",
      "          4908,  1182,  6995,  7794,  2243, 10553,  5806,  3246,  9390,  6495,\n",
      "          1165,  2550,  7598,  6969, 10359,  8112,  1512,  6976,  2436,  4313,\n",
      "          9732,   470,  3897,  2764,  5907,  4048,  5048,  9875,  4825,  5285,\n",
      "          1108,  7618,  6898,  9987,  1387,  5275, 10914, 10244,  3126,   274]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[ 2079,  9857,  5790,  7956,  5470,   698,  2937,  9335,  9485,  1718,\n",
      "          8460,  9470,  3147, 10786,  4701, 10952,  1234,  2224,  8620, 10269,\n",
      "           406,  1363,  6238,   631,  4425,  8680,  1757,  6445,  8701,  6656,\n",
      "          6328, 10024,  2139,  2249,  4557,   614,  1154,  3944,    38,  8354,\n",
      "          9859,  2779,  8102,  2471,  2629,  2707,  8219,   632,  1161,  6571]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[ 3026,  2441,  8945,  9520,  7503,  1253,  5861,   553,   167,  4180,\n",
      "          8572,  8526,  5797,  9818,  5810,  2877,  1958,  8280, 10110, 10877,\n",
      "           358,   825,  5147,  8596,  5478,  2372,  9172,  5513, 10392, 10507,\n",
      "          5297,  5369,  4758,  5113,  7040,  3353,  7238,  7437,  3936,   492,\n",
      "          2117,  1360,  7300,  5453, 10601,  3760,  5129,  2267,  8310,  8581]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[  942,  8524, 10540,  7805,  6966,  3529,  8792,  2229,  9976,  4839,\n",
      "          3910,  4848,  3347,  1028,  2561, 10201,  3772,  4732,  5681,  5326,\n",
      "          7181,   843,  1938,  7398,   946,  3631,  4749,  3849, 10383, 10122,\n",
      "          9276,  8515,  2422,  5839,  3863,  2103,  4279,  2600,  6686,  9104,\n",
      "          9955,  7862,  1908,  1200,  5304, 10158,  6404, 10498,  1085,  6226]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[ 1601,  3351,  7831,  6546,  8832,   829, 10830, 10275,  5222,  8765,\n",
      "          9572,  1135,  4898,  8981,  2097,  7079,  9673,  2039,  2119, 10242,\n",
      "           228,  1410,  8536,  3263,  7004,  3124,  6914,   443,  7766,  2277,\n",
      "          2917,  3144,  3169,  3494,  3939,  3417,  7596, 10169,  2847,   636,\n",
      "          7115,  4908,  5386, 10466,  7500,  9191,  9398,  8617,  4660,  7806]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[ 4550,  4590,  7348,  9198,  9550,  9484,  8393,  6415, 10218,  5926,\n",
      "          1013,  5960,  4004,  9696,  7471,  9525,   588,  4047,  2306,  1266,\n",
      "          8383,  2921,  8362,  6203,  7601,  5335,  6569,  7835,  1821,  5786,\n",
      "          3220,   228,   841,  6170,  2428,  2284,  8681,  7649,  7431,  3370,\n",
      "          2620,  4873,  9979, 10737,  5775,  2862,  5140,  6015,  9099,  4536]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[ 2306,   989,   871,  6335,  3662, 10006,  2498,  6935,  1203,  7695,\n",
      "          9905,  4831,  1299,  9219,  2399,  4781,  3208,  5018,  3089,   177,\n",
      "          4201,  6638, 10982,  8638,  2859, 10144,  4925,  9973,  5505,  3210,\n",
      "          2573,  7405,  4295,  8709,  1050,  9346,  1370,  7216,  7350, 10647,\n",
      "          2459,  8525,   226,  2768,  8693,  2621,  9775,  5344,  6552,  7566]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[ 8590,  9790, 10458, 10827,  8611,  1169,  6749,  2091,  8972,  5258,\n",
      "          4457, 10501,  4016,   551,  1210,  9094,  2882,  6605, 10054,  8373,\n",
      "          5314,  9470,  7424,  4000,  4671,  1335,  7797,  1982,  1766,  2728,\n",
      "         10699,  7651,  3517,  4849,  6278,  4344,  8947,  3312,  2872,  8442,\n",
      "          3894,   428, 10189,  4488,   800,  4896,  9728,  7689,   780,  8008]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[ 1269,  1336,  4543,  6080,  6710,  7282, 10242,  2940,  5102,  1570,\n",
      "          4075,  2271,   487,  1281,  9414,  8930,  4161, 10891,  7140,  3317,\n",
      "          1268,  2945,   754,  4635,  8467, 10066,   933,   491,  2545,  4684,\n",
      "          8897,  5719,  4441,  2509,  8016, 10984,  4124,  4013,  4215,  2777,\n",
      "          4309,  1375,  3197,  5316,  6108,  8678,  7186,  3009,  7376,  1807]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[ 7160,  7780,  6518,  2381,  1421,  7785,  9258,  8457,  8035,  9586,\n",
      "          9960,  9439,   947,  2923, 10688,  2343,  8226,  6541,  5166,  5558,\n",
      "          5424,  3540,  8437,  6418,  2137,  5980,  7145,  8708,  7547,  2005,\n",
      "          8812,  5292,  1752,    65,  6013,  7539,  8416,  1044,   152, 10085,\n",
      "          8668,  1640,  1571,  7454, 10008,  1997,  6632,  6096,  7008,  9582]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[10019,  2791,  9557,  6643,  1734,  6157,  8734,  6969,  5838,  1526,\n",
      "          2449,  9704,  2269,  8956,  4002,  5095,  5229,  8171,  4397,  1404,\n",
      "          2617,  6137,  6984, 10654,  3343,  7782,  1405,  1612,  4172,  5318,\n",
      "          4075,  8274,  5081,  6305,  6941,  8605,  8422,  8523,  2713, 10617,\n",
      "           318,  6553,  5026,  2678,   577,  2523,  4671,  5490,  8632,  6817]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[ 8741,  1711, 10288,  5581,  6231,  5547,  9139,  2891,  9511,  5543,\n",
      "          7478,  9482,  8863,  9058,  8954,   862,  8310,  2294,   622,   831,\n",
      "          9903,  5892,  4462,  4623,  5163,  4078, 10002, 10625,  6382,  4609,\n",
      "          2300,  3398,  1193,  3169, 10269,    73,  3430,  8615, 10202,  4397,\n",
      "         10182,  4420,  8001,  4876,  9114,  1482,  7369,  5490,   596, 10465]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[ 1114,  6496,  7419,  7752,  7093,  5192,  7979,  1031,  7788,   212,\n",
      "          5094,  1831,  6161,  1613,   639,  7693,  4743,  9543,  9998,  8531,\n",
      "          7651,  5431,  3590,  9691,  2962,  3621,   863,  3276,  6030,   555,\n",
      "          4478, 10544,   394,  3032, 10920,  9444,   309,  5582,  1354, 10757,\n",
      "          6508,  9639,  4084,  8078,  1288, 10685,  2687,  9535, 10889,  5180]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[  509,  9520,  1708,  8476,  7739,  8816,  1468,  7250,  9483,  8895,\n",
      "          2179,   654,  9192,  9485,  1201, 10191,   772,  9170,  4110,  4398,\n",
      "          8767,  8941,  5595,  3374,   856,  3818,   456,   743, 10285,  8586,\n",
      "          5375,  9274,   821,   789,  1392,  3010,   749,  9680,  7369,  3845,\n",
      "           938,  4713,  3537,   572,  8971,  2057,   149,   762,  5004,   806]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[ 7406,  9871, 10575,  6788,  4282, 10432,   927,  5738,  2055,  5206,\n",
      "          8625,  1067,  2520,  2333, 10835,  4886,   725,  6910,  6967,  7033,\n",
      "          2779,  9323, 10072, 10117,  8231,   283,  5532,  4001,  3685, 10763,\n",
      "          7016, 10658,  8015,  9236,  2584,  9287,  2223,  2102,  6516,  8552,\n",
      "          7580,  8365,  3597,  9797,  8560,  8042,  1472,  9663,  9003, 10232]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[ 9557, 10252,  8669,  8028, 10012,    20,  6187,  6988,  6433,  6201,\n",
      "          6849,  7620,  6499, 10098,  5237,  8612,  5589,  6171,   266,  5862,\n",
      "           897,  8622,  1138,    43,  6128,  9163,  6107,  4398,  4367, 10740,\n",
      "          2352,  3523,  1773,  7856,  6606,  6703,  8123,  3568,  5571,  6353,\n",
      "          7085,  9490,   496,  1272,  9322,   143,  5192,  4105,  7235,  7162]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[ 4131,  3523,  6552,  8425,   615,  3459,  4382,  9316,  9539,  6506,\n",
      "          4264,  3182,  6283,  6211,  4339,  4942,  1063,  7131,  3813,  4960,\n",
      "          1034,  6432, 10824,   445,  9152,  3733,  1709,  7850,  4045,  6970,\n",
      "          2511,  6537,  1835,  1174,   697,  5714,  6825, 10445,  9823,   314,\n",
      "          6265,  5019,  3274,  5372,  3678,  3354,  6482,  9005,  7387,  2188]],\n",
      "       device='cuda:0')\n",
      "top_indices:  tensor([[ 9439,  6802,  1836, 10054, 10241,  6515,  6977,  9204, 10762,  8497,\n",
      "           632,  3416,  8301,  8580,  3152,  8758,  5908,  5202,  3607,   698,\n",
      "          9122,  5818,   485,  2440,  8733,  1638,  8697,  1587,   545,  4260,\n",
      "          5410, 10701,  5302,  4426,  8781,  9571,  4316,  6232,  7614,  5318,\n",
      "          4173,  9010,  3644,  6362,  4236,  3596,  4750,  7995,  4143,  2391]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "k = 200\n",
    "records = []\n",
    "layers_to_cache = list(range(32))\n",
    "\n",
    "prompt = \"What is Yakuza 2?\"\n",
    "subject = \"Yakuza\"\n",
    "\n",
    "# prompt = \"What is Hello Kitty?\"\n",
    "# subject = \"Kitty\"\n",
    "\n",
    "print('prompt: ',prompt)\n",
    "print('subject: ',subject)  \n",
    "\n",
    "inp = make_inputs(mt.tokenizer, [prompt])\n",
    "e_range = find_token_range(mt.tokenizer, inp[\"input_ids\"][0], subject)\n",
    "e_range = [x for x in range(e_range[0], e_range[1])]\n",
    "\n",
    "print('e_range: ',e_range)\n",
    "source_index = e_range[-1]  #subj_last\n",
    "\n",
    "hooks = set_act_get_hooks(mt.model, source_index, mlp=True, mlp_coef=True)\n",
    "output = mt.model(**inp, output_hidden_states = True)\n",
    "remove_hooks(hooks)\n",
    "\n",
    "for layer in range(32):\n",
    "    positions = [(e_range[-1], f\"subj_last_{layer+1}\"),]\n",
    "    for (position, desc) in positions:\n",
    "        \n",
    "        hs = output[\"hidden_states\"][layer+1][0][position]\n",
    "        #print('hs: ',hs)\n",
    "        projs = hs.matmul(E.T).cpu().numpy()\n",
    "        ind = np.argsort(-projs)  #这个是倒叙排列的意思\n",
    "\n",
    "        #print('hs.shape: ',hs.shape)\n",
    "\n",
    "        records.append({\n",
    "            \"subject\": subject,\n",
    "            \"layer\": layer,\n",
    "            \"position\": position,\n",
    "            \"desc\": desc,\n",
    "            \"desc_short\": desc.rsplit(\"_\", 1)[0],\n",
    "            \"top_k_preds\": [decode_tokens(mt.tokenizer, [i])[0] for i in ind[:k]], #这个是倒叙排列后取前k个映射到的词\n",
    "        })\n",
    "\n",
    "    output_mlp_coef = mt.model.activations_[f\"m_coef_{layer}\"]\n",
    "    _, top_indices = torch.topk(output_mlp_coef, k=50)\n",
    "    print('top_indices: ',top_indices)\n",
    "    \n",
    "    #_, sorted_indices_item = torch.sort(output_mlp_coef, descending=True) \n",
    "    \n",
    "    output_mlp = mt.model.activations_[f\"m_out_{layer}\"]\n",
    "    projs_mlp = output_mlp.matmul(E.T).cpu().numpy()\n",
    "    ind_mlp = np.argsort(-projs_mlp)  #这个是倒叙排列的意思\n",
    "    #print(f'mlp_projections_{layer}: ',[decode_tokens(mt.tokenizer, [i])[0] for i in ind_mlp[:k]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tmp = pd.DataFrame.from_records(records)\n",
    "\n",
    "\n",
    "            \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   ['.', 'in', '(', ',', '…', '\\n', 'to', '…', 'for', '', '!', 'as', 'and', 'a', 'on', 'today', 'at', 'is', '-', 'with', ':', 'set', 'de', 'I', 'by', '-', 'o', 'has', 'A', 'Wikipédia', '/', 'idenote', 'ir', 'use', 'of', 'R', 'tail', 'if', 'Cl', 'latest', 'new', 'ac', 'suit', 't', 'stat', 'kn', 'tip', 'aire', 'among', '–', 'g', 'r', 'C', 'id', 'opt', 'autom', 'ast', '\"', 'Mexican', '=', '_', 'k', 'offer', '(', 'across', '[', 'end', 'f', 'far', 'simultaneously', 'Lat', 'Bir', 'en', 'resistance', 'пута', 'ña', '务', 'optical', 'wh', 'ens', 'may', 'hely', 'Christ', 'closure', 'op', '..', 'orth', 'wire', 'e', 'found', '|', 'vs', 'statement', '...', 'Ath', 'aer', 'beyond', 'c', 'F', 'al', 'nico', 'es', 'added', 'relationship', 'concept', 'one', 'joint', 'number', 'SG', 'Mag', '!!', 'versus', 'pair', 'eng', '瀬', 'physical', 'тельно', 'reci', 'focused', 'B', 'ann', '’', 'break', 'bolds', 'Ag', 'üge', 'reported', 'female', \"'\", 'ex', 'Opt', 'Stat', 'ϊ', '张', '\\u202d', 'des', 'bet', 'zat', 'ill', 'Foot', 'place', 'beta', 'intelligence', 'utility', 'ere', 'of', 'exercise', 'i', 'visual', 'T', 'Category', 'not', 'put', 'Pat', 'serving', 'start', 'ideal', 'ɫ', 'w', 'Am', 'future', 'int', 'un', 'Mechan', 'rig', 'offering', 'auto', 'Past', 'sl', 'you', 'Gott', 'inner', 'Latin', 'ra', 'under', 'computer', 'Bras', 'G', 'mechanical', 'j', 'Bre', 'off', 'Foot', 'sample', 'de', 'clos', 'w', 'Hel', 'H', 'gra', 'aff', 'Dit', 'h', 'aj', 'u', 'basket', 'fast', 'max', 'hard', 'per']\n",
      "1   ['opt', '\\n', 'latest', 'тельно', 'тель', 'de', 'VP', 'un', 'en', 'ót', '.', 'temp', 'Pat', 'irregular', 'aire', 'ün', 'ac', 'far', 'set', 'al', 'a', 'in', 'present', 'end', 'ir', 'Bras', 'f', 'kn', 'Bir', 'Hel', 'Cl', 'k', 'idenote', 'etter', 'id', 'Mechan', 'ens', 'tail', 'eng', 'ña', 'impl', 'eng', 'pat', 'culture', 'door', ',', '…', 'far', 'aff', 'es', 'est', 't', 'Rest', 'mic', 'clos', 'ļ', 'ema', 'anse', 'üge', 'inher', 'optical', 'ap', '⁻', 'ince', 'L', 'RelativeLayout', 'En', 'wa', 'on', 'arr', 'Iron', 'cult', '话', 'latest', 'intellect', 'pi', 'rest', 'ide', 'wire', 'ï', 'bore', 'ping', 'injection', 'ên', 'vare', 'uno', 'gs', 'ski', 'inner', 'e', 'coal', 'op', 'wh', 'ske', 'usammen', 'resistance', 'kwiet', 'equivalent', 'ñ', 'Dit', 'mechan', 'agg', 'Evangel', 'wh', 'ite', 'Mod', 'iron', 'fly', '┐', 'за', 'Tel', 'esz', 'pen', 'Opt', 'Cult', 'already', 'female', '…', 'hard', 'Par', 'Apost', 'r', 'iten', 'fon', 'Franklin', 'ұ', 'correspond', 'R', 'ew', 'invited', 'opt', 'Common', 'Hotel', 'tale', 'isson', 'ile', 'фо', 'coll', 'ep', 'trem', 'ma', 'hers', 'ответ', 'dream', 'media', 'endo', 'ide', 'ep', 'unf', 'soft', 'literally', '-', 'def', 'stat', 'rain', 'Bedeut', 'enh', 'story', 'PDF', 'hits', 'aut', 'inject', 'Bra', 'essential', '张', 'interval', 'aj', 'pin', 'Bass', 'мира', 'w', 'all', 'c', 'similarly', 'yours', '拉', 'ske', 'enda', 'gold', 'mechanical', 'Stat', 'adds', 'san', 'SG', 'Mac', 'sig', 'Culture', 'helping', 'ely', 'aks', 'MS', 'placeholder', 'close', 'stycz', 'Eng', 'Cab', 'Op', 'ania', 'Pref', 'Fuß']\n",
      "2   ['inn', 'isson', 'pen', 'es', 'opt', 'Pat', 'e', 'unf', 'iness', 'pat', 'door', 'Hel', 'Mechan', 'Aut', 'intellect', 'ique', 'Bir', 'nos', 'fuel', 'interval', 'Pres', 'ên', 'aran', 'ee', 'Shah', 'VP', 'attend', 'Log', 'est', 'aer', 'Bé', 'ac', 'innoc', 'ury', 'pole', 'deser', 'ebook', 'wa', 'за', 'resistance', 'hers', 'lands', 'pens', 'Opt', 'mechan', 'Oct', 'Schmidt', 'aire', 'exactly', 'stir', 'injection', 'undert', 'ara', 'Pen', 'Mag', 'Arnold', 'sharp', 'Kn', 'sent', 'Gall', 'silent', 'Sept', 'Hotel', 'eme', 'фо', 'needed', 'evangel', 'istan', 'aram', 'already', 'cookies', 'an', 'pointer', 'rural', 'дии', 'exact', 'enum', 'кан', 'aut', 'Opt', 'gra', 'gan', 'Iron', 'identical', 'Const', 'nose', 'registered', 'iron', 'ót', 'OIN', 'hotel', 'inho', 'reform', 'de', 'moment', 'ville', 'ema', 'rial', 'Bra', 'Ans', 'Mark', 'pi', 'opt', 'PDF', 'дия', 'Bras', 'eq', 'Inn', 'hes', 'ott', 'dict', 'Big', 'eu', 'optim', 'ir', 'тель', 'witz', 'Orleans', 'ely', 'лан', 'pen', 'endpoint', 'eman', 'HMS', 'en', 'Aer', '得', 'об', 'unique', 'tail', 'inject', 'helping', 'ï', 'latest', 'san', 'attended', 'latest', 'Mod', 'tower', 'Culture', 'org', 'dump', 'o', 'otta', 'y', 'mand', 'dfs', 'sh', 'струк', 'mechanism', 'kn', 'feed', 'Ma', 'Mass', 'pol', 'оп', 'Des', 'Hel', 'ik', 'ire', 'festival', 'Or', 'ide', 'following', 'arr', 'oman', 'ismo', 'advent', 'apro', 'iri', 'Mac', 'Mand', 'forum', 'irregular', 'blank', 'ovis', 'oauth', 'train', 'ene', 'edo', 'necessity', 'ahn', 'FO', 'enum', 'Evangel', 'toler', 'subs', 'Shang', 'presiden', 'yr', 'omen', 'inherit', 'rode', 'finish', 'Break', 'лий', 'зин', 'inher', 'iate', 'Tib']\n",
      "3   ['door', 'inn', 'heck', 'VP', 'wa', 'unf', 'pat', 'aram', 'Pascal', 'forth', 'pen', 'es', 'mand', '\\n', 'pi', 'el', 'omb', 'aer', 'arr', 'fir', 'Aer', 'ara', 'header', 'Salv', 'at', 'portal', 'Ans', 'Const', 'Hotel', 'Mand', 'iks', 'arn', 'dur', 'amount', 'aran', 'attend', 'fen', 'dfs', 'meaning', 'President', 'Pat', 'Mi', 'тель', 'hotel', 'ido', 'Norway', 'ên', 'iron', 'ir', 'Vol', 'in', 'Toul', 'Hel', 'nos', 'Nik', 'invol', 'door', 'ast', 'equal', 'Nelson', 'ott', 'subs', 'Reb', 'opt', 'yc', '.', 'Sin', 'kn', 'wire', '|', 'orr', 'Mod', 'foot', 'Bez', '-', 'reb', 'ac', 'оп', 'A', 'Iron', 'dump', 'gra', 'freedom', 'Prime', 'Ag', 'nar', 'ahn', 'mir', 'ill', 'eu', 'subt', 'fund', 'Rest', 'ill', 'folk', 'plans', 'aur', 'witz', 'stir', 'undert', 'exact', 'Bir', 'heading', 'gun', 'mov', 'an', 'starting', 'erie', 'тери', 'hs', 'Mechan', 'Aut', 'DT', 'glass', 'Inn', 'Ts', 'moment', 'sin', 'qa', 'de', 'Klaus', 'rest', 'otta', 'iness', 'ik', 'flexible', 'cab', 'whis', 'eq', 'tower', 'targets', ',', 'cookies', 'ic', 'o', 'Nell', 'const', 'Newton', 'stal', 'propos', '2', 'chief', 'sharp', 'am', 'ider', 'és', 'obser', 'IR', 'Mark', 'mount', 'refuge', 'or', 'pens', 'Tony', '0', '(', 'Clement', 'literature', 'needed', 'Bras', 'Nova', 'a', 'market', 'her', 'in', 'ziel', 'ely', 'cool', 'onderwerp', 'capt', 'series', 'fiddle', 'Bé', 'Pen', 'registered', 'era', 'invari', 'us', 'Op', 'Shah', 'за', 'golf', '关', 'ilar', 'ser', 'bum', 'prov', 'start', 'LAB', 'ram', 'urre', 'amba', 'esar', 'orb', 'pol', 'target', 'Roland', 'are', 'lement', 'elta']\n",
      "4   ['\\n', '(', 'in', '.', 'Rest', 'Hotel', 'es', 'Taylor', 'rest', 'Gilbert', 'heck', 'President', 'exact', 'Pascal', '果', 'Toul', 'uno', 'тель', 'opt', 'door', 'hole', 'fen', 'VP', 'ite', ',', 'rest', 'suit', 'stal', 'оп', 'Rest', 'проф', 'refuge', 'portal', 'aer', 'meaning', 'o', 'tun', 'hotel', 'ên', 'PM', 'Trace', 'and', 'és', 'Ans', 'delta', 'qa', 'ic', 'well', 'plans', 'Pin', 'ottom', 'inn', 'tens', 'Verm', 'SV', 'ppa', 'at', 'PT', 'pla', 'gebied', 'ir', 'pin', '…', 'onderwerp', 'ziel', 'pointing', 'み', 'pen', 'beskre', 'pi', '-', 'Mod', 'unf', 'hero', 'мы', 'cult', 'propos', 'Aer', 'TS', 'pens', 'Hero', 'or', 'literature', 'PN', 'aram', 'Newton', 'Tower', 'ora', 'Ada', 'mirror', '!', 'needed', 'livre', 'sv', 'Const', 'candidate', 'ství', 'fitting', 'fe', 'op', 'Health', 'pin', 'war', 'may', 'san', 'pur', 'ˇ', 'raised', 'ęż', 'ASCII', 'leading', \"'\", 'innoc', 'conseil', 'Tun', 'tower', 'reflect', 'isis', 'app', 'ERR', 'Hel', '’', 'LAB', 'gan', 'adapt', 'safely', 'history', 'dro', 'Fern', 'L', 'forth', 'tail', 'aur', 'Ernst', 'Jun', 'HC', '\\u2060', 'gra', 'advent', 'fran', 'goods', 'on', 'ätten', 'plain', 'stat', 'ott', 'aran', 'prüfe', 'invol', 'or', '/', 'fl', 'anten', 'mass', 'ppi', 'Salv', 'Vol', 'states', 'Cal', 'Lib', 'inv', 'IR', 'us', 'War', 'interpretation', 'pla', 'pol', 'én', 'finger', 'searching', 'обо', 'delta', 'provinces', 'iron', 'flexible', 'Xcode', 'arn', 'Pi', 'chief', 'Ten', 'Rewrite', 'äu', 'middle', 'Ps', 'dropped', 'do', 'culture', 'header', 'Sto', 'j', 'Hoff', 'tha', 'Free', 'Pat', 'becoming', 'DK', 'ac', 'accompan', 'Des', 'альбо']\n",
      "5   ['\\n', '(', 'Pascal', 'ite', 'in', '.', 'hole', 'SV', 'meaning', 'nar', 'uno', 'ites', 'ziel', 'heck', 'exact', 'én', 'mir', 'Einzeln', ',', 'gan', 'worth', 'ppi', 'rest', 'es', 'Référence', 'portal', 'Rest', '果', 'み', 'hotel', 'Hotel', 'or', 'Ps', 'fen', 'font', 'pla', 'Taylor', 'and', 'VP', 'Mir', 'suit', 'President', 'ĭ', 'sv', 'org', 'aur', 'unf', 'ic', 'PT', 'o', 'Verm', 'bunch', 'gra', 'Pin', '曲', 'Toul', 'isis', 'Font', '/', 'ţ', \"'\", '…', 'pla', 'тель', 'sh', 'Jun', 'ęż', 'font', '’', 'mirror', 'ℚ', 'quelle', 'mud', 'Morgan', 'bash', 'Health', 'nik', 'esc', 'ên', 'Trace', 'subt', 'Pierre', 'む', 'footer', 'dfs', 'apt', 'ok', 'sl', 'pure', 'Bedeut', 'health', 'refuge', 'ono', 'apk', 'stal', 'san', 'Gilbert', 'Museum', 'mic', 'оп', 'water', 'aer', 'pin', 'mand', 'iny', 'participation', 'mu', 'pt', 'hein', 'pur', 'PM', 'мы', 'target', 'dro', 'Nar', 'fitting', 'discrete', 'tun', 'opt', 'museum', 'paździer', 'estaven', 'ót', 'pair', 'hnen', 'Mod', 'well', 'delta', 'LAB', 'prüfe', 'за', 'Schloss', 'pin', 'states', 'war', 'literature', 'L', 'cic', 'series', 'flexible', 'рев', 'Const', 'needed', 'rest', 'Pla', 'performance', 'проф', 'ppa', 'dur', 'ství', 'Dynam', '월', 'Staaten', 'ac', 'hospital', 'ir', 'ante', '╬', 'Hinweis', 'of', 'fran', 'fly', 'book', 'fest', 'uß', 'qa', 'DK', 'candidate', 'lei', 'sem', '１', 'Hoff', 'any', 'foot', 'fer', 'becoming', 'fe', 'wire', 'hit', 'pie', 'arr', '™', 'secret', 'ula', 'const', 'kwiet', 'Rest', 'D', 'ASCII', 'do', 'y', '…', 'conseil', 'pointing', 'chief', 'ast', 'M', 'lod', 'gebied', 'Ḩ']\n",
      "6   ['\\n', 'unf', 'Pascal', '(', 'SV', 'in', 'ites', 'esc', 'ite', 'exact', 'es', 'fest', 'meaning', 'suit', 'み', 'ziel', 'or', 'ic', 'dro', 'én', 'tun', 'és', 'uno', 'const', 'sv', 'hole', 'stal', 'culture', 'Mi', 'do', 'ante', ',', 'pk', 'heck', 'LAB', 'PT', 'dropped', 'fen', 'uten', 'supp', 'оп', 'and', 'esp', 'loose', 'series', 'pla', 'chief', 'thin', 'ures', 'collection', 'Culture', 'us', '/', 'apt', 'cic', 'pt', 'President', 'iny', 'ppa', 'worth', 'ité', 'D', 'Cic', 'war', 'igs', 'sto', 'flexible', 'Turkey', 'мы', 'rest', 'px', 'nar', '打', 'ism', 'kwiet', 'execution', 'proxy', 'Bro', 'rest', 'fig', 'р', 'Cal', 'об', 'pure', 'Pat', 'Référence', 'тель', 'and', 'ozzá', 'hit', 'o', 'mirror', 'o', 'bunch', 'hotel', 'lab', 'pp', 'subt', '…', 'upper', 'lei', 'Mir', 'û', 'T', 'Culture', 'pla', 'Bald', 'ASCII', 'museum', 'det', 'ok', 'ppi', 'el', 'propos', '�', 'differential', 'bash', 'Wikip', '题', 'sh', 'gan', 'ins', 'ství', 'тур', 'sten', 'ccess', 'Gib', 'RED', 'Rest', 'livre', 'Pin', 'book', 'aur', 'Mur', '.', 'manuscript', 'needed', 'èn', 'sem', 'foot', '정', 'opt', 'Trace', 'om', 'Gilbert', 'pie', 'participation', '曲', 'quelle', 'ast', 'innoc', 'Const', 'ên', 'isme', 'posa', 'geb', 'Pas', 'conseil', 'literature', \"'\", 'Tib', 'proposal', 'Academy', 'const', 'Tor', 'flo', 'am', 'Fernando', 'Hotel', '�', 'language', '1', 'igli', 'мель', 'men', 'cloud', 'anten', 'randomly', 'pur', 'nik', 'Hat', 'turned', 'L', 'fic', 'oldest', 'serie', 'frequent', 'verband', 'alia', 'lect', 'iten', 'uß', 'jud', 'freedom', 'water', 'cult', 'schema', 'líder', 'M', 'u']\n",
      "7   ['\\n', '(', 'Pascal', 'ante', 'Bedeut', 'ppi', 'ism', 'meaning', 'pt', 'Wikip', 'Bro', 'Référence', 'RED', 'and', 'in', ',', 'us', 'iten', 'SV', 'uten', 'worth', 'and', 'pp', 'ites', 'ins', 'dro', 'én', 'or', '/', 'ok', 'rai', 'at', 'foot', 'Font', 'o', 'schema', 'pure', 'ité', 'Frank', 'continu', 'PT', 'lei', 'és', 'dropped', 'fest', 'Conf', 'anten', 'Museum', 'quelle', 'fitting', 'ℚ', 'мы', 'heck', 'tör', '.', 'ures', 'hole', 'bro', 'Binary', 'omb', 'DO', '┐', 'foot', 'League', 'exact', 'ite', 'hol', 'Import', '�', 'unf', 'Gemeins', 'fő', 'verband', 'L', 'ру', 'funds', 'suit', 'ic', 'sch', 'Fuß', 'cloud', 'esc', 'language', 'livre', 'const', 'HS', \"'\", 'pur', 'uno', 'museum', 'oss', 'igs', 'D', 'es', 'р', 'DO', 'sv', 'み', 'Fred', 'law', 'do', 'ぶ', 'sten', 'Rest', 'urb', 'oten', 'rc', 'Insel', 'sem', 'Culture', 'use', ')--(', 'ware', 'об', '╬', 'èn', 'basically', 'ang', 'Hinweis', 'dro', 'chief', 'ac', '◦', 'Sax', 'ên', 'def', 'Bro', 'Unity', 'ASCII', 'Hat', '者', '~', 'ßen', 'Logger', 'op', 'accomp', 'тур', 'land', 'era', 'And', 'ęż', 'atem', 'ppa', 'Austin', 'men', 'Bald', 'u', 'accompan', 'j', 'stan', 'frequent', 'randomly', 'за', 'kk', 'ill', 'ccess', 'fancy', 'mirror', 'PA', 'President', 'participation', 'series', 'hit', 'Liver', 'Newton', 'gra', 'are', 'hnen', 'uk', 'det', 'Hotel', 'Play', 'Random', 'fran', 'finally', 'ate', 'Cal', 'тель', 'Mir', 'ziel', 'Weit', 'font', 'a', 'sto', 'û', 'clouds', 'lod', 'freedom', 'pt', 'ór', 'Hob', 'gow', 'muz', 'play', 'cum', 'wur', 'mic', 'org', 'ланд', 'ils']\n",
      "8   ['Bedeut', 'Référence', 'ppi', 'Pascal', 'ante', ')--(', 'ok', 'mir', 'ism', 'Hinweis', 'Bro', 'лия', 'paździer', 'tör', 'Ook', 'succession', 'kwiet', 'Mir', 'mirror', 'us', 'atem', 'Weit', 'op', '~', 'Font', 'én', '\\n', 'об', 'ziel', 'style', 'Wikip', 'meno', 'Bast', 'Conf', 'łów', 'ric', 'ismo', 'Fuß', 'proxy', 'est', 'SV', 'п', 'aso', 'pp', 'isis', 'pez', 'meaning', 'proxy', 'ℚ', 'foot', 'за', 'rai', 'Culture', 'era', 'funds', '┐', 'hol', 'opus', 'urb', 'み', 'coll', 'RED', 'пли', 'ぶ', 'ali', 'uno', 'o', 'lod', 'Mie', 'mob', 'livre', 'frère', 'land', 'lä', 'suit', 'continu', 'ERR', 'men', '(', 'fir', 'pur', 'fur', 'Russell', 'оп', '族', 'тур', 'èn', 'ana', 'unf', 'Pal', 'shoulder', 'esten', 'PASS', 'pin', 'provinces', 'randomly', 'literature', 'Gemeins', 'Einzeln', 'cloud', '⁻', 'font', 'Bro', 'Fred', 'fu', 'ppa', 'basically', 'oss', 'bud', 'museum', 'ware', 'ど', 'ßen', 'DO', 'FT', 'lä', 'dro', 'firm', 'isme', 'ên', 'fő', 'rig', 'Import', 'chief', 'further', 'Logger', 'Fich', 'muz', 'ins', 'commerce', 'fest', 'esser', '~', 'anten', 'Atl', 'quelle', 'mur', 'мы', 'sten', 'agg', 'Einzel', 'culture', 'bro', 'Frank', 'org', 'participation', 'ider', 'schema', 'uria', '�', 'spl', 'raz', 'loose', 'fatt', 'finally', 'igs', 'Fern', 'Central', 'gate', 'accomp', 'thin', 'мп', 'ago', 'house', 'Bald', 'références', 'series', 'named', 'style', 'frü', 'President', 'Lab', 'onom', 'PT', 'prob', 'ft', 'ures', 'Tony', 'iai', 'temporada', 'uri', 'Voll', 'accompan', 'Amsterdam', 'cl', 'Museum', 'season', '╬', 'Liver', 'ć', '⋅', 'Ḩ', 'iso', 'cope', 'central', 'Austin', 'wur', 'ang', 'sem', 'def']\n",
      "9   ['Référence', 'Einzeln', 'paździer', 'kwiet', 'Bedeut', 'Hinweis', 'mir', 'ppi', 'лия', 'rai', 'esser', 'RED', 'Mir', 'łów', '╬', 'ism', 'Culture', 'culture', 'Pascal', 'aur', 'SV', '{#', 'Frank', 'Central', 'mirror', 'suit', 'pur', 'Fuß', 'atem', 'Bast', 'central', 'mob', 'isis', 'isl', 'ante', 'succession', 'ぶ', 'littérature', 'opus', 'ERR', 'cli', '𝓝', 'acker', 'Ruby', 'randomly', 'Font', 'literature', 'unf', 'ric', 'ßen', 'Atl', 'Logger', 'inglês', 'frère', 'ℚ', 'подо', 'cult', 'péri', 'п', 'som', 'ana', 'Russell', 'vest', 'uria', 'Bro', 'Blues', 'frü', 'Weit', 'spl', 'utos', 'és', 'Bevölker', 'QUE', 'Fich', 'men', 'ęż', 'ziel', 'style', 'hnen', 'ên', 'lei', 'Ook', 'livre', 'reflect', 'nom', 'uten', 'ali', 'pin', 'Paz', 'Wikip', 'random', 'op', 'uby', 'urb', 'områ', 'fe', 'Austin', 'foot', 'dots', 'continu', 'stycz', 'lä', 'esten', 'ћ', '(', 'accompan', '语', 'Selon', 'utto', 'o', 'def', 'temporada', 'eras', 'Unterscheidung', 'coll', 'raz', 'quelle', 'heut', 'ׁ', 'ogne', 'season', 'références', 'み', 'Random', '１', 'pez', '�', 'pp', 'фран', 'us', 'Cic', 'style', 'supp', 'Pin', 'ieben', 'û', 'ceu', 'Ḩ', 'era', 'meno', 'Jahrh', 'Ress', 'apt', 'cope', 'СР', 'об', 'nyel', 'Nova', 'Culture', 'ozzá', 'packet', 'lia', 'beskre', 'emp', 'sv', 'urch', 'helper', 'Przyp', 'dispos', 'estaven', 'loose', 'lä', 'uri', 'и', 'saison', 'Einzel', 'CURL', 'uno', 'prüfe', 'tile', '⋅', 'Begriffe', 'fő', 'Außer', 'aso', '.=', 'тель', '⁻', 'ismo', 'CHAP', 'fur', 'stress', 'inu', 'geme', 'ora', 'dro', 'gra', 'aton', 'Bald', 'bei', 'ibile', 'Nella', 'provinces', 'heures', 'Binary', 'Mie', 'abei', 'ҡ', 'otto', 'ờ']\n",
      "10   ['Bedeut', 'Einzeln', 'Référence', 'kwiet', '╬', 'Hinweis', 'paździer', 'ppi', 'Jahrh', 'ên', 'łów', 'mir', 'Bast', 'esten', 'Fich', '{#', 'pez', 'quelle', 'abei', 'esser', '𝓝', 'Mir', 'ׁ', 'Fuß', 'pur', 'RED', 'inglês', 'livre', 'temporada', 'Russell', 'péri', 'ßen', 'Pascal', 'Ḩ', 'SV', 'Begriffe', 'SR', 'лия', 'Liver', 'frü', 'Paz', 'usammen', 'Ook', 'spl', 'mirror', 'randomly', 'season', 'ogne', 'ism', 'мп', 'stycz', 'mob', 'ERR', 'cli', 'central', 'alone', 'Selbst', 'Unterscheidung', 'QUE', 'rai', 'Logger', 'Random', 'culture', 'atem', 'Central', 'ҡ', 'raz', 'random', 'fe', 'Ruby', 'continu', 'СР', 'Nella', 'prüfe', 'fur', 'irat', 'Culture', 'literature', 'alberga', 'brázky', 'men', 'dots', 'ouv', 'én', 'ど', 'چ', 'frère', 'Anleitung', 'педи', 'littérature', 'op', 'pin', 'unf', 'Bro', 'Wikip', 'nom', 'Voll', 'ℚ', 'suit', 'reflect', 'utto', 'uria', 'landet', 'succession', 'pp', '┐', 'urb', 'lia', 'ziel', 'feb', 'amery', 'isl', '.=', 'ぶ', 'lä', 'unächst', 'Font', 'foot', 'eras', '<s>', 'lias', 'juego', 'Stutt', '™', 'isis', 'références', 'Bro', '语', 'hnen', 'saison', '߬', 'Gemeins', 'enten', 'ric', '⁻', 'ok', 'alta', 'иг', 'noreferrer', 'Frank', 'Partei', 'û', '御', 'dispos', 'gon', 'CHAP', 'style', 'Fiche', 'fest', 'diam', 'erne', 'подо', 'names', 'foot', 'ppa', 'acker', 'рё', 'tile', 'chap', 'ismo', '⊢', 'perí', 'Bé', 'onom', 'uso', 'ณ', 'ccess', 'réseau', '１', 'Beispiel', '®', 'named', 'ora', 'wur', 'est', 'Clar', 'reform', 'nelle', 'exact', 'urch', 'ѫ', 'geordnet', 'hez', 'erie', 'Weit', 'च', 'ĭ', 'cu', 'coll', 'Gilbert', 'word', '☉', 'DO', 'ख', 'Austin', 'essen', 'otta', 'îne', 'ば', 'fb']\n",
      "11   ['Einzeln', 'Bedeut', 'paździer', 'ׁ', 'kwiet', 'ppi', 'raz', 'Bast', 'mir', '{#', 'Mir', 'Référence', 'livre', 'temporada', 'esten', 'mirror', 'quelle', '╬', 'utto', 'season', 'Hinweis', 'Central', 'ên', 'ßen', 'рё', 'Paz', 'Unterscheidung', 'Russell', 'op', 'cli', 'چ', 'ism', 'QUE', 'ど', 'Fuß', 'łów', 'pur', 'ziel', 'inglês', 'alberga', 'Jahrh', 'pez', 'verse', 'Font', 'succession', 'Pascal', 'Gew', 'Ruby', 'saison', 'références', 'central', 'ac', 'irat', 'Culture', 'мп', 'literature', 'ogne', 'culture', 'rai', 'ぶ', 'lä', 'pin', 'abei', 'Blue', 'péri', 'uri', 'лия', 'erte', 'littérature', 'СР', 'foot', '┐', 'Bé', 'collection', 'enten', 'SV', 'Fich', 'perí', '⁻', 'men', ')--(', 'Collection', 'Blue', 'usammen', '{.', 'Außer', 'Begriffe', '语', 'juego', 'brázky', 'Footnote', 'frü', 'spl', 'ob', 'lí', 'Stutt', 'ismo', 'amery', 'ĭ', 'meno', 'exact', 'ceu', 'réseau', 'word', 'Selbst', 'ista', 'style', 'random', 'dots', 'lei', 'pp', 'च', 'obe', 'erne', 'stycz', 'Anleitung', 'AGE', 'esser', 'ouv', 'frère', 'RED', 'Zür', 'games', 'chap', 'randomly', 'style', 'isis', 'NET', 'fest', 'mob', 'tie', 'foot', 'estaven', 'unf', 'cu', 'Voll', 'o', 'hnen', 'Bro', 'unächst', 'oct', '®', 'Liver', '古', 'óp', 'reflect', 'fő', 'uria', 'иг', 'Random', 'Hier', 'names', '∷', 'cope', 'uno', 'anten', 'superfic', 'ora', 'acker', 'isl', 'és', 'қ', 'iai', 'vuel', 'wur', '�', 'heures', 'líder', 'sezon', 'suit', 'geme', 'През', 'ana', 'alone', 'ric', 'père', 'fancy', 'Gegen', 'ok', 'Partei', 'œur', 'Gemeins', 'Ḩ', 'bek', 'ҡ', 'ccess', 'én', 'сто', 'feb', 'Ook', 'Begriff', 'ruby', 'ali', '̄', 'DO', 'alta', '𝓝', 'Ress', 'rais', 'Wikipédia']\n",
      "12   ['ppi', 'kwiet', 'Bedeut', 'paździer', 'mir', 'Einzeln', 'esten', 'raz', 'Bast', 'cli', 'Mir', 'ׁ', '╬', 'livre', 'irat', 'quelle', 'мп', 'utto', 'mirror', 'rai', 'Hinweis', 'рё', '┐', 'Russell', '{#', 'چ', 'ali', 'culture', 'alberga', 'Référence', 'abei', 'Culture', 'inglês', 'usammen', 'season', 'temporada', 'uri', ')--(', 'iai', 'collection', 'stycz', 'succession', 'ziel', '�', 'Begriffe', 'amery', 'ên', 'brázky', 'Paz', 'Font', 'hö', 'igs', 'łów', 'ど', 'geme', 'QUE', 'pin', 'ぶ', 'sierp', 'juego', 'Build', 'erte', 'Blue', 'lä', 'pur', 'op', 'Collection', 'Voll', 'bast', 'Bé', 'random', 'era', 'names', 'ccess', 'cope', 'références', 'esser', 'spl', 'isi', 'óp', 'free', 'lei', '\"^', 'heures', 'bunch', 'mob', 'word', 'ism', 'games', 'Unterscheidung', 'Hier', 'og', 'estilo', 'exact', 'pez', 'Außer', '构', 'bek', 'Blue', 'series', 'style', 'TAG', 'ogne', 'saison', 'ok', 'Liver', 'сві', 'verse', 'Browser', 'ceu', 'Gemeins', 'Random', 'step', 'Bro', 'removal', 'Fich', 'lí', 'Anleitung', 'за', '御', '⁻', 'Gew', 'reflect', 'unächst', 'loud', 'oc', 'fir', 'randomly', 'bei', 'unicode', 'nik', 'texte', 'iszt', 'rais', 'oct', 'frü', 'Footnote', 'pp', 'desar', 'mp', 'aka', 'réseau', 'chap', 'alta', 'ac', 'Central', 'ang', 'livres', 'Bulg', 'ouv', 'emple', 'Fuß', 'superfic', 'dots', 'tie', 'cop', 'littérature', 'ni', 'ßen', 'enten', '{.', 'च', 'fő', 'History', 'fancy', 'style', 'NET', 'selbst', 'SV', 'wa', 'лия', '𝓝', 'Begriff', 'titles', 'Pascal', 'Select', 'printStackTrace', 'фран', 'Fiche', 'isis', 'apt', 'swift', 'AGE', 'uro', 'ora', 'Nouvelle', 'erne', 'és', 'ismo', 'literature', 'ante', 'СР', 'select', 'Culture', 'uten', 'DO', 'péri', 'game', '้', 'conseil']\n",
      "13   ['Bedeut', 'kwiet', 'Einzeln', 'paździer', 'ppi', 'ׁ', 'мп', 'raz', 'рё', 'esten', '╬', 'Référence', 'mir', 'stycz', 'Bast', 'Wikip', 'utto', 'rai', 'sierp', 'abei', 'СР', '┐', 'Unterscheidung', 'iai', 'Hinweis', 'Begriff', 'Anleitung', 'چ', 'inglês', 'Mir', 'Russell', 'superfic', 'tie', 'temporada', 'Bé', ')--(', 'amery', 'games', 'irat', 'opus', 'Wikipédia', 'cli', 'livre', 'ziel', 'Außer', 'fen', 'season', 'ên', 'succession', 'ぶ', '{#', 'Begriffe', 'références', 'NET', 'quelle', 'च', '☉', 'Konst', 'style', 'Selon', 'random', '\\u202d', '̲', '➖', 'usammen', '御', 'word', 'lä', 'unächst', 'Ḩ', '̄', '{.', 'reflect', 'apt', 'patch', 'mirror', 'ℚ', 'ど', 'ὀ', 'Build', 'fir', 'gra', 'chief', 'Castle', 'chap', 'ῶ', 'Stutt', 'ieben', 'rais', 'Fich', 'ambiguation', 'isi', 'landet', 'History', 'og', 'juego', 'ccess', 'Culture', 'heures', 'andom', 'categoría', 'foot', 'óp', 'Liver', 'ism', 'Ps', 'berts', 'perí', 'enten', 'ờ', 'gross', 'Voll', 'simultane', 'obe', 'estilo', 'ioni', 'Fiche', 'Logger', 'Gew', 'utos', 'TAG', 'erte', 'Selbst', 'łów', 'ქ', 'Bald', 'collection', 'Blue', 'names', '构', 'alberga', 'opro', '☆', '∅', 'health', 'Tat', 'lei', 'mouv', 'select', 'Random', 'Footnote', 'free', '้', 'uto', 'spl', 'hidden', 'today', 'jsp', 'Lith', 'ac', 'estaven', 'ora', 'muz', 'Zür', 'era', 'mp', 'Fuß', 'Bulg', 'père', 'swift', 'Select', 'Collection', 'elet', 'dots', 'лия', 'game', 'nom', 'men', 'nia', 'PS', 'œur', 'ც', 'mism', 'spawn', 'geh', 'Bro', 'Font', 'series', 'isis', 'lí', 'ento', 'burn', 'brázky', 'dorf', 'removal', 'tile', 'isl', 'brid', 'cope', 'Hier', 'Paz', 'odore', 'истории', '\"^', '◦', 'geme', 'printStackTrace', 'Düsseld', 'versary', 'pp']\n",
      "14   ['Bedeut', 'Einzeln', 'kwiet', 'paździer', 'ppi', 'Wikip', 'мп', 'Anleitung', 'iai', '╬', 'esten', 'Begriff', 'games', 'ׁ', 'raz', 'Hinweis', 'stycz', '┐', '☉', 'tie', 'Unterscheidung', 'mir', 'СР', 'ziel', '̲', 'lei', 'ℚ', 'рё', 'Begriffe', 'utto', 'Konst', '(', 'cli', 'Bro', '\\u202d', 'style', 'collection', 'ccess', 'tap', 'چ', 'tile', 'Selon', 'ῶ', 'rai', 'gra', 'fen', 'Référence', 'inglês', 'opus', 'chief', 'sierp', 'spl', 'uno', 'Mir', 'season', 'og', '{.', 'isi', 'stress', 'mp', 'lär', 'men', '∅', 'Collection', '➖', 'irat', 'Net', 'Außer', 'hidden', 'word', 'today', 'net', 'geme', '御', 'NET', 'muz', 'amery', 'ism', 'QUE', 'quelle', 'Liver', 'conseil', '⋅', 'names', 'ên', 'ぶ', 'temporada', 'livre', 'opro', 'gross', 'reflect', 'steam', 'era', 'abei', 'random', 'Paz', '{#', 'Petersburg', 'ography', 'łów', 'Gew', 'free', 'Ps', 'omo', 'pez', 'Pic', 'lyn', 'health', '̄', 'brid', 'apt', 'ac', 'nar', '(/', 'Bast', 'cope', 'mob', 'utos', 'Culture', 'superfic', 'boost', 'nia', '𝓝', 'landet', 'uto', 'fir', 'style', 'patch', 'ismo', 'Friedrich', 'ό', 'Hier', 'categoría', 'removal', 'game', 'culture', 'history', 'foot', 'series', '后', 'typen', 'atform', 'chap', 'isis', 'powerful', '模', 'ioni', ')--(', 'ὀ', 'ora', 'lä', 'ქ', 'retain', 'én', 'références', '�', 'subt', 'jsp', 'Amts', 'tegen', 'succession', 'oc', '◦', '☆', 'AGE', 'могу', 'diam', 'graphics', 'Ḩ', 'pp', 'enten', 'ingly', 'mirror', 'MP', 'power', 'Mik', 'History', 'PS', 'ど', 'unus', 'Gebiet', 'estilo', 'Bitte', 'Bro', 'Wikipédia', 'च', 'ps', 'juego', 'Castle', 'oris', 'Blue', 'führ', 'andom', 'root', 'swift', 'ĭ', 'FX', 'massive', 'sezon', 'gef']\n",
      "15   ['Bedeut', 'Einzeln', '╬', 'мп', 'kwiet', '┐', 'paździer', 'Wikip', '̲', 'ℚ', '̄', '(', 'Référence', 'utto', 'tie', '☉', 'games', 'lär', '\\u202d', 'Anleitung', 'Hinweis', 'inglês', 'today', 'fir', 'ppi', 'iai', 'Rena', 'Konst', 'esten', 'apt', 'raz', 'lei', 'Bro', '\\n', 'рё', 'chief', 'Unterscheidung', 'fen', 'СР', 'چ', '{.', 'Wikipédia', 'Begriff', 'cli', 'ziel', 'anten', 'Begriffe', 'quelle', 'Außer', 'uno', 'stones', 'atform', 'ׁ', 'cope', 'widet', 'names', 'categoría', 'amery', 'style', 'temporada', 'ambiguation', 'utos', 'gross', 'alberga', 'ism', '𝓝', 'series', 'Zür', 'Amts', 'in', 'Castle', 'abei', 'nar', '☆', 'Bast', 'net', '➖', 'ῆ', '⋅', 'superfic', 'références', 'conseil', 'ęż', 'Culture', 'retain', 'succession', 'NET', 'rai', 'łów', '≫', 'landet', ')--(', 'ugust', 'ps', 'én', 'stycz', '御', 'Selon', '(/', 'déput', 'men', 'Net', 'muz', 'ismo', 'typen', 'irat', 'Gew', 'cum', 'penas', 'mp', 'tile', 'Cambridge', '∅', 'Düsseld', 'Liver', 'Mir', 'stress', 'agli', 'covering', 'dienst', 'ὀ', 'ccess', 'Oficina', '⊢', 'tegen', 'Nella', 'word', 'ό', 'Википеди', 'sierp', 'enta', 'spl', 'saison', '♦', 'estilo', '━', 'chap', 'mir', '◦', 'season', 'rais', '{#', 'Ḩ', 'collection', 'Paz', 'printStackTrace', 'brid', 'Names', 'livre', 'history', 'walt', 'elet', '�', 'culture', 'ên', 'health', 'фран', '…', 'Museum', '≃', 'erte', 'archar', 'explained', 'ぶ', 'geprüft', 'basically', 'пи', 'Ans', 'fest', 'spawn', 'jective', 'perí', 'pez', 'lä', 'Collection', 'reflect', 'beskre', 'vs', 'пня', 'Ps', 'článku', 'juego', 'stone', 'ighed', 'Bé', '∷', 'removal', 'leben', 'stream', 'meaning', 'Pic', 'Html', 'Bro', 'bero', 'ography', 'History', 'omo', 'berts', '�', 'steam']\n",
      "16   ['Bedeut', 'Einzeln', 'kwiet', '┐', 'Hinweis', '╬', 'Wikip', 'paździer', '(', 'utto', 'tie', 'Anleitung', '☉', '\\u202d', 'мп', 'raz', 'ℚ', 'Unterscheidung', 'Référence', 'СР', 'fen', 'games', 'Ps', 'ps', 'abei', '̄', '𝓝', 'ism', 'inglês', 'fir', 'Rena', 'Außer', 'ugust', '̲', 'style', 'quelle', 'chief', 'ambiguation', 'gresql', 'amery', 'Bro', 'atform', '\\u2060', 'categoría', 'nar', 'ismo', 'Selon', 'mp', 'apt', 'Mir', 'Begriffe', '\\n', 'mir', 'rai', 'lei', 'ppi', 'Stutt', 'Gegen', 'Konst', 'lär', 'PS', 'penas', 'temporada', '(/', 'estilo', 'anten', 'Zür', 'today', 'member', 'cli', 'gross', 'Friedrich', 'season', 'ziel', 'Düsseld', 'stress', 'iai', 'culture', 'MP', 'Ton', 'cope', 'ᵉ', 'spawn', 'XIV', 'NET', 'verso', 'widet', 'series', 'net', 'ῆ', 'Hen', 'mirror', '━', 'anas', 'succession', 'stream', 'meaning', 'Ḩ', 'typen', 'utos', 'mob', '☆', 'steam', 'landet', 'références', 'irat', 'пня', 'Paz', 'esten', 'chap', 'Amts', 'sierp', '頭', 'RelativeLayout', 'Cal', 'Tat', 'in', 'members', 'atto', 'Википеди', 'сери', 'simultane', '{.', 'hen', 'superfic', 'Museum', 'stone', 'retain', ')--(', 'ׁ', 'fest', 'tile', 'ḫ', 'چ', '\":{\"', 'ITable', '{#', 'reflection', '➖', 'Nella', 'sezon', 'Reform', \"'\", 'Culture', 'lod', 'Fen', 'Begriff', 'stycz', 'cí', '后', 'ί', 'líder', 'лся', 'ography', '♂', 'quel', 'Bast', 'NP', 'uno', 'jsp', 'spl', 'brid', 'zvuky', 'verse', 'loose', 'men', 'ться', 'Wikipédia', 'MP', 'Collection', 'Gew', 'virtuel', 'Ans', 'covering', 'ḍ', 'etro', 'game', 'basically', 'έ', 'groups', 'ό', 'confirm', 'agli', '>\\\\<', 'Rein', 'рё', '_(', 'sometimes', 'ên', 'Central', 'могу', 'hn', 'gebied', 'berts', 'elet', '≫', 'Bedeutung', 'gang', 'fx', 'literature']\n",
      "17   ['Bedeut', '(', 'Wikip', '┐', 'Außer', '╬', 'games', 'Einzeln', 'kwiet', 'anas', '\\n', 'style', 'ugust', 'tie', 'paździer', 'fir', 'verso', 'ps', 'Hinweis', 'categoría', 'abei', 'chief', 'amery', 'raz', 'Ps', 'СР', 'in', 'estilo', 'Museum', 'Bro', 'inglês', '𝓝', 'ℚ', 'penas', 'today', 'igli', 'Reform', 'Unterscheidung', 'ism', '☉', 'Rena', 'utto', 'ismo', 'evolution', '̄', 'Référence', 'apt', 'мп', 'Konst', 'gresql', '{#', 'Gegen', 'Selon', '\\u202d', '\\u2060', 'Font', 'PS', 'chap', 'fen', 'history', 'сери', 'mp', '➖', 'museum', 'widet', 'rai', 'mir', 'quelle', '…', '↳', '{.', 'stream', 'рё', '━', 'stress', 'Anleitung', 'season', 'reform', 'atform', '̲', 'confir', 'lod', 'game', 'powerful', 'steam', 'пня', 'ῆ', 'aro', 'bek', 'verse', 'zvuky', 'calc', 'Collection', 'телем', 'fest', '♦', 'series', 'geprüft', 'temporada', 'Begriffe', 'mob', 'men', 'MP', 'virtuel', 'ᵉ', 'stone', 'ethod', 'ό', 'lär', 'Nella', 'superfic', 'NET', \"'\", 'brand', '≫', 'ׁ', 'brid', 'Franklin', 'heures', 'Hir', 'Rein', 'ppi', 'hen', 'Phoenix', 'confirm', 'sound', 'DO', 'collection', 'äß', 'ḍ', 'consulté', 'ί', 'Hier', 'iai', 'walking', 'member', 'оні', 'én', 'groups', 'agli', '(/', 'proced', 'ờ', 'ḫ', 'rror', '/', 'irat', 'jsp', 'life', 'culture', '∅', 'succession', 'connexes', 'références', 'recens', 'suit', '后', 'berga', 'Ton', 'Ḩ', 'History', 'déput', 'Profil', 'atto', 'franch', 'covering', 'cult', 'berts', '⇔', 'gang', 'moy', 'sierp', 'ongodb', 'pez', 'фран', 'mer', 'sezon', 'juego', 'CP', 'jap', '⊢', 'spawn', 'stones', 'disc', 'tile', 'cí', 'anten', 'ющей', 'coll', 'And', 'vs', 'lei', '↵', 'fe', 'angel', '？', 'meaning', 'versary', 'ziel', 'mér']\n",
      "18   ['Bedeut', 'style', '(', '╬', 'games', 'tie', '\\u2060', '┐', 'estilo', '\\n', 'in', 'anas', '\\u202d', 'Einzeln', 'amery', '̄', 'Unterscheidung', 'verso', 'Font', '𝓝', 'Phoenix', 'chief', 'penas', 'Rena', 'utto', 'Wikip', 'jin', 'style', 'game', 'culture', '☉', 'Bro', 'abei', 'СР', 'evolution', 'Konst', 'jap', 'ℚ', 'traffic', 'Hir', '…', 'moy', 'steam', 'confir', 'Référence', 'verse', 'пня', 'today', 'ism', '̲', 'iden', 'stress', 'raz', 'history', 'charm', 'fe', 'sh', 'spawn', 'ellen', 'aro', 'PS', 'temporada', 'Gegen', 'kwiet', 'hen', 'Hen', '/', 'superfic', 'Logger', 'inglês', 'Jim', 'categoría', 'ờ', 'Selon', 'ismo', '⊢', 'season', 'Online', 'Museum', 'heures', 'accomp', '━', 'Ton', '%;\\r', 'agi', 'member', 'dens', 'confirm', 'ugust', 'Hinweis', '↳', 'iare', 'hot', 'Lith', 'rei', 'NET', '──', 'Rein', 'CP', 'fen', '\\x08', 'рё', 'Tat', 'itecture', 'dic', 'craft', 'enst', 'ography', 'virtuel', '？', 'apt', 'series', 'ulator', 'esc', 'xspace', '>\\\\<', '♦', 'cult', 'tile', 'Außer', 'Style', '월', 'ich', 'Ged', 'bek', 'Ten', 'paździer', 'confirmed', '┘', 'museum', 'Style', '∅', 'orch', 'fest', 'Blue', 'mp', 'iai', 'meaning', 'pez', 'лением', 'ps', '.', 'igli', 'Tools', 'console', 'craft', 'Liver', 'ikai', 'Doug', 'calc', 'nar', 'mir', 'cí', 'ί', 'Bro', 'fx', 'official', 'сери', 'fir', 'stone', 'vs', 'dl', 'brid', 'Hen', 'Lexikon', 'studio', 'Bevölker', 'publish', 'Begriffe', 'lod', 'members', 'Studio', 'Han', 'careful', 'ָ', 'Ī', 'jsp', 'Ans', 'men', 'ා', 'custom', 'XIV', '♂', 'Studio', 'педи', 'ῆ', 'atol', 'Life', 'ongodb', 'History', 'Ressource', 'demselben', 'Collection', 'ĭ', 'coll', 'ׁ', 'Japan', 'bro', 'dem', 'titles']\n",
      "19   ['Bedeut', 'style', '\\u2060', '(', 'estilo', '╬', 'Phoenix', 'verse', '̄', 'jin', '┐', 'Hir', 'tie', 'iden', 'games', 'style', 'Unterscheidung', 'tile', 'mob', 'abei', 'Style', 'ej', 'amery', 'Wikip', 'chief', 'XIV', 'eria', '\\n', 'game', 'traffic', 'Life', 'Selon', 'in', 'СР', 'anas', 'Hen', 'moy', 'penas', '系', '♂', 'hen', 'ố', 'macht', 'Gegen', 'stress', 'Lexikon', 'dens', 'evolution', 'tears', 'ḍ', 'aro', 'тори', 'Référence', 'iai', 'ellen', 'Zür', 'Japan', 'member', 'jap', 'пня', 'Einzeln', 'careful', 'orig', 'Ton', 'ismus', '%;\\r', 'ᵉ', 'superfic', 'bez', 'Orig', 'ugust', '월', 'Ken', 'meaning', 'Font', 'Doug', 'culture', 'baseball', '☆', 'wire', 'Tokyo', '⇔', 'launch', 'fe', 'bek', 'dro', 'Begriffe', 'dog', 'ism', 'Jim', 'rei', 'fen', 'Ț', 'ub', 'franch', 'verso', 'Museum', 'CPU', 'Ged', 'Tok', 'accomp', 'Ich', 'ida', 'psum', 'oro', 'Ges', '↳', 'series', 'Member', 'life', 'ém', 'ich', 'Online', 'ismo', 'territory', 'Ī', 'چ', 'versary', 'men', '̲', 'History', '♦', 'Han', 'Joh', 'Tools', '<%=', 'ub', 'äl', 'history', 'Ten', 'season', 'рист', 'vs', 'mir', 'gesamt', 'itaire', 'Style', 'enst', 'réseau', 'iare', 'ento', 'Хронологи', 'obe', 'ськ', 'historical', 'business', 'today', 'prob', 'uten', 'fir', 'tact', 'igli', '┘', 'sterd', 'Kin', '\\x08', 'lär', 'fu', 'pez', 'berga', 'fashion', 'łów', 'tutorial', 'temporada', 'cí', 'Amsterdam', 'ide', 'ulator', 'wire', 'steam', 'Rem', 'ografi', 'loose', 'ALSE', 'ethod', 'nar', 'gang', 'Berl', 'related', 'itate', 'agli', 'stat', 'Bedeutung', 'dem', 'retain', 'charm', 'mov', 'usual', 'berts', 'Hinweis', 'succession', 'Geschäft', 'истории', 'Kub', '☉', 'street', 'confir', 'живело', 'GT', 'ʲ']\n",
      "20   ['style', 'Bedeut', '\\u2060', 'estilo', 'Hir', 'Style', 'traffic', 'eria', '(', 'style', 'games', 'Gegen', 'СР', '╬', 'tie', 'Online', 'XIV', 'Life', 'amery', 'hen', 'Hen', 'tile', 'abei', 'chief', 'wire', 'چ', 'member', 'Unterscheidung', 'PS', 'Museum', 'cide', 'moy', 'steam', 'Ton', '系', '̄', 'iai', 'bek', 'tact', 'nar', 'franch', 'confir', 'stress', '┐', 'series', '↳', 'Jim', 'game', 'Selon', 'bez', 'ej', 'ᵉ', '♦', 'aro', 'fen', 'Zür', 'careful', 'Ten', 'Bedeutung', 'charm', 'oro', 'kwiet', 'ться', 'mob', 'Wikip', 'uten', 'orig', 'Phoenix', 'verse', 'life', 'réseau', 'Style', 'macht', 'business', 'dem', 'ethod', 'ism', '%;\\r', 'trakten', 'Geschäft', 'dens', 'ellen', 'tears', 'Référence', 'jin', 'oning', 'iare', '\\n', 'ḍ', '𝓝', 'patch', 'ismo', '☆', 'baseball', 'Pascal', 'g', 'season', 'jap', 'ctl', 'Orig', 'y', 'Japan', 'sezon', 'enst', 'prob', 'пня', 'berga', '☉', 'itate', 'icación', 'telt', 'temporada', 'pez', 'meaning', 'тори', 'members', 'craft', 'verso', 'łów', 'evolution', 'persist', 'quel', 'Ț', 'Central', '⇔', 'ich', 'ļ', 'paździer', 'apt', 'Y', 'Ges', 'Hinweis', 'agi', 'versary', 'gesamt', 'cija', 'fashion', 'Ich', 'suit', 'fe', 'ố', 'itaire', 'Life', 'uses', 'vr', '━', 'λ', 'spin', 'related', 'пове', 'Club', 'dog', 'mirror', 'obe', 'enem', '──', 'hn', 'loose', 'present', 'Member', 'Tokyo', 'Außer', 'dl', 'Japanese', 'anas', 'History', 'CPU', 'in', 'ungen', 'rival', 'igli', 'Frank', 'лением', 'proxy', 'савезној', 'by', 'psum', 'wire', 'VIS', 'mov', 'Ley', 'сери', '\\x08', 'ismus', 'territory', '̲', 'slot', 'Beat', 'Bath', 'men', 'vs', 'wh', '样', 'fir', 'proced', 'curity', 'eras', 'Font', 'story', 'Einzeln']\n",
      "21   ['style', 'Online', 'games', 'PS', '\\u2060', 'Bedeut', 'estilo', 'iai', '(', 'y', 'game', 'member', 'mob', 'tie', 'members', 'chief', 'Unterscheidung', 'réseau', 'obe', '̄', 'para', 'Style', 'ên', 'lei', 'season', 'Font', 'eria', 'Bald', 'Museum', 'Phoenix', 'ться', 'Ges', 'СР', '☆', 'meaning', 'temporada', 'dens', '%;\\r', 'steam', 'ob', '\\n', 'вич', '❯', 'definition', 'tact', 'hen', 'fa', 'Gegen', 'uses', 'moy', 'XIV', 'traffic', 'fen', 'cide', 'dl', 'careful', 'Member', 'Jim', 'geh', 'icación', 'Tokyo', 'Hir', 'amery', 'prob', '></', 'bek', 'suit', 'style', 'Beat', 'ugust', 'Selon', 'stress', 'ismo', 'Ton', 'member', 'Pascal', 'apt', 'fill', 'Référence', '╬', 'present', 'charm', 'in', 'business', 'evolution', 'ctl', '̀', 'historical', 'confir', 'cos', 'Hen', 'ḍ', 'Ich', 'ñas', 'pill', 'usual', 'atto', 'proced', 'agi', 'eras', 'Bath', 'verso', 'Y', 'ider', 'Life', 'slot', 'enem', 'p', 'patch', 'Mans', 'territory', 'verse', 'cus', 'called', 'ethod', '{.', 'nar', 'ismus', 'blood', 'loose', 'Y', 'kwiet', 'Geschäft', 'Rem', 'ori', 'ᵉ', 'adm', 'related', 'series', 'gens', 'ism', 'Pic', 'paździer', 'mirror', 'Ten', 'currency', 'ố', 'Einzeln', 'چ', 'tile', 'ycz', 'verf', 'dem', 'Bry', 'ĭ', 'contre', 'duty', 'ungen', 'iden', 'Goth', 'ikai', 'uten', 'Ga', 'Burn', 'divers', 'Außer', 'igli', 'patch', 'wire', 'зы', 'ulator', 'persist', 'relax', 'DR', 'women', 'history', 'life', \"'\", 'lär', 'innoc', 'ichi', 'ou', 'ich', 'HL', 'craft', 'vr', 'Ps', 'тори', 'Петер', '↳', 'aro', 'open', '>\";', 'Proxy', 'font', '➜', 'ire', '系', 'lug', 'liv', 'abei', '̲', 'ASCII', 'elements', 'Wikip', 'wh', 'Weit', 'density', 'Und', 'title']\n",
      "22   ['iai', 'Online', 'style', 'tie', 'mob', 'games', 'PS', 'estilo', 'ga', 'y', 'member', 'Ges', '(', 'zero', 'dl', 'fen', 'emon', '\\u2060', 'stress', 'Y', 'uten', 'ên', 'Zero', 'Jim', 'called', 'members', 'Hir', 'Phoenix', 'chief', 'hen', 'season', 'moy', 'persist', 'proced', 'ḍ', 'lei', 'spin', 'adm', 'Selon', 'learned', 'consp', 'game', 'ichi', 'Ten', 'confir', 'steam', 'careful', 'Style', 'тори', 'вич', 'Ich', 'penas', 'evolution', 'réseau', 'slot', 'aro', 'iden', 'ĭ', 'enst', '系', 'para', 'Tokyo', 'ố', 'ться', 'wire', 'VIS', 'Mans', 'lax', 'patch', 'divers', 'Ga', 'open', 'ou', 'dem', '？', 'isl', 'history', 'agi', 'Wars', 'eno', 'triangle', 'Lake', 'confirm', 'obe', 'HL', 'Rem', '%;\\r', 'nar', 'fa', 'liv', 'opens', 'ej', 'Member', '></', 'Hen', '☆', 'life', 'invest', '̀', 'prob', 'charm', 'temporada', 'Bath', 'enta', 'Life', 'eria', 'definition', 'Max', 'patch', 'Beat', 'rott', 'geh', 'pill', 'tile', '?', 'historical', 'Studios', 'detail', 'cos', '❯', 'style', 'oris', 'Studio', 'series', 'oge', 'pet', 'истории', 'ice', 'Wikip', 'Gegen', 'business', 'gens', 'bek', 'dens', 'mirror', 'orno', 'orsz', 'wrong', 'warm', \"'\", 'ohn', 'affili', 'rou', 'suit', 'oro', 'Tri', 'blood', 'franch', 'Ps', 'Museum', 'VS', 'Référence', 'ider', 'demand', 'loose', 'card', 'cross', 'ire', 'rei', 'asa', 'toler', 'studio', 'ethod', 'verf', 'vr', '│', 'ob', 'present', 'ży', 'ps', 'XIV', 'member', 'Ap', 'tact', 'active', 'ctl', 'details', 'Ton', 'enem', 'stdout', 'Bedeut', 'ALSE', 'ív', 'iza', 'dens', 'igli', 'Y', 'font', 'currency', 'wh', 'рь', 'enemy', 'ungen', '╬', 'ma', 'Goth', 'baseball', 'p', 'Burn', 'Font']\n",
      "23   ['Online', 'iai', 'tie', 'style', 'PS', 'games', 'spin', 'member', 'moy', 'liv', 'rott', 'estilo', 'Rem', 'Mans', 'ichi', '(', 'agi', 'fen', 'quel', 'adm', 'ice', '\\u2060', 'proced', 'dl', 'asa', 'вич', 'members', 'opens', 'hen', 'ub', 'Ges', 'slot', 'Style', '系', 'elev', 'evolution', 'Member', 'ambiguation', 'anh', 'Y', 'isl', 'ga', 'y', 'liv', 'тори', 'learned', 'Ga', 'member', 'uten', 'obe', 'Ps', 'oris', 'series', 'Ich', 'emon', 'careful', 'рь', '样', 'dem', 'Ten', 'publish', 'demand', 'penas', 'titles', 'ên', 'Bath', '?', 'baseball', 'verse', 'lei', 'Zero', 'rei', 'Beat', 'ASCII', 'ethod', 'zero', 'VIS', 'Jim', 'loose', '？', 'divers', 'entr', 'font', 'Lake', 'mob', '❯', 'franch', \"'\", 'Life', 'Selon', 'orsz', 'enta', 'curity', 'confir', 'title', 'ej', 'confirm', \"`'\", 'fill', 'ou', 'Museum', 'invest', 'ĭ', 'lax', 'game', 'currency', 'criminal', 'истории', '×', 'Burn', 'Liv', 'K', '></', 'eria', 'persist', 'historical', 'Studio', 'Rom', 'bez', 'called', 'oi', 'ps', 'rem', 'cores', 'Ry', 'iden', 'bek', 'eno', 'stress', 'immediate', 'studio', 'cos', '%;\\r', 'enem', 'Ap', '̀', '́', 'stub', 'Hir', 'Y', 'pet', 'whole', 'neural', 'XIV', 'prob', 'DR', 'ob', 'ники', 'amery', 'uba', 'iben', 'oid', 'nar', 'Studios', 'orno', 'abe', 'iso', 'tact', 'Publish', 'Print', 'uden', 'blood', '☆', 'Kin', 'bath', 'fa', 'triangle', 'rän', 'Tokyo', 'Wars', '(/', 'lear', 'adó', 'opter', 'Ken', 'FT', 'laten', 'Font', 'consp', 'chief', 'gens', 'Ans', 'Sec', 'ubs', 'HL', 'ALSE', 'ív', 'Петер', 'фо', 'Verm', 'present', 'worth', 'ться', 'tradicional', 'verf', 'vr', 'Corn', 'ator', 'para', 'jack']\n",
      "24   ['Online', 'games', 'tie', 'iai', 'style', '(', 'spin', 'proced', 'isl', 'PS', 'fen', 'baseball', '❯', 'Wars', 'game', 'Ga', 'ice', 'asa', 'ga', 'Rem', 'elev', 'lax', 'Zero', 'series', 'adm', 'lei', 'stub', 'Mans', 'publish', 'Y', 'member', 'members', 'dl', '样', 'slot', 'present', 'Tokyo', 'titles', 'title', 'agi', 'verse', 'loose', \"'\", 'penas', 'Studios', 'quel', 'Ps', 'K', 'chief', 'Member', 'y', 'ambiguation', 'Life', 'ob', 'steam', 'ou', 'Selon', 'stat', 'ASCII', 'asc', 'cos', 'oris', 'lean', 'iso', 'Jim', 'franch', 'rott', 'liv', 'life', 'ism', 'evolution', 'estilo', 'iben', 'Ges', 'Burn', 'Ap', '宝', 'Studio', 'mas', 'currency', 'zero', 'careful', 'gens', 'bez', '？', 'ên', 'Beat', 'obe', 'eno', 'истории', 'Mass', 'VIS', 'anh', 'font', 'rei', 'immediate', 'member', 'criminal', 'ps', 'emon', 'enas', 'Print', '?', 'фо', 'XIV', 'Rom', 'Ry', 'stress', 'jack', 'mob', 'demand', 'persist', 'whole', 'studio', 'w', 'neural', 'б', 'd', 'divers', 'foot', '\\u2060', 'ichi', 'ALSE', 'opter', 'entr', 'ly', 'learned', 'blood', 'dr', 'hen', 'called', 'Pic', 'ники', 'opens', 'wär', '></', 'ma', 'dem', 'tbl', 'card', 'Publish', 'ѐ', 'Ich', 'burn', 'DR', 'eria', 'fill', 'consp', 'worth', '̀', 'mang', 'Style', 'isis', 'oge', 'вич', 'moy', 'invest', 'ap', 'origin', 'Net', 'flex', 'schedule', 'Петер', '系', 'nar', 'transl', 'asta', 'confirm', '’', 'RE', 'Bath', 'Goth', \"`'\", 'рем', 'ej', 'iden', 'pin', 'Japanese', 'ethod', 'fa', 'Mas', 'vr', 'ться', 'Phoenix', 'ĭ', 'FT', 'Lear', 'Corn', 'confir', 'Prés', 'NET', 'рь', 'ohn', 'accommod', 'pet', 'Amsterdam', 'stud', 'Hir', '/', 'founder']\n",
      "25   ['Online', 'games', 'tie', 'Y', '❯', 'style', 'isl', '(', 'series', 'Rem', 'Wars', 'member', 'K', 'publish', 'members', 'elev', 'fen', 'Ich', 'lei', 'iai', 'agi', 'game', 'present', 'y', 'рем', 'spin', 'baseball', 'currency', 'chief', 'ASCII', 'ice', 'Zero', 'verse', 'XIV', 'emon', 'stress', 'Selon', 'ichi', \"'\", 'Tokyo', '', '？', 'evolution', 'member', 'slot', 'VIS', 'quel', 'b', 'liv', 'Member', 'Prés', 'lean', ':', '样', 'Publish', '宝', 'dl', 'IV', 'titles', 'stat', 'Lake', 'open', 'invest', 'mas', 'concrete', 'PS', 'Ga', 'stub', 'careful', '></', 'ej', 'wär', 'ники', 'ism', 'obe', 'cre', 'turn', 'moy', 'ambiguation', 'isis', 'ob', 'lod', 'ou', 'ap', 'Pic', 'developer', 'asa', 'Net', \"`'\", 'iso', 'Ry', 'proced', 'истории', 'Life', 'сп', 'font', 'Princess', 'tbl', 'zero', 'demon', 'rott', 'eno', 'in', 'card', 'Przyp', 'asta', 'origin', 'Mas', 'oge', 'title', '?', 'developer', 'founder', 'Japan', 'Ot', 'bez', 'hen', 'assim', 'flower', 'abe', '%;\\r', 'schedule', 'asc', 'Studio', 'steam', 'newspaper', 'dem', 'фо', 'ender', 'persist', 'ĭ', 'criminal', 'nar', 'fx', 'ș', 'confirm', 'wa', 'suit', 'iv', 'w', 'Phoenix', 'neural', 'immediate', 'mob', 'adm', 'rei', 'Print', 'life', 'ma', 'franch', 'd', 'movie', 'penas', 'iben', 'Ken', 'Japanese', 'opens', 'net', 'ly', 'ḍ', 'Style', 'enas', 'uri', 'RE', 'Ka', 'ém', 'fancy', 'ên', 'liv', 'blood', 'DR', 'Rou', 'dr', 'equ', 'like', 'mak', 'lax', 'studio', 'arm', 'Linux', 'z', 'divers', 'ismo', 'storm', 'estilo', 'logic', 'enta', 'disag', 'ў', '’', 'тори', 'ga', 'Ap', 'accommod', 'V', 'Jim', 'ig', 'ohn', 'Mans', 'Liv']\n",
      "26   [':', 'Online', 'games', '(', 'tie', 'K', 'member', 'series', '❯', 'style', '', 'movie', 'isl', 'publish', 'members', 'Rem', 'isis', 'in', 'game', 'blood', 'present', 'Member', 'ap', 'origin', 'spin', 'b', 'wär', 'lei', 'studio', 'asc', 'elev', 'ice', 'like', 'fen', \"'\", 'IV', 'verse', 'demon', 'ma', 'Net', 'asta', 'net', 'baseball', 'turn', 'Lake', 'Zero', 'Mas', '：', 'careful', 'currency', 'sp', 'VIS', 'PS', 'Ga', 'rott', 'wa', 'Publish', 'ob', 'iza', 'dem', 'moy', 'developer', '\\n', 'Princess', 'w', 'Ot', 'oti', 'Under', 'lean', 'member', 'iai', 'film', 'uch', 'Studio', 'сп', 'Os', 'Style', 'card', 'fancy', 'Wars', 'the', 'founder', '4', 'proced', 'wife', 'bi', 'Like', 'mas', 'chief', 'dr', 'cre', 'stress', 'business', 'agi', 'Pic', 'ej', '></', 'season', 'Studios', 'mov', 'titles', '’', 'abe', 'wa', 'su', 'c', '?', 'films', 'ș', 'worth', 'истории', 'Ken', 'Movie', 'O', 'immediate', '理', 'ey', 'online', 'dl', 'poll', 'uri', 'slot', 'lieutenant', 'criminal', 'heat', ':', 'concrete', 'Ich', 'white', 'membership', 'tak', 'Ley', 'Gold', 'Orig', 'enas', 'open', 'zero', '/', 'locations', 'Przyp', 'Tokyo', 'iv', 'ism', 'Ap', 'lod', ':\\\\', 'diam', 'ém', 'XIV', 'Phoenix', 'invest', 'Kaz', 'ride', 'life', 'stat', 'Order', 'ider', 'franch', 'body', 'gens', 'confir', 'Os', 'Pro', 'ou', 'Dem', '恋', 'III', 'oug', 'ASCII', 'moon', '宝', 'ommen', 'ub', 'fil', 'title', 'vr', 'like', 're', 'V', 'music', 't', 'star', 'z', 'ori', 'loose', 'agin', 'iden', 'and', 'Life', 'б', 'Ka', 'lattice', 'Like', 'Ps', 'ichi', 'Baker', 'Ren', 'Se', 'hen', 'вич']\n",
      "27   [':', 'Online', '?', 'K', '', '(', 'member', 'games', '？', 'Zero', 'members', 'style', 'movie', 'series', '\\n', 'tie', 'b', 'wär', 'spin', 'like', 'origin', 'Member', 'publish', \"'\", '?:', 'Lake', 'sp', 'zero', 'isl', 'ma', 'in', 'Ga', 'Under', '’', 'wa', 'w', 'Ap', 'game', 'Like', 'Mas', '❯', 'blood', 'ice', 'IV', 'Rem', 'ap', 'baseball', '?', 'G', 'online', 'and', 'season', 'PS', 'Gold', 'immediate', 'O', 'iza', 'elev', '4', 'Princess', '?)', 'verse', 'business', 'acqu', 'card', 'Orig', 'Dem', 'member', 'dr', ':', 'demon', 'Style', 'iv', 'turn', 'white', 'music', 'chief', 'isis', 'истории', 'musical', 'VIS', 'worth', 'Se', 'Os', 'the', 'Mass', 'ém', 'historical', 'bran', 'ori', 'сп', 'Ken', 'cos', 'film', 'Games', 'lax', 'Movie', 'g', 'fen', 'mas', 'han', 'IP', 'cre', 'currency', 'fancy', 'lean', 'Kin', 'Wars', 'Ke', 'ey', 'R', 'assim', 'careful', 'ride', 'In', 'history', 'custom', 'present', 'asc', 'vs', 'fil', 'star', 'abe', 'lan', '/', 'or', 'net', 'Zero', 'oti', '：', 'ism', 'uri', 'ami', 'mov', 'Lang', 'Net', 'Order', 'Ps', 'Phoenix', 't', 'ob', '></', 'Kaz', 'Kate', 'bi', 'uch', 'suit', 'founder', 'like', 'I', 'studio', 'New', 're', 'K', 'schedule', 'p', 'called', 'black', '`?', 'God', 'III', 'ps', 'tact', 'slot', 'VII', 'membership', 'Ich', 'wife', 'boost', ',', 'life', 'Pic', 'an', 'wars', 'titles', 'm', 'Publish', 'XIV', 'poll', 'online', 'arm', 'Ot', 'Custom', 'вич', 'spiritual', 'cross', 'st', 'Ka', 'ș', 'hide', 'criminal', 'wa', 'hus', 'accommod', 'an', 'сери', 'mirror', 'S', 'asta', 'ly']\n",
      "28   [':', 'Online', 'K', '(', '', '?', 'member', 'members', '\\n', 'in', 'like', 'games', 'b', 'Zero', 'movie', 'series', \"'\", 'zero', 'Member', 'origin', 'ma', '’', 'sp', '❯', 'IV', 'and', 'Like', 'O', 'tie', 'season', 'PS', 'game', 'Rem', 'style', 't', '/', 'black', 'Lake', '≫', 'su', ',', 'online', 'L', 'card', 'spin', 'white', 'turn', 'member', 'Ap', 'ap', 'wa', 'd', 'IR', '?:', 'empre', 'elev', 'wär', 'Princess', '4', 'Under', 'ra', 'G', 'or', 'p', 'g', 'Os', 'mov', 'ice', 'baseball', 'history', 'film', 'net', 'ey', 'W', 'business', 'the', 'New', 'iv', 'Mas', 'ori', 'w', 'ly', '?', 'Ga', 'a', '？', 'Dem', 'истории', ':', 'Gold', 'Se', 'like', 's', 'chief', 'acqu', 'Phoenix', 'blood', 'orno', 'Goth', 'iza', 'sun', 'VIS', 'I', 'fen', 'prin', 'publish', 'isis', 'reg', 'Ke', 'invest', 'Movie', 'Order', 'bi', 'demon', 'musical', 'Games', 'immediate', 'sh', 'life', 'today', 'present', 'heat', 'Life', '.', 'dr', 'music', 'mas', 'to', 'called', 'restaur', 'historical', 'by', 'on', 'ps', 'God', 'oti', 'restaurant', 'vs', 'Cl', 'spiritual', 'сп', 'Pro', 'cre', 'membership', 'uri', 'Out', 'locations', 'ch', 'S', 'part', 'careful', '?)', 'open', 'poll', 'films', 'del', 'l', 'han', 'titles', 'ami', 'In', 'sand', 'min', 'R', 'bran', 'IP', 'title', 'founder', 'sub', 'calling', 'Lang', 'Ka', 'diam', 'har', 'fil', 'fa', 'rising', 'Mitch', 'ordered', 'under', 'la', 'Ot', 'C', 'Mass', 'tak', 'boost', 'an', 'custom', 'ém', 'm', 'ste', 'K', '0', 'f', 're', 'z', 'Sh', 'be', 'tact', 'Kate']\n",
      "29   [':', '', 'like', 'K', '(', '?', 'in', 'Online', '\\n', 'member', 'members', 'Like', \"'\", 'Rem', '’', 'and', 'b', 'series', ',', 'L', 'games', '.', 't', 'O', 'ma', 'Ap', 'tie', '/', 'Member', 'or', 'sp', 'IV', 'G', 'like', 'ap', 'Princess', 'to', 'turn', 'black', '-', 'movie', 'W', 'I', 'the', 'Zero', 'on', 'zero', 'online', '4', 'origin', '≫', 'white', 'prin', 'now', 'PS', 'card', 'rem', 's', 'style', 'ra', 'sh', 'Lake', 'IR', 'game', 'spin', 'Like', 'a', '!', 'dead', 'R', 'tak', 'part', 'IP', 'Ke', 'season', 'sun', '?', 'reg', 'w', 'd', 'm', 'Lith', 'su', '❯', 'at', 'vs', 'coll', 'present', 'iv', 'as', 'historical', 'so', 'g', 'cre', 're', 'history', 'st', 'ste', 'Os', 'T', 'ly', '…', 'is', 'S', 'K', 'demon', 'lei', 'M', '?:', '0', 'member', 'just', 'music', 'l', 'o', 'called', 'by', 'very', 'fa', 'an', 'min', '–', 'Gold', 'of', 'ordered', 'Japanese', 'blood', 'baseball', 'thought', 'originally', 'for', 'Order', 'Mus', 'Sp', 'turned', 'p', 'first', 'wa', 'The', 'acqu', 'Phoenix', 'Ly', 'D', 'news', 'business', 'chief', 'mov', 'rub', 'today', 'Ka', 'El', 'ch', 'V', 'musical', 'poll', 'world', 'f', 'IO', 'Under', 'titles', 'New', 'ore', 'Games', 'ice', 'La', 'E', 'Wars', 'local', 'publish', 'under', 'Dem', 'co', 'Ga', 'with', 'iza', 'treatment', 'k', 'Lang', 'accused', 'title', 'diam', 'action', ':', 'mus', 'English', 'wär', 'F', 'outside', '-', 'developer', 'apk', 'isis', 'asc', 'tied', 'moon', 'Now', 'dr', 'heat', 'chapter', '/']\n",
      "30   ['', ':', '(', '\\n', ',', 'K', 'in', '?', 'like', 'and', \"'\", 'b', '.', 'Online', '’', 'Like', 'L', '/', 'I', 'O', '-', 'G', 'Ap', 'sp', 'or', 't', 'to', 'W', 'R', 'T', 'S', 'on', 'the', 'Rem', 'member', 'members', 'a', 'so', '?', 'ap', 'as', 'Sp', 'for', 'M', 're', 'at', 'D', '-', '!', 'of', 'F', '–', 'series', 'E', 'The', 'g', 'IV', 'is', 'P', '[', '...', 'p', 'ma', 'd', 'sh', '…', 'C', 'Now', 's', 'Ke', 'We', 'A', 'now', 'online', '\"', 'o', 'games', 'El', 'e', 'c', 'by', 'm', 'an', 'V', 'Zero', 'l', 'v', 'In', 'Le', 'Princess', 'He', 'B', 'ch', 'spin', '4', 'f', '&', 'H', 'La', 'origin', 'IP', 'part', 'w', '/', 'tie', 'like', 'k', '(', 'ra', 'turn', 'just', 'Member', 'black', 'do', 'Go', 'style', 'zero', 'thought', 'Cl', 'we', 'N', 'vs', 'su', ':', \"'\", 'real', 'be', 'st', 'cre', 'w', '�', '0', 'game', 'al', 'r', 'movie', '_', 'all', 'Like', 'J', 'today', 'originally', ';', '|', 'prin', 'Land', 'also', 'On', 'Black', 'with', 'rem', 'business', 'called', 'Ren', 'Dem', 'de', '[', '_', 'Sh', 'dead', '...', '.', 'Under', 'co', 'not', 'Ka', 'Is', 'Do', 'p', 'AP', 'Re', 'history', 'that', 'pre', 'about', 'bi', 'Y', 'New', 'season', 'n', 'American', 'Japanese', 'Origin', 'le', 'Gold', 'VI', 'God', 'Ex', 'dr', '…', 'Of', 'Pro', 'reg', 'but', 'sun', '\\xa0', 'Orig', 'turned', 'under', 'el']\n",
      "31   [':', '', 'K', '?', 'Like', ',', \"'\", 'Online', 'Ap', '’', 'like', '(', 'Rem', 'and', 'Zero', '\\n', '?', 'L', 'in', 'Princess', '/', 'G', 'Movie', 'Sp', 'Dead', 'Orig', 'T', '-', 'or', 'R', 'Soul', 'W', 'series', 'O', '–', 'Games', 'b', 'El', 'Now', 'Moon', 'Game', 'Ka', 'movie', '-', 'IV', 'ap', '.', 'We', 'Reb', 'La', 'Lan', 'I', 'F', 'Ke', 'D', 'S', 'Spider', 'P', 'games', 'AP', '/', 'Land', 'M', 'Turn', 'film', 'Mus', 'Dream', 'member', '...', 'game', 'Dem', 'Lat', 'Real', 'Spirit', '|', 'Black', 'V', ':', 'Go', 'Member', '&', 'Dam', '�', 'Japanese', 'B', 'Season', 'spin', 'Dragon', 'War', '?:', 'Origin', 'E', 'Film', 'The', 'zero', \"'\", 'vs', 'Tokyo', 'Studio', 'Law', 'to', 'Ren', 'Lady', 'SP', 'Wars', 'mov', 'Bob', 'III', 'IP', 'Le', ';', 'Phoenix', 'Goth', 'Rec', 'Lake', 'Radio', 'Son', 'API', 'Gold', 'Sh', 'Cl', 'Live', 'A', 'Garden', 'of', 'Re', '!', 'On', 'Music', 'by', 'Style', 'Girl', 'Pro', 'a', 'on', '\"', 'Japan', 'Under', 'Str', 'at', 'RE', 'Se', 'H', 'History', 'Sou', 'After', 'Act', 'Press', 'Women', 'members', 'Series', 'World', 'II', 'Bill', 'In', 'Chapter', 'Business', 'now', '[', 'for', 'VI', 'franch', 'sp', 'VII', 'Rou', 'PS', 'so', 'turn', 'Justice', 'God', 'Bi', 'J', 'Advent', 'Street', 'Studios', 'Got', 'as', 't', 'season', 'Mah', 'Like', 'style', 'Life', 'And', 'Jud', 'Pap', 'dead', '0', 'online', 'prin', 'tie', 'Is', '(', 'Y', 'Do', 'St', 'Day', 'Baseball', 'Mov', '4']\n"
     ]
    }
   ],
   "source": [
    "for ix,item in enumerate(records):\n",
    "    print(ix, \" \", item['top_k_preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12422\n",
      "442\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 加载.pt文件\n",
    "data = torch.load('/root/Unlearn_Harry_Potter/50_50_preds.pt')\n",
    "data0 = torch.load('/root/Unlearn_Harry_Potter/0_10_preds.pt')\n",
    "\n",
    "# 打印加载的数据\n",
    "print(len(data0))\n",
    "print(len(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation on FFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' LAN', ' Berlin', 'kell', 'debian', ' radicals', ' dred', 'Living', 'prototype', ' Kramer', ' Module', ' Butterfly', 'reed', ' Knights', 'itar', ' Blaz', ' Durant', ' Escape', 'PB', ' flurry', 'ursive', ' Manila', ' Walt', ' Diver', ' circ', 'ASC', ' periodic', ' pil', 'YR', ' anthology', ' Floating', ' Young', ' debian', ' State', ' slips', ' Vive', 'testers', ' Bing', ' PB', 'Transfer', ' wake', 'Did', ' Alice', ' period', ' appar', ' Failure', ' Booster', ' consoles', ' Ember', ' Transfer', 'aration', 'ustration', 'Damn', 'LAN', ' Isle', '田', ' bod', ' Dates', ' Blade', ' Living', ' Thinking', ' pads', ' Confeder', ' Celebr', ' Ankara', 'angers', ' vic', ' Protestants', ' Manitoba', 'Unit', 'aito', ' buried', ' Dominican', 'Tang', 'film', ' superf', ' Date', ' Force', ' founding', 'ua', ' Final', 'Layer', 'amina', '女', ' FALSE', ' spaced', ' \"_', ' assassin', ' supporting', ' gran', 'fare', ' Ottoman', 'Force', ' living', ' Civilization', ' booklet', ' Bomber', ' Dante', ' holders', 'Connection', ' omin', 'Irish', ' jQuery', 'Constructed', ' seminal', 'î', ' Pakistani', ' Overse', ' enact', ' lb', 'isa', ' Unit', ' strings', 'Lou', ' choke', ' 1910', 'regation', ' fulfillment', 'each', ' flowing', 'Brave', 'aki', 'secret', ' Myers', ' veter', ' invoke', ' herself', ' panels', ' Did', ' fals', 'ilers', ' Arctic', ' failing', ' Transgender', ' threat', 'nian', ' nun', ' Lazarus', ' realm', 'Alice', ' robber', ' Han', ' buddies', ' Expansion', 'period', ' Protoss', ' retirees', 'itent', ' Dreams', 'Was', ' Qing', ' Vampire', ' biomedical', ' fists', ' fou', ' 04', ' booster', '?!\"', ' Beginning', ' spew', ' wandering', ' Pearl', 'Ku', '�', ' Haas', 'Documents', ' rational', 'ends', ' Brewing', ' Boyle', 'ionics', ' Andersen', ' Forget', 'izarre', ' Harlem', ' bursts', ' tapes', ' timestamp', 'Volume', ' Areas', 'wikipedia', 'illation', ' Allies', ' sings', ' arg', ' Sense', 'okes', 'south', 'nin', ' tiss', 'rene', ' transfer', ' overse', 'agle', ' boolean', ' secretly', ' Irish', ' Eternal', 'alis', ' acc', 'acl', ' scholars', ' ports', 'nesia', 'yard', 'arrass', 'onents', ' grapple', 'Override', ' Vintage', ' Alloy', ' glove', ' Akira', '\\x01', 'boss', ' flow', 'itational', ' mis', ' Assassin', ' tape', ' knights', 'relations', '�', ' Pend', ' sweeps', ' Wide', ' Falling', 'beans', ' Hast', ' Aires', ' Rebel', 'Han', ' knockout', ' Birds', ' Philos', ' Ham', ' occ', ' Burst', ' Greenland', 'living', ' Pilgrim', 'ober', ' fingers', ' Discipline', ' terms', 'cultural', ' qual', ' Passage', ' Radiation', 'heading', ' Ireland', ' Baldwin', 'repeat', 'bers', ' doors', ' shadow', 'Ry', 'odan', 'pei', ' gain', ' :=', ' Officers', ' Conf', ' strangers', 'Block', ' spaghetti', ' Slave', ' aggression', ' wrest', ' LAST', ' Fritz', 'volume', ' sabot', ' Lady', 'Termin', ' �', '\\\\.', ' young', ' dense', 'assin', ' authors', ' diagrams', ' aliens', ' Tournament', ' abbrevi', ' each', ' Railroad', ' slip', ' rulers', ' ber', ' Allied', ' Battles', ' foam', 'pad', 'Fighting', ' floating', ' pattern', ' Expression', ' notation', 'igan', 'FIR', ' Debian', ' runaway', 'RY', ' undefined', ' Vita', ' assassins', ' Hog', ' page', ' imply', 'flying', ' antibody', 'record', 'Billy', ' panel', 'NL', 'ateur', ' Nursing', ' Navy', 'OVA', ' Rune', ' BOX', ' ratification', ' ].', 'ievers', ' neighbors', ' severed', 'sk', '194', ' Lerner', ' Zed', ' Shakespeare', ' sneak', ' perpetual', ' runes', ' Wrest', ' warheads', ' conscious', 'var', ' comb', ' disclaimer', ' freed', 'Boy', ' ey', ' Bash', 'assert', ' Bird', ' Bridge', ' Death', 'kson', 'meter', 'uments', ' Layout', 'akespe', 'World', 'igans', ' Shiite', 'encies', ' line', ' diabetic', ' Creatures', ' Outdoor', ' webs', 'BBC', ' walking', 'Nazis', ' Dylan', ' Script', ' blankets', 'inement', ' declaration', ' nose', ' Complete', ' RU', ' Architect', ' Tang', ' families', ' alley', ' ls', 'ennett', ' Dart', ' corrected', ' acknow', ' Wikimedia', ' Prague', 'ş', ' Puppet', 'irk', ' Willie', ' pad', ' COMPLE', ' PlayStation', ' meanings', 'vard', 'WARNING', ' patterns', ' indicator', 'aron', 'allel', ' Circle', ' Decl', ' Breaker', ' allegiance', ' rock', 'ensions', ' whist', 'Happy', ' bonds', ' segregation', ' dart', ' Acquisition', 'Blocks', ' Commander', 'PAC', 'ère', ' wink', ' Sons', 'linear', 'Lady', 'iddle', '装', '大', 'ributes', ' Winc', 'terms', ' Founding', ' textile', 'mber', ' divers', ' Fall', ' Creator', ' (@', ' Instrument', 'pd', ' Brad', ' Germany', 'RANT', 'elson', ' BUR', ' flows', ' Quincy', ' acknowledgment', ' Brothers', 'Thursday', ' expansion', 'Characters', ' hasht', 'ersen', 'ETF', ' grou', 'orters', 'Document', 'angling', 'Cross', ' decap', ' Philosophy', ' Official', ' barric', ' Freed', 'lator', ' scripts', ' parody', ' Stru', ' Ellis', ' mish', ' Moran', ' failure', 'Rh', ' Lin', ' remembering', ' Linda', 'Alabama', ' Bastard', ' list', ' liner', ' Woody', ' SLI', ' inc', ' Ning', ' strateg', ' mast', ' Bahá', ' accuse', ' bel', ' components', '195', ' widgets', ' Bil', ' DS', 'umbling', ' Assistance', ' brackets', 'ronic', ' Armed', 'irds', ' fo', ' remnants', 'Radio', ' matched', ' Dimension', 'liner']\n",
      "iPod 不存在于列表中\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 200000)\n",
    "print(tmp[ (tmp['layer'] == 18) & (tmp['desc_short'] == \"subj_last\") & (tmp['subject'] == \"iPod Classic\")]['top_k_preds'][:600].item()) #& (tmp['subject'] == \"Iron Man\") ###tmp['subject']==\"Beats Music\" & 'iPod Classic'\n",
    "\n",
    "\n",
    "value_to_check = 'iPod'\n",
    "if value_to_check in tmp[ (tmp['layer'] == 22) & (tmp['desc_short'] == \"subj_last\") & (tmp['subject'] == \"iPod Classic\")]['top_k_preds'][:600].item():\n",
    "    print(f\"{value_to_check} 存在于列表中\")\n",
    "else:\n",
    "    print(f\"{value_to_check} 不存在于列表中\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1209it [00:07, 151.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# Projection of token embeddings  #这里就是把最开始的一层：embbedding层的部分进行映射\n",
    "\n",
    "records = []\n",
    "for row_i, row in tqdm(knowns_df.iterrows()):\n",
    "    subject = row.subject\n",
    "    prompt = row.prompt\n",
    "    prompt = \"<|endoftext|> \" + prompt  # fix first-position bias\n",
    "    \n",
    "    inp = make_inputs(mt.tokenizer, [prompt])\n",
    "    e_range = find_token_range(mt.tokenizer, inp[\"input_ids\"][0], subject)\n",
    "    e_range = [x for x in range(e_range[0], e_range[1])]\n",
    "    subject_tok = [inp[\"input_ids\"][0][i].item() for i in e_range]\n",
    "    subject_tok_str = [decode_tokens(mt.tokenizer, [t])[0] for t in subject_tok]\n",
    "    \n",
    "    vec = E[subject_tok, :].mean(axis=0)  #是把subject_tok的部分qu\n",
    "    proj = vec.matmul(E.T).cpu().numpy()\n",
    "    ind = np.argsort(-proj)  #这个是倒叙排列的意思\n",
    "    record = {\n",
    "        \"example_index\": row_i,\n",
    "        \"prompt\": row.prompt,\n",
    "        \"subject\": subject,\n",
    "        \"subject_tok\": subject_tok,\n",
    "        \"subject_tok_str\": str(subject_tok_str),\n",
    "        \"top_k_preds_str\": [decode_tokens(mt.tokenizer, [t])[0] for t in ind[:k]], #这个是倒叙排列后取前k个映射到的词\n",
    "    }\n",
    "    records.append(record)\n",
    "\n",
    "tmp = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_index</th>\n",
       "      <th>prompt</th>\n",
       "      <th>subject</th>\n",
       "      <th>subject_tok</th>\n",
       "      <th>subject_tok_str</th>\n",
       "      <th>top_k_preds_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>157</td>\n",
       "      <td>iPod Classic is developed by</td>\n",
       "      <td>iPod Classic</td>\n",
       "      <td>[26915, 13449]</td>\n",
       "      <td>[' iPod', ' Classic']</td>\n",
       "      <td>[ the,  of,  a, ,,  to,  and,  Classic, .,  The,  is,  iPod, The,  with, -,  was,  for,  in,  (, :,  are, 's,  his, &lt;|endoftext|&gt;, _, ).,  that,  I,  were,  \", \\n, $.,  on, ;,  by,  their,  from, ), Classic,  an,  you,  be,  your, /,  has, );,  classic, i,  this,  B,  $, ].,  have,  k,  In, I, ),,  A, $,,  it, $, a,  =, &gt;,  P,  they,  as,  my,  de, },  S,  K,  C,  him, s, 2,  D, In,  $\\,  he,  M,  we, B,  her, \\,  T,  This,  F, \",  It,  [,  its, .\", (,  using,  p,  n,  G,  at, ])., P, ...]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     example_index                        prompt       subject  \\\n",
       "157            157  iPod Classic is developed by  iPod Classic   \n",
       "\n",
       "        subject_tok        subject_tok_str  \\\n",
       "157  [26915, 13449]  [' iPod', ' Classic']   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    top_k_preds_str  \n",
       "157  [ the,  of,  a, ,,  to,  and,  Classic, .,  The,  is,  iPod, The,  with, -,  was,  for,  in,  (, :,  are, 's,  his, <|endoftext|>, _, ).,  that,  I,  were,  \", \\n, $.,  on, ;,  by,  their,  from, ), Classic,  an,  you,  be,  your, /,  has, );,  classic, i,  this,  B,  $, ].,  have,  k,  In, I, ),,  A, $,,  it, $, a,  =, >,  P,  they,  as,  my,  de, },  S,  K,  C,  him, s, 2,  D, In,  $\\,  he,  M,  we, B,  her, \\,  T,  This,  F, \",  It,  [,  its, .\", (,  using,  p,  n,  G,  at, ])., P, ...]  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 50000)\n",
    "tmp[tmp['subject'] == 'iPod Classic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GPTJMLP' object has no attribute 'c_fc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block_module \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlp\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     42\u001b[0m     block_config \u001b[38;5;241m=\u001b[39m {layer_: all_mlp_dims \u001b[38;5;28;01mfor\u001b[39;00m layer_ \u001b[38;5;129;01min\u001b[39;00m block_layers}\n\u001b[0;32m---> 43\u001b[0m     block_mlp_hooks \u001b[38;5;241m=\u001b[39m \u001b[43mset_block_mlp_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     output \u001b[38;5;241m=\u001b[39m mt\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minp, output_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     45\u001b[0m     remove_hooks(block_mlp_hooks)\n",
      "Cell \u001b[0;32mIn[3], line 161\u001b[0m, in \u001b[0;36mset_block_mlp_hooks\u001b[0;34m(model, values_per_layer, coef_value)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m         values \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 161\u001b[0m     hooks\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_fc\u001b[49m\u001b[38;5;241m.\u001b[39mregister_forward_hook(\n\u001b[1;32m    162\u001b[0m         change_values(values, coef_value)\n\u001b[1;32m    163\u001b[0m     ))\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hooks\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/torch/nn/modules/module.py:1207\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1206\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1207\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1208\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GPTJMLP' object has no attribute 'c_fc'"
     ]
    }
   ],
   "source": [
    "# Projection of token representations while applying knockouts to MHSA/MLP sublayers\n",
    "\n",
    "all_mlp_dims = list(range(mt.model.config.hidden_size * 4))\n",
    "subject_repr_layer = 22\n",
    "num_block_layers = 10\n",
    "\n",
    "records = []\n",
    "for row_i, row in tqdm(knowns_df.iterrows()):\n",
    "    prompt = row.prompt\n",
    "    subject = row.subject\n",
    "    inp = make_inputs(mt.tokenizer, [prompt])\n",
    "    e_range = find_token_range(mt.tokenizer, inp[\"input_ids\"][0], subject)\n",
    "    e_range = [x for x in range(e_range[0], e_range[1])]\n",
    "    position = e_range[-1]\n",
    "    \n",
    "    output_ = mt.model(**inp, output_hidden_states = True)\n",
    "    hs_ = output_[\"hidden_states\"][subject_repr_layer+1][0, position]\n",
    "    projs_ = hs_.matmul(E.T).cpu().numpy()\n",
    "    ind_ = np.argsort(-projs_)\n",
    "    top_k_preds_ = [decode_tokens(mt.tokenizer, [i])[0] for i in ind_[:k]]\n",
    "    \n",
    "    for start_block_layer in range(subject_repr_layer):\n",
    "        records.append({\n",
    "            \"example_index\": row_i,\n",
    "            \"subject\": subject,\n",
    "            \"layer\": subject_repr_layer,\n",
    "            \"position\": position,\n",
    "            \"block_layers\": [],\n",
    "            \"block_module\": \"None\",\n",
    "            \"start_block_layer\": start_block_layer,\n",
    "            \"end_block_layer\": -1,\n",
    "            \"num_block_layers\": 0,\n",
    "            \"num_block_layers_\": 0,\n",
    "            \"top_k_preds\": top_k_preds_\n",
    "        })\n",
    "        \n",
    "        end_block_layer = min(start_block_layer + num_block_layers + 1, subject_repr_layer)\n",
    "        block_layers = [l for l in range(start_block_layer, end_block_layer)]\n",
    "        for block_module in [\"mlp\", \"attn\"]:\n",
    "            with torch.no_grad():\n",
    "                if block_module == \"mlp\":\n",
    "                    block_config = {layer_: all_mlp_dims for layer_ in block_layers}\n",
    "                    block_mlp_hooks = set_block_mlp_hooks(mt.model, block_config)\n",
    "                    output = mt.model(**inp, output_hidden_states = True)\n",
    "                    remove_hooks(block_mlp_hooks)\n",
    "                elif block_module == \"attn\":\n",
    "                    block_config = {layer_: [] for layer_ in block_layers}\n",
    "                    block_attn_hooks = set_block_attn_hooks(mt.model, block_config, opposite=True)\n",
    "                    output = mt.model(**inp, output_hidden_states = True)\n",
    "                    remove_wrapper(mt.model, block_attn_hooks)\n",
    "\n",
    "            hs = output[\"hidden_states\"][subject_repr_layer+1][0, position]\n",
    "            projs = hs.matmul(E.T).cpu().numpy()\n",
    "            ind = np.argsort(-projs)\n",
    "\n",
    "            records.append({\n",
    "                \"example_index\": row_i,\n",
    "                \"subject\": subject,\n",
    "                \"layer\": subject_repr_layer,\n",
    "                \"position\": position,\n",
    "                \"block_layers\": block_layers,\n",
    "                \"block_module\": block_module,\n",
    "                \"start_block_layer\": start_block_layer,\n",
    "                \"end_block_layer\": end_block_layer-1,\n",
    "                \"num_block_layers\": num_block_layers,\n",
    "                \"num_block_layers_\": len(block_layers),\n",
    "                \"top_k_preds\": [decode_tokens(mt.tokenizer, [i])[0] for i in ind[:k]]\n",
    "            })\n",
    "\n",
    "tmp = pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'layer'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_colwidth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m50000\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m tmp[(tmp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubject\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miPod Classic\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m&\u001b[39m (\u001b[43mtmp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlayer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m22\u001b[39m) ][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_k_preds\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/core/frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3896\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3898\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'layer'"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 50000)\n",
    "tmp[(tmp['subject'] == 'iPod Classic') & (tmp['desc_short'] == 'subj_last') & (tmp['layer'] == 22) ]['top_k_preds']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare attributes rate evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid file path or buffer object type: <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Processing of Wikipedia paragraphs for automatic attribute rate evaluation.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# This should be a path to a csv file with 2 columns and a header of column names \"subject\" and \"paragraphs\".\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Each entry should have (a) a subject (string) from the \"knowns\" data (knowns_df) \u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# and (b) paragraphs concatenated with space about the subject (a single string).\u001b[39;00m\n\u001b[1;32m      6\u001b[0m paragraphs_data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m df_wiki \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparagraphs_data_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Tokenize, remove duplicate tokens, stopwords, and subwords. \u001b[39;00m\n\u001b[1;32m     10\u001b[0m df_wiki[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext_tokenized_dedup\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df_wiki[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparagraphs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mprogress_apply(\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(decode_tokens(mt\u001b[38;5;241m.\u001b[39mtokenizer, mt\u001b[38;5;241m.\u001b[39mtokenizer([x])[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m])))\n\u001b[1;32m     12\u001b[0m )\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/io/common.py:718\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    715\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    717\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 718\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    727\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m/var/conda/envs/memit/lib/python3.9/site-packages/pandas/io/common.py:460\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(filepath_or_buffer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filepath_or_buffer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    458\u001b[0m ):\n\u001b[1;32m    459\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid file path or buffer object type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(filepath_or_buffer)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m IOArgs(\n\u001b[1;32m    463\u001b[0m     filepath_or_buffer\u001b[38;5;241m=\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    464\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    467\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    468\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid file path or buffer object type: <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "# Processing of Wikipedia paragraphs for automatic attribute rate evaluation.\n",
    "\n",
    "# This should be a path to a csv file with 2 columns and a header of column names \"subject\" and \"paragraphs\".\n",
    "# Each entry should have (a) a subject (string) from the \"knowns\" data (knowns_df) \n",
    "# and (b) paragraphs concatenated with space about the subject (a single string).\n",
    "paragraphs_data_path = None\n",
    "df_wiki = pd.read_csv(paragraphs_data_path)\n",
    "\n",
    "# Tokenize, remove duplicate tokens, stopwords, and subwords. \n",
    "df_wiki[\"context_tokenized_dedup\"] = df_wiki[\"paragraphs\"].progress_apply(\n",
    "    lambda x: list(set(decode_tokens(mt.tokenizer, mt.tokenizer([x])['input_ids'][0])))\n",
    ")\n",
    "df_wiki[\"context_tokenized_dedup_len\"] = df_wiki.context_tokenized_dedup.apply(lambda x: len(x))\n",
    "\n",
    "df_wiki[\"context_tokenized_dedup_no-stopwords\"] = df_wiki.context_tokenized_dedup.apply(\n",
    "    lambda x: [\n",
    "        y for y in x \n",
    "        if y.strip() not in stopwords0_ and len(y.strip())>2\n",
    "    ]\n",
    ")\n",
    "df_wiki[\"context_tokenized_dedup_no-stopwords_len\"] = df_wiki[\"context_tokenized_dedup_no-stopwords\"].apply(\n",
    "    lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_wiki_overlap(subject, top_preds):\n",
    "    wiki_toks = df_wiki[df_wiki.subject == subject]\n",
    "    if len(wiki_toks) == 0:\n",
    "        return -1\n",
    "    wiki_toks = wiki_toks.iloc[0][\"context_tokenized_dedup_no-stopwords\"]\n",
    "    preds_wiki_inter = set(top_preds).intersection(set(wiki_toks))\n",
    "    \n",
    "    return len(preds_wiki_inter) * 100.0 / len(top_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Evaluate attributes rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[\"top_k_preds_clean\"] = tmp.top_k_preds.progress_apply(lambda x: [\n",
    "    y for y in x \n",
    "    if y.strip().lower() not in stopwords0_ and len(y.strip())>2\n",
    "])\n",
    "tmp[\"num_clean_tokens\"] = tmp.top_k_preds_clean.progress_apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 50  # evaluate the 50 top-scoring tokens\n",
    "tmp[\"top_k_preds_in_context\"] = tmp.progress_apply(\n",
    "    lambda row: get_preds_wiki_overlap(row[\"subject\"], row[\"top_k_preds_clean\"][:m]), \n",
    "    axis=1\n",
    "    )\n",
    "print(len(tmp[tmp.top_k_preds_in_context == -1]) * 100.0 / len(tmp))\n",
    "print(tmp[tmp.top_k_preds_in_context > -1].subject.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the attributes rate at different positions across layers \n",
    "\n",
    "tmp[\"desc_short_\"] = tmp.desc_short.apply(\n",
    "    lambda x: {\"subj_first\": \"subject first\", \n",
    "               \"subj_last\": \"subject last\", \n",
    "               \"no_subj_follow\": \"subject subseq.\", \n",
    "               \"no_subj_last\": \"input last\",\n",
    "               \"first_token\": \"input first\"}[x]\n",
    "    )\n",
    "tmp[\"layer_1\"] = tmp.layer.apply(lambda x: x+1)\n",
    "order = [\"subject last\", \"subject first\", \"subject subseq.\", \"input last\"]\n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "ax = sns.lineplot(data=tmp[tmp.top_k_preds_in_context > -1], \n",
    "                 x=\"layer_1\", y=\"top_k_preds_in_context\", hue=\"desc_short_\",\n",
    "                style=\"desc_short_\",\n",
    "                dashes=True,\n",
    "                linewidth=2,\n",
    "                markers=False,\n",
    "                palette=palette[:4],\n",
    "                hue_order=order,\n",
    "                style_order=order\n",
    "                 )\n",
    "ax.set_xlabel(\"layer\")\n",
    "ax.set_ylabel(f\"attributes rate\")\n",
    "sns.move_legend(ax, \"upper left\", title=\"\", \n",
    "                labelspacing=0.3, handlelength=1.0, handletextpad=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the change in the attributes rate in the subject representation at a specific layer,\n",
    "#  when knocking out different MLP/MHSA sublayers\n",
    "\n",
    "subject_repr_layer = 40\n",
    "\n",
    "tmp[\"desc_short\"] = tmp[['block_module', 'num_block_layers']].apply(tuple, axis=1)\n",
    "tmp[\"desc_short_\"] = tmp.desc_short.apply(\n",
    "    lambda x: {'mlp': \"MLP sublayers\", \n",
    "               'attn': \"MHSA sublayers\", \n",
    "               'None': \"No intervention\"}[x[0]]\n",
    "    )\n",
    "tmp[\"start_block_layer_1\"] = tmp.start_block_layer.apply(lambda x: x+1)\n",
    "\n",
    "plt.figure(figsize=(4,2))\n",
    "tmp_ = tmp[(tmp.top_k_preds_in_context > -1) & (tmp.num_block_layers.isin([0, 10]))]\n",
    "ax = sns.lineplot(data=tmp_, \n",
    "                  x=\"start_block_layer\", y=\"top_k_preds_in_context\", \n",
    "                  hue=\"desc_short_\",\n",
    "                  style=\"desc_short_\",\n",
    "                  palette=palette[:3],\n",
    "                  dashes=True,\n",
    "                  linewidth=2,\n",
    "                  markers=False\n",
    "                 )\n",
    "ax.legend_.set_title(\"\")\n",
    "ax.set_ylabel(f\"attributes rate\\nat layer {subject_repr_layer}\")\n",
    "ax.set_xlabel(\"intervention layers\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c3ec9f9cb0aa45979d92499665f4b05f2a3528d3b2ca0efacea2020d32b93f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
