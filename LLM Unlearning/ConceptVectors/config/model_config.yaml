llama2-7b:
  hf_key: "/root/data/transformers/Llama-2-7b-chat-hf"
  question_start_tag: "[INST] "
  question_end_tag: " [/INST]"
  answer_tag: ""
  flash_attention2: "false"
  gradient_checkpointing: "true"
  ft_model_path: "/root/autodl-tmp/transformers/final_ft_noLORA_5_epochs_inst_lr1e-05_llama2-7b_full/checkpoint-625" #this model will be used for unlearning by defauly
olmo-7b:
  hf_key: "/root/data/transformers/OLMo-7B"
  question_start_tag: "Question: "
  question_end_tag: "\n"
  answer_tag: "Answer: "
  flash_attention2: "false"
  gradient_checkpointing: "false"
  ft_model_path: "/root/autodl-tmp/transformers/final_ft_noLORA_5_epochs_inst_lr1e-05_olmo-7b_full/checkpoint-625"


  
